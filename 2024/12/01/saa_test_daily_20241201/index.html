<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>SAA è€ƒè¯•æ¯æ—¥ç»ƒä¹  - 2024/12/01 - æ£®è§é¹¿çš„åšå®¢</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="æ£®è§é¹¿çš„åšå®¢"><meta name="msapplication-TileImage" content="https://image.senjianlu.com/blog/icon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="æ£®è§é¹¿çš„åšå®¢"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="æ¥æºï¼šAmazon AWS Certified Solutions Architect - Associate SAA-C03 Exam30 é¢˜ (No.191 ~ No.220) åªè®°å½•äº† 10 é“é¦–æ¬¡ç¢°åˆ°çš„ã€é”™è¯¯çš„æˆ–æœ‰ç–‘é—®çš„é¢˜ç›®ï¼Œä»…ä¾›è‡ªå·±å¤ä¹ ä½¿ç”¨ã€‚å¦‚æœä¾µæƒè¯·è”ç³»åˆ é™¤ã€‚"><meta property="og:type" content="article"><meta property="og:title" content="SAA è€ƒè¯•æ¯æ—¥ç»ƒä¹  - 2024/12/01"><meta property="og:url" content="https://senjianlu.com/2024/12/01/saa_test_daily_20241201/"><meta property="og:site_name" content="æ£®è§é¹¿çš„åšå®¢"><meta property="og:description" content="æ¥æºï¼šAmazon AWS Certified Solutions Architect - Associate SAA-C03 Exam30 é¢˜ (No.191 ~ No.220) åªè®°å½•äº† 10 é“é¦–æ¬¡ç¢°åˆ°çš„ã€é”™è¯¯çš„æˆ–æœ‰ç–‘é—®çš„é¢˜ç›®ï¼Œä»…ä¾›è‡ªå·±å¤ä¹ ä½¿ç”¨ã€‚å¦‚æœä¾µæƒè¯·è”ç³»åˆ é™¤ã€‚"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://image.senjianlu.com/blog/2024-09-01/075639.png"><meta property="article:published_time" content="2024-12-01T11:00:00.000Z"><meta property="article:modified_time" content="2024-12-01T12:00:00.000Z"><meta property="article:author" content="Rabbir"><meta property="article:tag" content="AWS"><meta property="article:tag" content="SAA"><meta property="article:tag" content="æ¯æ—¥ç»ƒä¹ "><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://image.senjianlu.com/blog/2024-09-01/075639.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://senjianlu.com/2024/12/01/saa_test_daily_20241201/"},"headline":"SAA è€ƒè¯•æ¯æ—¥ç»ƒä¹  - 2024/12/01","image":["https://image.senjianlu.com/blog/2024-09-01/075639.png"],"datePublished":"2024-12-01T11:00:00.000Z","dateModified":"2024-12-01T12:00:00.000Z","author":{"@type":"Person","name":"Rabbir"},"publisher":{"@type":"Organization","name":"æ£®è§é¹¿çš„åšå®¢","logo":{"@type":"ImageObject","url":{"text":"æ£®è§é¹¿çš„åšå®¢"}}},"description":"æ¥æºï¼šAmazon AWS Certified Solutions Architect - Associate SAA-C03 Exam30 é¢˜ (No.191 ~ No.220) åªè®°å½•äº† 10 é“é¦–æ¬¡ç¢°åˆ°çš„ã€é”™è¯¯çš„æˆ–æœ‰ç–‘é—®çš„é¢˜ç›®ï¼Œä»…ä¾›è‡ªå·±å¤ä¹ ä½¿ç”¨ã€‚å¦‚æœä¾µæƒè¯·è”ç³»åˆ é™¤ã€‚"}</script><link rel="canonical" href="https://senjianlu.com/2024/12/01/saa_test_daily_20241201/"><link rel="icon" href="https://image.senjianlu.com/blog/icon.png"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/6.0.0/css/all.min.css"><link data-pjax rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/11.7.0/styles/atom-one-dark.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/css/default.css"><!--!--><script src="https://www.googletagmanager.com/gtag/js?id=G-D3LX598ZY6" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-D3LX598ZY6');</script><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.10.0/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.8.1/css/justifiedGallery.min.css"><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><script data-ad-client="ca-pub-7999470995937770" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" async></script><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="æ£®è§é¹¿çš„åšå®¢" type="application/atom+xml">
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">æ£®è§é¹¿çš„åšå®¢</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/senjianlu"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="ç›®å½•" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="æœç´¢" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-12-01T11:00:00.000Z" title="12/1/2024, 7:00:00 PM">2024-12-01</time>å‘è¡¨</span><span class="level-item"><a class="link-muted" href="/categories/%E8%BF%90%E7%BB%B4%E7%AC%94%E8%AE%B0/">è¿ç»´ç¬”è®°</a><span>Â /Â </span><a class="link-muted" href="/categories/%E8%BF%90%E7%BB%B4%E7%AC%94%E8%AE%B0/%E5%A4%87%E8%80%83/">å¤‡è€ƒ</a></span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>æ¬¡è®¿é—®</span></div></div><h1 class="title is-3 is-size-4-mobile">SAA è€ƒè¯•æ¯æ—¥ç»ƒä¹  - 2024/12/01</h1><div class="content"><blockquote>
<p>æ¥æºï¼š<a target="_blank" rel="noopener" href="https://www.examtopics.com/exams/amazon/aws-certified-solutions-architect-associate-saa-c03/">Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam</a><br>30 é¢˜ (No.191 ~ No.220) <strong>åªè®°å½•äº† 10 é“é¦–æ¬¡ç¢°åˆ°çš„ã€é”™è¯¯çš„æˆ–æœ‰ç–‘é—®çš„é¢˜ç›®</strong>ï¼Œä»…ä¾›è‡ªå·±å¤ä¹ ä½¿ç”¨ã€‚<br>å¦‚æœä¾µæƒè¯·è”ç³»åˆ é™¤ã€‚</p>
</blockquote>
<span id="more"></span>

<hr>
<p><strong>ğŸŒŸ å•è¯ï¼š</strong></p>
<ol>
<li>comprehend<sub><u>v. ç†è§£ï¼›é¢†æ‚Ÿï¼›æ‡‚</u></sub></li>
<li>transcribe<sub><u>v. è®°å½•ï¼ŒæŠ„å½•ï¼ŒæŠŠâ€¦è½¬æˆï¼ˆå¦ä¸€ç§ä¹¦å†™å½¢å¼ï¼‰ï¼Œç”¨éŸ³æ ‡æ ‡éŸ³</u></sub></li>
</ol>
<hr>
<h3 id="ä¸€ã€Medical-information"><a href="#ä¸€ã€Medical-information" class="headerlink" title="ä¸€ã€Medical information"></a>ä¸€ã€Medical information</h3><p>A hospital wants to create digital copies for its large collection of historical written records. The hospital will continue to add hundreds of new documents each day. The hospitalâ€™s data team will scan the documents and will upload the documents to the AWS Cloud.<br>A solutions architect must implement a solution to analyze the documents, extract the medical information, and store the documents so that an application can run SQL queries on the data. The solution must maximize scalability and operational efficiency.<br>Which combination of steps should the solutions architect take to meet these requirements? (Choose two.)</p>
<ol>
<li>Write the document information to an Amazon EC2 instance that runs a MySQL database.</li>
<li>âœ… Write the document information to an Amazon S3 bucket. Use Amazon Athena to query the data.</li>
<li>Create an Auto Scaling group of Amazon EC2 instances to run a custom application that processes the scanned files and extracts the medical information.</li>
<li>Create an AWS Lambda function that runs when new documents are uploaded. Use Amazon Rekognition to convert the documents to raw text. Use Amazon Transcribe Medical to detect and extract relevant medical information from the text.</li>
<li>âœ… Create an AWS Lambda function that runs when new documents are uploaded. Use Amazon Textract to convert the documents to raw text. Use Amazon Comprehend Medical to detect and extract relevant medical information from the text.</li>
</ol>
<blockquote>
<p>âœ¨ å…³é”®è¯ï¼šdocumentsã€SQL queriesã€medical information</p>
</blockquote>
<blockquote>
<p>2ï¸âƒ£ 5ï¸âƒ£ âœ… </p>
</blockquote>
<blockquote>
<p>ğŸ’¡ è§£æï¼šç°æœ‰å¤§é‡æ–‡æ¡£ï¼Œä¹‹åæ¯å¤©è¿˜æœ‰å‡ ç™¾å’Œæ–‡ä»¶ã€‚è¦èƒ½ä½¿ç”¨ SQL æŸ¥è¯¢æ–‡æ¡£æ•°æ®å¹¶æå–åŒ»å­¦æ•°æ®ã€‚<br>è¿‡ä¸‹æ¶‰åŠåˆ°çš„ AI å·¥å…·ï¼š  </p>
<ul>
<li><code>Amazon Rekognition</code> - å›¾åƒã€è§†é¢‘è¯†åˆ«</li>
<li><code>Amazon Transcribe Medical</code> - åŒ»ç–—è¯­éŸ³è½¬æ–‡æœ¬</li>
<li><code>Amazon Textract</code> - æ–‡æ¡£æ–‡æœ¬æ£€æµ‹å’Œåˆ†æã€ä¿¡æ¯æå–</li>
<li><code>Amazon Comprehend Medical</code> - åŒ»ç–—æ–‡æœ¬åˆ†æå’Œä¿¡æ¯æå–</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/zh_cn/rekognition/latest/dg/what-is.html">ä»€ä¹ˆæ˜¯ Amazon Rekognitionï¼Ÿ</a></p>
<blockquote>
<p>Amazon Rekognition æ˜¯ä¸€é¡¹åŸºäºäº‘çš„å›¾åƒå’Œè§†é¢‘åˆ†ææœåŠ¡ï¼Œå¯ä»¥è½»æ¾åœ°å‘åº”ç”¨ç¨‹åºæ·»åŠ é«˜çº§è®¡ç®—æœºè§†è§‰åŠŸèƒ½ã€‚è¯¥æœåŠ¡ç”±ä¹…ç»è€ƒéªŒçš„æ·±åº¦å­¦ä¹ æŠ€æœ¯æä¾›æ”¯æŒï¼Œæ— éœ€ä»»ä½•æœºå™¨å­¦ä¹ ä¸“ä¸šçŸ¥è¯†å³å¯ä½¿ç”¨ã€‚Amazon Rekognition åŒ…å«ä¸€ä¸ª easy-to-use ç®€å•çš„ APIï¼Œå¯ä»¥å¿«é€Ÿåˆ†æå­˜å‚¨åœ¨ Amazon S3 ä¸­çš„ä»»ä½•å›¾åƒæˆ–è§†é¢‘æ–‡ä»¶ã€‚</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://aws.amazon.com/cn/transcribe/medical/?nc1=h_ls">Amazon Transcribe Medical</a></p>
<blockquote>
<p>Amazon Transcribe Medical æ˜¯ä¸€ç§è‡ªåŠ¨è¯­éŸ³è¯†åˆ« (ASR) æœåŠ¡ï¼Œè®©æ‚¨èƒ½å¤Ÿè½»æ¾åœ°ä¸ºå…·æœ‰è¯­éŸ³åŠŸèƒ½çš„åº”ç”¨ç¨‹åºæ·»åŠ åŒ»ç–—è¯­éŸ³è½¬æ–‡æœ¬åŠŸèƒ½ã€‚åŒ»ç–—ä¿å¥æä¾›è€…å’Œæ‚£è€…ä¹‹é—´çš„å¯¹è¯ä¸ºæ‚£è€…çš„è¯Šæ–­å’Œæ²»ç–—è®¡åˆ’ä»¥åŠä¸´åºŠæ–‡æ¡£å·¥ä½œæµç¨‹æä¾›äº†åŸºç¡€ã€‚ç¡®ä¿è¿™äº›ä¿¡æ¯å‡†ç¡®æ— è¯¯æ˜¯è‡³å…³é‡è¦çš„ã€‚ç„¶è€Œï¼Œå‡†ç¡®çš„åŒ»ç–—è½¬å½•ï¼ˆå¦‚å£æˆè®°å½•å™¨å’ŒæŠ„å†™å‘˜ï¼‰ä»·æ ¼æ˜‚è´µã€è€—æ—¶é•¿ï¼Œè€Œä¸”ä¼šç ´åæ‚£è€…çš„ä½“éªŒã€‚æŸäº›ç»„ç»‡ä½¿ç”¨ç°æœ‰çš„åŒ»ç–—è½¬å½•è½¯ä»¶ï¼Œä½†å‘ç°å®ƒä»¬çš„æ•ˆç‡å’Œè´¨é‡éƒ½å¾ˆä½ã€‚</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/zh_cn/textract/latest/dg/what-is.html">ä»€ä¹ˆæ˜¯ Amazon Textractï¼Ÿ</a></p>
<blockquote>
<p>Amazon Textract è®©æ‚¨å¯ä»¥å‘åº”ç”¨ç¨‹åºè½»æ¾æ·»åŠ æ–‡æ¡£æ–‡æœ¬æ£€æµ‹å’Œåˆ†æåŠŸèƒ½ã€‚<br>ä»¥ä¸‹æ˜¯ä½¿ç”¨ Amazon Textract çš„å¸¸è§ä½¿ç”¨æ¡ˆä¾‹ï¼š  </p>
<ul>
<li>åˆ›å»ºæ™ºèƒ½æœç´¢ç´¢å¼•</li>
<li>ä½¿ç”¨æ™ºèƒ½æ–‡æœ¬æå–åŠŸèƒ½è¿›è¡Œè‡ªç„¶è¯­è¨€å¤„ç† (NLP)</li>
<li>åŠ å¿«æ¥è‡ªä¸åŒæ¥æºçš„æ•°æ®çš„æ•è·å’Œæ ‡å‡†åŒ–</li>
<li>è‡ªåŠ¨ä»è¡¨å•ä¸­æ•è·æ•°æ®</li>
</ul>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/zh_cn/comprehend-medical/latest/dev/comprehendmedical-welcome.html">ä»€ä¹ˆæ˜¯ Amazon Comprehend Medicalï¼Ÿ</a></p>
<blockquote>
<p>Amazon Comprehend Medical å¯ä»¥æ£€æµ‹å¹¶è¿”å›éç»“æ„åŒ–ä¸´åºŠæ–‡æœ¬ä¸­çš„æœ‰ç”¨ä¿¡æ¯ï¼Œä¾‹å¦‚åŒ»ç”Ÿè®°å½•ã€å‡ºé™¢æ‘˜è¦ã€æ£€éªŒç»“æœã€ç—…ä¾‹è®°å½•ç­‰ã€‚Amazon Comprehend Medical ä½¿ç”¨è‡ªç„¶è¯­è¨€å¤„ç† (NLP) æ¨¡å‹æ¥æ£€æµ‹å®ä½“ï¼Œè¿™äº›å®ä½“æ˜¯å¯¹åŒ»ç–—ä¿¡æ¯ [ä¾‹å¦‚åŒ»å­¦çŠ¶å†µã€è¯ç‰©æˆ–å—ä¿æŠ¤çš„å¥åº·ä¿¡æ¯ (PHI)] çš„æ–‡æœ¬å¼•ç”¨ã€‚æœ‰å…³æ£€æµ‹åˆ°çš„å®ä½“çš„å®Œæ•´åˆ—è¡¨ï¼Œè¯·å‚é˜… æ£€æµ‹å®ä½“ï¼ˆç‰ˆæœ¬ 2ï¼‰ã€‚Amazon Comprehend Medical è¿˜å…è®¸ç”¨æˆ·é€šè¿‡æœ¬ä½“é“¾æ¥æ“ä½œå°†è¿™äº›æ£€æµ‹åˆ°çš„å®ä½“ä¸æ ‡å‡†åŒ–åŒ»å­¦çŸ¥è¯†åº“ï¼ˆ RxNorm ä¾‹å¦‚ ICD-10-CMï¼‰å…³è”èµ·æ¥ã€‚</p>
</blockquote>
</blockquote>
<blockquote>
<p>ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦ ç¤¾åŒºè®¨è®ºï¼šB and E are correct.Textract to extract text from files. Rekognition can also be used for text detection but after Rekognition - itâ€™s mentioned that Transcribe is used.Transcribe is used forSpeech to Text.So that option D may not be valid.</p>
</blockquote>
<hr>
<h3 id="äºŒã€DynamoDB-keep-data-for-30-days"><a href="#äºŒã€DynamoDB-keep-data-for-30-days" class="headerlink" title="äºŒã€DynamoDB keep data for 30 days"></a>äºŒã€DynamoDB keep data for 30 days</h3><p>A company runs an application on a large fleet of Amazon EC2 instances. The application reads and writes entries into an Amazon DynamoDB table. The size of the DynamoDB table continuously grows, but the application needs only data from the last 30 days. The company needs a solution that minimizes cost and development effort.<br>Which solution meets these requirements?</p>
<ol>
<li>âŒ Use an AWS CloudFormation template to deploy the complete solution. Redeploy the CloudFormation stack every 30 days, and delete the original stack.</li>
<li>Use an EC2 instance that runs a monitoring application from AWS Marketplace. Configure the monitoring application to use Amazon DynamoDB Streams to store the timestamp when a new item is created in the table. Use a script that runs on the EC2 instance to delete items that have a timestamp that is older than 30 days.</li>
<li>Configure Amazon DynamoDB Streams to invoke an AWS Lambda function when a new item is created in the table. Configure the Lambda function to delete items in the table that are older than 30 days.</li>
<li>âœ… Extend the application to add an attribute that has a value of the current timestamp plus 30 days to each new item that is created in the table. Configure DynamoDB to use the attribute as the TTL attribute.</li>
</ol>
<blockquote>
<p>âœ¨ å…³é”®è¯ï¼šDynamoDBã€needs only data from the last 30 days</p>
</blockquote>
<blockquote>
<p>1ï¸âƒ£ âŒ -&gt; 4ï¸âƒ£ âœ…</p>
</blockquote>
<blockquote>
<p>ğŸ’¡ è§£æï¼š<code>DynamoDB</code> åˆ é™¤ 30 å¤©ä»¥ä¸Šçš„æ•°æ®ã€‚<br>å¿˜è®° <code>AWS CloudFormation</code> æ˜¯ä»€ä¹ˆäº†ï¼š<a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/zh_cn/AWSCloudFormation/latest/UserGuide/Welcome.html">ä»€ä¹ˆæ˜¯ AWS CloudFormationï¼Ÿ</a></p>
<blockquote>
<p>AWS CloudFormation æ˜¯ä¸€é¡¹æœåŠ¡ï¼Œå¯å¸®åŠ©æ‚¨å¯¹ AWS èµ„æºè¿›è¡Œå»ºæ¨¡å’Œè®¾ç½®ï¼Œä»¥ä¾¿èƒ½èŠ±è¾ƒå°‘çš„æ—¶é—´ç®¡ç†è¿™äº›èµ„æºï¼Œè€Œå°†æ›´å¤šçš„æ—¶é—´èŠ±åœ¨è¿è¡Œäº AWS ä¸­çš„åº”ç”¨ç¨‹åºä¸Šã€‚æ‚¨åˆ›å»ºä¸€ä¸ªæè¿°æ‚¨æ‰€éœ€çš„æ‰€æœ‰ AWS èµ„æºï¼ˆå¦‚ Amazon EC2 å®ä¾‹æˆ– Amazon RDS æ•°æ®åº“å®ä¾‹ï¼‰çš„æ¨¡æ¿ï¼Œå¹¶ä¸” CloudFormation å°†è´Ÿè´£ä¸ºæ‚¨é¢„ç½®å’Œé…ç½®è¿™äº›èµ„æºã€‚æ‚¨æ— éœ€å•ç‹¬åˆ›å»ºå’Œé…ç½® AWS èµ„æºå¹¶äº†è§£ what; CloudFormation å¥æŸ„å¤„ç†è¯¥å·¥ä½œæ—¶æ‰€ä¾èµ–çš„å†…å®¹ã€‚ä»¥ä¸‹æ–¹æ¡ˆæ¼”ç¤º CloudFormation å¦‚ä½•æä¾›å¸®åŠ©ã€‚</p>
</blockquote>
<p>å®ƒå…¶å®å°±æ˜¯å’Œ Terraform ä¸€æ ·çš„ IaCï¼ˆåŸºç¡€è®¾æ–½å³ä»£ç ï¼‰å·¥å…·ï¼Œå› æ­¤è¿™é‡Œè‚¯å®šä¸é€‰ 1ï¸âƒ£ã€‚<br>3ï¸âƒ£ å…¶å®æ˜¯æˆ‘è‡ªå·±é¡¹ç›®é‡Œçš„è§£å†³æ–¹æ¡ˆï¼Œæ–°çš„æ•°æ®æ¥çš„æ—¶å€™åšä¸€æ¬¡æ—§æ•°æ®çš„åˆ é™¤ã€‚ä½†æ˜¯å­˜åœ¨é—®é¢˜ä¸€ç›´ä¸æ¥æ–°æ•°æ®æ€ä¹ˆåŠã€‚<br>4ï¸âƒ£ è™½ç„¶è¦æ”¹åˆ°ä»£ç ï¼Œä½†æ˜¯å¦‚æœ <code>DynamoDB</code> æœ¬èº«ä¸æ”¯æŒå¯¹æ•°æ®æ’å…¥æ—¶é—´çš„åˆ¤æ–­çš„è¯ï¼Œå·²ç»æ˜¯æœ€ä¼˜è§£äº†ã€‚</p>
<p>æ¥çœ‹ä¸‹ <code>DynamoDB</code> TTL æ˜¯ä»€ä¹ˆï¼š<a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/TTL.html">Using time to live (TTL) in DynamoDB</a></p>
<blockquote>
<p>DynamoDB çš„ â€œæœ‰æ•ˆæ—¶é—´â€ï¼ˆTTLï¼‰æ˜¯åˆ é™¤ä¸å†ç›¸å…³çš„é¡¹ç›®çš„ä¸€ç§ç»æµæœ‰æ•ˆçš„æ–¹æ³•ã€‚TTL å…è®¸ä½ å®šä¹‰æ¯ä¸ªé¡¹ç›®çš„è¿‡æœŸæ—¶é—´æˆ³ï¼Œä»¥æŒ‡ç¤ºä½•æ—¶ä¸å†éœ€è¦é¡¹ç›®ã€‚DynamoDB ä¼šåœ¨è¿‡æœŸåå‡ å¤©å†…è‡ªåŠ¨åˆ é™¤è¿‡æœŸé¡¹ç›®ï¼Œè€Œä¸ä¼šæ¶ˆè€—å†™ååé‡ã€‚</p>
<p>è¦ä½¿ç”¨ TTLï¼Œé¦–å…ˆè¦åœ¨è¡¨ä¸Šå¯ç”¨å®ƒï¼Œç„¶åå®šä¹‰ä¸€ä¸ªç‰¹å®šå±æ€§æ¥å­˜å‚¨ TTL è¿‡æœŸæ—¶é—´æˆ³ã€‚æ—¶é—´æˆ³å¿…é¡»ä»¥ Unix æ—¶é—´æ ¼å¼å­˜å‚¨ï¼Œç²’åº¦ä¸ºç§’ã€‚æ¯æ¬¡åˆ›å»ºæˆ–æ›´æ–°é¡¹ç›®æ—¶ï¼Œéƒ½å¯ä»¥è®¡ç®—è¿‡æœŸæ—¶é—´å¹¶å°†å…¶ä¿å­˜åœ¨ TTL å±æ€§ä¸­ã€‚</p>
</blockquote>
<p>æ˜¾ç„¶å®ƒå°±æ˜¯æœ¬é¢˜çš„è€ƒç‚¹ã€‚</p>
</blockquote>
<blockquote>
<p>ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦ ç¤¾åŒºè®¨è®ºï¼šchanging myanswer to D after researching a bit.<br>The DynamoDB TTL feature allows you to define a per-item timestamp to determine when an item is no longer needed.Shortly after the date and time of the specified timestamp, DynamoDB deletes the item from your table without consuming any write throughput.</p>
</blockquote>
<hr>
<h3 id="ä¸‰ã€Amazon-Transcribe"><a href="#ä¸‰ã€Amazon-Transcribe" class="headerlink" title="ä¸‰ã€Amazon Transcribe"></a>ä¸‰ã€Amazon Transcribe</h3><p>A telemarketing company is designing its customer call center functionality on AWS. The company needs a solution that provides multiple speaker recognition and generates transcript files. The company wants to query the transcript files to analyze the business patterns. The transcript files must be stored for 7 years for auditing purposes.<br>Which solution will meet these requirements?</p>
<ol>
<li>Use Amazon Rekognition for multiple speaker recognition. Store the transcript files in Amazon S3. Use machine learning models for transcript file analysis.</li>
<li>âœ… Use Amazon Transcribe for multiple speaker recognition. Use Amazon Athena for transcript file analysis.</li>
<li>Use Amazon Translate for multiple speaker recognition. Store the transcript files in Amazon Redshift. Use SQL queries for transcript file analysis.</li>
<li>Use Amazon Rekognition for multiple speaker recognition. Store the transcript files in Amazon S3. Use Amazon Textract for transcript file analysis.</li>
</ol>
<blockquote>
<p>âœ¨ å…³é”®è¯ï¼šgenerates transcript files from voiceã€file analysis</p>
</blockquote>
<blockquote>
<p>2ï¸âƒ£ âœ…</p>
</blockquote>
<blockquote>
<p>ğŸ’¡ è§£æï¼šéœ€è¦è¯­éŸ³è½¬æ–‡å­—ï¼Œå¹¶å°†æ–‡æœ¬ä¿å­˜å’Œåˆ†æã€‚<br><code>Amazon Rekognition</code> æ˜¯è¯­éŸ³å’Œå›¾åƒ<strong>è¯†åˆ«</strong>å·¥å…·ï¼Œå¤„ç†ç±»ä¼¼ä¸æ‰“æ ‡ç­¾æˆ–æ˜¯åˆ¤æ–­æ˜¯å¦å­˜åœ¨ç‰©ä½“çš„å·¥ä½œã€‚<br>é¢˜ç›®ä¸­æ¶‰åŠåˆ°çš„ AI æœåŠ¡ï¼š</p>
<ul>
<li><code>Amazon Transcribe</code> - è¯­éŸ³è½¬æ–‡æœ¬</li>
<li><code>Amazon Translate</code> - ç»“åˆæœºå™¨å­¦ä¹ çš„ç¿»è¯‘æœåŠ¡</li>
<li><code>Amazon Textract</code> - æ–‡æ¡£æ–‡æœ¬æ£€æµ‹å’Œåˆ†æã€ä¿¡æ¯æå–</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/zh_cn/transcribe/latest/dg/what-is.html">ä»€ä¹ˆæ˜¯ Amazon Transcribeï¼Ÿ</a></p>
<blockquote>
<p>Amazon Transcribeæ˜¯ä¸€ç§è‡ªåŠ¨è¯­éŸ³è¯†åˆ«æœåŠ¡ï¼Œå®ƒä½¿ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹å°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡æœ¬ã€‚æ‚¨å¯ä»¥ç”¨Amazon Transcribeä½œç‹¬ç«‹çš„è½¬å½•æœåŠ¡ï¼Œä¹Ÿå¯ä»¥å‘ä»»ä½•åº”ç”¨ç¨‹åºæ·»åŠ speech-to-textåŠŸèƒ½ã€‚</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/zh_cn/translate/latest/dg/what-is.html">ä»€ä¹ˆæ˜¯ Amazon Translateï¼Ÿ</a></p>
<blockquote>
<p>Amazon Translate æ˜¯ä¸€ç§æ–‡æœ¬ç¿»è¯‘æœåŠ¡ï¼Œå®ƒä½¿ç”¨å…ˆè¿›çš„æœºå™¨å­¦ä¹ æŠ€æœ¯ï¼ŒæŒ‰éœ€æä¾›é«˜è´¨é‡çš„ç¿»è¯‘ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ Amazon Translate æ¥ç¿»è¯‘éç»“æ„åŒ–æ–‡æœ¬æ–‡æ¡£æˆ–æ„å»ºä½¿ç”¨å¤šç§è¯­è¨€çš„åº”ç”¨ç¨‹åºã€‚</p>
</blockquote>
</blockquote>
<blockquote>
<p>ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦ ç¤¾åŒºè®¨è®ºï¼šThe correct answer is B: Use Amazon Transcribe for multiple speaker recognition. Use Amazon Athena for transcript file analysis.<br>Amazon Transcribe isa service that automatically transcribes spoken language into written text. It can handle multiple speakers and can generate transcript files in real-time or asynchronously.These transcript files can be stored in Amazon S3 for long-term storage.<br>Amazon Athena isa query service that allows you to analyze data stored in Amazon S3 using SQL. You can use it to analyze the transcript filesand identify patterns in the data.  </p>
<p>Option A is incorrect because Amazon Rekognition isa service for analyzing imagesand videos, not transcribing spoken language.<br>Option C is incorrect because Amazon Translate isa service for translating text from one language to another, not transcribing spoken language.<br>Option D is incorrect because Amazon Textract isa service forextracting text and data from documentsand images, not transcribing spoken language.  </p>
</blockquote>
<hr>
<h3 id="å››ã€Amazon-Cognito-and-API-access"><a href="#å››ã€Amazon-Cognito-and-API-access" class="headerlink" title="å››ã€Amazon Cognito and API access"></a>å››ã€Amazon Cognito and API access</h3><p>A company hosts its application on AWS. The company uses Amazon Cognito to manage users. When users log in to the application, the application fetches required data from Amazon DynamoDB by using a REST API that is hosted in Amazon API Gateway. The company wants an AWS managed solution that will control access to the REST API to reduce development efforts.<br>Which solution will meet these requirements with the LEAST operational overhead?</p>
<ol>
<li>Configure an AWS Lambda function to be an authorizer in API Gateway to validate which user made the request.</li>
<li>For each user, create and assign an API key that must be sent with each request. Validate the key by using an AWS Lambda function.</li>
<li>Send the userâ€™s email address in the header with every request. Invoke an AWS Lambda function to validate that the user with that email address has proper access.</li>
<li>âœ… Configure an Amazon Cognito user pool authorizer in API Gateway to allow Amazon Cognito to validate each request.</li>
</ol>
<blockquote>
<p>âœ¨ å…³é”®è¯ï¼šAmazon Cognitoã€control access to the REST API</p>
</blockquote>
<blockquote>
<p>4ï¸âƒ£ âœ…</p>
</blockquote>
<blockquote>
<p>ğŸ’¡ è§£æï¼šä½¿ç”¨ <code>Amazon Cognito</code> ç®¡ç†ç”¨æˆ·ï¼Œç”¨æˆ·ç™»å½•åº”ç”¨åå¯ä»¥é€šè¿‡ <code>Amazon API Gateway</code> æä¾›çš„ API è·å– <code>DynamoDB</code> çš„æ•°æ®ã€‚ç°åœ¨å¸Œæœ›ä½¿ç”¨ AWS çš„æœåŠ¡æ¥è§£å†³ API æƒé™é—®é¢˜ã€‚<br>ä½¿ç”¨ <code>Amazon Cognito ç”¨æˆ·æ±  (user pool)</code> æ§åˆ¶ç”¨æˆ·å¯¹ REST API çš„è®¿é—®æ˜¯å®˜æ–¹çš„è§£å†³æ–¹æ¡ˆã€‚<br>å¤§æ¦‚åˆ†ä¸º 3 æ­¥ï¼š</p>
<ol>
<li>åœ¨ <code>Amazon Cognito</code> æ§åˆ¶å°åˆ›å»ºç”¨æˆ·æ± </li>
<li>åœ¨ <code>API Gateway</code> æ§åˆ¶å°é€‰å®šç”¨æˆ·æ± åˆ›å»º <code>API Gateway Authorizerï¼ˆæˆæƒæ–¹ï¼‰</code></li>
<li>åœ¨ <code>API Gateway</code> æ§åˆ¶å°å¯¹æŒ‡å®šçš„ API å¯åŠ¨æˆæƒæ–¹</li>
</ol>
<p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/zh_cn/cognito/latest/developerguide/what-is-amazon-cognito.html">ä»€ä¹ˆæ˜¯ Amazon Cognitoï¼Ÿ</a></p>
<blockquote>
<p>Amazon Cognito æ˜¯ Web å’Œç§»åŠ¨åº”ç”¨ç¨‹åºçš„èº«ä»½å¹³å°ã€‚å®ƒæ˜¯ä¸€ä¸ªç”¨æˆ·ç›®å½•ã€ä¸€ä¸ªèº«ä»½éªŒè¯æœåŠ¡å™¨ä»¥åŠä¸€ä¸ªç”¨äº OAuth 2.0 è®¿é—®ä»¤ç‰Œå’Œ AWS å‡­æ®çš„æˆæƒæœåŠ¡ã€‚ä½¿ç”¨ Amazon Cognitoï¼Œæ‚¨å¯ä»¥å¯¹å†…ç½®ç”¨æˆ·ç›®å½•ã€ä¼ä¸šç›®å½•ä»¥åŠ Google å’Œ Facebook ç­‰ä½¿ç”¨è€…èº«ä»½æä¾›è€…ä¸­çš„ç”¨æˆ·è¿›è¡Œèº«ä»½éªŒè¯å’Œæˆæƒã€‚</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/zh_cn/apigateway/latest/developerguide/apigateway-integrate-with-cognito.html">ä½¿ç”¨ Amazon Cognito ç”¨æˆ·æ± ä½œä¸ºæˆæƒæ–¹æ§åˆ¶å¯¹ REST API çš„è®¿é—®</a></p>
<blockquote>
<p>ä½œä¸ºä½¿ç”¨ IAM è§’è‰²å’Œç­–ç•¥æˆ– Lambda æˆæƒæ–¹ï¼ˆä»¥å‰ç§°ä¸ºè‡ªå®šä¹‰æˆæƒæ–¹ï¼‰çš„æ›¿ä»£æ–¹æ¡ˆï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ Amazon Cognito ç”¨æˆ·æ± æ¥æ§åˆ¶è°å¯ä»¥åœ¨ Amazon API Gateway ä¸­è®¿é—®æ‚¨çš„ APIã€‚</p>
<p>è¦å°† Amazon Cognito ç”¨æˆ·æ± ä¸æ‚¨çš„ API ä¸€èµ·ä½¿ç”¨ï¼Œæ‚¨å¿…é¡»å…ˆåˆ›å»º <code>COGNITO_USER_POOLS</code> ç±»å‹çš„æˆæƒæ–¹ï¼Œç„¶åé…ç½® API æ–¹æ³•ä»¥ä½¿ç”¨è¯¥æˆæƒæ–¹ã€‚éƒ¨ç½² API ä¹‹åï¼Œå®¢æˆ·ç«¯å¿…é¡»å…ˆå°†ç”¨æˆ·æ³¨å†Œåˆ°ç”¨æˆ·æ± ï¼Œè·å–ç”¨æˆ·çš„èº«ä»½ä»¤ç‰Œæˆ–è®¿é—®ä»¤ç‰Œï¼Œç„¶åä½¿ç”¨ä»¤ç‰Œä¹‹ä¸€è°ƒç”¨ API æ–¹æ³•ï¼Œè¿™é€šå¸¸è®¾ç½®ä¸ºè¯·æ±‚çš„ <code>Authorization</code> æ ‡å¤´ã€‚åªæœ‰æä¾›äº†æ‰€éœ€çš„ä»¤ç‰Œå¹¶ä¸”æä¾›çš„ä»¤ç‰Œæœ‰æ•ˆæ—¶ï¼ŒAPI è°ƒç”¨æ‰ä¼šæˆåŠŸï¼Œå¦åˆ™ï¼Œå®¢æˆ·ç«¯æœªè·å¾—æˆæƒæ¥æ‰§è¡Œè°ƒç”¨ï¼Œå› ä¸ºå®¢æˆ·ç«¯æ²¡æœ‰å¯ç”¨äºæˆæƒçš„å‡­è¯ã€‚</p>
<p>ä½¿ç”¨èº«ä»½ä»¤ç‰Œï¼ŒåŸºäºå·²ç™»å½•ç”¨æˆ·çš„èº«ä»½å£°æ˜æ¥æˆæƒ API è°ƒç”¨ã€‚ä½¿ç”¨è®¿é—®ä»¤ç‰Œï¼ŒåŸºäºæŒ‡å®šè®¿é—®å—ä¿æŠ¤èµ„æºçš„è‡ªå®šä¹‰èŒƒå›´æˆæƒ API è°ƒç”¨ã€‚</p>
<p>è¦ä¸º API åˆ›å»ºå’Œé…ç½® Amazon Cognito ç”¨æˆ·æ± ï¼Œè¯·æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡ï¼š</p>
<ol>
<li>ä½¿ç”¨ Amazon Cognito æ§åˆ¶å°ã€CLI&#x2F;å¼€å‘å·¥å…·åŒ…æˆ– API åˆ›å»ºç”¨æˆ·æ± ï¼Œæˆ–è€…ä½¿ç”¨ç”±å…¶ä»– AWS è´¦æˆ·æ‹¥æœ‰çš„ç”¨æˆ·æ± ã€‚</li>
<li>ä½¿ç”¨ API Gateway æ§åˆ¶å°ã€CLI&#x2F;å¼€å‘å·¥å…·åŒ…æˆ– API åˆ›å»ºå…·æœ‰é€‰å®šç”¨æˆ·æ± çš„ API Gateway Authorizerã€‚</li>
<li>ä½¿ç”¨ API Gateway æ§åˆ¶å°ã€CLI&#x2F;å¼€å‘å·¥å…·åŒ…æˆ– APIï¼Œåœ¨æ‰€é€‰ API æ–¹æ³•ä¸Šå¯ç”¨æˆæƒæ–¹ã€‚</li>
</ol>
</blockquote>
</blockquote>
<blockquote>
<p>ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦ ç¤¾åŒºè®¨è®ºï¼šKEYWORD: LEAST operational overhead<br>To control access to the REST API and reduce development efforts, the company can use an Amazon Cognito user pool authorizer in API Gateway.This will allow Amazon Cognito to validate each request and ensure that onlyauthenticated users can access the API.This solution has the LEAST operational overhead,as it does not require the company to develop and maintain anyadditional infrastructure or code.<br>Therefore, Option D is the correct answer.<br>Option D. Configure an Amazon Cognito user pool authorizer in API Gateway to allow Amazon Cognito to validate each request.</p>
</blockquote>
<hr>
<h3 id="äº”ã€SMS-messages"><a href="#äº”ã€SMS-messages" class="headerlink" title="äº”ã€SMS messages"></a>äº”ã€SMS messages</h3><p>A company is developing a marketing communications service that targets mobile app users. The company needs to send confirmation messages with Short Message Service (SMS) to its users. The users must be able to reply to the SMS messages.<br>The company must store the responses for a year for analysis.<br>What should a solutions architect do to meet these requirements?</p>
<ol>
<li>âŒ Create an Amazon Connect contact flow to send the SMS messages. Use AWS Lambda to process the responses.</li>
<li>âœ… Build an Amazon Pinpoint journey. Configure Amazon Pinpoint to send events to an Amazon Kinesis data stream for analysis and archiving.</li>
<li>Use Amazon Simple Queue Service (Amazon SQS) to distribute the SMS messages. Use AWS Lambda to process the responses.</li>
<li>Create an Amazon Simple Notification Service (Amazon SNS) FIFO topic. Subscribe an Amazon Kinesis data stream to the SNS topic for analysis and archiving.</li>
</ol>
<blockquote>
<p>âœ¨ å…³é”®è¯ï¼šsend SMS and get the reply</p>
</blockquote>
<blockquote>
<p>1ï¸âƒ£ âŒ -&gt; 2ï¸âƒ£ âœ… </p>
</blockquote>
<blockquote>
<p>ğŸ’¡ è§£æï¼šå…¬å¸éœ€è¦å‘é€çŸ­ä¿¡å¹¶å—åˆ°å›å¤ï¼Œå›å¤éœ€è¦ä¿å­˜ä¸€å¹´ç”¨ä½œåˆ†æã€‚  </p>
<p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/zh_cn/pinpoint/latest/userguide/welcome.html">ä»€ä¹ˆæ˜¯ Amazon Pinpointï¼Ÿ</a></p>
<blockquote>
<p>æ‚¨å¯ä»¥ä½¿ç”¨ Amazon Pinpoint é€šè¿‡å¤šä¸ªæ¶ˆæ¯æ¸ é“ä¸å®¢æˆ·äº’åŠ¨ã€‚ AWS æœåŠ¡ æ‚¨å¯ä»¥ä½¿ç”¨ Amazon Pinpoint é€šè¿‡è‡ªå®šä¹‰æ¸ é“å‘é€æ¨é€é€šçŸ¥ã€åº”ç”¨ç¨‹åºå†…é€šçŸ¥ã€ç”µå­é‚®ä»¶ã€æ–‡æœ¬æ¶ˆæ¯ã€è¯­éŸ³æ¶ˆæ¯ç­‰ã€‚å®ƒåŒ…æ‹¬å®¢æˆ·ç»†åˆ†ã€æ´»åŠ¨å’Œæ—…ç¨‹åŠŸèƒ½ï¼Œå¯å¸®åŠ©æ‚¨åœ¨æ­£ç¡®çš„æ—¶é—´é€šè¿‡æ­£ç¡®çš„æ¸ é“å‘æ­£ç¡®çš„å®¢æˆ·å‘é€æ­£ç¡®çš„ä¿¡æ¯ã€‚</p>
</blockquote>
<p>æ˜¾ç„¶ä½¿ç”¨ <code>Amazon Pinpoint</code> å¯ä»¥å®ç°å‘é€ SMS è¿™ä¸ªéœ€æ±‚ï¼Œé‚£ä¹ˆæ¥æ”¶å“åº”å‘¢ï¼Ÿ<br>éœ€è¦ä½¿ç”¨åˆ° <code>two-way SMS</code>ï¼š<a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/zh_cn/sms-voice/latest/userguide/two-way-sms-phone-number.html">åœ¨ â€œAWS æœ€ç»ˆç”¨æˆ·SMSæ¶ˆæ¯â€ ä¸­ä¸ºç”µè¯å·ç è®¾ç½®åŒå‘æ¶ˆæ¯ SMS</a>  </p>
<blockquote>
<p>AWS æœ€ç»ˆç”¨æˆ·æ¶ˆæ¯SMSåŒ…æ‹¬å¯¹åŒå‘çš„æ”¯æŒSMSã€‚è®¾ç½®åŒå‘æ—¶SMSï¼Œæ‚¨å¯ä»¥æ¥æ”¶æ¥è‡ªå®¢æˆ·çš„ä¼ å…¥æ¶ˆæ¯ã€‚æ‚¨è¿˜å¯ä»¥å°†åŒå‘æ¶ˆæ¯ä¸ Lambda å’Œ Amazon Lex ç­‰å…¶ä»– AWS æœåŠ¡æ¶ˆæ¯ä¸€èµ·ä½¿ç”¨ï¼Œä»¥åˆ›å»ºäº¤äº’å¼çŸ­ä¿¡ä½“éªŒã€‚</p>
<p>å½“æ‚¨çš„ä¸€ä½å®¢æˆ·å‘æ‚¨çš„ç”µè¯å·ç å‘é€æ¶ˆæ¯æ—¶ï¼Œæ¶ˆæ¯æ­£æ–‡å°†å‘é€åˆ°äºšé©¬é€ŠSNSä¸»é¢˜æˆ– Amazon Connect å®ä¾‹è¿›è¡Œå¤„ç†ã€‚</p>
</blockquote>
<p>è€Œå…³äºæ•°æ®å­˜å‚¨ä¸€å¹´çš„éœ€æ±‚ï¼Œ<code>Amazon Kinesis Data Stream</code> è¶³ä»¥åšåˆ°äº†ï¼š<a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/zh_cn/streams/latest/dev/kinesis-extended-retention.html">æ›´æ”¹æ•°æ®ç•™å­˜æœŸ</a></p>
<blockquote>
<p>Amazon Kinesis Data Streams æ”¯æŒæ›´æ”¹æ•°æ®æµçš„æ•°æ®è®°å½•ä¿ç•™æœŸã€‚Kinesis æ•°æ®æµæ˜¯æ•°æ®è®°å½•çš„æœ‰åºåºåˆ—ï¼Œå¯ç”¨äºæ‰§è¡Œå®æ—¶å†™å…¥å’Œè¯»å–ã€‚å› æ­¤ï¼Œæ•°æ®è®°å½•ä¸´æ—¶å­˜å‚¨åœ¨æ‚¨çš„æµçš„åˆ†ç‰‡ä¸­ã€‚ä»æ·»åŠ è®°å½•å¼€å§‹ï¼Œåˆ°è®°å½•ä¸å†å¯ä¾›è®¿é—®ä¸ºæ­¢çš„æ—¶é—´æ®µç§°ä¸ºä¿ç•™æœŸã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒKinesis æ•°æ®æµçš„è®°å½•å­˜å‚¨æ—¶é—´ä» 24 å°æ—¶åˆ° 8760 å°æ—¶ï¼ˆ365 å¤©ï¼‰ä¸ç­‰ã€‚</p>
</blockquote>
</blockquote>
<blockquote>
<p>ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦ ç¤¾åŒºè®¨è®ºï¼šBy using Pinpoint, the company can effectively send SMS messages to its mobile app users. Additionally, Pinpoint allows the configuration of journeys, which enable the tracking and management of user interactions.The events generated during the journey, including user responses to SMS, can be captured and sent to an Kinesis data stream.This data stream can then be used for analysisand archiving purposes.  </p>
<p>A. Creating an Amazon Connect contact flow is primarily focused on customer support and engagement,and it lacks the capability to store and processSMS responses for analysis.<br>C. Using SQS isa message queuing service and is not specifically designed for handling SMS responses or capturing them for analysis.<br>D. Creating an SNS FIFO topic and subscribing a Kinesis data stream is not the most appropriate solution for capturing and storing SMS responses,asSNS is primarily used for message publishing and distribution.  </p>
<p>In summary, option B is the best choice as it leverages Pinpoint to send SMS messagesand captures user responses for analysis and archiving using an Kinesis data stream.</p>
</blockquote>
<hr>
<h3 id="å…­ã€Data-Lake-and-fine-grained-permissions"><a href="#å…­ã€Data-Lake-and-fine-grained-permissions" class="headerlink" title="å…­ã€Data Lake and fine-grained permissions"></a>å…­ã€Data Lake and fine-grained permissions</h3><p>An online retail company has more than 50 million active customers and receives more than 25,000 orders each day. The company collects purchase data for customers and stores this data in Amazon S3. Additional customer data is stored in Amazon RDS.<br>The company wants to make all the data available to various teams so that the teams can perform analytics. The solution must provide the ability to manage fine-grained permissions for the data and must minimize operational overhead.<br>Which solution will meet these requirements?</p>
<ol>
<li>Migrate the purchase data to write directly to Amazon RDS. Use RDS access controls to limit access.</li>
<li>Schedule an AWS Lambda function to periodically copy data from Amazon RDS to Amazon S3. Create an AWS Glue crawler. Use Amazon Athena to query the data. Use S3 policies to limit access.</li>
<li>âœ… Create a data lake by using AWS Lake Formation. Create an AWS Glue JDBC connection to Amazon RDS. Register the S3 bucket in Lake Formation. Use Lake Formation access controls to limit access.</li>
<li>Create an Amazon Redshift cluster. Schedule an AWS Lambda function to periodically copy data from Amazon S3 and Amazon RDS to Amazon Redshift. Use Amazon Redshift access controls to limit access.</li>
</ol>
<blockquote>
<p>âœ¨ å…³é”®è¯ï¼šget data from S3 and RDSã€fine-grained permissions</p>
</blockquote>
<blockquote>
<p>3ï¸âƒ£ âœ…</p>
</blockquote>
<blockquote>
<p>ğŸ’¡ è§£æï¼šéœ€è¦æ±‡æ€» <code>S3</code> å’Œ <code>RDS</code> ä¸­çš„æ•°æ®å¹¶æä¾›ç²¾ç»†çš„æƒé™æ§åˆ¶ã€‚<br>æ˜¾ç„¶éœ€è¦ä½¿ç”¨åˆ°æ•°æ®æ¹–æˆ–è€…æ•°æ®ä»“åº“ã€‚<br>çœ‹ä¸‹ <code>AWS Lake Formation</code>ï¼š<a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/zh_cn/lake-formation/latest/dg/what-is-lake-formation.html">ä»€ä¹ˆæ˜¯ AWS Lake Formationï¼Ÿ</a></p>
<blockquote>
<p>AWS Lake Formation å¸®åŠ©æ‚¨é›†ä¸­ç®¡ç†ã€ä¿æŠ¤å’Œå…¨çƒå…±äº«ç”¨äºåˆ†æå’Œæœºå™¨å­¦ä¹ çš„æ•°æ®ã€‚æ‚¨å¯ä»¥å¯¹ Amazon Simple Storage Service (Amazon S3) ä¸Šçš„æ•°æ®æ¹–æ•°æ®åŠå…¶åœ¨ AWS Glue Data Catalogä¸­çš„å…ƒæ•°æ®è¿›è¡Œç²¾ç»†è®¿é—®æ§åˆ¶ã€‚</p>
</blockquote>
<p>æ˜¾ç„¶å®Œç¾ç¬¦åˆé¢˜ç›®éœ€æ±‚ã€‚<br>å†çœ‹ä¸‹åŒä¸ºæ•°æ®ä»“åº“çš„ <code>Redshift</code>ï¼š<a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/zh_cn/redshift/latest/mgmt/welcome.html">ä»€ä¹ˆæ˜¯ Amazon Redshift</a></p>
<blockquote>
<p>Amazon Redshift æ˜¯äº‘ä¸­ä¸€ç§å®Œå…¨æ‰˜ç®¡çš„ PB çº§æ•°æ®ä»“åº“æœåŠ¡ã€‚Amazon Redshift Serverless è®©æ‚¨å¯ä»¥è®¿é—®å’Œåˆ†ææ•°æ®ï¼Œè€Œæ— éœ€å¯¹é¢„ç½®æ•°æ®ä»“åº“æ‰§è¡Œä»»ä½•é…ç½®æ“ä½œã€‚</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/r_Database_objects.html">æ•°æ®åº“å®‰å…¨</a></p>
<blockquote>
<p>æ‚¨å¯ä»¥é€šè¿‡æ§åˆ¶å“ªäº›ç”¨æˆ·å¯ä»¥è®¿é—®å“ªäº›æ•°æ®åº“å¯¹è±¡æ¥ç®¡ç†æ•°æ®åº“å®‰å…¨ã€‚å¯ä»¥ä¸ºç”¨æˆ·åˆ†é…è§’è‰²æˆ–ç»„ï¼Œæˆäºˆç»™ç”¨æˆ·ã€è§’è‰²æˆ–ç»„çš„æƒé™å†³å®šäº†ä»–ä»¬å¯ä»¥è®¿é—®å“ªäº›æ•°æ®åº“å¯¹è±¡ã€‚</p>
</blockquote>
<p>4ï¸âƒ£ çœ‹ä¸Šå»ä¹Ÿèƒ½å®Œæˆä»»åŠ¡ï¼Œä½†æ˜¯æ“ä½œæ¯” 3ï¸âƒ£ æ›´å¤æ‚ã€‚  </p>
</blockquote>
<blockquote>
<p>ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦ ç¤¾åŒºè®¨è®ºï¼šAnswer : C keyword â€œmanage-fine-grainedâ€<br><a target="_blank" rel="noopener" href="https://aws.amazon.com/blogs/big-data/manage-fine-grained-access-control-using-aws-lake-formation/">https://aws.amazon.com/blogs/big-data/manage-fine-grained-access-control-using-aws-lake-formation/</a></p>
<p>Lake Formation enables the creation of a secure and scalable data lake on AWS,allowing centralized access controls for both S3 and RDS data. By using Lake Formation, the company can manage permissionseffectivelyand integrate RDS data through the AWS Glue JDBC connection. Registering the S3 in Lake Formation ensures unified access control.This solution reduces operational overhead while providing fine-grained permissions management.<br>A. Directly writing purchase data to Amazon RDS with RDS access controls lacks comprehensive permissions management for both S3 and RDS data.<br>B. Periodically copying data from RDS to S3 using Lambda and using AWS Glue and Athena for querying does not offer finegrained permissions management and introduces data synchronization complexities.<br>D. Creating an Redshift cluster and copying data from S3 and RDS to Redshift adds complexityand operational overhead without the flexibility of Lake Formationâ€™s permissions management capabilities.</p>
</blockquote>
<hr>
<h3 id="ä¸ƒã€EC2-connect-to-S3"><a href="#ä¸ƒã€EC2-connect-to-S3" class="headerlink" title="ä¸ƒã€EC2 connect to S3"></a>ä¸ƒã€EC2 connect to S3</h3><p>A company needs to move data from an Amazon EC2 instance to an Amazon S3 bucket. The company must ensure that no API calls and no data are routed through public internet routes. Only the EC2 instance can have access to upload data to the S3 bucket.<br>Which solution will meet these requirements?</p>
<ol>
<li>âœ… Create an interface VPC endpoint for Amazon S3 in the subnet where the EC2 instance is located. Attach a resource policy to the S3 bucket to only allow the EC2 instanceâ€™s IAM role for access.</li>
<li>âŒ Create a gateway VPC endpoint for Amazon S3 in the Availability Zone where the EC2 instance is located. Attach appropriate security groups to the endpoint. Attach a resource policy to the S3 bucket to only allow the EC2 instanceâ€™s IAM role for access.</li>
<li>Run the nslookup tool from inside the EC2 instance to obtain the private IP address of the S3 bucketâ€™s service API endpoint. Create a route in the VPC route table to provide the EC2 instance with access to the S3 bucket. Attach a resource policy to the S3 bucket to only allow the EC2 instanceâ€™s IAM role for access.</li>
<li>Use the AWS provided, publicly available ip-ranges.json file to obtain the private IP address of the S3 bucketâ€™s service API endpoint. Create a route in the VPC route table to provide the EC2 instance with access to the S3 bucket. Attach a resource policy to the S3 bucket to only allow the EC2 instanceâ€™s IAM role for access.</li>
</ol>
<blockquote>
<p>âœ¨ å…³é”®è¯ï¼šmove data from an Amazon EC2 instance to an Amazon S3 bucketã€no data are routed through public internet</p>
</blockquote>
<blockquote>
<p>2ï¸âƒ£ âŒ -&gt; 1ï¸âƒ£ âœ…</p>
</blockquote>
<blockquote>
<p>ğŸ’¡ è§£æï¼š<code>EC2</code> çš„æ•°æ®è¦èµ°ç§ç½‘ä¼ è¾“åˆ° <code>S3</code> å­˜å‚¨æ¡¶ä¸­ã€‚<br>ç¤¾åŒºåœ¨ 1ï¸âƒ£ å’Œ 2ï¸âƒ£ äº‰è®®è¾ƒå¤§ã€‚<br>äº‰è®®çš„é‡ç‚¹åœ¨äº 2ï¸âƒ£ çš„ â€œAttach appropriate security groups to the endpointâ€ è¿™å¥ï¼Œå°†é€‚å½“çš„å®‰å…¨ç»„é™„åŠ åˆ°ç»ˆç«¯èŠ‚ç‚¹ä¸Šã€‚<br>å¦‚æœå®ƒå¯ä»¥å®ç°ï¼Œé‚£ä¹ˆ 2ï¸âƒ£ æ˜¾ç„¶æ˜¯æœ€ä¼˜é€‰æ‹©ï¼Œä½†å¦‚æœå®ƒæ— æ³•å®ç°ï¼Œé‚£å°±åªèƒ½é€‰ 1ï¸âƒ£ã€‚<br><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/zh_cn/vpc/latest/privatelink/create-interface-endpoint.html">ä½¿ç”¨æ¥å£ VPC ç«¯ç‚¹è®¿é—® AWS æœåŠ¡</a>  </p>
<blockquote>
<p><strong>å‰ææ¡ä»¶</strong><br>ä¸ºç«¯ç‚¹ç½‘ç»œæ¥å£ (endpoint network interface) åˆ›å»ºä¸€ä¸ªå®‰å…¨ç»„ï¼Œå…è®¸æ¥è‡ª VPC èµ„æºçš„é¢„æœŸæµé‡ã€‚ä¾‹å¦‚ï¼Œä¸ºç¡®ä¿ AWS CLI å¯ä»¥å‘ AWS æœåŠ¡ å‘é€ HTTPS è¯·æ±‚ï¼Œå®‰å…¨ç»„å¿…é¡»å…è®¸å…¥ç«™ HTTPS æµé‡ã€‚</p>
</blockquote>
<p>é¦–å…ˆæˆ‘ä»¬æ˜ç¡® <code>interface VPC endpoint</code> æ˜¯å¯ä»¥é…ç½®å®‰å…¨ç»„çš„ã€‚å®æµ‹äº†ä¸‹ä¹Ÿç¡®å®ï¼š<br><img src="https://image.senjianlu.com/blog/2024-12-03/exam_aws_test_02.png" alt="æ¥å£ç»ˆç«¯èŠ‚ç‚¹">  </p>
<p>é‚£ä¹ˆç½‘å…³ç«¯ç‚¹å‘¢ï¼Ÿå¾ˆé—æ†¾çš„æ˜¯ AWS çš„æ–‡æ¡£é‡Œå¹¶æ²¡æœ‰æ˜è¯´ï¼Œå®è·µçœ‹ä¸‹å§ï¼š<br><img src="https://image.senjianlu.com/blog/2024-12-03/exam_aws_test_01.png" alt="ç½‘å…³ç»ˆç«¯èŠ‚ç‚¹"><br>åˆ›å»ºè¿‡ç¨‹ä¸­å’Œåˆ›å»ºå®Œæˆåéƒ½æ²¡æœ‰å®‰å…¨ç»„ç›¸å…³é…ç½®ï¼Œ<strong>å› æ­¤å¾—å‡ºç»“è®º <code>Gateway endpoint</code> ä¸æ”¯æŒå®‰å…¨ç»„é…ç½®</strong>ï¼Œé€‰ 1ï¸âƒ£ã€‚     </p>
</blockquote>
<blockquote>
<p>ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦ ç¤¾åŒºè®¨è®ºï¼šI thinkanswer should be A and not B.<br>as we cannot â€œAttach a security groups to a gatewayendpoint.â€</p>
</blockquote>
<hr>
<h3 id="å…«ã€Files-convert"><a href="#å…«ã€Files-convert" class="headerlink" title="å…«ã€Files convert"></a>å…«ã€Files convert</h3><p>A companyâ€™s reporting system delivers hundreds of .csv files to an Amazon S3 bucket each day. The company must convert these files to Apache Parquet format and must store the files in a transformed data bucket.<br>Which solution will meet these requirements with the LEAST development effort?</p>
<ol>
<li>Create an Amazon EMR cluster with Apache Spark installed. Write a Spark application to transform the data. Use EMR File System (EMRFS) to write files to the transformed data bucket.</li>
<li>âœ… Create an AWS Glue crawler to discover the data. Create an AWS Glue extract, transform, and load (ETL) job to transform the data. Specify the transformed data bucket in the output step.</li>
<li>Use AWS Batch to create a job definition with Bash syntax to transform the data and output the data to the transformed data bucket. Use the job definition to submit a job. Specify an array job as the job type.</li>
<li>âŒ Create an AWS Lambda function to transform the data and output the data to the transformed data bucket. Configure an event notification for the S3 bucket. Specify the Lambda function as the destination for the event notification.</li>
</ol>
<blockquote>
<p>âœ¨ å…³é”®è¯ï¼šconvert files from .csv to Apache Parquet formatã€S3</p>
</blockquote>
<blockquote>
<p>4ï¸âƒ£ âŒ -&gt; 2ï¸âƒ£ âœ…</p>
</blockquote>
<blockquote>
<p>ğŸ’¡ è§£æï¼šéœ€è¦å°† <code>S3</code> å­˜å‚¨æ¡¶å†…çš„ .csv æ–‡ä»¶è½¬ä¸º Apache Parquet æ ¼å¼å†å­˜å…¥å¦ä¸€ä¸ªæ¡¶ä¸­ã€‚<br>4ï¸âƒ£ å½“ç„¶å¯ä»¥è§£å†³é—®é¢˜ï¼Œä½†æ˜¯å¤ªè¿‡ç¹çã€‚  </p>
<p><code>Glue</code> æ˜¯å®˜æ–¹å»ºè®®çš„è§£å†³æ–¹å¼ï¼š<a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/three-aws-glue-etl-job-types-for-converting-data-to-apache-parquet.html">Three AWS Glue ETL job types for converting data to Apache Parquet</a></p>
<blockquote>
<p>On the Amazon Web Services (AWS) Cloud, AWS Glue is a fully managed extract, transform, and load (ETL) service. AWS Glue makes it cost-effective to categorize your data, clean it, enrich it, and move it reliably between various data stores and data streams.  </p>
</blockquote>
<p>è¿˜éœ€è¦è¡¥å……ä¸€ç‚¹æ˜¯ <code>Glue</code> æ˜¯æ”¯æŒæ•°æ®æµçš„ï¼š<a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/zh_cn/glue/latest/dg/edit-jobs-source-streaming.html">ä½¿ç”¨æµå¼å¤„ç†æ•°æ®æº</a></p>
<blockquote>
<p>æ‚¨å¯ä»¥åˆ›å»ºè¿ç»­è¿è¡Œå¹¶ä½¿ç”¨æ¥è‡ªæµå¼å¤„ç†æºçš„æ•°æ®çš„æµå¼å¤„ç†æå–ã€è½¬æ¢å’Œè´Ÿè½½ï¼ˆETLï¼‰ä»»åŠ¡ï¼Œä¾‹å¦‚ Amazon Kinesis Data Streamsã€Apache Kafka å’Œ Amazon Managed Streaming for Apache Kafkaï¼ˆAmazon MSKï¼‰ã€‚</p>
</blockquote>
<p>é¡ºä¾¿çœ‹åˆ° 1ï¸âƒ£ çš„æ—¶å€™æ„£äº†ä¸€ä¸‹ï¼Œåˆå¿˜è®° <code>EMR</code> æ˜¯ä»€ä¹ˆäº†ï¼š<a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/zh_cn/emr/latest/ManagementGuide/emr-what-is-emr.html">ä»€ä¹ˆæ˜¯ Amazon EMRï¼Ÿ</a></p>
<blockquote>
<p>Amazon EMRï¼ˆä»¥å‰ç§°ä¸º Amazon Elastic MapReduceï¼‰æ˜¯ä¸€ä¸ªæ‰˜ç®¡é›†ç¾¤å¹³å°ï¼Œå¯ç®€åŒ–åœ¨AWSä¸Šè¿è¡Œå¤§æ•°æ®æ¡†æ¶ï¼ˆå¦‚ Apache Hadoop å’Œ Apache Sparkï¼‰çš„è¿‡ç¨‹ï¼Œä»¥å¤„ç†å’Œåˆ†ææµ·é‡æ•°æ®ã€‚ä½¿ç”¨è¿™äº›æ¡†æ¶å’Œç›¸å…³çš„å¼€æºé¡¹ç›®ï¼Œæ‚¨å¯ä»¥å¤„ç†ç”¨äºåˆ†æç›®çš„çš„æ•°æ®å’Œä¸šåŠ¡æƒ…æŠ¥å·¥ä½œè´Ÿè½½ã€‚Amazon EMR è¿˜å…è®¸æ‚¨è½¬æ¢å¤§é‡æ•°æ®å¹¶ç§»å‡º&#x2F;ç§»å…¥åˆ°å…¶å®ƒAWSæ•°æ®å­˜å‚¨å’Œæ•°æ®åº“ä¸­ï¼Œä¾‹å¦‚ Amazon Simple Storage Serviceï¼ˆAmazon S3ï¼‰å’Œ Amazon DynamoDBã€‚</p>
</blockquote>
<p><code>Amazon EMR</code> æ˜¯å¤§æ•°æ®æ¡†æ¶æ‰˜ç®¡å¹³å°ã€‚  </p>
</blockquote>
<blockquote>
<p>ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦ ç¤¾åŒºè®¨è®ºï¼šAWS Glue isa fully managed ETL service that simplifies the process of preparing and transforming data for analytics. Using AWS Glue requires minimal development effort compared to the other options.  </p>
<p>Option A requires more development effort as it involves writing a Sparkapplication to transform the data. It also introduces additional infrastructure management with the EMR cluster.<br>Option C requires writing and managing custom Bash scripts for data transformation. It requires more manual effort and does not provide the built-in capabilities of AWS Glue for data transformation.<br>Option D requires developing and managing a custom Lambda for data transformation. While Lambda can handle the transformation, it requires more effort compared to AWS Glue, which is specifically designed for ETL operations.  </p>
<p>Therefore, option B provides the easiest and least development effort by leveraging AWS Glueâ€™s capabilities for data discovery, transformation,and output to the transformed data bucket.</p>
</blockquote>
<hr>
<h3 id="ä¹ã€Second-infrastructure-for-DR"><a href="#ä¹ã€Second-infrastructure-for-DR" class="headerlink" title="ä¹ã€Second infrastructure for DR"></a>ä¹ã€Second infrastructure for DR</h3><p>A company runs a global web application on Amazon EC2 instances behind an Application Load Balancer. The application stores data in Amazon Aurora. The company needs to create a disaster recovery solution and can tolerate up to 30 minutes of downtime and potential data loss. The solution does not need to handle the load when the primary infrastructure is healthy.<br>What should a solutions architect do to meet these requirements?</p>
<ol>
<li>âœ… Deploy the application with the required infrastructure elements in place. Use Amazon Route 53 to configure active-passive failover. Create an Aurora Replica in a second AWS Region.</li>
<li>Host a scaled-down deployment of the application in a second AWS Region. Use Amazon Route 53 to configure active-active failover. Create an Aurora Replica in the second Region.</li>
<li>Replicate the primary infrastructure in a second AWS Region. Use Amazon Route 53 to configure active-active failover. Create an Aurora database that is restored from the latest snapshot.</li>
<li>Back up data with AWS Backup. Use the backup to create the required infrastructure in a second AWS Region. Use Amazon Route 53 to configure active-passive failover. Create an Aurora second primary instance in the second Region.</li>
</ol>
<blockquote>
<p>âœ¨ å…³é”®è¯ï¼šDR</p>
</blockquote>
<blockquote>
<p>1ï¸âƒ£ âœ…</p>
</blockquote>
<blockquote>
<p>ğŸ’¡ è§£æï¼šå…¬å¸éœ€è¦ç¾å¤‡æ–¹æ¡ˆï¼Œå…è®¸ 30 åˆ†é’Ÿçš„ç¦»çº¿å’Œæ•°æ®ä¸¢å¤±ï¼Œä½†æ˜¯è¦æ±‚è¿™ä¸ªæ–¹æ¡ˆï¼ˆå®¹ç¾æ¶æ„ï¼‰åœ¨ä¸»æœåŠ¡æ­£å¸¸çš„æƒ…å†µä¸‹ä¸è¦å·¥ä½œã€‚<br>ä¸ºäº†è¾¾åˆ°ä¸»æœåŠ¡æ­£å¸¸çš„æƒ…å†µä¸‹ä¸å·¥ä½œçš„éœ€æ±‚ï¼Œéœ€è¦ä½¿ç”¨ <code>Amazon Route 53</code> çš„ <code>ä¸»åŠ¨/è¢«åŠ¨ (active-passive)</code> æ•…éšœè½¬ç§»ã€‚<br>å…³äº <code>ä¸»åŠ¨/ä¸»åŠ¨ (active-active)</code> å’Œ <code>ä¸»åŠ¨/è¢«åŠ¨ (active-passive)</code> çš„åŒºåˆ«ï¼š<a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/zh_cn/Route53/latest/DeveloperGuide/dns-failover-types.html">ä¸»åŠ¨&#x2F;ä¸»åŠ¨å’Œä¸»åŠ¨&#x2F;è¢«åŠ¨æ•…éšœè½¬ç§»</a>  </p>
<blockquote>
<p><strong>ä¸»åŠ¨&#x2F;ä¸»åŠ¨æ•…éšœè½¬ç§»</strong><br>å¦‚æœæ‚¨<u>å¸Œæœ›æ‰€æœ‰èµ„æºåœ¨å¤§éƒ¨åˆ†æ—¶é—´å†…éƒ½å¯ç”¨</u>ï¼Œå¯ä½¿ç”¨æ­¤æ•…éšœè½¬ç§»é…ç½®ã€‚å½“æŸä¸ªèµ„æºä¸å¯ç”¨æ—¶ï¼ŒRoute 53 å¯ä»¥æ£€æµ‹åˆ°å®ƒè¿è¡ŒçŠ¶å†µä¸ä½³å¹¶ä¸”åœæ­¢åœ¨å“åº”æŸ¥è¯¢æ—¶åŒ…å«è¯¥èµ„æºã€‚<br>åœ¨åŒæ´»æ•…éšœè½¬ç§»ä¸­ï¼Œå…·æœ‰ç›¸åŒåç§°ã€ç›¸åŒç±»å‹ï¼ˆä¾‹å¦‚ A æˆ– AAAAï¼‰å’Œç›¸åŒè·¯ç”±ç­–ç•¥ï¼ˆå¦‚åŠ æƒæˆ–å»¶è¿Ÿï¼‰çš„æ‰€æœ‰è®°å½•å¤„äºæ´»åŠ¨çŠ¶æ€ï¼Œé™¤é Route 53 è®¤ä¸ºå®ƒä»¬è¿è¡ŒçŠ¶å†µä¸è‰¯ã€‚Route 53 å¯ä»¥ä½¿ç”¨ä»»ä½•è¿è¡ŒçŠ¶å†µè‰¯å¥½çš„è®°å½•å“åº” DNS æŸ¥è¯¢ã€‚</p>
<p><strong>ä¸»åŠ¨&#x2F;è¢«åŠ¨æ•…éšœè½¬ç§»</strong><br>å¦‚æœæ‚¨å¸Œæœ›ä¸»èµ„æºæˆ–èµ„æºç»„åœ¨å¤§éƒ¨åˆ†æ—¶é—´å†…å¯ç”¨ï¼ŒåŒæ—¶<u>å¸Œæœ›è¾…åŠ©èµ„æºæˆ–èµ„æºç»„å¤„äºå¤‡ç”¨çŠ¶æ€ä»¥é˜²æ‰€æœ‰ä¸»èµ„æºå‡ä¸å¯ç”¨</u>ï¼Œå¯ä½¿ç”¨ä¸»åŠ¨&#x2F;è¢«åŠ¨æ•…éšœè½¬ç§»é…ç½®ã€‚å“åº”æŸ¥è¯¢æ—¶ï¼ŒRoute 53 å°†åªåŒ…å«è¿è¡ŒçŠ¶å†µè‰¯å¥½çš„ä¸»èµ„æºã€‚å¦‚æœæ‰€æœ‰ä¸»èµ„æºçš„è¿è¡ŒçŠ¶å†µéƒ½ä¸ä½³ï¼ŒRoute 53 å°†åªåœ¨ DNS æŸ¥è¯¢çš„å“åº”ä¸­åŒ…å«è¿è¡ŒçŠ¶å†µè‰¯å¥½çš„è¾…åŠ©èµ„æºã€‚</p>
</blockquote>
<p>4ï¸âƒ£ æ— ç–‘ä¹Ÿæ˜¯å¯ä»¥åšåˆ°æ¢å¤æ¶æ„çš„ï¼Œç¤¾åŒºé‡Œæœ‰äººæåˆ°äº† <code>AWS Backup</code> çš„ RTO æ˜¯ä»¥å°æ—¶è®¡ç®—çš„ï¼Œæˆ‘å¹¶æ²¡æœ‰æ‰¾åˆ°è¯¦ç»†çš„èµ„æ–™è¯´æ˜ã€‚ä½†æ˜¯å¯ä»¥è‚¯å®šçš„æ˜¯å®ƒä¸€å®šæ²¡æœ‰é€‰é¡¹ 1ï¸âƒ£ æ¢å¤å¾—å¿«ã€‚<br>4ï¸âƒ£ çš„å¤šä¸»æ•°æ®åº“ä»…é€‚ç”¨äº MySQL å¼•æ“ï¼Œä¸è¿‡åœ¨è¿™é‡Œå¹¶æ²¡æœ‰å¿…è¦ï¼Œåº”ç”¨éƒ½åœäº†ï¼Œæ•°æ®åº“è¿˜è·‘ç€æ²¡æœ‰æ„ä¹‰ã€‚  </p>
</blockquote>
<blockquote>
<p>ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦ ç¤¾åŒºè®¨è®ºï¼šAnything that is not instant recovery isactive - passive.<br>In active -passive we have:</p>
<ol>
<li>Aws Backup(least op overhead) - RTO&#x2F;RPO &#x3D; hours</li>
<li>Pilot Light ( Basic Infra isalready deployed, but needs to be fully implemented) -RTO&#x2F;RPO &#x3D; 10â€™s of minutes.</li>
<li>Warm Standby- (Basic infra + runs small loads ( might need to add auto scaling) -RTO&#x2F;RPO&#x3D; minutes</li>
<li>( ACTIVE -ACTIVE ) : Multi AZ option : instant</li>
</ol>
<p>here we can tolerate 30 mins<br>hence B,D are incorrect. AWS backup is in hours, hence D is incorrect.<br>therefore A</p>
</blockquote>
<hr>
<h3 id="åã€In-memory-tasks"><a href="#åã€In-memory-tasks" class="headerlink" title="åã€In-memory tasks"></a>åã€In-memory tasks</h3><p>A companyâ€™s application is having performance issues. The application is stateful and needs to complete in-memory tasks on Amazon EC2 instances. The company used AWS CloudFormation to deploy infrastructure and used the M5 EC2 instance family.<br>As traffic increased, the application performance degraded. Users are reporting delays when the users attempt to access the application.<br>Which solution will resolve these issues in the MOST operationally efficient way?  </p>
<ol>
<li>Replace the EC2 instances with T3 EC2 instances that run in an Auto Scaling group. Make the changes by using the AWS Management Console.</li>
<li>Modify the CloudFormation templates to run the EC2 instances in an Auto Scaling group. Increase the desired capacity and the maximum capacity of the Auto Scaling group manually when an increase is necessary.</li>
<li>Modify the CloudFormation templates. Replace the EC2 instances with R5 EC2 instances. Use Amazon CloudWatch built-in EC2 memory metrics to track the application performance for future capacity planning.</li>
<li>âœ… Modify the CloudFormation templates. Replace the EC2 instances with R5 EC2 instances. Deploy the Amazon CloudWatch agent on the EC2 instances to generate custom application latency metrics for future capacity planning.</li>
</ol>
<blockquote>
<p>âœ¨ å…³é”®è¯ï¼šin-memory tasks</p>
</blockquote>
<blockquote>
<p>4ï¸âƒ£ âœ…</p>
</blockquote>
<blockquote>
<p>ğŸ’¡ è§£æï¼šM5 å‹çš„ <code>EC2</code> è¿è¡Œå†…å­˜å‹ä»»åŠ¡å‡ºç°äº†æ€§èƒ½ç“¶é¢ˆã€‚é—®æœ‰ä»€ä¹ˆæœ€å…·æ“ä½œæ€§ä»·æ¯”çš„è¡Œä¸ºã€‚<br>1ï¸âƒ£ 2ï¸âƒ£ é€‰æ‹©äº†æ°´å¹³æ‰©å®¹ï¼›3ï¸âƒ£ 4ï¸âƒ£ é€‰æ‹©äº†å‚ç›´æ‰©å®¹å¹¶ç›‘æ§çŠ¶æ€ä¸ºä¹‹åçš„æ‰©å®¹è®¡åˆ’åšå‡†å¤‡ã€‚<br>æ˜¾ç„¶æ˜¯ 3ï¸âƒ£ 4ï¸âƒ£ æ›´åŠ åˆç†ã€‚<br>è¿‡ä¸€ä¸‹å„ç±»å‹çš„ <code>EC2</code> å®ä¾‹ï¼š<a target="_blank" rel="noopener" href="https://www.amazonaws.cn/ec2/instance-types/">Amazon EC2 å®ä¾‹ç±»å‹</a></p>
<blockquote>
<ul>
<li>M ç³»åˆ—ï¼ˆé€šç”¨å‹å®ä¾‹ï¼‰- æä¾›äº†è®¡ç®—ã€å†…å­˜å’Œç½‘ç»œèµ„æºçš„å¹³è¡¡ï¼Œå¯ç”¨äºå„ç§ä¸åŒçš„å·¥ä½œè´Ÿè½½ã€‚<blockquote>
<p>è¿™äº›å®ä¾‹éå¸¸é€‚åˆäºä»¥ç›¸ç­‰æ¯”ä¾‹ä½¿ç”¨è¿™äº›èµ„æºçš„åº”ç”¨ç¨‹åºï¼Œä¾‹å¦‚ Web æœåŠ¡å™¨å’Œä»£ç åº“ã€‚ </p>
</blockquote>
</li>
<li>C ç³»åˆ—ï¼ˆè®¡ç®—ä¼˜åŒ–å‹å®ä¾‹ï¼‰- æ˜¯è®¡ç®—é™åˆ¶å‹åº”ç”¨ç¨‹åºçš„ç†æƒ³é€‰æ‹©ï¼Œå¯ä»¥å—ç›Šäºé«˜æ€§èƒ½å¤„ç†å™¨ã€‚<blockquote>
<p>éå¸¸é€‚åˆäºæ‰¹å¤„ç†å·¥ä½œè´Ÿè½½ã€åª’ä½“è½¬ç ã€é«˜æ€§èƒ½ Web æœåŠ¡å™¨ã€é«˜æ€§èƒ½è®¡ç®—ï¼ˆHPCï¼‰ã€ç§‘å­¦å»ºæ¨¡ã€ä¸“ç”¨æ¸¸æˆæœåŠ¡å™¨å’Œå¹¿å‘ŠæœåŠ¡å™¨å¼•æ“ã€æœºå™¨å­¦ä¹ æ¨ç†å’Œå…¶ä»–è®¡ç®—å¯†é›†å‹åº”ç”¨ç¨‹åºã€‚</p>
</blockquote>
</li>
<li>R ç³»åˆ—ï¼ˆå†…å­˜ä¼˜åŒ–å‹å®ä¾‹ï¼‰- å†…å­˜ä¼˜åŒ–å‹å®ä¾‹æ—¨åœ¨ä¸ºå¤„ç†å†…å­˜ä¸­å¤§å‹æ•°æ®é›†çš„å·¥ä½œè´Ÿè½½æä¾›å¿«é€Ÿæ€§èƒ½ã€‚<blockquote>
<p>å†…å­˜å¯†é›†å‹å·¥ä½œè´Ÿè½½ï¼Œå¦‚å¼€æºæ•°æ®åº“ã€å†…å­˜ç¼“å­˜å’Œå®æ—¶å¤§æ•°æ®åˆ†æã€‚</p>
</blockquote>
</li>
</ul>
</blockquote>
</blockquote>
<blockquote>
<p>ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦ ç¤¾åŒºè®¨è®ºï¼šD is the correct answer.<br>â€œin-memory tasksâ€ &#x3D;&gt; need the â€œRâ€ EC2 instance type to archive memory optimization.So we are concerned about C &amp; D.<br>Because EC2 instances donâ€™t have built-in memory metrics to CW by default. Asa result, we have to install the CW agent to archive the purpose.</p>
</blockquote>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css"></div><div class="article-licensing box"><div class="licensing-title"><p>SAA è€ƒè¯•æ¯æ—¥ç»ƒä¹  - 2024/12/01</p><p><a href="https://senjianlu.com/2024/12/01/saa_test_daily_20241201/">https://senjianlu.com/2024/12/01/saa_test_daily_20241201/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>ä½œè€…</h6><p>Rabbir</p></div></div><div class="level-item is-narrow"><div><h6>å‘å¸ƒäº</h6><p>2024-12-01</p></div></div><div class="level-item is-narrow"><div><h6>æ›´æ–°äº</h6><p>2024-12-01</p></div></div><div class="level-item is-narrow"><div><h6>è®¸å¯åè®®</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="" rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/AWS/">AWS</a><a class="link-muted mr-2" rel="tag" href="/tags/SAA/">SAA</a><a class="link-muted mr-2" rel="tag" href="/tags/%E6%AF%8F%E6%97%A5%E7%BB%83%E4%B9%A0/">æ¯æ—¥ç»ƒä¹ </a></div><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/css/share.min.css"><div class="social-share"></div><script src="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2024/12/02/translate_news_nhk_20241202_k10014655341000/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">æ—¥è¯­ç¿»è¯‘ - æ–°é—» - ãƒãƒ³ã‚·ãƒ§ãƒ³â€œæŠ•è³‡ã‚ˆã‚Šå±…ä½ç›®çš„ã®äººã«â€ä¸å‹•ç”£ä¼šç¤¾ã«æ–°ãŸãªå‹•ã</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2024/12/01/song_lyric_hacking_to_the_gate/"><span class="level-item">æ—¥è¯­ç¿»è¯‘ - æ­Œè¯ - Hacking to the Gate</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card" id="comments"><div class="card-content"><h3 class="title is-5">è¯„è®º</h3><div class="content twikoo" id="twikoo"></div><script src="https://cdnjs.loli.net/ajax/libs/twikoo/1.6.30/twikoo.all.min.js"></script><script>twikoo.init({
            envId: 'https://qnoej4ws5b2lotcsig3lrcxvom0jlivf.lambda-url.us-west-2.on.aws/',
            
            lang: "zh-CN",
        });</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">ç›®å½•</h3><ul class="menu-list"><li><a class="level is-mobile" href="#ä¸€ã€Medical-information"><span class="level-left"><span class="level-item">ä¸€ã€Medical information</span></span></a></li><li><a class="level is-mobile" href="#äºŒã€DynamoDB-keep-data-for-30-days"><span class="level-left"><span class="level-item">äºŒã€DynamoDB keep data for 30 days</span></span></a></li><li><a class="level is-mobile" href="#ä¸‰ã€Amazon-Transcribe"><span class="level-left"><span class="level-item">ä¸‰ã€Amazon Transcribe</span></span></a></li><li><a class="level is-mobile" href="#å››ã€Amazon-Cognito-and-API-access"><span class="level-left"><span class="level-item">å››ã€Amazon Cognito and API access</span></span></a></li><li><a class="level is-mobile" href="#äº”ã€SMS-messages"><span class="level-left"><span class="level-item">äº”ã€SMS messages</span></span></a></li><li><a class="level is-mobile" href="#å…­ã€Data-Lake-and-fine-grained-permissions"><span class="level-left"><span class="level-item">å…­ã€Data Lake and fine-grained permissions</span></span></a></li><li><a class="level is-mobile" href="#ä¸ƒã€EC2-connect-to-S3"><span class="level-left"><span class="level-item">ä¸ƒã€EC2 connect to S3</span></span></a></li><li><a class="level is-mobile" href="#å…«ã€Files-convert"><span class="level-left"><span class="level-item">å…«ã€Files convert</span></span></a></li><li><a class="level is-mobile" href="#ä¹ã€Second-infrastructure-for-DR"><span class="level-left"><span class="level-item">ä¹ã€Second infrastructure for DR</span></span></a></li><li><a class="level is-mobile" href="#åã€In-memory-tasks"><span class="level-left"><span class="level-item">åã€In-memory tasks</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="adsense"><div class="card-content"><div class="menu"><h3 class="menu-label">å¹¿å‘Š</h3><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-7999470995937770" data-ad-slot="4944880547" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">æ£®è§é¹¿çš„åšå®¢</a><p class="is-size-7"><span>&copy; 2025 Rabbir</span>Â Â Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>Â &amp;Â <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">å…±<span id="busuanzi_value_site_uv">0</span>ä¸ªè®¿å®¢</span></p></div><div class="level-end"></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/js/column.js"></script><script type="text/javascript" id="MathJax-script" async>MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      chtml: {
        matchFontHeight: false
      }
    };</script><script src="https://cdnjs.loli.net/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js"></script><!--!--><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.10.0/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><script data-pjax src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container" id="algolia-input"></div><div id="algolia-poweredby" style="display:flex;margin:0 .5em 0 1em;align-items:center;line-height:0"></div><a class="searchbox-close" href="javascript:;">Ã—</a></div><div class="searchbox-body"></div><div class="searchbox-footer"></div></div></div><script src="https://cdnjs.loli.net/ajax/libs/algoliasearch/4.0.3/algoliasearch-lite.umd.js" crossorigin="anonymous" defer></script><script src="https://cdnjs.loli.net/ajax/libs/instantsearch.js/4.3.1/instantsearch.production.min.js" crossorigin="anonymous" defer></script><script src="/js/algolia.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadAlgolia({"applicationId":"7AJZPXBDT5","apiKey":"9912c3c2f115ee79e98f584754add4a8","indexName":"hexo-theme-icarus"}, {"hint":"æƒ³è¦æŸ¥æ‰¾ä»€ä¹ˆ...","no_result":"æœªæ‰¾åˆ°æœç´¢ç»“æœ","untitled":"(æ— æ ‡é¢˜)","empty_preview":"(æ— å†…å®¹é¢„è§ˆ)"});
        });</script></body></html>