{"posts":[{"title":"为 acme.sh 配置 Cloudflare 的 DNS 验证来申请泛域名 SSL 证书","text":"前言easycrawl.dev 网站需要一个 SSL 证书，但是不清楚后面会有多少子域名，因此直接申请泛域名证书吧。顺便提一下，dev 后缀的域名是强制使用 HTTPS 的，用 HTTP 访问可能会报以下错误： 网址为 https://easycrawl.dev/ 的网页可能暂时无法连接，或者它已永久性地移动到了新网址。ERR_SSL_UNRECOGNIZED_NAME_ALERT 方案概述 安装 acme.sh 配置 Cloudflare 的 DNS 验证 创建可以修改 Cloudflare DNS 的 API Token 配置 acme.sh 使用 Cloudflare 的 DNS 验证 申请泛域名 SSL 证书 安装 Nginx 安装证书并配置自动更新 配置 Nginx 使用 SSL 证书 操作步骤一、安装 acme.sh123456789# 安装所需软件apt-get install curlapt-get install socat# 安装 acmecurl https://get.acme.sh | sh# 添加软链接ln -s /root/.acme.sh/acme.sh /usr/local/bin/acme.sh# 查看 acme.sh 版本acme.sh --version 二、配置 Cloudflare 的 DNS 验证我是在 Namecheap 上注册的域名，因此需要先在 Namecheap 上配置 DNS 解析。进入控制台选择对应的域名，点击 Manage 进入域名管理页面：选择 Custom DNS 并填入 Cloudflare 分配给你的 Nameserver： 在你的 Cloudflare 控制台选择 加入域（添加域名）后继续操作，会在某一步提供给你两个 Nameserver： 三、创建可以修改 Cloudflare DNS 的 API Token进入 Cloudflare 的用户 API 令牌页面，选择 创建令牌：选择 编辑区域 DNS 的模板：选择特定的区域（域名）：之后一步步确认并创建即可。创建完成后，你就拥有了下面三个内容： token: xxxxxxxxxxxxxxxxx8faebc zone_id: 023e105f4ecefXXXXXxxxxxxxxx account_id: 023e105f4ecefXXXXXxxxxxxxxx 其中 zone_id 和 account_id 是固定的，token 是刚刚生成的。zone_id（区域 ID）和account_id（账户 ID）在 Cloudflare 对应域名的控制台右上角可以找到： 四、配置 acme.sh 使用 Cloudflare 的 DNS 验证其实只要设置一下环境变量即可： 123export CF_Token=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxexport CF_Zone_ID=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxexport CF_Account_ID=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 五、申请泛域名 SSL 证书1acme.sh --issue --dns dns_cf -d easycrawl.dev -d '*.easycrawl.dev' 如果出现下面的错误： [Sun Aug 31 13:33:01 BST 2025] Using CA: https://acme.zerossl.com/v2/DV90[Sun Aug 31 13:33:02 BST 2025] No EAB credentials found for ZeroSSL, let’s obtain them[Sun Aug 31 13:33:02 BST 2025] acme.sh is using ZeroSSL as default CA now.[Sun Aug 31 13:33:02 BST 2025] Please update your account with an email address first.[Sun Aug 31 13:33:02 BST 2025] acme.sh –register-account -m my@example.com[Sun Aug 31 13:33:02 BST 2025] See: https://github.com/acmesh-official/acme.sh/wiki/ZeroSSL.com-CA[Sun Aug 31 13:33:02 BST 2025] Please check log file for more details: /root/.acme.sh/acme.sh.log 则需要先随便使用一个邮箱注册一下： 1acme.sh --register-account -m example@example.com 之后再申请证书即可。 没问题的话，大概 30 秒证书就申请成功了： 六、安装 Nginx你可以简单地安装旧版本的 Nginx： 1apt-get install nginx 或者使用我的脚本来安装最新版的：rabbir/nginx.bash 七、安装证书并配置自动更新我习惯将证书安装到 /etc/nginx/ssl 目录下，因此使用下面的命令： 12345mkdir -vp /etc/nginx/ssl/easycrawl.devacme.sh --install-cert -d easycrawl.dev \\ --fullchain-file /etc/nginx/ssl/easycrawl.dev/certificate.crt \\ --key-file /etc/nginx/ssl/easycrawl.dev/private.key \\ --reloadcmd &quot;systemctl reload nginx&quot; 之后每隔大概 2 个月，acme.sh 会自动更新证书，并使用 systemctl reload nginx 重新加载 Nginx 来使用新的证书。 八、配置 Nginx 使用 SSL 证书我的 /etc/nginx/conf.d/default.conf 文件内容如下： 1234567891011121314151617181920212223242526272829303132# 非域名访问返回 500 错误server { listen 80; listen [::]:80; server_name _; location / { return 500; } # 特殊的证书认证用的路径 location /.well-known/acme-challenge/ { # acme.sh --webroot 模式，认证文件生成后放置的路径 root /var/acme/webroot/; }}# 非域名访问防止发送 SSL 证书server { listen 443 ssl default_server; server_name _; ssl_protocols TLSv1.2 TLSv1.3; # 启用拒绝 TLS 握手 ssl_reject_handshake on; # SSL Session 缓存，不设置的话无缓存配置不生效 ssl_session_cache shared:SSL:10m; ssl_session_timeout 10m; # log 位置自行替换 access_log /var/log/nginx/host.access.log;} 需要新建一下 api.easycrawl.dev.conf 文件来让子域名使用泛域名证书： 1vi /etc/nginx/conf.d/api.easycrawl.dev.conf 12345678910111213141516171819202122server { listen 443 ssl; server_name api.easycrawl.dev; # SSL 配置 ssl_certificate /etc/nginx/ssl/easycrawl.dev/certificate.crt; ssl_certificate_key /etc/nginx/ssl/easycrawl.dev/private.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; location / { proxy_pass http://127.0.0.1:8000; proxy_set_header Host $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-Port $server_port; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; # This allows the ability for the execute shell window to remain open for up to 15 minutes. Without this parameter, the default is 1 minute and will automatically close. proxy_read_timeout 900s; }} 之后重启 Nginx 即可： 1systemctl reload nginx 不一样版本的 Nginx 支持的配置不一样，一般出错的话删除对应的配置项即可。 再次访问 https://api.easycrawl.dev/docs 就可以看到 SSL 证书已经生效了：结束。 参考资料： acme+cloudflare生成免费证书（自动续期）","link":"/2025/08/31/acme_cloudflare_certificate_ssl/"},{"title":"使用 AWS Lambda 构建 Twikoo 静态网站评论系统并在 Icarus 主题中使用","text":"前言看到篇用 AWS 部署 Twikoo 评论和说说系统帖子，恰巧博客的评论功能一直没有开启，而且最近在准备 AWS 相关的考试，正好动手实践下 AWS Lambda。暂时不开启图片评论功能。 方案概述可行性 数据库使用官方推荐的 MongoDB Atlas，数据容量在 500 MiB 内是免费的。 后端使用 AWS Lambda，每月提供 100 万个免费请求和长达 320 万秒的计算时间。 流程 设置 Mongodb Atlas 数据库 将 Twikoo 的 API 服务部署到 AWS Lambda Icarus 主题中启用 Twikoo 评论功能 测试评论功能 操作步骤一、设置 Mongodb Atlas 数据库 官方文档：MongoDB Atlas 创建免费的集群，推荐地区选择 AWS 的 us-west-2，因为后面部署 AWS Lambda 也是在这个地区：设置用户名和密码：之后创建用户，后面是选择用什么方式连接数据库，一路下一步即可。之后允许所有 IP 连接到该数据库：之后回到数据库处，点击 Connect，选择 Connect your application，之后复制连接字符串： 1mongodb+srv://mongodb:&lt;db_password&gt;@twikoo.&lt;place&gt;.mongodb.net/?retryWrites=true&amp;w=majority&amp;appName=Twikoo 二、将 Twikoo 的 API 服务部署到 AWS Lambda 官方文档：AWS Lambda 部署 因为没有什么经验，就用官方推荐的 Terraform CLI 方式进行部署。关于 Terraform 详细的安装和 AWS 云服务提供商配置过程，可以参考我的另一片文章：Mac 下安装 Terraform 基础结构即代码工具，并添加 AWS 云服务提供商 当你确保你的环境可用后，下载部署 Twikoo 用的文件：twikoo/src/server/aws-lambda 12git clone https://github.com/twikoojs/twikoo.gitcd twikoo/src/server/aws-lambda 然后进入到 terraform 目录，修改存放变量的 variables.tf 文件： 123456789101112131415161718192021222324# === AWS Provider 相关 ===variable &quot;region&quot; { description = &quot;AWS region to deploy the function in.&quot; # AWS 区域，我这里也是 us-west-2 因此不用修改 default = &quot;us-west-2&quot;}# AWS 访问密钥variable &quot;access_key&quot; { default = &quot;AKIA5J2Z5J2Z5J2Z5J2Z&quot;}# AWS 秘密密钥variable &quot;secret_key&quot; { default = &quot;cpt_jqc7TUG6mtg1avjzce*quq4BXQ8gec&quot;}# === MongoDB 相关 ===variable &quot;mongodb_uri&quot; { description = &quot;MongoDB connection URI. The value will be passed to the Lambda function as environment variable MONGODB_URI.&quot; sensitive = true # 之前复制的 MongoDB 连接字符串 default = &quot;mongodb+srv://mongodb:&lt;db_password&gt;@twikoo.&lt;place&gt;.mongodb.net/?retryWrites=true&amp;w=majority&amp;appName=Twikoo&quot;} 然后修改下 main.tf 文件中的 provider 部分： 123456provider &quot;aws&quot; { region = var.region # 新增下面两行 access_key = var.access_key secret_key = var.secret_key} 之后就可以部署了： 12terraform initterraform apply 稍等片刻就部署完成了： 访问 API Gateway 的 URL，可以看到 Twikoo 的 API 服务已经部署成功了： 1{&quot;code&quot;:100,&quot;message&quot;:&quot;Twikoo 云函数运行正常，请参考 https://twikoo.js.org/frontend.html 完成前端的配置&quot;,&quot;version&quot;:&quot;1.6.39&quot;} 三、Icarus 主题中启用 Twikoo 评论功能 官方文档：Twikoo 修改下 _config.icarus.yml 文件： 123456# 评论系统comment: type: twikoo # Twikoo 的 API 服务地址 env_id: https://xxxxxxxxxxxxxxxxxxxxxxxxxxx.lambda-url.us-west-2.on.aws/ lang: zh-CN 再次部署后，访问页面就能看到评论框了： 四、测试评论功能输入下评论： 单条评论对于 MongoDB Atlas 数据库 500 MiB 免费容量的占用几乎可以忽略不计。而消耗 AWS Lambda 1 次请求、2.1 秒左右的计算时间，对于免费的 100 万次请求和 320 万秒的计算时间来说也是微不足道的： 由于没有设置图床，因此无法上传图片：开启的话大概会被灰产刷吧 🤦 就不开了。 【系统设计】用 AWS 部署 Twikoo 评论和说说系统 基于腾讯云，给你的 Icarus 博客配上 Twikoo 评论系统","link":"/2024/10/02/aws_lambda_twikoo_icarus/"},{"title":"【归档文章】分布式配置中心 Apollo 的使用（一）构建 Apollo 的 Docker 容器镜像并连接到现有数据库","text":"关于部署 Apollo 的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 优化之前组的 K3s 集群的时候，想到每次配置文件的小修小改都要重启一大堆容器实在麻烦，只怪最初没考虑完全，趁这次机会起一个配置中心来解决这个麻烦。 ① 什么是配置中心？配置中心将配置从各应用中剥离出来，对配置进行统一管理，应用自身不需要自己去管理配置，可以参考下图：② 为什么选择 Apollo？携程开源且 GitHub 更新勤快，截止 2022 年 1 月 5 日还在更新。具体可以参照这篇文章：分布式配置中心（Nacos、Apollo）选型比较 Apollo 的运行需要 8 GB 左右的内存，如果你的服务器配置低于 2 核 8 GB，那就不用尝试了。​官方给了 2 种方式来部署 Apollo：在服务器中直接启动和使用 Docker 启动，在服务器中直接启动就不用说了，而官方所使用的 Docker 镜像：nobodyiam/apollo-quick-start 是自带 MySQL 数据库的，我并不需要，于是就只能自己构建了。我希望最终容器可以和 apolloconfig/apollo-configservice 启动命令一样（并不是官方镜像因此不使用），能够指定数据库连接。我的 Dockerfile 文件：Apollo-docker我构建完的 Docker 镜像：rabbir/apollo 1、安装和配置 Apollo 运行环境 官方描述的运行环境： Linux JDK（1.8 以上，推荐 1.8） MySQL（5.65 及以上，我有外置的数据库因此不做安装） ① 直接拉取一个 CentOS7 的镜像： 1234# 拉取镜像docker pull centos:centos7# 运行镜像docker run -it docker.io/centos:centos7 /bin/bash 之后的命令都是在容器内执行！ ② 安装 JDK1.8： 123456789101112# 安装位置cd /usr/local/yum -y install wget# 下载压缩包wget --no-check-certificate --no-cookies --header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.tar.gz# 解压并重命名tar -zxvf jdk-8u131-linux-x64.tar.gzmv jdk1.8.0_131 jdk1.8# 删除压缩包rm -f jdk-8u131-linux-x64.tar.gz# 配置环境变量vi ~/.bashrc 新增以下两行： 12345678......# Java 相关export JAVA_HOME=/usr/local/jdk1.8export PATH=$PATH:$JAVA_HOME/binexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar...... 使配置生效： 123source ~/.bashrc# 确认 Java 版本java -version 2、下载 Apollo Quick Start 安装包官方文档中对应的位置：下载 Quick Start 安装包项目地址：nobodyiam/apollo-build-scripts 123yum -y install git# 克隆项目git clone https://github.com/nobodyiam/apollo-build-scripts 修改一下 demo.sh 使其能从环境变量中读取数据库连接信息： 12sed -i 's#jdbc:mysql://localhost:3306/ApolloConfigDB?characterEncoding=utf8&amp;serverTimezone=Asia/Shanghai#$APOLLO_CONFIG_DB_JDBC#' /usr/local/apollo-build-scripts/demo.shsed -i 's#&quot;dbc:mysql://localhost:3306/ApolloPortalDB?characterEncoding=utf8&amp;serverTimezone=Asia/Shanghai#$APOLLO_PORTAL_DB_JDBC#' /usr/local/apollo-build-scripts/demo.sh 原本的片段： 123456789# apollo config db infoapollo_config_db_url=&quot;jdbc:mysql://localhost:3306/ApolloConfigDB?characterEncoding=utf8&amp;serverTimezone=Asia/Shanghai&quot;apollo_config_db_username=${APOLLO_CONFIG_DB_USERNAME:-root}apollo_config_db_password=${APOLLO_CONFIG_DB_PASSWORD:-}# apollo portal db infoapollo_portal_db_url=&quot;jdbc:mysql://localhost:3306/ApolloPortalDB?characterEncoding=utf8&amp;serverTimezone=Asia/Shanghai&quot;apollo_portal_db_username=${APOLLO_PORTAL_DB_USERNAME:-root}apollo_portal_db_password=${APOLLO_PORTAL_DB_PASSWORD:-} 修改后的片段： 123456789# apollo config db infoapollo_config_db_url=&quot;$APOLLO_CONFIG_DB_JDBC&quot;apollo_config_db_username=${APOLLO_CONFIG_DB_USERNAME:-root}apollo_config_db_password=${APOLLO_CONFIG_DB_PASSWORD:-}# apollo portal db infoapollo_portal_db_url=&quot;$APOLLO_PORTAL_DB_JDBC&quot;apollo_portal_db_username=${APOLLO_PORTAL_DB_USERNAME:-root}apollo_portal_db_password=${APOLLO_PORTAL_DB_PASSWORD:-} 3、构建 Docker 容器镜像并运行① 配置一下 Apollo 运行所需要的数据库结构，需要新增两个 DB：ApolloPortalDB 和 ApolloConfigDB，文档中的位置：2.1 创建数据库我是买的腾讯云数据库，因此直接在网页端执行（需要手动创建数据库后选定数据库执行剩下的语句，部分 SET 语句出错可以跳过）：之后检查一下： 12-- 检查 ApolloPortalDBselect `Id`, `AppId`, `Name` from ApolloPortalDB.App; Id AppId Name 1 SampleApp Sample App ApolloConfigDB 同理，创建数据库并建表之后检查： 12-- 检查 ApolloConfigDBselect `NamespaceId`, `Key`, `Value`, `Comment` from ApolloConfigDB.Item; NamespaceId Key Value Comment 1 timeout 100 sample timeout配置 ② 将上述所有命令写入 Dockerfile（部分命令如环境变量的配置会有所不同）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 基础镜像系统版本为 CentOS:7FROM centos:7# 维护者信息LABEL maintainer=&quot;Rabbir admin@cs.cheap&quot;# Docker 内用户切换到 rootUSER root# 设置时区为东八区ENV TZ Asia/ShanghaiRUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime &gt; /etc/timezone# 安装 Git 和 WgetRUN yum -y install wgetRUN yum -y install git# 切换到 /usr/local/ 目录下WORKDIR /usr/local/# 下载解压 JDKRUN wget --no-check-certificate --no-cookies --header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.tar.gzRUN tar -zxvf jdk-8u131-linux-x64.tar.gzRUN mv jdk1.8.0_131 jdk1.8RUN rm -f jdk-8u131-linux-x64.tar.gz# 添加容器内的永久环境变量RUN sed -i &quot;2 a export JAVA_HOME=/usr/local/jdk1.8&quot; /etc/profileRUN sed -i &quot;3 a export PATH=\\$PATH:\\$JAVA_HOME/bin&quot; /etc/profileRUN sed -i &quot;4 a export CLASSPATH=.:\\$JAVA_HOME/lib/dt.jar:\\$JAVA_HOME/lib/tools.jar&quot; /etc/profileRUN source /etc/profileRUN sed -i '1 a source /etc/profile' ~/.bashrcRUN source ~/.bashrc# 添加构建用的临时环境变量ENV JAVA_HOME /usr/local/jdk1.8ENV PATH $PATH:$JAVA_HOME/binENV CLASSPATH .:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar# 克隆源码并修改 demo.sh 文件WORKDIR /usr/local/RUN git clone https://github.com/nobodyiam/apollo-build-scriptsWORKDIR /usr/local/apollo-build-scripts/RUN sed -i 's#jdbc:mysql://localhost:3306/ApolloConfigDB?characterEncoding=utf8&amp;serverTimezone=Asia/Shanghai#$APOLLO_CONFIG_DB_JDBC#' demo.shRUN sed -i 's#jdbc:mysql://localhost:3306/ApolloPortalDB?characterEncoding=utf8&amp;serverTimezone=Asia/Shanghai#$APOLLO_PORTAL_DB_JDBC#' demo.sh# 创建启动脚本RUN echo &quot;/bin/bash /usr/local/apollo-build-scripts/demo.sh start &amp;&amp; tail -f /dev/null&quot; &gt; start.sh# 启动命令ENTRYPOINT [&quot;/bin/bash&quot;, &quot;start.sh&quot;]CMD [&quot;&quot;] 构建（镜像名和版本自行替换）： 1docker build -t rabbir/apollo:latest . ③ 启动并登录管理界面Apollo 启动会用到三个端口： 8070（Apollo Portal 管理界面端口） 8080（提供配置的读取、推送等功能，服务对象是 Apollo 的各客户端） 8090（提供配置的修改、发布等功能，服务对象是 Apollo Portal） 暂时不做文件夹的映射，因此启动命令如下（数据库连接信息自行更改）： 1234567891011docker run --name apollo -d \\ -p 18070:8070 \\ -p 18080:8080 \\ -p 18090:8090 \\ -e APOLLO_CONFIG_DB_JDBC=&quot;jdbc:mysql://127.0.0.1:3306/ApolloConfigDB?characterEncoding=utf8&quot; \\ -e APOLLO_CONFIG_DB_USERNAME=&quot;myusername&quot; \\ -e APOLLO_CONFIG_DB_PASSWORD=&quot;mypassword&quot; \\ -e APOLLO_PORTAL_DB_JDBC=&quot;jdbc:mysql://127.0.0.1:3306/ApolloPortalDB?characterEncoding=utf8&quot; \\ -e APOLLO_PORTAL_DB_USERNAME=&quot;myusername&quot; \\ -e APOLLO_PORTAL_DB_PASSWORD=&quot;mypassword&quot; \\ rabbir/apollo:latest 启动并查看日志： 1docker logs apollo 显示如上则说明没有问题，确保防火墙和安全组开放的情况下就能去访问管理界面了，登录账号为 apollo 密码为 admin（我将容器的 8070 端口映射到了宿主机的 18070 端口上）： 成功，结束。","link":"/2022/01/06/bak_apollo_note_01/"},{"title":"【归档文章】CentOS7 下安装 code-server","text":"关于部署 code-server 的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 记录下 code-server 从官方源下载安装并配置 HTTPS 的过程。 官方 GitHub 项目地址：code-server 1、下载安装选个中意的 Release 下载并解压： 123456# 下载wget https://github.com/cdr/code-server/releases/download/v3.11.0/code-server-3.11.0-linux-amd64.tar.gz# 解压tar -xzvf code-server-3.11.0-linux-amd64.tar.gz# 转移到你想转移的目录mv code-server-3.11.0-linux-amd64 /usr/local/code-server 2、配置账号密码和启动端口code-server 的配置文件目录：~/.config/code-server/config.yaml先启动一下生成目录： 1/usr/local/code-server/code-server 然后停止掉程序后修改配置文件：注：cert 可以选择为 false，后面再 Nginx 处配置证书即可。 1234bind-addr: 0.0.0.0:8080auth: passwordpassword: $passwordcert: false 再启动即可。加入开机自启动： 12echo &quot;@reboot /usr/local/code-server/code-server&quot; &gt;&gt; /var/spool/cron/rootservice crond restart 3、配置 Nginx 反代和开启 SSL 证书注：自行替换 example.com 为你的域名和修改 SSL 证书所在位置。 123456789101112131415161718192021222324252627...server { listen 80; server_name example.com; return 301 https://$host$request_uri;}server { listen 443 ssl; server_name example.com; # SSL 配置 ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_certificate cert/1_example.com_bundle.crt; ssl_certificate_key cert/2_example.com.key; # 反代 8080 端口的 code-server location / { proxy_pass http://localhost:8080; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; proxy_set_header Host $host; }}... 至此完成，以上。","link":"/2021/07/22/bak_centos7_code_server/"},{"title":"【归档文章】CentOS7 下用 Docker 部署 Firefox 以实现浏览器套浏览器访问被屏蔽的网站","text":"关于 Docker 配置代理的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 公司用的日本专线，日方为了防止上班摸鱼把博客园都屏蔽了，使用中文搜索问题检索结果永远只有 CSDN 和内容农场……恰巧看到这个贴子：使用 Docker 安装 Firefox 浏览器让小鸡发光发热，看了下最终的效果是能在浏览器标签内构建一个 Firefox 浏览器，无视本机的任何防火墙限制，立马决定试下。 最终的效果如下，你可以先确定是否符合你的需求再往下看，说一句视频是肯定看不了的，页面的刷新能看到较为明显的渲染过程：且请使用 2 核以上的服务器，1H2G 服务器在页面刷新时占用如下： 1、安装 Docker 和下载 Firefox 容器镜像一笔带过 CentOS7 下 Docker 的安装和启动： 12yum -y install dockerservice docker start 下载镜像，Docker Hub 地址：jlesage/firefox 1docker pull jlesage/firefox 2、启动容器基础启动命令： 1234567891011docker run -d \\--name=firefox \\-e TZ=Asia/Hong_Kong \\-e DISPLAY_WIDTH=1920 \\-e DISPLAY_HEIGHT=1080 \\-e KEEP_APP_RUNNING=1 \\-e ENABLE_CJK_FONT=1 \\-e VNC_PASSWORD=my_password \\-p 80:5800 \\--security-opt seccomp=unconfined --shm-size 4000m \\jlesage/firefox 参数解析： 参数 解释 样例 TZ 时区。 Asia/Hong_Kong DISPLAY_WIDTH 浏览器分辨率长。 1920 DISPLAY_HEIGHT 浏览器分辨率高。 1080 KEEP_APP_RUNNING 是否保持运行。不保持的话选 0，即所有标签关闭后容器停止。 1 ENABLE_CJK_FONT 字体选项？反正不开启中文会乱码。 1 VNC_PASSWORD 访问密码。 my_password 端口映射不说了，容器内的 5800 端口映射到宿主机的 80 端口，这样就能直接用宿主机的 IP 访问服务了；--security-opt seccomp=unconfined 允许容器执行全部的系统的调用，即给予容器最大权限；--shm-size 4000m 限制容器内存占用。 开放端口和安全组之后，直接使用服务器 IP 访问即可： 由于我使用的是 Linode 的赠金开的服务器，而且是上班开机下班删机的那种，因此暂时没有再做进一步的安全配置。 结束。","link":"/2021/12/15/bak_centos7_docker_firefox_in_browser/"},{"title":"【归档文章】CentOS7 下用 Docker 部署 Odoo 开源 ERP 系统（企业资源规划及客户关系管理系统）","text":"关于部署 Odoo ERP 的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 身边有个需求需要对接现有的进销存系统再做管理，于是就找了一下有无开源软件，发现了这个 24k Star 的项目 Odoo，文档完善且社区活跃，同时官方有提供付费版的企业版本，应该有能力长久维护的，用这篇博文记录下部署过程吧。 官网：https://www.odoo.com/zh_CNGitHub 地址：https://github.com/odoo/odoo 1、配置数据库Odoo 有且仅支持 PostgreSQL 数据库，且需要获取完整的权限，因此推荐单独部署一个 PostgreSQL 数据库容器给它使用，参照 Docker Hub 页面上的命令，我这里选择的数据库版本是 postgres:13： 1docker run -d --name odoo-db -e POSTGRES_USER=odoo -e POSTGRES_PASSWORD=odoo -e POSTGRES_DB=postgres -v /rab/docker/odoo-db/data:/var/lib/postgresql/data -p 5432:5432 postgres:13 执行后稍等片刻，看下日志确认启动成功： 1docker logs odoo-db 2、启动 Odoo使用 Docker 启动的话，有两种方式连接数据库：① 通过 Docker 容器之间的虚拟网络 --link 使用容器名进行连接： 1docker run -p 8069:8069 --name odoo --link odoo-db:db -t odoo:15 ② 手动配置数据库连接： 1docker run -p 8069:8069 --name odoo -e HOST=$db_host -e PORT=$db_port -e USER=odoo -e PASSWORD=odoo odoo:15 我比较推荐第二种，我个人在实际部署中自定义了数据库密码，因此也只能使用第二种连接方式。 3、配置 OdooOdoo 容器启动完成后，就能通过 http://IP:8069 进行访问了，首次登录需要配置主密码和数据库名字等信息：之后点击创建数据库，就能跳到主页面了：后面模块就看你自己需要添加。 结束。","link":"/2022/02/19/bak_centos7_docker_odoo/"},{"title":"【归档文章】CentOS7 下用 Docker 部署 Peer2Profit 出售流量赚取收益","text":"关于用 Docker 部署 Peer2Profit 节点的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 之前在主机论坛看到了这个帖子：挖 Peer2Profit 网赚回血保姆级教程 支持 Windows/Debian/Ubuntu/Android，想到自己还有 40 来台小鸡，闲着也是闲着索性都挂上来回点本钱吧。这篇教程是在我挂了 1 天后写的，这期间主机商（主要是 VirMach 和 Sentris）并未发来警告邮件，我检查了实际的日志，起了 Peer2Profit 的容器除了对 api.peer2profit.global 进行访问以保持在线状态，其他流量均是加密的，而且目标地址均为 IP 形式，也就是说即使用以违规用途也不会触发 ToS，可以放心食用，唯一的坏处是你的 IP 可能会变脏。当然，请不要用国内主机挂这个！不仅是因为收益很少（实测一天就只会跑大概 20 MB 左右的流量，官方给的价格是 $0.8/GB），更需要担心的是被不法分子用以电信诈骗而导致的后续问题。​ 明确风险后那我们就开始吧！ 1、了解收益官方给的收益预期是单主机一个月 2 美刀左右：而实际上被标识为 IDC 机房的 IP 不会有这么高的收益，实际价目表为：我跑了将近 1 天，实际消耗流量分别为（residential 为家宽，hosting 为机房 IP，我在同主机上开了 4 个容器试试流量会不会叠加，因此后 4 个流量需要累加）：大致就能估算出家宽 IP 每月消耗流量在 150 MB 左右，收益为 0.1 美刀左右；而机房 IP 则在 100 MB 左右，收益为 0.03 美刀。不能说很少，只能说基本没有…… 2、注册账号如果这点收益你能接受，或者说你对自己的 IP 很有自信的话，那么就来试一试吧。访问 https://peer2profit.com 并注册账号： 如果愿意的话你可以填入我的邀请码：164194907761de27958da86，我将会得到你赚取金额的额外 50% 作为奖励，而你实际的赚取金额不会有任何减少。 后续你的邮箱会被用以软件的启动和绑定。 3、下载官方容器镜像官方只提供了 .deb 格式的安装文件，在 CentOS7 系统上安装极为麻烦，因此这里使用官方的 Docker 容器镜像来启动。镜像地址：peer2profit/peer2profit_x86_64直接在服务器上执行： 1docker pull peer2profit/peer2profit_x86_64:latest 如果你还没有安装 Docker 的话，使用下面的指令安装和开启开机自启动： 123yum -y install dockersystemctl start docker.servicesystemctl enable docker.service 4、启动容器启动较为简单： 1docker run -d --name peer2profit --restart always --env P2P_EMAIL=test@example.com peer2profit/peer2profit_x86_64:latest 只需要把邮箱 test@example.com 替换为你注册账号的邮箱即可，启动后稍等片刻查看下容器内的运行状况： 1docker logs peer2profit 如上说明启动成功，前往 Peer2Profit 的控制面板，选择 My network 之后应该就能看到这个节点了：之后静待收益入账即可。 如果想停止的话，直接关闭和删除容器即可： 12docker stop peer2profitdocker rm peer2profit 5、关于提现官方支持多种虚拟货币提现，我推荐莱特币、USDT 和币安智能链上的代币，因为他们转账所需要的油费相对更少： 关于 MetaMask 钱包的安装和币安智能链的添加，可以看我这篇教程：基于以太坊 ETH 的智能合约学习（一）下载和使用小狐狸钱包 MetaMask（Chrome 插件版）并添加 BSC 主网络进行 BNB 转账 结束。","link":"/2022/01/15/bak_centos7_docker_peer2profit/"},{"title":"【归档文章】CentOS7 下 Docker 配置代理以解决国内服务器无法拉取官方镜像的问题（需要账号密码的代理也可使用）","text":"关于 Docker 配置代理的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 国内服务器访问不到各种官方镜像应该是老生常谈的问题了，Docker 也不例外，拉取官方镜像时各种 EOF 错误大概率就是墙的问题了，这篇文档不会记录 Linux 整体环境代理的配置方法，只会配置 Docker 的。 1、首先确定你的代理可以被稳定访问：12345# 相关参数自行替换，如果不需要认证信息可以直接跳到第 2 步# HTTP 代理curl -x http://$username:$password@$host:$port http://ip-api.com/json/?lang=zh-CN# SOCKS5 代理 curl -x socks5://$username:$password@$host:$port http://ip-api.com/json/?lang=zh-CN 如果你的代理需要认证信息，那么是不能直接被配置到 Docker 的配置文件中的，如果强行配置的话，运行时会出现以下信息：光从代理打码长度也能看到根本没有使用账号密码去访问代理。你需要做的是使用 GOST 做转发，在本地搭建一个无需账号密码的长久代理： 123456789101112# 从我的 Gitee 仓库下载 GOST 压缩包curl -s https://gitee.com/senjianlu/one-click-scripts/raw/main/CentOS7%20%E4%B8%8B%E4%B8%8B%E8%BD%BD%20Gitee%20%E8%B6%85%E8%BF%87%201%20MB%20%E5%A4%A7%E5%B0%8F%E7%9A%84%E6%96%87%E4%BB%B6/download.sh | bash -s https://gitee.com/senjianlu/one-click-scripts/raw/main/mirror/GOST/gost-linux-amd64-2.11.1.gz# 解压gunzip gost-linux-amd64-2.11.1.gz# 转移到 /usr/bin 使其在任意目录都可执行mv gost-linux-amd64-2.11.1 /usr/bin/gostchmod 777 /usr/bin/gost# 开启开机自启动，本地端口和代理信息自行替换echo &quot;@reboot gost -L :$local_port -F=socks5://$username:$password@$host:$port&quot; &gt;&gt; /var/spool/cron/rootservice crond restart# nohup 启动在后台nohup gost -L :$local_port -F=socks5://$username:$password@$host:$port &gt;/dev/null 2&gt;&amp;1 &amp; 接着测试本地代理是否正常，和最上面的测试方法一样，不过不需要账号密码了。 1curl -x socks5://127.0.0.1:$local_port http://ip-api.com/json/?lang=zh-CN 2、配置 Docker 代理。参照文档：Control Docker with systemd此方法配置的代理对 Docker 长久有效，如果你的代理失效了及时修改 GOST 的转发配置即可。 12# 为 Docker 服务创建一个内嵌的 systemd 目录mkdir -p /etc/systemd/system/docker.service.d 创建 /etc/systemd/system/docker.service.d/http-proxy.conf 文件， 1vi /etc/systemd/system/docker.service.d/http-proxy.conf 文件内容如下，只需要这 3 行即可： 123[Service]Environment=&quot;HTTP_PROXY=socks5://127.0.0.1:$local_port&quot;Environment=&quot;HTTPS_PROXY=socks5://127.0.0.1:$local_port&quot; 然后重新加载配置，确定下代理配置没问题后重启即可。 123456# 重新加载配置systemctl daemon-reload# 查看配置是否生效systemctl show --property=Environment docker# 无误后重启systemctl restart docker 然后就去 Pull 需要的镜像吧！","link":"/2021/07/22/bak_centos7_docker_pull_proxy/"},{"title":"【归档文章】CentOS7 下 Docker 启动的 RabbitMQ 开启 WebSocket 以使用 JavaScript 进行连接","text":"关于使 RabbitMQ 支持 WebSocket 连接的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 自用的油猴脚本需要追加一个消息推送的功能，决定用 RabbitMQ 消费者的方式实现，但是看了下 JavaScript 连接 RabbitMQ 一般都是加装 STOMP 相关的插件使其支持 WebSocket 连接方式。我的 RabbitMQ 是 Docker 直接启动的，需要进入容器里执行，和一般的安装版本有些区别，于是还是决定记录一下顺便写个 JS 的例子。 1、Docker 启动 RabbitMQ一笔带过了： 1docker run -d --name rabbitmq --restart=always -p 5672:5672 -p 15672:15672 -p 15674:15674 rabbitmq:3.9-management 注意这里的 15674 端口是用以 WebSocket 连接的，一定要配置映射并在宿主机上开放！如果你之前没有开启的话，请停止容器并手动修改配置文件后重启。① 停止容器： 123456# 查看所有容器，并记录 CONTAINER IDdocker ps -a# 停止容器docker stop 164xxxxxx282# 停止 Docker 服务service docker stop ② 修改对应容器的配置文件，首先进入文件夹： 1cd /var/lib/docker/containers/$CONTAINER_ID/ 修改第一个配置文件： 1vi hostconfig.json 123456789......{ &quot;PortBindings&quot;:{ &quot;15674/tcp&quot;:[{&quot;HostIp&quot;:&quot;&quot;,&quot;HostPort&quot;:&quot;15674&quot;}] }}...... 修改第二个配置文件 1vi config.v2.json 123456789......{ &quot;ExposedPorts&quot;:{ &quot;15674/tcp&quot;:{} }}...... ③ 重启 Docker 服务和容器： 12service docker startdocker start $CONTAINER_ID 再检查容器就可以看到 15674 端口映射好了。 确保宿主机对应端口和防火墙开启后，访问 http://IP:15672 就可以访问到管理页面，账户密码均为 guest：同时可以看到当前是 STOMP 相关服务的监听端口的。 2、进入容器安装 STOMP 相关插件进入 RabbitMQ 容器： 1docker exec -it $CONTAINER_ID /bin/bash 安装 STOMP 相关插件： 1rabbitmq-plugins enable rabbitmq_web_stomp rabbitmq_web_stomp_examples 之后退出容器。 3、重启容器执行： 1docker restart $CONTAINER_ID 重启之后回到管理页面，看到有 stomp 服务和其监听端口就说明成功了： 4、JavaScript 连接样例12345678910111213141516171819202122232425262728293031323334353637383940&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;RabbitMQ WebSocket 测试页面&lt;/title&gt; &lt;!-- 依赖的包 --&gt; &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/stomp.js/2.3.3/stomp.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/sockjs-client/1.6.0/sockjs.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; // 连接信息，自行替换 IP var yourIp = &quot;127.0.0.1&quot;; var ws = new WebSocket(&quot;ws://&quot;+yourIp+&quot;:15674/ws&quot;); var client = Stomp.over(ws); // 禁用心跳 client.heartbeat.outgoing = 0; client.heartbeat.incoming = 0; // 连接成功的回调函数 var on_connect = function(x) { // 消费者 client.subscribe(&quot;/queue/queue&quot;, function(data) { var msg = data.body; $(&quot;#message&quot;).append(&quot;收到数据：&quot; + msg); }); }; // 出错时的回调函数 var on_error = function() { console.log(&quot;error&quot;); }; // 连接RabbitMQ，用户密码请自行替换 client.connect(&quot;guest&quot;, &quot;guest&quot;, on_connect, on_error, &quot;/&quot;); console.log(&quot;已连接至 RabbitMQ！&quot;); &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;/body&gt;&lt;/html&gt; 启动页面后，去控制台查看下日志：运行正常的话到管理页面确定队列状态：插入一条信息确认回调函数正常： 结束。","link":"/2021/04/01/bak_centos7_docker_rabbitmq_websocket/"},{"title":"【归档文章】CentOS7 下 Docker 部署 RedisInsight Redis 网页版的可视化工具","text":"关于部署 RedisInsight Redis 网页版的可视化工具的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 Redis Desktop Manager 在 Windows 下占用太多内存，且在 M1 版本的 Macbook 上安装老是出错，于是决定换成网页版的可视化工具。注意：RedisInsight 无法配置账户密码认证，因此请不要在公网服务器上部署！ 1、拉取 Docker 镜像Docker Hub 地址：https://hub.docker.com/r/redislabs/redisinsight/tags执行： 1docker pull redislabs/redisinsight:latest 2、配置持久化和启动容器内的 \\db 目录下会存放配置文件和数据，因此需要在宿主机上建立挂载用文件夹并映射以实现持久化： 需要先设置好挂载用文件夹的权限，不然会出现 PermissionError: [Errno 13] Permission denied: '/db/rsnaps' 错误。 1chown -R 1001 /rab/docker/redisinsight 1docker run --name redisinsight -d -v /rab/docker/redisinsight:/db -p 8001:8001 redislabs/redisinsight 启动后检查日志： 1docker logs redisinsight 如果没有日志说明启动成功了，而出现了日志一般是出错了。 3、访问页面并连接至现有 Redis 数据库前往 http://IP:8001 访问可视化页面，第一次访问需要同意部分隐私条款：选择我已经有 Redis 数据库：我是在内网另一台服务器上自建的，因此选第一项：填写连接信息：之后就能看到该 Redis 数据库的运行情况了：可以编辑值或者运行命令： 结束。","link":"/2022/04/19/bak_centos7_docker_redisinsight/"},{"title":"【归档文章】CentOS7 下用 Docker 部署 UnblockNeteaseMusic 并在 Clash 中配置分流以在局域网内解锁网易云音乐变灰的歌曲","text":"关于部署 UnblockNeteaseMusic 的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 之前也是部署过这个项目的，但是后来嫌 PC 端和手机端的网易云音乐都要手动配置有点麻烦，于是就放弃了。现在在路由器上安装了 Clash，想到既然它能做指定域名的分流，那么应该也能指定网易云的流量走解锁用的服务器来达到灰歌解锁的功能吧（最后发现：只有在 Clash 为网关的情况下才可以实现无需任何多余配置的全客户端灰歌解锁，普通模式仍需配置 Clash 为 HTTP 代理），尝试一下！ 1、服务器端的安装参考官方文档：UnblockNeteaseMusic，执行执行即可： 1docker run --name unblock-netease-music --restart=always -d -p 18080:8080 nondanee/unblockneteasemusic -o kugou kuwo xiami migu 如果需要加代理认证功能可以使用如下命令： 1docker run --name unblock-netease-music --restart=always -d -p 18080:8080 nondanee/unblockneteasemusic -o kugou kuwo xiami migu -t $your_username:$your_password 需要注意：Windows 端和 macOS 端认证功能无法生效，虽然能测试通过，但是无法播放歌曲且会报连接错误！如果要在这两个端使用，你必须使用 GOST 或 Clash 等工具将需要认证的代理转换为本地不需要认证的代理。​ 之后记得防火墙和安全组都开放指定端口。 2、测试解锁是否生效PC 端的网易云代理设置方法如下：填入你的代理后点击测试：显示该代理可用，再来看看灰歌的解锁情况。这是配置前的截图：配置后：成功！ 3、在路由器的 Clash 插件上进行配置既然是在路由器上配置，那么该局域网内所有设备的网易云音乐都会自动解锁灰歌（需要 Clash 在网关模式下才能实现），比起在每个设备上都配置一遍代理来的方便的多。代码片段： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950proxies: # 无需认证 - {name: 网易云音乐灰歌解锁节点, type: http, server: 63.225.10.10, port: 18080 } # 需要认证 # - {name: 网易云音乐灰歌解锁节点, type: http, server: 63.225.10.10, port: 18080, username: your_username, password: your_password }proxy-groups: - name: 网易云音乐 type: select proxies: - 网易云音乐灰歌解锁节点 # 多配置个直连以防不测 - DIRECTrules: # 网易云音乐域名和 IP 段 # UWP 版只使用以下两个即可 - DOMAIN-SUFFIX,music.163.com,网易云音乐 - DOMAIN-SUFFIX,music.126.net,网易云音乐 # 为保险添加以下所有域名和 IP 段 - DOMAIN-SUFFIX,163yun.com,网易云音乐 - DOMAIN-SUFFIX,api.iplay.163.com,网易云音乐 - DOMAIN-SUFFIX,apm.music.163.com,网易云音乐 - DOMAIN-SUFFIX,apm3.music.163.com,网易云音乐 - DOMAIN-SUFFIX,interface.music.163.com,网易云音乐 - DOMAIN-SUFFIX,interface3.music.163.com,网易云音乐 - DOMAIN-SUFFIX,mam.netease.com,网易云音乐 - DOMAIN-SUFFIX,hz.netease.com,网易云音乐 - IP-CIDR,39.105.63.80/32,网易云音乐 - IP-CIDR,45.254.48.1/32,网易云音乐 - IP-CIDR,47.100.127.239/32,网易云音乐 - IP-CIDR,59.111.21.14/31,网易云音乐 - IP-CIDR,59.111.179.214/32,网易云音乐 - IP-CIDR,59.111.181.38/32,网易云音乐 - IP-CIDR,59.111.181.60/32,网易云音乐 - IP-CIDR,59.111.160.195/32,网易云音乐 - IP-CIDR,59.111.160.197/32,网易云音乐 - IP-CIDR,59.111.181.35/32,网易云音乐 - IP-CIDR,59.111.238.29/32,网易云音乐 - IP-CIDR,101.71.154.241/32,网易云音乐 - IP-CIDR,103.126.92.132/32,网易云音乐 - IP-CIDR,103.126.92.133/32,网易云音乐 - IP-CIDR,112.13.119.17/32,网易云音乐 - IP-CIDR,112.13.122.1/32,网易云音乐 - IP-CIDR,115.236.118.33/32,网易云音乐 - IP-CIDR,115.236.121.1/32,网易云音乐 - IP-CIDR,118.24.63.156/32,网易云音乐 - IP-CIDR,193.112.159.225/32,网易云音乐 - IP-CIDR,223.252.199.66/32,网易云音乐 - IP-CIDR,223.252.199.67/32,网易云音乐 抓包步骤可以参考这篇文章：Fiddler 学习（一）安装、配置和尝试抓取 UWP 版网易云音乐的请求域名 后话（在我发现路由器端的 Clash 插件并没有那么万能的情况下做的补充）​：如果你已经将 Clash 设置为网关，实现了透明代理的话，那么 Windows 和安卓端都不再需要配置代理了，直接使用即可。但如果你和我一样只是在路由器上安装了 Clash，并没有实现透明代理，那么你仍需要将网易云音乐的代理手动指向路由器上 Clash： 错误排查用：① Clash 日志中可以看到网易云音乐流量的走向，如果发现明明在网易云音乐客户端进行了操作，Clash 却没捕捉到流量，说明你 Clash 并非透明代理模式。你需要将路由器上的 Clash 设置为允许局域网内设备访问，并手动在网易云音乐中配置其 HTTP 端口，就和我上面演示的一样。② 歌曲是否成功解锁了？你可以通过在服务器上执行以下命令，查看 Docker 容器内的日志来确定： 1docker logs unblock-netease-music 结束。","link":"/2021/11/04/bak_centos7_docker_unblock_netease_music/"},{"title":"【归档文章】CentOS7 下用 Docker 安装和启动 Zabbix 企业级服务器监控系统","text":"关于通过 Docker 部署 Zabbix 监控的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 又购置了一批 VPS 后，大大小小的 Linux 服务器数量来到了 40 多台，自己写的服务器探针开始感受到压力了，专业性先不提，服务器一多前端那么多 Echarts 图标就够 Chrome 受的了……本来想着咬咬牙花时间研究下 Zabbix 的配置上企业级监控，结果发现官方的 Docker 镜像从 server 端到面板前端到 agent 端居然全都有，因为自用的数据库就是 PostgreSQL，还省了安装，Docker pull 完直接使用即可（数据库的安装可以参考我的这篇文章：PostgreSQL 学习笔记 (一) 数据库的安装与环境配置）。 我的安装顺序是：server 端 –&gt; 前端面板 –&gt; agent 端请结合你自己的情况选择。 1、server 端官方 Docker 镜像：zabbix-server-pgsql注意：使用 MySQL 和 PostgreSQL 时 Docker 镜像是不同的，且在启动 Docker 镜像之前就先创建好名为 zabbix 的数据库。 1234567891011121314151617181920# pulldocker pull zabbix/zabbix-server-pgsql:4.0-centos-latest# 启动，自行更改 host、port、username 和 password 数据库连接参数（ZBX_STARTPOLLERS 参数可以保证你在监听大量高延迟服务器下不产生 zabbix poller process more than 75% busy 的错误，如果出错之后再去修改 config.v2.json 会比较麻烦）docker run --name some-zabbix-server-pgsql -p 10051:10051 --net=host -e DB_SERVER_HOST=&quot;$pgsql_host&quot; -e DB_SERVER_PORT=$pgsql_port -e POSTGRES_USER=&quot;$pgsql_username&quot; -e POSTGRES_PASSWORD=&quot;$pgsql_password&quot; -e ZBX_STARTPOLLERS=15 -d docker.io/zabbix/zabbix-server-pgsql:4.0-centos-latest# 查看 logdocker logs some-zabbix-server-pgsql# 没有报错的话将其设为开机启动docker update --restart=always some-zabbix-server-pgsql``` #### 2、面板前端官方 Docker 镜像：[zabbix-web-nginx-pgsql](https://hub.docker.com/r/zabbix/zabbix-web-nginx-pgsql) **注意**：一般情况下都和 server 端安装在同一个服务器上。 ```bash# pulldocker pull zabbix/zabbix-web-nginx-pgsql:4.0-centos-latest# 启动，自行替换数据库连接参数，并将容器的 8080 端口映射到本机 10052 端口（注意该容易已经内置 Nginx，因此如果你准备在宿主机中安装 Nginx 并解析域名反代该容器，请使用 8080 端口，如果只准备用端口访问服务，则映射 80 端口也无妨）docker run --name some-zabbix-web-nginx-pgsql -p 10052:8080 -e DB_SERVER_HOST=&quot;$pgsql_host&quot; -e DB_SERVER_PORT=$pgsql_port -e POSTGRES_USER=&quot;$pgsql_username&quot; -e POSTGRES_PASSWORD=&quot;$pgsql_password&quot; -e PHP_TZ=&quot;Asia/Shanghai&quot; -d docker.io/zabbix/zabbix-web-nginx-pgsql:4.0-centos-latest# 查看 logdocker logs some-zabbix-web-nginx-pgsql 在防火墙和安全组 10052 端口开放之后，通过外网访问 http://服务器 IP:10052 检查面板是否启动成功，默认登录用户名为：Admin，密码为：zabbix。 12# 没有报错的话将其设为开机启动docker update --restart=always some-zabbix-web-nginx-pgsql 中文界面开启方式： 3、agent 端官方 Docker 镜像：zabbix-agent注意：这里虽然还是安装 server 所在的“本机”作为案例，但是因为 Docker 之间走的是虚拟网络，IP 并非 127.0.0.1，因此配置和在外网被监控机的一样：IP 需填外网 IP 并开放 10050（agent 默认）端口。 1234# pulldocker pull zabbix/zabbix-agent:4.0-centos-latest# 启动，server_ip 填写 server 端所在服务器的外网 IP，端口默认为 10051，而 hostname 则需要在前端面板上配置好，参考下方步骤。docker run --name some-zabbix-agent -p 10050:10050 -e ZBX_HOSTNAME=&quot;$hostname&quot; -e ZBX_SERVER_HOST=&quot;$server_ip&quot; -e ZBX_SERVER_PORT=$server_port -d docker.io/zabbix/zabbix-agent:4.0-centos-latest 选择创建主机：主机名称就是 hostname，需要注意的是不能有汉字。主机群组选 Zabbix servers 即可，后续自行更改。 1234# 查看 logdocker logs some-zabbix-agent# 开机自启动docker update --restart=always some-zabbix-agent 没有问题的话去前端检查一下 Zabbix 是否可用：如果可用的话，再去看下监控图形： 如果都没问题的话，Zabbix 的安装就结束了，以上。","link":"/2021/07/19/bak_centos7_docker_zabbix/"},{"title":"【归档文章】CentOS7 下搭建 HTTP 和 SOCKS5 代理服务","text":"关于搭建 HTTP 和 SOCKS5 代理服务的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 如果你没有不过墙的 IPLC 线路的话，请不要在境外服务器上搭建 HTTP 或 SOCKS5 代理，连上以后流量稍微一大就会使 IP 被墙。 HTTP 和 SOCKS5 代理搭建的方式有很多：使用 Tinyproxy 搭建 HTTP 代理、使用 ss5 搭建 SOCKS5 代理等等……我这里使 GOST 来启动代理服务端，优点是安装方便（只有一个可执行脚本），且同时能启动加密的 HTTP 和 SOCKS5 代理服务。 附上一些我的开源脚本：HTTP 代理：CentOS7 下一键安装 Tinyproxy 代理SOCKS5 代理：CentOS7 下一键安装 SOCKS5 代理同时安装 HTTP 和 SOCKS5 代理：CentOS7 下一键安装 GOST 并启动 HTTP 和 SOCKS5 代理服务 1、下载并安装 GOST下载 GOST： 1wget https://github.com/ginuerzh/gost/releases/download/v2.11.1/gost-linux-amd64-2.11.1.gz 如果境内下载慢的话可以用我 Gitee 上的源：gost-linux-amd64-2.11.1.gz 下载完成后解压出 gost 执行文件，并放在 /usr/bin 等目录下以方便在任何地方调用： 1234# 解压gunzip gost-linux-amd64-2.11.1.gz# 移动mv gost-linux-amd64-2.11.1 /usr/bin/gost 2、启动 GOST使用 GOST 开启 HTTP 和 SOCKS5 代理功能的命令比较简单： 1gost -L $username:$password@:$port 参数说明及样例： 参数 说明 样例 username 代理认证用的用户名。 myusername password 代理认证用的密码。 mypassword port 代理服务的端口。 1080 GOST 强大的其他功能可以参考官方文档：GOST v2 启动成功并确定对应端口的防火墙和安全组开放后可以在其他 Linux 服务器上测试一下（$host 为你代理服务器的 IP 地址）： 1curl -x http://$username:$password@$host:$port http://ip-api.com/json/?lang=zh-CN 3、使用 Screen 启动并设置为开机自启动你会发现 GOST 在你退出终端后就会停止，这里使用 Screen 新建一个窗口并运行 GOST： 1234# 安装 Screenyum -y install screen# 新建 Screen 并在其中运行 GOSTscreen -dmS screen-for-gost &amp;&amp; screen -S screen-for-gost -X stuff '/usr/bin/gost -L $username:$password@:$port\\n' 而开机自启动则需要配置 Linux 系统任务： 1crontab -e 新加一条任务： 1@reboot screen -dmS screen-for-gost &amp;&amp; screen -S screen-for-gost -X stuff '/usr/bin/gost -L $username:$password@:$port\\n' 之后重启 Cron 即可： 1service crond restart 结束。","link":"/2022/01/08/bak_centos7_http_and_socks5_proxy/"},{"title":"【归档文章】CentOS7 下安装 RabbitMQ","text":"关于安装 RabbitMQ 的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 最近的新项目考虑到有分布式的需要，感觉加入消息队列不仅能增强各系统直接的协调性，对服务器资源也能提高利用效率，决定试下 RabbitMQ，于是便有了这篇 CentOS7 下安装 RabbitMQ 的笔记。 1、首先安装所需的依赖包12yum -y install epel-releaseyum install build-essential openssl openssl-devel unixODBC unixODBC-devel make gcc gcc-c++ kernel-devel m4 ncurses-devel tk tc xz 2、安装 Erlang需要注意的是，RabbitMQ 的版本和 Erlang 的版本是需要匹配的，具体可以参照这里：RabbitMQ Erlang Version Requirements 如果你不想折腾，您可以选择直接 1&gt;yum -y install erlang 安装 Erlang，而这样默认安装的版本是 03.18.el7，虽然看起来没有对应版本的 RabbitMQ 可以安装，但是实测至少 3.6.5 版本的 RabbitMQ 实际上是可以验证 Erlang 版本通过并安装，后续的使用也没有问题。 但是在这里我还是选择安装最新的版本，反正是个人项目，在新特性和版本稳定之间有选择的情况下，前项对我的吸引力开始更大，反正记了笔记大不了回退就是了。 12345# 更新 yum 源至最新wget https://packages.erlang-solutions.com/erlang-solutions-1.0-1.noarch.rpmrpm -Uvh erlang-solutions-1.0-1.noarch.rpm# 安装 Erlangyum install erlang 完成后检查 Erlang 版本 1yum info erlang 3、安装 RabbitMQErlang 版本为最新的话，理论上 RabbitMQ 的版本可以随便挑，这里我就挑当前最新的吧。 123wget https://github.com/rabbitmq/rabbitmq-server/releases/download/v3.8.17/rabbitmq-server-3.8.17-1.el7.noarch.rpmyum -y install socatrpm -ivh rabbitmq-server-3.8.17-1.el7.noarch.rpm 注意，3.8.17-1.el7 的 el7 所代表的就是 CentOS7 系统所适用的包结束后检查一下 1rabbitmq-server status 没有问题的话将可视化管理界面一并安装： 1rabbitmq-plugins enable rabbitmq_management 4、启动服务并配置用户首先启动服务： 12systemctl start rabbitmq-serverrabbitmqctl status 然后开放防火墙和端口组，来确保可视化管理界面也运行成功，默认地址及端口：http://127.0.0.1:15672，IP 请自行替换，出现以下界面说明启动成功。接下来配置用户，指令如下： 123456#添加新用户，用户名为&quot;root&quot;，密码为&quot;root&quot;rabbitmqctl add_user root root#设置用户为管理员角色rabbitmqctl set_user_tags root administrator #授权远程访问 rabbitmqctl set_permissions -p / root &quot;.&quot; &quot;.&quot; &quot;.*&quot; 5、设置为开机自启动1systemctl enable rabbitmq-server 至此结束。","link":"/2020/12/31/bak_centos7_install_rabbitmq/"},{"title":"【归档文章】CentOS7 下的一些 iptables 实用配置","text":"关于基础的 iptables 规则的记录。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 一些基础的 iptables 规则来保护服务器，持续更新。 1、查看当前 iptables 入方向规则注意：和 Nginx 规则一样，从上到下匹配，有符合的就直接跳出不会再向下执行！ 1iptables -L INPUT --line-numbers 2、删除指定行的入方向规则1iptables -D INPUT $row_no 3、允许指定 MAC 地址访问本机所有端口1iptables -I INPUT -m mac --mac-source xx:D3:xx:7A:02:xx -j ACCEPT 4、屏蔽所有人对域名（包括子域名的访问）注意：需要放在最后一行处！ 1iptables $row_no -I INPUT -p tcp --dport $port -m string --string &quot;example.com&quot; --algo kmp -j DROP","link":"/2021/09/30/bak_centos7_iptables/"},{"title":"【归档文章】CentOS7 下安装 Java 环境（JDK11）","text":"关于安装 Java 环境的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 为了在 CentOS7 服务器下部署 Java Web 项目和使用 RabbitMQ 所留的笔记。 1、首先检查服务器当前 OpenJDK 版本，如果不是需要的版本请先卸载。1234567891011121314151617181920212223242526272829303132333435java -version``` 由于这次我们使用的是下载压缩包直接解压后将路径添加至环境变量的方法，并非使用 rmp 命令等直接安装，因此如果后续要更新版本只需要更改环境变量路径即可。 rmp 命令等安装的卸载方法请自行参考：[CentOS7 卸载 OpenJDK 安装 Oracle JDK](https://blog.csdn.net/zitong_ccnu/article/details/40041533) #### 2、下载 Java 开发者工具包 JDK。 官方地址：[Java SE Downloads](https://www.oracle.com/java/technologies/javase-downloads.html) *注：官方下载目前需要注册账号，如果你和我一样使用的 JDK 11 的话可以直接[通过我的 Google 云盘分享链接进行下载](https://drive.google.com/file/d/1VlWux2xAUTvk53D03qon-Z_oW9JQhFfB/view?usp=sharing)。* 由于个人目前用的是 JDK 11 因此以此为例： ![点击 JDK Download](https://image.senjianlu.com/blog/2024-09-01/111623.png) 注意服务器架构和下载完成包： ![注意服务器架构和下载完成包](https://image.senjianlu.com/blog/2024-09-01/111708.png) 下载完后通过 Xftp 等工具上传至服务器。 #### 3、解压并移动到所需目录下（以我常用的 /opt/java 为例）。 ```bashmkdir /opt/javamv jdk-11.0.11_linux-x64_bin.tar.gz /opt/java/cd /opt/javatar -xzvf jdk-11.0.11_linux-x64_bin.tar.gz``` ![目录](https://image.senjianlu.com/blog/2024-09-01/111744.png) 此时 Java 所需要添加进环境变量的路径即为：/opt/java/jdk-11.0.11#### 4、添加至环境变量并使其生效。 编辑文件```bashvi /etc/profile``` 在文件末尾追加，JDK 11 以后只需添加以下环境变量： ```viexport JAVA_HOME=/opt/java/jdk-11.0.11export PATH=$PATH:$JAVA_HOME/bin 注意！JDK 11 以前还需要涉及到 JRE_HOME 以及 CLASS_PATH（以 JDK 1.8 为例）： 1234&gt;export JAVA_HOME=/home/java/jdk1.8.0_171&gt;export JRE_HOME=$JAVA_HOME/jre&gt;export CLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib&gt;export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin 执行 source 命令使环境变量立即生效： 1source /etc/profile 5、检查是否安装成功。1java -version","link":"/2020/12/31/bak_centos7_jdk/"},{"title":"【归档文章】CentOS7 下安装 Jupyter","text":"关于安装 Jupyter 的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 因为 Linux 系统下用 code-server 作为编译器预览 Matplotlib 图表实在过于麻烦，于是决定多装一个 Jupyter 作为数据分析图表预览用工具。安装较为简单，但是开机启动碰到了一些问题，但还是做个整体的记录吧。 1、安装 Python3，已经安装则跳过使用我的一键脚本即可： 1curl -s https://gitee.com/senjianlu/one-click-scripts/raw/main/CentOS7%20%E4%B8%8B%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%20Python3%20%E7%8E%AF%E5%A2%83/install.sh | bash 2、pip3 安装 Jupyter1pip3 install notebook 3、生成和修改配置文件以使其能被外部访问，同时支持密码验证1jupyter notebook --generate-config 配置文件会生成在用户目录的 .jupyter/jupyter_notebook_config.py 下，不用记录位置，先去生成密码验证用的密钥： 1python3 12345from notebook.auth import passwdpasswd()# 输入密码# 获取形如 argon2:$argon2id$v=19$m=10240,t=10,p=8$dhDVXQegS13Rxxxxxxxxxxxxxxxxxxx 的密钥exit() 保存好密钥后去修改配置文件： 1vi /root/.jupyter/jupyter_notebook_config.py 找到以下各行，按下述修改： 1234c.NotebookApp.ip='*' # 设置所有 IP 皆可访问c.NotebookApp.password=u'argon2:$a....' # 复制刚才生成的那个密文c.NotebookApp.open_browser=False # 禁止自动打开浏览器c.NotebookApp.port=8888 # 默认为 8888 端口 4、开启对应端口的防火墙和安全组基础操作，做个提醒。 5、尝试启动1jupyter notebook --allow-root 输入密码登录，出现目录页面则说明安装没问题。 6、新建笔记文件Jupyter 实际上并不是专业的 IDE，而是笔记工具，因此创建的文件实际上也是笔记文件类型，以下虽然显示的是 Python3 实际创建的是 .ipynb 文件。最简单的代码试下功能： 7、设置开机自启动如果没有 Screen 先安装： 123yum -y install screen# 配置 Screen 能读取环境变量echo 'shell -$SHELL' &gt;&gt; /etc/screenrc crontab 中新增启动任务： 12# 使用 python3 -m 而非 jupyter 命令是因为 crond 的环境变量和全局变量不一致@reboot screen -dmS jupyter &amp;&amp; screen -S jupyter -X stuff 'python3 -m notebook --allow-root\\n' 结束。","link":"/2021/09/24/bak_centos7_jupyter/"},{"title":"【归档文章】CentOS7 下解决 Python3 使用 Matplotlib 生成图表时中文乱码的问题","text":"关于解决 Matplotlib 生成图表时中文乱码问题的记录。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 不需要 Yum 安装任何其他软件，也不需要修改 Matplotlib 包的配置文件，实测是最简单的方法了。全程使用 HostVDS 新开的服务器并只安装了 Python3.8.2 以保证教程正确。 1、首先看下没有安装字体时生成含中文的图表时会出现上面错误。12345678910111213141516171819202122232425262728293031323334353637383940414243import sysimport matplotlib as mplimport matplotlib.pyplot as pltfrom matplotlib.font_manager import FontProperties&quot;&quot;&quot;@description: 执行 SQL -------@param:-------@return:&quot;&quot;&quot;def main(): # 一般教程都会用到的所谓指定字体路径，此篇教程用不到 # font_prop = FontProperties(fname=&quot;/usr/local/python3/lib/python3.8/site-packages/matplotlib/mpl-data/fonts/ttf/SimHei.ttf&quot;) # 待字体安装完后指定字体，SimHei 存在缺少部分特殊符号的问题，所以用 YaHei # mpl.rcParams['font.sans-serif'] = [&quot;Microsoft YaHei&quot;] # 防止 - 号出错，和上一行同时解注 # mpl.rcParams[&quot;axes.unicode_minus&quot;] = False data = [[&quot;AAA&quot;, &quot;BBB&quot;, &quot;CCC&quot;, &quot;数据&quot;, &quot;数据&quot;]] column_labels = [&quot;商品中文名&quot;, &quot;商品英文名&quot;, &quot;最低售价&quot;, &quot;在售数量&quot;, &quot;更新时间&quot;] fig = plt.figure(figsize=(3, 3), dpi=600) ax = fig.add_subplot(111, frame_on=False,) ax.xaxis.set_visible(False) ax.yaxis.set_visible(False) ax.table(cellText=data, colLabels=column_labels) ax.set_title(&quot;测试&quot;) plt.savefig('test.png')&quot;&quot;&quot;@description: 单体测试-------@param:-------@return:&quot;&quot;&quot;if __name__ == &quot;__main__&quot;: try: main() except Exception as e: print(str(e)) 直接运行后日志和图片如下所示： 1234567891011121314151617181920212223[root@test test]# python3 main.py/usr/local/python3/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 27979 missing from current font. font.set_text(s, 0.0, flags=flags)/usr/local/python3/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 35797 missing from current font. font.set_text(s, 0.0, flags=flags)/usr/local/python3/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 25968 missing from current font. font.set_text(s, 0.0, flags=flags)/usr/local/python3/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 25454 missing from current font. font.set_text(s, 0.0, flags=flags)``` ![无指定中文](https://image.senjianlu.com/blog/2024-09-03/63d1f43d03778.png) #### 2、给系统安装中文字体。 这里不考虑一般教程所采用的只给 Matplotlib 安装中文字体。 ```bash# 新建中文文件夹并下载微软雅黑字体cd /usr/share/fonts/mkdir chinesechmod -R 755 chinesecd chinesewget https://www.wfonts.com/download/data/2014/06/01/microsoft-yahei/chinese.msyh.ttf# 查看当前系统里的中文字体以确认安装成功fc-list :lang=zh 出现以下命令则说明安装成功： 12[root@test chinese]# fc-list :lang=zh/usr/share/fonts/chinese/chinese.msyh.ttf: Microsoft YaHei:style=Regular,Normal 清除之前 Matplotlib 的缓存后此步骤结束。 1234[root@test chinese]# rm ~/.cache/matplotlib -Rrm: descend into directory ‘/root/.cache/matplotlib’? yrm: remove regular file ‘/root/.cache/matplotlib/fontlist-v330.json’? yrm: remove directory ‘/root/.cache/matplotlib’? y 3、再执行图片生成脚本以确认中文字体安装成功。解注以下两行： 123456...# 待字体安装完后指定字体，SimHei 存在缺少部分特殊符号的问题，所以用 YaHeimpl.rcParams['font.sans-serif'] = [&quot;Microsoft YaHei&quot;]# 防止 - 号出错，和上一行同时解注mpl.rcParams[&quot;axes.unicode_minus&quot;] = False... 成功，结束。","link":"/2021/09/02/bak_centos7_matplotlib_chinese/"},{"title":"【归档文章】CentOS7 下 MinIO 的安装和配置","text":"关于部署 MinIO 的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 起因是 BuyVM 的存储块补货了，于是下单买了一年 256 GB 的再套个 CloudFalre 用来做对象存储，存存图片和 Docker 镜像文件应该是够了，反正不够还能继续挂载。 顺便把 BuyVM 挂载硬盘的流程一起记下：1、购买后去控制台把 Block Storage 附加到（Attached To）对应的 VPS 上。2、在 VPS 里查看数据块编号，类似 scsi-0BUYVM_SLAB_VOLUME-1331 的就是存储块。 1ls /dev/disk/by-id/ 3、格式化。 1mkfs.ext4 -F /dev/disk/by-id/scsi-0BUYVM_SLAB_VOLUME-1331 4、新建文件夹并挂载，这里以根目录下的 /storage 为例： 1mount -o discard,defaults /dev/disk/by-id/scsi-0BUYVM_SLAB_VOLUME-1331 /storage 5、设置开机自动挂载，完成。 1echo '/dev/disk/by-id/scsi-0BUYVM_SLAB_VOLUME-1331 /storage ext4 defaults,nofail,discard 0 0' | sudo tee -a /etc/fstab MinIO 的安装也没有任何难度，因为有现成编译好的版本，直接下载运行就行了。 1、我是用的是 CentOS7 系统，所以选择 linux-amd64 版本：1wget https://dl.minio.io/server/minio/release/linux-amd64/minio 2、下载下来的文件加上权限就能运行，但是为了方便管理还是放到 /usr/local 路径下：12mv minio /usr/local/chmod +x /usr/local/minio 测试启动一下： 1/usr/local/minio server /stroage --address &quot;:9000&quot; --console-address &quot;:9001&quot; 启动成功，默认账号密码都是：minioadmin 3、修改账号密码。最新版本的 MinIO 已经停用从配置文件中读取账号密码启动的功能，因此现在只能将用户信息配置在系统的环境变量中。以下命令仅可用来测试，在终端关闭后就会失效。 12export MINIO_ROOT_USER=usernameexport MINIO_ROOT_PASSWORD=password 永久配置请参照这个命令，修改 /etc/profile 文件： 1vi /etc/profile 并在空白处添加： 12export MINIO_ROOT_USER=usernameexport MINIO_ROOT_PASSWORD=password 使其生效： 1source /etc/profile 4、开机启动。这里用最简单的方法实现开机启动： 1crontab -e 123# MinIO 开机启动# . /etc/profile; 作用为先读取环境变量，不配置无法读取账号密码。@reboot . /etc/profile;/usr/local/minio server /storage --address &quot;:9000&quot; --console-address &quot;:9001&quot; 1service crond restart 如果重启后 MinIO 没有自启动的话，请自行查看 log，crontab 的配置头上可能需要加上 3 行： 123SHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=root 这些是用来选择语言、可执行文件目录和用户的，具体情况还是看日志处理。 5、Nginx 上传文件的配置。我至今遇到了两个错误： 413 Request Entity Too Large 修改上传文件最大大小解决。 文件下载报错 403 SignatureDoesNotMatch 就很巧全是大家碰到过的问题，修改 headers 传递解决。 最后的 Nginx 配置如下： 12345678910111213141516...location / { proxy_pass http://127.0.0.1:9001; # MinIO 上传最大大小 1 GB client_max_body_size 1024m; proxy_http_version 1.1; # headers 传递 proxy_set_header Host $host; proxy_set_header Connection &quot;upgrade&quot;; proxy_set_header Upgrade $http_upgrade; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-Proto $scheme;}... 至此结束。 2021/07/21 更新回滚以解决部分错误：MinIO 9000 端口强制跳转 9001 端口且报 This ‘admin’ API is not supported by server in ‘mode-server-fs’、An error occurred, please try again 和 The server side encryption configuration was not found 错误","link":"/2021/07/19/bak_centos7_minio/"},{"title":"【归档文章】解决 MinIO 9000 端口强制跳转 9001 端口报错的问题","text":"解决 MinIO 9000 端口强制跳转 9001 端口且报 This ‘admin’ API is not supported by server in ‘mode-server-fs’、An error occurred, please try again 和 The server side encryption configuration was not found 错误。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 刚装完 MinIO 测试的时候其实就发现了部分页面会出错，但是看了下错误基本都是认证错误，响应代码为 500，觉得可能是 Nginx 配置有误，实则不然……具体见帖子：windows 启动之后minio之后。访问127.0.0.1:9000 跳转到了 127.0.0.1:9001 是什么原因 1、最直观的表现就是最新版本的 MinIO 9000 端口会强制被转到 9001 的控制台端口登录页面是这样的： 2、操作过程中，会出现部分错误① 查看存储桶具体信息时页面报错： This ‘admin’ API is not supported by server in ‘mode-server-fs’ 后端报错： 123...original error -&gt; (user_buckets.go:123: error server side encryption configuration not found)friendly error: The server side encryption configuration was not found ② 分享文件时页面报错： An error occurred, please try again 后端报错： 12...original error -&gt; (user_objects.go:51: A header you provided implies functionality that is not implemented) 3、解决方法和帖子里讲的一样，回退版本，我出错的版本是 2021/07/18 更新的版本，是通过： 1wget https://dl.minio.io/server/minio/release/linux-amd64/minio 直接下载的，看同目录下文件应该是 minio.RELEASE.2021-07-15T22-27-34Z 版本，GitHub 上也有发布，但是不知道为什么问题这么多……帖子推荐版本是 RELEASE.2021-07-12T02-44-53Z，但是经过测试向前推 2 个版本强制跳转控制台的问题依旧存在，于是看文件大小选了个想必不包括控制台的版本：RELEASE.2021-06-14T01-29-23Z，下载后因为本地已经配置好了环境变量的关系，直接覆盖之前的 minio 文件然后重启服务即可。 1/usr/local/minio server /storage --address &quot;:9000&quot; Unable to initialize OpenID: found invalid keys (client_secret= redirect_uri= ) for ‘identity_openid’ sub-system, use ‘mc admin config reset myminio identity_openid’ to fix invalid keys (*fmt.wrapError)启动时你有可能会和我一样碰到上面的报错，你可以忽略它，在我的测试下即使有错误 MinIO 的所有功能也都正常。如果你是强迫症，那么请遵循下面的步骤来解决它： 先删除之前的 mc 再下载对应版本的：mc.RELEASE.2021-06-13T17-48-22Z 在后台启动你的 MinIO，因为 mc 需要访问你的 MinIO 服务。 然后执行： 12345# 新增 host，这里的 myminio 是你上面所缺少的 host 的名字，请自行替换# $minio_host 可以是 IP 也可以是你已经反代完成的域名，只要能正常访问即可mc config host add myminio http://$minio_host $root_user $root_password --api s3v4# 保存中提醒你做的刷新操作./mc admin config reset myminio identity_openid 再启动，理论上就已经不报错了，如果还有错误请花时间对照文档修复吧：MinIO Client 完全指南 小声逼逼，挺离谱的……","link":"/2021/07/21/bak_centos7_minio_error/"},{"title":"【归档文章】CentOS7 下搭建哪吒监控面板（附带监控端的安装）","text":"关于搭建哪吒监控面板的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 1. Zabbix 痛点和其他监控面板的选型虽然已经搭建了 Zabbix 用以监控业务服务器的运行状况，不过其仍存在部分痛点： 繁琐的 agent 节点添加流程，注定了它不适用于生命周期较短的边缘服务器。 需要双向开放端口用以通信。国外不少小厂商的控制面板上并不支持安全组相关的操作，因此“允许某 IP 连接本服务器的某端口”只能通过 iptables 等进行实现，耗费时间。 于是乎重新挑选了一下轻量级的监控面板，发现全球主机交流论坛上比较火两款监控（探针面板）是 ServerStatus 和 nezha（哪吒），稍稍做了下对比： 项目 ServerStatus nezha（哪吒） 开源 ✅ ✅ 语言 Python2.7 Go 前端面板 ✅ ✅ 无需 agent 端开放端口 ✅ ✅ agent 对 server 的注册方式 agent 端执行安装脚本时手动填写 在前端面板上填写 agent 信息后，复制带参数的命令，去 agent 服务器上一键执行 前端面板主题切换 上传并替换 server 端文件 前端面板设置处切换 最终考虑哪吒监控面板添加 agent 节点更加简单，因此选用。 如果你想体验下 ServerStatus 的安装流程，可以看这篇文章：CentOS7 下搭建 ServerStatus 监控（ServerStatus-Hotaru 版且带客户端的安装），我做了单服务端和单客户端的最小部署。 面板搭建完成后的预览：ServerStatus | 哪吒 2. 哪吒监控面板的运作方式不关注具体实现，简单来说哪吒监控主要做了 2 件事： agent 端将监控数据 Push 给 server 后端。 server 后端处理和保存监控数据后，在前端需要时将其返回。 3. 安装部署3.1 安装前的准备工作在进行哪吒监控的安装部署之前，还需要准备些东西： 两个域名，都解析到 server 端服务器的 IP 地址上。其中一个给前端面板用，另一个给 agent 端推送监控数据时用。我的是 nezha.ceshiku.cn 和 nezha-api.ceshiku.cn。​需要注意的是：nezha-api.ceshiku.cn 这种给 agent 端准备的域名，由于是用以解析 server 端服务器 IP 地址的，因此不能套 CDN！ 在 GitHub 创建 OAuth App 后获取 Client ID 和 Client secrets，并填写 server 前端面板域名的回调地址。 关于如何创建 OAuth App 可以看官方的这篇文档：创建 OAuth 应用程序，记得在创建后保存 Client ID 和 Client secrets。 3.2 安装 server 端 官方文档：安装 Dashboard 在面板服务器中，运行安装脚本： 1curl -L https://raw.githubusercontent.com/naiba/nezha/master/script/install.sh -o nezha.sh &amp;&amp; chmod +x nezha.sh &amp;&amp; sudo ./nezha.sh 如果你的面板服务器位于中国大陆，可以使用镜像： 1curl -L https://jihulab.com/nezha/nezha/-/raw/master/script/install.sh -o nezha.sh &amp;&amp; chmod +x nezha.sh &amp;&amp; sudo CN=true ./nezha.sh 选择安装面板端： 安装完成后输入 GitHub OAuth App 的相关信息： 配置成功后，前往你的地址查看，我这里端口用的默认，因此地址是：http://nezha.ceshiku.cn:8008 安装 Nginx、修改配置使其支持只用域名访问： 12345678# 安装 Nginx 并设置为开启自启动yum -y install epel-releaseyum -y install nginxsystemctl enable nginx# 启动 Nginxservice nginx start# 修改配置文件vi /etc/nginx/nginx.conf 添加这么一段： 123456789101112131415161718server { listen 80; server_name nezha.ceshiku.cn; location / { proxy_pass http://127.0.0.1:8008; proxy_set_header Host $http_host; proxy_set_header Upgrade $http_upgrade; } location ~ ^/(ws|terminal/.+)$ { proxy_pass http://127.0.0.1:8008; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;Upgrade&quot;; proxy_set_header Host $http_host; }} 之后重启 Nginx： 12nginx -s reloadservice nginx restart 接着尝试用域名直接访问，可以发现成功了： 打开 Cloudflare 的 SSL/TLS 加密模式使支持 HTTPS 访问： 再访问以下发现有小锁了，成功： 至此哪吒监控的 server 端就安装完成了。 3.3 安装 agent 端 官方文档：安装 Agent 配置 agent 访问 server 后端用的域名： 登陆 server 面板并添加一台需要监控的主机： 复制 agent 一键安装命令并前往服务器执行： 之后回到面板，就能看到监控生效了： 修改 agent 监控端的配置来关闭远程 SSH 功能或增大信息上报的间隔。找到并编辑配置文件： 1vi /etc/systemd/system/nezha-agent.service 找到下面这一行： 1ExecStart=/opt/nezha/agent/nezha-agent -s nezha-api.ceshiku.cn:5555 -p 0bcxxxxxxxxxxxf39 --disable-auto-update 我关闭了远程 SSH 功能并将上报间隔改为了 2 秒，以下是配置行可供参考： 1ExecStart=/opt/nezha/agent/nezha-agent -s nezha-api.ceshiku.cn:5555 -p 0bcxxxxxxxxxxxf39 --disable-auto-update --disable-command-execute --report-delay=2 重启 nezha-agent 后生效： 12systemctl daemon-reloadservice nezha-agent start 完成的可配置项如下： 参数 解释 –report-delay 系统信息上报的间隔，默认为 1 秒，可以设置为 3 来进一步降低 agent 端系统资源占用（配置区间 1-4） –skip-conn 不监控连接数，机场/连接密集型机器推荐设置，不然比较占 CPU(shirou/gopsutil/issues#220) –skip-procs 不监控进程数，也可以降低 agent 占用 –disable-auto-update 禁止 Agent 自动更新（安全特性） –disable-command-execute 禁止在 Agent 机器上执行定时任务、打开在线终端（安全特性） 至此哪吒监控的 agent 端就安装完成了。 4. 后记得益于开发者奶爸提供的一键脚本，哪吒监控的安装部署可以说是相当简单，其文档中记录的常见问题与解决方案更是全面，非常值得学习。","link":"/2022/11/29/bak_centos7_nezha/"},{"title":"【归档文章】CentOS7 下哪吒监控面板的搭建的监控端的安装","text":"关于搭建哪吒监控面板的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 部分境外代理用的服务器连入 Zabbix 实在是太吃资源了，过高的延迟也使得连接一直中断，考虑了一下决定将边缘业务用的服务器全抽离出来，单独用哪吒监控做管理。 1、首先注册一个新的 GitHub 应用哪吒监控管理员后台的登录认证使用的是 GitHub OAuth，即：将认证步骤交给 GitHub，面板只负责接收回调并判断是否是本人。注册新的应用：回调地址在域名基础上加上 /oauth2/callback 即可：接着创建一下私钥：将 Client ID 和新建的 Client secret 都保存一下，Client secret 之后就再也不会完整出现了！ 注：OAuth 不同于部分应用对你 GitHub 账号的绑定，OAuth 是不会像下面的图一样向你请求仓库的权限的:它只会需要一些个人公开信息（第 2 步面板端安装结束后有截图），因此使用上可以放心。更多详情请参照：授权 OAuth 应用程序 2、安装面板端（相当于 Zabbix 的 server + nginx 端）参照官方文档，执行： 12curl -L https://raw.githubusercontent.com/naiba/nezha/master/script/install.sh -o nezha.sh &amp;&amp; chmod +x nezha.shsudo ./nezha.sh 境内服务器安装使用加速源： 12curl -L https://cdn.jsdelivr.net/gh/naiba/nezha@master/script/install.sh -o nezha.sh &amp;&amp; chmod +x nezha.shsudo ./nezha.sh 依旧无法下载脚本或端安装文件的情况下，请使用临时代理（代理请自行准备，关闭连接后此配置会失效）： 1export http_proxy=socks5://99999:22222@63.225.10.10:20800 选择安装面板端：期间需要安装 Docker，之后以此输入 Client ID、Client Secret 和 GitHub 用户名和站点标题即可，端口用默认的就行：别忘了开放防火墙和安全组，之后启动面板即可： 如果你和我一样是使用 Certbot 申请免费的Let’s encrypt 证书，且使用的是在网站目录下放验证文件的方法，那么可以直接参考我的 Nginx 配置： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455 ... ... server { listen 80; server_name status.example.com; # Let's Encrypt 证书认证 location ~ /.well-known { root /usr/share/nginx; allow all; } # 非强制跳转 HTTPS location / { # 套 CDN 重定向次数过多则放开 301 跳转 proxy_pass http://localhost:8008; proxy_set_header Host $host; # 不套 CDN 时 301 跳转 HTTPS # return 301 https://$host$request_uri; } } server { listen 443 ssl; server_name status.example.com; # SSL 配置 ssl_certificate /etc/letsencrypt/live/status.example.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/status.example.com/privkey.pem; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; location / { proxy_pass http://localhost:8008; proxy_set_header Host $host; } location /ws { proxy_pass http://127.0.0.1:8008; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;Upgrade&quot;; proxy_set_header Host $host; } location /terminal { proxy_pass http://127.0.0.1:8008; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;Upgrade&quot;; proxy_set_header Host $host; } }...... 前往页面授权登录即可： 3、安装被监控端（即 Zabbix agent 端）首先在管理面板新建被监控服务器：获取密钥留用：接着前往被监控服务器，执行的命令和面板端的一样： 12curl -L https://raw.githubusercontent.com/naiba/nezha/master/script/install.sh -o nezha.sh &amp;&amp; chmod +x nezha.shsudo ./nezha.sh 这里的域名可以直接输入监控端的外网 IP 而不一定要是域名，反正不是套 CDN 就行了：回到页面上，就能看到服务器数据了： 结束。","link":"/2021/10/28/bak_centos7_nezha_monitor/"},{"title":"【归档文章】CentOS7 下 Nginx + uWSGI 配置 Django 项目","text":"关于部署 Django 项目的笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 服务器的部署笔记。​各部分功能介绍： Nginx 是一个高性能的 HTTP 和反向代理 Web 服务器，同时也提供了 IMAP/POP3/SMTP 服务。 uWSGI 负责多线程，即支持多人同时访问网站。 Django 是由 Python 编写的开源 Web 应用框架，适合个人小项目搭建。 服务器系统为 CentOS7，当然记录的所有命令再更高版本上也都可以使用。 1、升级至 Python3既然搭建的是 Python 项目，首先升级以下服务器端的 Python 版本，默认 Linux 自带 Python2，我们把它先升级为 Python3。安装依赖软件 12yum -y install sqlite-develyum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel 下载安装 Python3.6 12345wget https://www.python.org/ftp/python/3.6.1/Python-3.6.1.tgztar zxvf Python-3.6.1.tgzcd Python-3.6.1./configure --prefix=/usr/local/python3make &amp;&amp; make install 创建 Python 及 pip 命令软链接 12ln -s /usr/local/python3/bin/python3 /usr/bin/python3ln -s /usr/local/python3/bin/pip3 /usr/bin/pip3 这样 Python3 就已经安装完成了，键入 Python3 再回车就可以进入 Python 编译了。注：Ctrl+Z 退出 Python 编译 2、安装 Django接下来安装 Django 并配置项目，这里选择的版本是 2.1.8，单纯的因为够用且稳定，新版本的环境配置没有前人指导。 1pip3 install django==2.1.8 等待安装完成后，上传 Django 项目到服务器上任意目录，使用 Xftp 或者 git clone 都可以 12cd 项目文件夹python3 manage.py runserver 0.0.0.0:80 注意，运行项目时可能报错： You have 15 unapplied migration(s). Your project may not work properly until you apply the migrations for app(s): admin, auth, contenttypes, sessions.Run ‘python manage.py migrate’ to apply them. 这时只需要按照提示，输入以下内容即可 1python3 manage.py migrate 出现以下信息则说明启动成功。注意： 如果访问页面出现了以下错误，那么进入你的项目，修改 settings.py 将 ALLOWED——HOSTS = [] 修改为 [‘*’] 即可解决。 DisallowedHost at / Invalid HTTP_HOST header: ‘47.56.227.27’. You may need to add ‘47.56.227.27’ to ALLOWED_HOSTS. 至此，Python 环境与 Django 环境就安装完成。​ 3、安装 uWSGI Web 网关首先下载安装 uWSGI 123456wget http://projects.unbit.it/downloads/uwsgi-2.0.1.tar.gztar zxvf uwsgi-2.0.1.tar.gzcd uwsgi-2.0.1python3 uwsgiconfig.py --buildcp -R /home/uwsgi-2.0.1 /usr/local/uwsgiln -s /usr/local/uwsgi/uwsgi /usr/bin/uwsgi 然后测试 uWSGI 是否安装成功，创建测试文件 1vi test.py 文件内容为： 123def application(env, start_response): start_response('200 OK', [('Content-Type','text/html')]) return [b&quot;Hello World&quot;] 输入完成后 :wq 保存，然后执行以下命令进行测试。 1/usr/local/uwsgi/uwsgi --http :9090 --wsgi-file /home/test.py 防火墙开放端口指令： 12345# 查看当前开放的所有端口firewall-cmd --list-all# 替换为你需要开放的端口firewall-cmd --add-port=80/tcp --permanentfirewall-cmd --reload 然后去对应服务商的安全组处开放安全组。这里就以阿里云国际为例。 前往你的 IP:9090 出现 Hello World 就说明 uWSGI 的安装已经完成了！ 4、uWSGI 和 Django 结合1uwsgi --http :9090 --chdir /home/Django 项目文件夹 --wsgi-file Django 项目(与 manage.py 同级)/wsgi.py --master --processes 4 --threads 2 --stats 127.0.0.1:9192 同样访问 IP:9090 ，如果可以访问 Django 页面则说明成功。注：如果在访问 Django 项目时静态文件加载失败可以先忽略，在 Nginx 配置中会指定静态文件路径，配置后可以正常访问。 5、安装 Nginx首先下载安装依赖第三方软件 PCRE 12wget http://jaist.dl.sourceforge.net/project/pcre/pcre/8.34/pcre-8.34.tar.bz2tar jxvf pcre-8.34.tar.bz2 如果报错：bzip2: Cannot exec: No such file or directory执行：yum -y install bzip2 123cd pcre-8.34./configure --enable-utf8make &amp;&amp; make install 下载安装依赖第三方软件 OpenSSL 12wget http://distfiles.macports.org/openssl/openssl-1.0.2h.tar.gztar zxvf openssl-1.0.2h.tar.gz 下载安装 Nginx 1234wget http://nginx.org/download/nginx-1.9.9.tar.gztar zxvf nginx-1.9.9.tar.gz./configure --prefix=/usr/local/nginx --with-pcre --with-http_stub_status_module --with-http_ssl_module --with-openssl=/home/openssl-1.0.2h --with-http_gzip_static_module --with-http_sub_module --with-cc=/usr/bin/gccmake install 新建 www 用户 1useradd -s /sbin/nologin -M www 备份、修改 Nginx 配置文件 123456cd /usr/local/nginx/confcp -f nginx.conf nginx.conf_bakvi nginx.conf (修改文件) user www; # 修改启动用户为 www worker_processes 4; # 启动4个进程，根据实际需求配置 启动 Nginx 12cd /usr/local/nginx/sbin./nginx 如果报错：nginx: [emerg] still could not bind()说明80端口目前被占用执行： 1netstat -apn | grep 80 然后： 12345678910111213141516171819202122232425262728kill -9 26105``` *26105 为搜索出来的 0.0.0.0/80 对应的 PID* *注意：需要删除 5-6 次，因为执行的适合有进程保护*再访问 IP:80 显示 Nginx 页面说明 Nginx 安装成功。 ![成功](https://image.senjianlu.com/blog/2024-09-03/63d1fff1a7107.png) #### 6、Nginx + uWSGI + Django 三者连携首先在 Django 项目文件夹中创建 uwsgi.ini```bashvi uwsgi.ini (文件内容) [uwsgi] # uwsgi启动端口 socket = 127.0.0.1:9090 # django项目目录 chdir=/home/SteamCash module=SteamCash.wsgi master = true processes=2 threads=2 max-requests=2000 chmod-socket=664 vacuum=true # 日志路径 daemonize = /home/SteamCash/logs/uwsgi.log 配置 Nginx 1234567891011121314151617181920212223vi /usr/local/nginx/conf/nginx.conf (文件内容) ...... server { listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; # 选择为你项目的static文件夹 location /static { alias /home/SteamCash/static; } location / { include uwsgi_params; uwsgi_pass 127.0.0.1:9090; root html; index index.html index.htm; } ...... 启动 uWSGI 1uwsgi --ini /home/SteamCash/uwsgi.ini 启动 Nginx 1./usr/local/nginx/sbin/nginx 接着访问页面即可。","link":"/2020/01/10/bak_centos7_nginx_uwsgi_django/"},{"title":"【归档文章】CentOS7 下使用 OpenSSL 生成 CA 自签发证书并解决 Windows 下信任证书后 Chrome 出现 ERR_CERT_COMMON_NAME_INVALID 的问题","text":"关于在 Windows 下信任自签证书的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 主要是两个步骤：1、生成 SSL 私钥（.key 文件）和证书签发请求文件（.csr 文件）；2、自己充当证书颁发机构（CA）进行签发生成证书（.crt 文件）。 1、检查是否已经安装 OpenSSL1openssl version 没有安装的话执行以下命令安装： 1yum -y install openssl 2、生成私钥秘钥文件名可以自己更改，我因为是给 K3s Rancher 用才这么命名。 12# 允许后需要输入至少 4 位的密码，后面有去除密码的步骤因此随便输入即可openssl genrsa -des3 -out rancher.key 4096 3、生成证书签发请求在证书生成目录新建配置文件，以配置 SubjectAltName 来防止 Chrome 报“没有指定主题备用名称”的错误： 1vi ext.ini 文件内容： 1234567891011121314151617181920212223242526[ req ]default_bits = 4096distinguished_name = req_distinguished_namereq_extensions = req_ext[ req_distinguished_name ]countryName = Country Name (2 letter code)countryName_default = CNstateOrProvinceName = State or Province Name (full name)stateOrProvinceName_default = ZhejianglocalityName = Locality Name (eg, city)localityName_default = HangzhouorganizationName = Organization Name (eg, company)organizationName_default = k3sorganizationalUnitName = Organizational Unit Name (eg, section)organizationalUnitName_default = ranchercommonName = Common Name (e.g. server FQDN or YOUR name)commonName_max = 64commonName_default = rancher.k3s.cn[ req_ext ]subjectAltName = @alt_names[alt_names]DNS.1 = k3s.cnDNS.2 = *.k3s.cn subj 参数解释： 字段 字段含义 示例 /C= Country 国家 CN /ST= State or Province 省 Zhejiang /L= Location or City 城市 Hangzhou /O= Organization 组织或企业 k3s /OU= Organization Unit 部门 rancher /CN= Common Name 域名或 IP rancher.k3s.com 生成证书请求文件： 1openssl req -new -sha256 -out rancher.csr -key rancher.key -config ext.ini 4、去除私钥中的密码以防止每次启动Web服务器时，都被要求输入密码： 1openssl rsa -in rancher.key -out rancher.key 5、自己充当 CA 进行证书的签发12# 签发 10 年的证书openssl x509 -req -days 3650 -in rancher.csr -signkey rancher.key -out rancher.crt -extensions req_ext -extfile ext.ini 完成后看下目录确定是否生成成功： 123[root@VM-8-6-centos ~]# ls# 有 .crt 文件说明成功rancher.crt rancher.csr rancher.key ext.ini 6、Nginx 配置12345678910111213141516171819202122232425262728293031......server { listen 80; server_name rancher.k3s.com; # 强制跳转 HTTPS location / { # root /usr/share/nginx/html; # index index.html; return 301 https://$server_name$request_uri; }}server { listen 443 ssl; server_name rancher.k3s.com; # SSL 配置 ssl_certificate /etc/nginx/ssl/rancher.crt; ssl_certificate_key /etc/nginx/ssl/rancher.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; location / { root /usr/share/nginx/html; index index.html; }}...... 通过 HTTPS 访问仍然会显示不安全，查看下证书发现生效了但是因为是自签的所以不受信任： 7、Windows 本地信任证书12# cmd 键入 mmc 打开控制台mmc 添加/删除单元：为根节点添加证书选项，弹出框选择当前用户即可：根目录中导入证书：将服务上的 .crt 文件下载到本地，导入一路选择“是”即可完成导入：回页面看一眼证书现在已经被信任了： 8、Chrome 信任证书存在一些情况 Edge 已经信任证书，但是 Chrome 还不信任：前往 Chrome 高级设置里的证书处导入即可： 结束。","link":"/2021/09/28/bak_centos7_openssl_ca/"},{"title":"【归档文章】CentOS7 下 Docker 启动的 RabbitMQ 遇到 Virtual host &#x2F; experienced an error on node rabbit@41xx9xx9xxc6 and may be inaccessible 问题的解决","text":"关于 RabbitMQ 的问题解决记录。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 消费者离线了两天，结果 RabbitMQ 就崩了……. 1、错误情况管理页面的错误消息如下： 1Virtual host / experienced an error on node rabbit@41xx9xx9xxc6 and may be inaccessible 2、调查首先去检查生产者和消费者的日志，说一句因为 RabbitMQ 已经 Down 掉了，所以生产者和消费者是登录不上 RabbitMQ 的，而且崩溃的原因大都是因为消费者方出问题，所以我这次直接就去找消费者的服务器了。试了下，消费者服务器居然关机了……想到是不是生产者把队列塞满了，磁盘 100% 了，去腾讯云后台监控看了一眼，果然…… 3、解决停掉之前的容器（这里我容器的名字是 rabbitmq）： 1docker stop rabbitmq 清理容器残留： 1docker system prune 重启容器： 1docker run -d --name rabbitmq --restart=always -p 5672:5672 -p 15672:15672 rabbitmq:3.9-management 然后去生产者代码部分加上对队列长度判断以防万一。 结束。","link":"/2022/03/25/bak_centos7_rabbitmq_error_disk/"},{"title":"【归档文章】CentOS7 下搭建 ServerStatus 监控（ServerStatus-Hotaru 版且带客户端的安装）","text":"关于搭建 ServerStatus 监控面板的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 1. 我不使用 ServerStatus 的理由我在经过较长时间的纠结后选择了 nezha（哪吒）而非 ServerStatus，主要原因有三点： 哪吒官方支持使用 Docker 部署，而 ServerStatus 不支持。 哪吒有前端的控制面板，支持在前端修改配置和管理服务器节点，且每次添加节点时，只需要复制命令前往节点服务器一键执行即可；ServerStatus 每次添加节点却需要前往服务端修改 config.json 配置文件，过于繁琐。 哪吒可以通过控制面板远程在服务器节点上执行 SSH 命令，而 ServerStatus 不支持。 2. 安装部署我这里选择了 ServerStatus-Hotaru 这个版本进行部署，因为它相比 ServerStatus 页面部署方式更加简单，同时页面也更加美观，对比如下： 2.1 server 端安装 官方文档：服务端安装方法 直接执行： 1234567cd /root/ &amp;&amp; mkdir ServerStatus &amp;&amp; cd /root/ServerStatus# 下载安装脚本wget https://raw.githubusercontent.com/cokemine/ServerStatus-Hotaru/master/status.sh# 若服务器位于中国大陆建议选择 Coding.net 仓库# wget https://cokemine.coding.net/p/hotarunet/d/ServerStatus-Hotaru/git/raw/master/status.sh# 执行安装脚本bash status.sh s 选择安装服务端：之后选择安装源和端口：在配置 HTTP 服务这里，我推荐选择 不需要自动部署，马上我会附上我的 Nginx 配置。等待 ServerStatus 的服务端安装完成并启动后，我们来配置前端项目！极为简单，只需要在 Nginx 中为对应的域名配置 ServerStatus 的前端文件目录即可（路径默认为 /usr/local/ServerStatus/web）： 12# 编辑 Nginx 的配置文件vi /etc/nginx/nginx.conf 添加如下代码段： 12345server { listen 80; server_name server-status.ceshiku.cn; root /usr/local/ServerStatus/web;} 重启 Nginx： 12nginx -s reloadservice nginx restart 然后前往你的域名，看到这个页面则说明服务端安装和启动成功了！ 2.2 节点添加和 agent 端安装 节点添加，首先编辑配置文件并输入你 agent 服务器的信息： 1vi /usr/local/ServerStatus/server/config.json 1234567891011121314{ &quot;servers&quot;: [ { &quot;username&quot;: &quot;main&quot;, &quot;password&quot;: &quot;xxxxxxxxxx&quot;, &quot;name&quot;: &quot;斯巴达-美国洛杉矶-1H1.5G-主控&quot;, &quot;type&quot;: &quot;KVM&quot;, &quot;host&quot;: &quot;45.151.132.xxx&quot;, &quot;location&quot;: &quot;US&quot;, &quot;disabled&quot;: false, &quot;region&quot;: &quot;US&quot; } ]} 你可以在维基百科关于 ISO 3166-1 找到你服务器的 location 和 region。 之后重启服务端和 Nginx： 1234# 重启服务端，之后选择 6. 重启 服务端bash status.sh s# 重启 Nginxservice nginx restart 看到页面上服务器的名字变更就说明成功了。 agent 端安装 官方文档：服务端安装方法 到 agent 服务器上执行： 1234567cd /root/ &amp;&amp; mkdir ServerStatus &amp;&amp; cd /root/ServerStatus# 下载安装脚本wget https://raw.githubusercontent.com/cokemine/ServerStatus-Hotaru/master/status.sh# 若服务器位于中国大陆建议选择 Coding.net 仓库# wget https://cokemine.coding.net/p/hotarunet/d/ServerStatus-Hotaru/git/raw/master/status.sh# 执行安装脚本bash status.sh c 输入刚刚在服务端的 IP 或域名、配置的账号密码开始安装： 看到如下信息则说明安装成功： 前往页面： 服务器的监控数据已经开始更新了，至此 server 端和 agent 端都安装成功！ 3. 后记ServerStatus 的 agent 节点添加过程中，不可避免地需要登陆 server 端所在的服务器进行配置文件的更新，对于小鸡买买丢丢的我来说属实是太过折腾。而哪吒端的节点添加则简单很多：管理面板上 agent 服务器名和分组一设置，接着复制带密钥信息的安装指令直接去 agent 服务器执行即可，省事太多，因此最终我选择的也是哪吒监控。","link":"/2023/01/21/bak_centos7_serverstatus/"},{"title":"【归档文章】CentOS7 下安装 Shadowsocks 服务端","text":"关于 Shadowsocks 协议节点的搭建教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 安装个 Shadowsocks 给新买的隧道用。 1、配置 repo 仓库给后面 YUM 安装使用注：原仓库已经删除，现在只剩备份仓库，使用的 repo 源是备用仓库中 README.md 中记载的，应该是可信的，并且我参考大量的教程也均使用的是这个地址，如果你还是不放心请在代理专用服务器上安装。 123cd /etc/yum.repos.d/# 配置 repo 仓库curl -O https://copr.fedorainfracloud.org/coprs/librehat/shadowsocks/repo/epel-7/librehat-shadowsocks-epel-7.repo 2、YUM 安装执行： 1yum install -y shadowsocks-libev 测试下是否安装成功： 1ss-server 3、配置默认配置路径为：/etc/shadowsocks-libev/config.json 1vi /etc/shadowsocks-libev/config.json 默认的配置如下： 12345678{ &quot;server&quot;:&quot;127.0.0.1&quot;, &quot;server_port&quot;:8388, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;mypassword&quot;, &quot;timeout&quot;:60, &quot;method&quot;:&quot;chacha20-ietf-poly1305&quot;} 参数的解释（连接用的客户端简称为小飞机）： 参数 解释 样例 效果 server 和 Nginx 的 server 差不多，解析来自指定 IP 或域名的流量。 example.com 只解析来自 example.com 的流量，连接时小飞机也配置同样的域名。 server_port 服务端启动在的哪个端口。 18388 小飞机配置连接本服务器时的端口。 local_port 客户端连接用的端口。 1080 服务启动在本地的 1080 端口上，与连接信息无关。 password 客户端连接用的端口。 mypassword 小飞机配置连接本服务器时需要使用的密码。 timeout 连接超时时间。 60 method 加密方式 aes-256-cfb 小飞机配置连接本服务器时需要使用的加密方式。 加密方式可选：rc4、rc4-md5、aes-128-cfb、aes-192-cfb、aes-256-cfb、bf-cfb、camellia-128-cfb、camellia-192-cfb、camellia-256-cfb、cast5-cfb 和 des-cfb，推荐选择最常用的 aes-256-cfb 以免造成客户端不支持部分加密方式的尴尬情况。 我修改后的配置： 123456789{ // 0.0.0.0 即接受所有来源的请求，如果配置域名的话你需要先将域名解析到此服务器，防止出现 failed to resolve server name 的错误。 &quot;server&quot;:&quot;0.0.0.0&quot;, &quot;server_port&quot;:18388, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;mypassword&quot;, &quot;timeout&quot;:60, &quot;method&quot;:&quot;aes-256-cfb&quot;} 4、开放防火墙和安全组不赘述流程但是不要忘记有这一步。 我的 Linux 基础指令笔记中也有：Linux 命令（1）防火墙端口开启关闭 5、启动服务启动和其他的常用指令一起写上： 12345678# 启动 Shadowsocks 服务systemctl start shadowsocks-libev# 检查服务状态systemctl status shadowsocks-libev# 服务开机自启systemctl enable shadowsocks-libev# 查看 Shadowsocks 服务的全部日志journalctl -u shadowsocks-libev 启动完状态应该是 active 的： 6、客户端测试连接一般情况下你们都是在 Windows 或是手机端进行测试连接，这种情况我就不掩饰了手头没有闲置机器。我这里挑一台空闲的 CentOS7 机器安装 Shadowsocks 客户端（说是客户端，其实 Shadowsocks 服务端和客户端是一体的）来测试刚刚配置的服务端能否正常使用： 12# CentOS7 下一键安装 Shadowsocks 客户端curl -s https://gitee.com/senjianlu/one-click-scripts/raw/main/CentOS7%20%E4%B8%8B%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%20Shadowsocks%20%E5%AE%A2%E6%88%B7%E7%AB%AF/install.sh | bash 然后配置下客户端连接信息（位置和服务端都一样的）： 1vi /etc/shadowsocks-libev/config.json 配置文件只将 server 改为服务端的 IP 或绑定域名即可，其他不动： 123456789{ &quot;server&quot;:&quot;188.188.18.99&quot;, &quot;server_port&quot;:18388, // 客户端的本地端口就在后续的访问上用到了 &quot;local_port&quot;:1080, &quot;password&quot;:&quot;mypassword&quot;, &quot;timeout&quot;:60, &quot;method&quot;:&quot;aes-256-cfb&quot;} 改为使用 ss-local 来启动客户端： 12# 启动后在后台运行nohup /usr/bin/ss-local -c /etc/shadowsocks-libev/config.json &gt;/dev/null 2&gt;&amp;1 &amp; 测试访问一下： 12# 访问 IP 信息获取接口，1080 为客户端所在端口curl -x socks5://127.0.0.1:1080 http://ip-api.com/json/?lang=zh-CN 1{&quot;status&quot;:&quot;success&quot;,&quot;country&quot;:&quot;日本&quot;,&quot;countryCode&quot;:&quot;JP&quot;,&quot;region&quot;:&quot;xx&quot;,&quot;regionName&quot;:&quot;Tokyo&quot;,&quot;city&quot;:&quot;东京&quot;,&quot;zip&quot;:&quot;xxx-xxxx&quot;,&quot;lat&quot;:xx.xxxx,&quot;lon&quot;:xxx.xxx,&quot;timezone&quot;:&quot;Asia/Tokyo&quot;,&quot;isp&quot;:&quot;xxxxxx&quot;,&quot;org&quot;:&quot;xxxxxx&quot;,&quot;as&quot;:&quot;xxxxxxx&quot;,&quot;query&quot;:&quot;188.188.18.99&quot;} IP 对上了，说明配置没错！ 结束。","link":"/2021/10/25/bak_centos7_shadowsocks_server/"},{"title":"【归档文章】CentOS7 下安装 SOCKS5 代理并使用 GOST 搭建加密中转隧道","text":"关于安装 SOCKS5 代理并使用 GOST 搭建加密中转隧道的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 虽然 Telegram 的 APP 自带 SOCKS5 代理支持，直接配置即可使用，但是几乎配置完连上就是秒封，必须通过国内服务器做中转，即：国外服务器先安装 SOCKS5 代理，再安装 GOST 将国内机中转来的流量转发到本机 SOCKS5 对应端口；国内服务器则只需要安装 GOST 将中转流量转发至国外服务器即可。 我所配置的例子中流量所经历的转发过程：客户端 –&gt; 国内服务器:15555 –&gt;（加密）–&gt; 国外服务器:15554 –&gt;（本机转发）–&gt; 国外服务器:15555（SOCKS5 代理服务所在端口） 1、国外服务器安装 SOCKS5 代理不做介绍，CentOS7 直接使用我的一键脚本：CentOS7 下一键安装 SOCKS5 代理 123456curl -s https://gitee.com/senjianlu/one-click-scripts/raw/main/CentOS7%20下一键安装%20SOCKS5%20代理/install.sh | bash -s $ss5_port $ss5_username $ss5_password``` 注意安装过程中会自动开放防火墙的指定端口，如果安装完无法连接请自行检查云服务器端口组。 检查用指令： ```bashcurl -x socks5://$ss5_username:$ss5_password@$ip:$ss5_port http://ip-api.com/json/?lang=zh-CN 2、国内服务器安装 GOST使用我克隆的 GOST 管理一键脚本：注：原作者：KANIKIG；脚本原地址：Multi-EasyGost 1wget --no-check-certificate -O gost.sh https://gitee.com/senjianlu/one-click-scripts/raw/main/CentOS7%20下一键安装%20GOST%20并启动%20HTTP%20和%20SOCKS5%20代理服务/关联脚本/CentOS7%20下简单的%20GOST%20配置脚本/gost.sh &amp;&amp; chmod +x gost.sh &amp;&amp; ./gost.sh 出现一下界面则说明脚本下载并启动成功，首先输入“1”安装， 121y 安装成功后再次启动脚本，以提前配置好转发规则， 1./gost.sh 选择“7”， 17 由于是国内中转机，因此选择加密隧道流量转发“2”， 12 接下来的配置参考以下即可，一般选用 tls 隧道即可，IP 则需要替换为境外服务器 IP，国内机配置至此结束。 3、国外服务器安装 GOST 解密隧道流量并转发至 SOCKS5 端口配置与国内机大同小异，不过需要选解密隧道流量而非加密隧道流量，然后将流量转发至 SOCKS5 所在端口，我这里 SOCKS5 所在 15555 端口。至此 GOST 隧道转发配置就完成了。 出现问题请按以下步骤排查： 两边服务器防火墙和安全组是否都已经开放。 单访问国外服务器 SOCKS5 代理服务是否可行。 两边 GOST 配置是否匹配。 结束。","link":"/2023/06/15/bak_centos7_socks5_gost/"},{"title":"【归档文章】CentOS7 下建立 SWaP 分区以增加虚拟内存","text":"关于安装 CentOS7 下通过 SWaP 增加虚拟内存的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 明明腾讯云才免费帮忙升过配置，1H2G 升到了 2H4G，结果稍微部署了一点 Docker 又不够了……看了下现在的这些容器基本都是做端口流量转发的任务，内存交换量不需要很大，想试着加下虚拟内存看看能不能解决问题，毕竟 2H8G 的服务器就要到 70 多一个月了，能省则省。 1、确定需求因为 SWaP 分区相当于是将硬盘作为内存使用，硬盘 IO 速率如果不行会很影响程序运行，所以请先确定虚拟内存是否能满足你的需要。因我的需求是新增内存以运行更多的 Docker 容器，起一个样例并循环调用查看它的运行情况。粗略可以看到大概为 4 kB/s 的内存速率要求……再野鸡的 VPS 钻石盘都能满足，但还是来看下腾讯云硬盘 IO： 1time dd if=/dev/zero of=/test.disk bs=8k count=300 肯定能满足要求了。 2、创建 SWaP 分区首先查看是否是否已经有 SWaP 分区存在： 123# 一般情况下 SWaP 分区操作都在服务器根目录下执行cd /free -m 如果有的话先删除，执行以下命令清理分区： 12# swapfile 为你的分区文件名swapoff /swapfile 如果没有既存分区或者分区清理完毕以后，便可以开始着手增加分区了。网上一般都建议增加 1 到 2 倍原内存的虚拟内存空间，实际上还是得看你是否真的需要这些内存和其性能是否能满足你的要求，部分情况下堆积过多缓存在 SWaP 会严重影响程序运行，在最边缘的扇区 IO 速率甚至会降到不到 1mB/s 以下，详细可以参照这篇讨论：How can swapoff be that slow?回归正题，因为我对内存速率一点要求都没有，因此直接扩容到当前内存的 2 倍大小， 12345678# 创建分区文件，我的分区文件名为 swapfilesudo dd if=/dev/zero of=/swapfile bs=1k count=7578000# 建立 SWaPmkswap /swapfile# 启动 SWaPswapon /swapfile# 查看虚拟内存是否创建成功free -m 创建成功。 3、开机自动启动 SWaP 分区只需要修改 /etc/fstab 文件，在最后添加一行内容即可。 12sudo chmod 777 /etc/fstabsed -i '$a /swapfile swap swap defaults 0 0' /etc/fstab 至此，SWaP 分区创建成功，可以重启看下配置是否均生效。","link":"/2021/07/12/bak_centos7_swap/"},{"title":"【归档文章】CentOS7 搭建 Trojan 协议的节点（Trojan-Go 版且含与原版的测速对比）","text":"关于 Trojan 协议节点的搭建教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 1. 关于 TrojanTrojan 官方的文档中是这么描述自己的： Trojan is not a fixed program or protocol. It’s an idea, an idea that imitating the most common service, to an extent that it behaves identically, could help you get across the…… 这意味着 Trojan 严格意义上来说并不是一种协议，任何符合以下两种要求的协议都可以被看作 Trojan 的一种实现： 流量经过加密后，再伪装成正常的 HTTPS 请求形式。 有针对主动或被动探测的防御手段，难以确定这个域名和服务器的用途。 附上一张图简单介绍 Trojan 协议下请求内容的组成： 但在本文中，我会仍然把 Trojan 作为一种协议来方便读者理解。​ 1.1 Trojan 的优点（相比 SS） 在 Trojan 基本原理有详细介绍。 保密性（无法得知传输的内容） 完整性（一旦试图篡改传输的密文，通讯双方都会发现） 不可抵赖（无法伪造身份冒充服务端或者客户端） 前向安全（即使密钥泄露，也无法解密先前的加密流量） 1.2 Trojan 的缺点 需要有自己的域名。 官方部署方式会占用 443 端口，导致之后服务器部署站点有点麻烦。 1.3 我选择 Trojan 的理由 Trojan 协议天生的各种优点，并且相比其他协议 Trojan 更为小众，理论上在互联网流量中更隐蔽。 部署简单：下载软件包并解压、申请 SSL 证书并配置，之后直接启动即可。 我的代理服务器都和生产服务器有明确区分，因此没有共用 443 端口的场景。 我常用的客户端小猫咪和 Surge 都支持该协议。 2. Trojan、Trojan-Go 和开启 BBR 后的测速对比 这里选择的是 RackNerd 洛杉矶机房的服务器，测速结果只能用来对比不能用作购买建议。 油管晚高峰测速 油管测速时的系统占用 Trojan Trojan（BBR 开启后） Trojan-Go Trojan-Go（BBR 开启后） 结论： 原版 Trojan 和 Trojan-Go 的油管测速相差不大。 BBR 开启后提速超 80%！ 3. 安装部署我选择了 Trojan-Go 版本以使用其支持的特殊功能：连接复用，它可以给我的 Python 爬虫脚本带来相当多的提升。 3.1 服务端部署3.1.1 将域名解析到服务器注意不要开启 CDN！ 3.1.2 安装 Nginx 用以设置伪装页面和申请 Let’s Encrypt 的免费 SSL 证书12345yum -y install epel-releaseyum -y install nginxservice nginx start# 设置开机启动systemctl enable nginx 访问 IP 测试下是否能访问到页面，不能到话去开启下防火墙和安全组，之后配置 Nginx： 12cd /etc/nginxvi nginx.conf 为 80 端口的监听新增一段 Let’s Encrypt 证书认证用的配置： 12345678910111213141516171819202122232425......server { listen 80; listen [::]:80; root /usr/share/nginx/html; include /etc/nginx/default.d/*.conf; # 新增的代码段 # Let's Encrypt 证书认证（优先级最高放在最前面） location ~ /.well-known { root /usr/share/nginx; allow all; } error_page 404 /404.html; location = /404.html { } error_page 500 502 503 504 /50x.html; location = /50x.html { }}...... 之后重启： 12nginx -s reloadservice nginx restart 3.1.3 安装 certbot 并申请 SSL 证书123yum -y install certbot# 申请证书，在证书即将过期时会有邮件提醒certbot certonly --webroot --agree-tos -v -t --email admin@ceshiku.cn -w /usr/share/nginx/ -d trojan.ceshiku.cn 申请完成后证书的路径为： cert 文件：/etc/letsencrypt/live/trojan.ceshiku.cn/fullchain.pem key 文件：/etc/letsencrypt/live/trojan.ceshiku.cn/privket.pem申请完成后别忘记添加定时任务更新证书，防止 3 个月后证书过期： 12# 配置定时任务crontab -e 12# 每 12 小时更新一下证书0 */12 * * * certbot renew --pre-hook &quot;service nginx stop&quot; --post-hook &quot;service nginx start&quot; 12# 刷新定时任务service crond restart 3.1.4 下载 Trojan-Go 软件包并解压12345678cd /root/# 下载yum -y install wgetwget https://github.com/p4gefau1t/trojan-go/releases/download/v0.10.6/trojan-go-linux-amd64.zip# 解压到 /root/trojan-go 目录mkdir /root/trojan-goyum -y install unzipunzip -d trojan-go/ trojan-go-linux-amd64.zip 原版： 123456cd /root/# 下载yum -y install wgetwget https://github.com/trojan-gfw/trojan/releases/download/v1.16.0/trojan-1.16.0-linux-amd64.tar.xz# 解压到 /root/trojan 目录tar -xvf trojan-1.16.0-linux-amd64.tar.xz 之后进入目录创建配置文件： 12cd /root/trojan-govi config.json 配置内容在下方，修改下你的密码和域名即可，我这里的可执行文件 trojan-go 在 /root/trojan-go/ 中，如果你和我不一样也请自己更改下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677{ &quot;run_type&quot;: &quot;server&quot;, &quot;local_addr&quot;: &quot;0.0.0.0&quot;, &quot;local_port&quot;: 443, &quot;remote_addr&quot;: &quot;127.0.0.1&quot;, &quot;remote_port&quot;: 80, &quot;log_level&quot;: 1, &quot;log_file&quot;: &quot;/root/trojan-go/test.log&quot;, &quot;password&quot;: [ &quot;YourPassword&quot; ], &quot;buffer_size&quot;: 32, &quot;dns&quot;: [], &quot;ssl&quot;: { &quot;verify&quot;: true, &quot;verify_hostname&quot;: true, &quot;cert&quot;: &quot;/etc/letsencrypt/live/trojan.ceshiku.cn/fullchain.pem&quot;, &quot;key&quot;: &quot;/etc/letsencrypt/live/trojan.ceshiku.cn/privkey.pem&quot;, &quot;key_password&quot;: &quot;&quot;, &quot;cipher&quot;: &quot;&quot;, &quot;cipher_tls13&quot;: &quot;&quot;, &quot;curves&quot;: &quot;&quot;, &quot;prefer_server_cipher&quot;: false, &quot;sni&quot;: &quot;trojan.ceshiku.cn&quot;, &quot;alpn&quot;: [ &quot;http/1.1&quot; ], &quot;session_ticket&quot;: true, &quot;reuse_session&quot;: true, &quot;plain_http_response&quot;: &quot;&quot;, &quot;fallback_port&quot;: 80, &quot;fingerprint&quot;: &quot;firefox&quot;, &quot;serve_plain_text&quot;: false }, &quot;tcp&quot;: { &quot;no_delay&quot;: true, &quot;keep_alive&quot;: true, &quot;reuse_port&quot;: false, &quot;prefer_ipv4&quot;: false, &quot;fast_open&quot;: false, &quot;fast_open_qlen&quot;: 20 }, &quot;mux&quot;: { &quot;enabled&quot;: true, &quot;concurrency&quot;: 8, &quot;idle_timeout&quot;: 60 }, &quot;router&quot;: { &quot;enabled&quot;: false, &quot;bypass&quot;: [], &quot;proxy&quot;: [], &quot;block&quot;: [], &quot;default_policy&quot;: &quot;proxy&quot;, &quot;domain_strategy&quot;: &quot;as_is&quot;, &quot;geoip&quot;: &quot;/root/trojan-go/geoip.dat&quot;, &quot;geosite&quot;: &quot;/root/trojan-go/geosite.dat&quot; }, &quot;websocket&quot;: { &quot;enabled&quot;: false, &quot;path&quot;: &quot;/&quot;, &quot;hostname&quot;: &quot;trojan.ceshiku.cn&quot;, &quot;obfuscation_password&quot;: &quot;&quot;, &quot;double_tls&quot;: true, &quot;ssl&quot;: { &quot;verify&quot;: true, &quot;verify_hostname&quot;: true, &quot;cert&quot;: &quot;/etc/letsencrypt/live/trojan.ceshiku.cn/fullchain.pem&quot;, &quot;key&quot;: &quot;/etc/letsencrypt/live/trojan.ceshiku.cn/privkey.pem&quot;, &quot;key_password&quot;: &quot;&quot;, &quot;prefer_server_cipher&quot;: false, &quot;sni&quot;: &quot;trojan.ceshiku.cn&quot;, &quot;session_ticket&quot;: true, &quot;reuse_session&quot;: true, &quot;plain_http_response&quot;: &quot;&quot; } }} 原版： 12cd /root/trojanvi config.json 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354{ &quot;run_type&quot;: &quot;server&quot;, &quot;local_addr&quot;: &quot;0.0.0.0&quot;, &quot;local_port&quot;: 443, &quot;remote_addr&quot;: &quot;127.0.0.1&quot;, &quot;remote_port&quot;: 80, &quot;password&quot;: [ &quot;YourPassword&quot; ], &quot;log_level&quot;: 1, &quot;ssl&quot;: { &quot;cert&quot;: &quot;/etc/letsencrypt/live/trojan.ceshiku.cn/fullchain.pem&quot;, &quot;key&quot;: &quot;/etc/letsencrypt/live/trojan.ceshiku.cn/privkey.pem&quot;, &quot;key_password&quot;: &quot;&quot;, &quot;cipher&quot;: &quot;ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384&quot;, &quot;cipher_tls13&quot;: &quot;TLS_AES_128_GCM_SHA256:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_256_GCM_SHA384&quot;, &quot;prefer_server_cipher&quot;: true, &quot;alpn&quot;: [ &quot;http/1.1&quot; ], &quot;alpn_port_override&quot;: { &quot;h2&quot;: 81 }, &quot;reuse_session&quot;: true, &quot;session_ticket&quot;: false, &quot;session_timeout&quot;: 600, &quot;plain_http_response&quot;: &quot;&quot;, &quot;curves&quot;: &quot;&quot;, &quot;dhparam&quot;: &quot;&quot; }, &quot;tcp&quot;: { &quot;prefer_ipv4&quot;: false, &quot;no_delay&quot;: true, &quot;keep_alive&quot;: true, &quot;reuse_port&quot;: false, &quot;fast_open&quot;: false, &quot;fast_open_qlen&quot;: 20 }, &quot;mysql&quot;: { &quot;enabled&quot;: false, &quot;server_addr&quot;: &quot;127.0.0.1&quot;, &quot;server_port&quot;: 3306, &quot;database&quot;: &quot;trojan&quot;, &quot;username&quot;: &quot;trojan&quot;, &quot;password&quot;: &quot;&quot;, &quot;key&quot;: &quot;&quot;, &quot;cert&quot;: &quot;&quot;, &quot;ca&quot;: &quot;&quot; }}启动下试试：```bash/root/trojan-go/trojan-go -config /root/trojan-go/config.json 原版： 1/root/trojan/trojan /root/trojan/config.json没有报错的话就说明软件的安装没有问题。 3.1.5 将 Trojan-Go 注册为服务新建服务： 12cd /usr/lib/systemd/system/vi trojan-go.service 内容： 1234567891011121314[Unit]Description=trojan-goAfter=network.target nss-lookup.targetWants=network-online.target[Service]Type=simpleExecStart=/root/trojan-go/trojan-go -config /root/trojan-go/config.jsonRestart=on-failureRestartSec=10RestartPreventExitStatus=23[Install]WantedBy=multi-user.target 之后的控制命令就很简单了： 12345678# 关闭systemctl stop trojan-go.service# 启动systemctl start trojan-go.service# 设置开机自启动systemctl enable trojan-go.service# 确保运行状态service trojan-go status 原版： 12cd /usr/lib/systemd/system/vi trojan.service 1234567891011121314[Unit]Description=trojanAfter=network.target nss-lookup.targetWants=network-online.target[Service]Type=simpleExecStart=/root/trojan/trojan /root/trojan/config.jsonRestart=on-failureRestartSec=10RestartPreventExitStatus=23[Install]WantedBy=multi-user.target 12345678# 关闭systemctl stop trojan.service# 启动systemctl start trojan.service# 设置开机自启动systemctl enable trojan.service# 确保运行状态service trojan status 3.1.6 重设定时任务使 Trojan-Go 使用最新的 SSL 证书1crontab -e 12# 每 12 小时更新一下证书0 */12 * * * certbot renew --pre-hook &quot;service nginx stop &amp; service trojan-go stop&quot; --post-hook &quot;service nginx start &amp; service trojan-go start&quot; 原版： 12# 每 12 小时更新一下证书0 */12 * * * certbot renew --pre-hook &quot;service nginx stop &amp; service trojan stop&quot; --post-hook &quot;service nginx start &amp; service trojan start&quot; 3.2 客户端设置Trojan 协议在客户端的配置极为简单，只需要：域名、端口和密码三个参数即可。 3.2.1 小猫咪配置代码段12proxies: - {name: 自建-Trojan, type: trojan, server: trojan.ceshiku.cn, port: 443, password: YourPassword } 3.2.2 Surge 配置代码段12[Proxy]自建-Trojan = trojan, trojan.ceshiku.cn, 443, password=YourPassword 3.2.3 小火箭节点配置 3.3 进阶设置3.3.1 BBR 加速从之前测速图可以看出，开启 BBR 加速后提速超 80%，油管测速可从 24W 提升至 44W 多。 具体安装方法可以参考这篇文章：CentOS7 安装新版内核和开启 BBR 加速 4. 后记看到过这么一篇帖子：发现 trojan 挺搞笑的，楼下的回复提到关于 Trojan 的设计：取 Hex 是为了让数据像HTTP那样 Human-readable， 以 CRLF 分割同样是为了能够跟 HTTP 采取同样的处理方式，不需要特地以 56 字节作为密码结束的标志。如果实际情况真的像这个回复所说的，那么 Trojan 作者的水平应该是不错的，且在第一版开发时就考虑到了后续的版本迭代，即使最差的情况出现：由于某种原因删库，有想法的源代码也应该会被容易地接手。因此在我看来，Trojan 是有未来的，可以作为一个长期使用的协议。","link":"/2023/01/22/bak_centos7_trojan/"},{"title":"【归档文章】CentOS7 下搭建 Trojan 服务端（附带搬瓦工机器的一些特殊配置）","text":"关于 Trojan 协议节点的搭建教程，以及搬瓦工机器的特殊配置。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 1、安装 Nginx 并启动安装 Nginx： 12345yum -y install epel-releaseyum -y install nginxservice nginx start# 设置开机启动systemctl enable nginx 访问 IP 测试下是否能访问到页面，不能到话去开启下防火墙和安全组，搬瓦工不需要这些操作因此在本文中略过。接着配置 Nginx： 12cd /etc/nginxvi nginx.conf 123456789101112131415161718192021222324252627282930# nginx.conf ... ... # ====== example.com ====== # === usa-bwg-01.example.com === server { listen 80; listen [::]:80; server_name usa-bwg-01.example.com; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; # Let's Encrypt 证书认证（优先级最高放在最前面） location ~ /.well-known { root /usr/share/nginx; allow all; } error_page 404 /404.html; location = /404.html { } error_page 500 502 503 504 /50x.html; location = /50x.html { } } ... ... 之后重启： 12nginx -s reloadservice nginx restart 2、安装 certbot 并申请证书安装： 1yum -y install certbot 申请证书： 1certbot certonly --webroot --agree-tos -v -t --email xxxxxx@qq.com -w /usr/share/nginx/ -d usa-bwg-01.example.com 这里我出现过两个错误：① 搬瓦工上出现的证书过期错误： 1234567...... if 'timed out' in str(err) or 'did not complete (read)' in str(err): # Python 2.6TypeError: __str__ returned non-string (type Error)An unexpected error occurred:TypeError: __str__ returned non-string (type Error)Please see the logfiles in /var/log/letsencrypt for more details. 想起来似乎是 2022 年上半年 Let’s Encrypt 的证书过期过一次，于是检查了下服务器的根证书版本： 1yum list updates -q | grep ca-certificates 返回的版本： 1ca-certificates.noarch 2021.2.50-72.el7_9 updates 果然是过期了，更新下： 1234# 查看更新日志rpm -qa --changelog ca-certificates | head -n5# 安装更新yum -y update ca-certificates 之后再申请就会成功了。② 阿里云上碰到的 python2 脚本相关导入出错： 1234567891011121314151617181920212223...... File &quot;/usr/lib/python2.7/site-packages/certbot/_internal/constants.py&quot;, line 6, in &lt;module&gt; from acme import challenges File &quot;/usr/lib/python2.7/site-packages/acme/challenges.py&quot;, line 11, in &lt;module&gt; import requests File &quot;/usr/lib/python2.7/site-packages/requests/__init__.py&quot;, line 58, in &lt;module&gt; from . import utils File &quot;/usr/lib/python2.7/site-packages/requests/utils.py&quot;, line 32, in &lt;module&gt; from .exceptions import InvalidURL File &quot;/usr/lib/python2.7/site-packages/requests/exceptions.py&quot;, line 10, in &lt;module&gt; from urllib3.exceptions import HTTPError as BaseHTTPError File &quot;/usr/lib/python2.7/site-packages/urllib3/__init__.py&quot;, line 10, in &lt;module&gt; from .connectionpool import ( File &quot;/usr/lib/python2.7/site-packages/urllib3/connectionpool.py&quot;, line 31, in &lt;module&gt; from .connection import ( File &quot;/usr/lib/python2.7/site-packages/urllib3/connection.py&quot;, line 45, in &lt;module&gt; from .util.ssl_ import ( File &quot;/usr/lib/python2.7/site-packages/urllib3/util/__init__.py&quot;, line 4, in &lt;module&gt; from .request import make_headers File &quot;/usr/lib/python2.7/site-packages/urllib3/util/request.py&quot;, line 5, in &lt;module&gt; from ..exceptions import UnrewindableBodyErrorImportError: cannot import name UnrewindableBodyError 执行一下命令重新安装 python-requests 模块即可： 123456sudo pip uninstall requestssudo pip uninstall urllib3sudo yum remove python-urllib3sudo yum remove python-requestssudo yum install python-urllib3sudo yum install python-requests 申请完成后别忘记添加定时任务更新证书，防止 3 个月后证书过期： 12# 配置定时任务crontab -e 12# 每 12 小时更新一下证书0 */12 * * * certbot renew --pre-hook &quot;service nginx stop&quot; --post-hook &quot;service nginx start&quot; 12# 刷新定时任务service crond restart 3、安装 Trojan-Go注：这里使用 Trojan-Go 的原因是其支持连接复用，比起普通的 Trojan 服务端建立连接会更快，当然对后续视频的下载速度不会有太大影响。Trojan 原版和 Go 版的安装配置可以说是一样的，如果你想要安装原版的话只需要切换下载压缩包的地址即可。下载并解压： 1234567# 下载yum -y install wgetwget https://github.com/p4gefau1t/trojan-go/releases/download/v0.10.6/trojan-go-linux-amd64.zip# 解压到 trojan-go 目录mkdir trojan-goyum -y install unzipunzip -d trojan-go/ trojan-go-linux-amd64.zip 原版： 123456# 下载yum -y install wgetwget https://github.com/trojan-gfw/trojan/releases/download/v1.16.0/trojan-1.16.0-linux-amd64.tar.xz# 解压出 trojan 目录tar -xvf trojan-1.16.0-linux-amd64.tar.xz# 注意之后的操作中需要把 trojan-go 目录修改为 trojan之后进入目录创建配置文件： 12cd trojan-govi config.json 配置内容在下方，修改下你的密码和域名即可，我这里的可执行文件 trojan-go 在 /root/trojan-go/ 中，如果你和我不一样也请自己更改下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677{ &quot;run_type&quot;: &quot;server&quot;, &quot;local_addr&quot;: &quot;0.0.0.0&quot;, &quot;local_port&quot;: 443, &quot;remote_addr&quot;: &quot;127.0.0.1&quot;, &quot;remote_port&quot;: 80, &quot;log_level&quot;: 1, &quot;log_file&quot;: &quot;/root/trojan-go/test.log&quot;, &quot;password&quot;: [ &quot;YourPassword&quot; ], &quot;buffer_size&quot;: 32, &quot;dns&quot;: [], &quot;ssl&quot;: { &quot;verify&quot;: true, &quot;verify_hostname&quot;: true, &quot;cert&quot;: &quot;/etc/letsencrypt/live/usa-bwg-01.example.com/fullchain.pem&quot;, &quot;key&quot;: &quot;/etc/letsencrypt/live/usa-bwg-01.example.com/privkey.pem&quot;, &quot;key_password&quot;: &quot;&quot;, &quot;cipher&quot;: &quot;&quot;, &quot;cipher_tls13&quot;: &quot;&quot;, &quot;curves&quot;: &quot;&quot;, &quot;prefer_server_cipher&quot;: false, &quot;sni&quot;: &quot;usa-bwg-01.example.com&quot;, &quot;alpn&quot;: [ &quot;http/1.1&quot; ], &quot;session_ticket&quot;: true, &quot;reuse_session&quot;: true, &quot;plain_http_response&quot;: &quot;&quot;, &quot;fallback_port&quot;: 80, &quot;fingerprint&quot;: &quot;firefox&quot;, &quot;serve_plain_text&quot;: false }, &quot;tcp&quot;: { &quot;no_delay&quot;: true, &quot;keep_alive&quot;: true, &quot;reuse_port&quot;: false, &quot;prefer_ipv4&quot;: false, &quot;fast_open&quot;: false, &quot;fast_open_qlen&quot;: 20 }, &quot;mux&quot;: { &quot;enabled&quot;: true, &quot;concurrency&quot;: 8, &quot;idle_timeout&quot;: 60 }, &quot;router&quot;: { &quot;enabled&quot;: false, &quot;bypass&quot;: [], &quot;proxy&quot;: [], &quot;block&quot;: [], &quot;default_policy&quot;: &quot;proxy&quot;, &quot;domain_strategy&quot;: &quot;as_is&quot;, &quot;geoip&quot;: &quot;/root/trojan-go/geoip.dat&quot;, &quot;geosite&quot;: &quot;/root/trojan-go/geosite.dat&quot; }, &quot;websocket&quot;: { &quot;enabled&quot;: false, &quot;path&quot;: &quot;/&quot;, &quot;hostname&quot;: &quot;usa-bwg-01.example.com&quot;, &quot;obfuscation_password&quot;: &quot;&quot;, &quot;double_tls&quot;: true, &quot;ssl&quot;: { &quot;verify&quot;: true, &quot;verify_hostname&quot;: true, &quot;cert&quot;: &quot;/etc/letsencrypt/live/usa-bwg-01.example.com/fullchain.pem&quot;, &quot;key&quot;: &quot;/etc/letsencrypt/live/usa-bwg-01.example.com/privkey.pem&quot;, &quot;key_password&quot;: &quot;&quot;, &quot;prefer_server_cipher&quot;: false, &quot;sni&quot;: &quot;usa-bwg-01.example.com&quot;, &quot;session_ticket&quot;: true, &quot;reuse_session&quot;: true, &quot;plain_http_response&quot;: &quot;&quot; } }} 启动试下： 1/root/trojan-go/trojan-go -config /root/trojan-go/config.json 如果跳出了请检查端口占用和日志。端口占用查看： 12yum -y install lsoflsof -i:443 日志: 1cat /root/trojan-go/test.logClash 中的配置段： 123456......proxies: - {name: Trojan-搬瓦工美国, type: trojan, server: usa-bwg-01.example.com, port: 443, password: YourPassword }...... 4、将 Trojan-Go 注册为服务方便开机启动新建服务： 12cd /usr/lib/systemd/system/vi trojan-go.service 内容： 1234567891011121314[Unit]Description=trojan-goAfter=network.target nss-lookup.targetWants=network-online.target[Service]Type=simpleExecStart=/root/trojan-go/trojan-go -config /root/trojan-go/config.jsonRestart=on-failureRestartSec=10RestartPreventExitStatus=23[Install]WantedBy=multi-user.target 之后的控制命令就很简单了： 123456# 启动systemctl start trojan-go.service# 关闭systemctl stop trojan-go.service# 设置开机自启动systemctl enable trojan-go.service 结束。","link":"/2022/07/20/bak_centos7_trojan_server_for_bwg/"},{"title":"【归档文章】CentOS7 下通配符 SSL 证书的购买和配置","text":"关于在 Namecheap 购买通配符 SSL 证书并配置的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 一个边缘服务涉及到的服务器和子域名实在太多，自签证书在每个服务器上都配置一遍想想就觉得麻烦，而且有些子域名需要暴露给外部访问，在用户机器人上安装证书也不太现实，索性购买下通配符证书来解决吧。 1、证书的购买选择在 Namecheap 上进行购买，链接：https://www.namecheap.com/security/ssl-certificates/，注意需要选择 Wildcard 类型的证书： 两年起购买更优惠。 2、证书的激活① 购买后的证书进入激活阶段时，需要你提供 CSR，我这里选择使用在线工具生成：CSR在线生成工具注意：生成后一定要下载 KEY 文件！生成后一定要下载 KEY 文件！生成后一定要下载 KEY 文件！同时因为你购买的是通配符域名，所以这里的域名要填写 *.your_domain.com。拷贝到激活页的框中，即可看到适配的域名也是通配符域名了：② 选择添加 DNS 解析的方式来验证域名所有权：③ 选择证书发送到哪个邮箱：④ 提交：⑤ 去添加 DNS 解析来等待审核：接着前往 https://mxtoolbox.com/CnameLookup.aspx 验证 CNAME 是否生效：之后只需静等 15 到 30 分钟即可，审核通过后证书会发送至你的邮箱。 3、证书的配置发来的证书会有 2 个文件：拷贝至服务器后拼接为 .crt 文件： 1cat STAR_xxxx_xxx.crt STAR_xxxx_xxx.ca-bundle &gt; xxxx_xxx.bundle.crt 接着把生成 CSR 时一起下载的 .key 文件放到服务器上，补齐完整的证书链：之后就能使用了，直接去 Nginx 中配置即可，样例： 1234567891011121314151617181920212223242526272829......server { listen 80; server_name test.xxxx.xxx; root /usr/share/nginx/html; location / { # 跳转 HTTPS return 301 https://$host$request_uri; } } server { listen 443 ssl; server_name test.xxxx.xxx; # SSL 配置 ssl_certificate /rab/ssl/xxxx_xxx.bundle.crt; ssl_certificate_key /rab/ssl/private.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; location / { root /usr/share/nginx/html; } } ... ... 访问确认证书生效： 结束。","link":"/2022/04/16/bak_centos7_wildcard_ssl_certificate/"},{"title":"【归档文章】CentOS7 下 Zabbix Docker 容器修复管理界面中文字体为方框的问题","text":"关于如何解决旧版本 Zabbix 页面端中文字体不显示问题的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 这次迁移又需要修复一下中文字体的问题，记录一下。 1、下载有中文的字体前端管理界面出现以下方框的原因就是 Zabbix 默认使用的 DejaVuSans.ttf 字体中缺少中文字体样式：因此先下载中文字体： 1wget https://www.wfonts.com/download/data/2014/06/01/microsoft-yahei/chinese.msyh.ttf 2、将中文字体拷贝到 Docker 容器内首先确定 Zabbix Web Nginx 容器的 ID： 1docker ps -a 我这里为 60d60911c8a7，进行拷贝： 1docker cp chinese.msyh.ttf 60d60911c8a7:/usr/share/zabbix/assets/fonts 3、进去容器修改配置文件进入容器： 1docker exec -it 60d60911c8a7 /bin/bash 确定字体拷贝成功和打开配置文件： 12345# 确定字体文件拷贝成功cd /usr/share/zabbix/assets/fonts/ls# 打开配置文件vi /usr/share/zabbix/include/defines.inc.php 如下修改后保存（字体文件名去掉 .ttf）：注：大概在 67 行左右。 4、页面刷新 结束。","link":"/2021/10/06/bak_centos7_zabbix_fix_font/"},{"title":"【归档文章】Clash 学习（一）配置文件各项在实际使用中的用处和创建自己的第一个配置文件","text":"关于小猫咪的学习笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 Clash 的优点太多了不赘述了，我选择它的理由是 OpenWrt 的 Clash 插件可以在软路由层面将流量分流到不同节点，比如说：YouTube 使用香港节点、Netflix 走日本节点同时谷歌学术使用自建节点，这可以帮助我大幅度降低延迟和增强自建节点可用性（不会因为使用大量流量而被侦测到）。本章内容和标题描述的一样，会尽量帮助你了解配置文件各项在 Clash 实际使用中的用处，最后也会从零书写一个自己的配置文件。我会推荐在开始阅读之前先看完这个很棒的介绍 Clash 配置的视频：Clash 配置文件详解，看完你自己也可以写规则 1、配置文件各项的用处一个配置文件最简单的模板： 12345678910111213141516171819202122232425262728293031323334353637# HTTP 协议代理所在端口port: 7890# SOCKS5 协议代理所在端口socks-port: 7891# 允许局域网内其他设备连接以上 2 个代理端口allow-lan: true# 规则模式（可选：全局、规则和直连 3 种模式）mode: Rule# 日志级别log-level: info# RESTful 风格的控制 API 服务地址（你可以自己写程序调用接口以切换代理节点等）external-controller: 0.0.0.0:9090# 代理节点池proxies: - {name: 自建节点 1, type: ss, server: proxy.example.com, port: 12345, cipher: aes-256-cfb, password: mypassword }# 代理节点组proxy-groups: # type: select 意为着这个节点组内的节点需要你手动选择切换 - name: 使用代理的组名 type: select proxies: - 自建节点 1 # 不使用代理直连 - name: 直连的组名 type: select proxies: # DIRECT 意为直连 - DIRECT# 规则，“规则模式”下需要配置，你设备每一次发送的请求都会经由该规则列表由上至下筛选# 格式为：- $匹配模式,$匹配参数,$代理节点组rules: - DOMAIN-SUFFIX,google.com,使用代理的组名 - GEOIP,CN,直连的组名 - MATCH,使用代理的组名 部分配置选项解释（各种协议的节点配置不在这章解释）：proxy-groups 中各组 type 可选：select、url-test 和 fallback 等。注：fallback 和 url-test 都为测速并自动选择节点，fallback 需要事前配置好域名服务器以防止 DNS 污染等造成的测速失败。rules 中各规则匹配模式可选：DOMAIN、DOMAIN-KEYWORD、DOMAIN-SUFFIX、GEOIP 和 MATCH 等，具体功能可以参照下表： 匹配规则 功能 DOMAIN 表示包含完整的域名 DOMAIN-SUFFIX 表示包含什么后缀的域名 DOMAIN-KEYWORD 表示包含 xxx域名关键字的链接 IP-CIDR IPV4 匹配 IP-CIDR6 IPV6 匹配 PROCESS-NAME 表示进程名称 GEOIP 数据库（国家代码）匹配 MATCH 全匹配（一般放在最后） 当启动了 Clash 并载入了以上的配置文件，你尝试访问 Google，节点配置无误的情况下你会惊喜的发现连接上了，那么它是怎么工作的呢？首先因为是 Rule 规则模式，目标域名为 www.google.com 的请求没有管节点和节点组，直奔 rules 规则组查找有没有自身匹配的……似乎是有的！就在第一条，www.google.com 的域名后缀是 google.com，匹配上了！然后看看这条规则对应的代理组，“使用代理的组名”，进入，代理组内的选择模式为手动选择……当前被选上的代理是：“自建节点 1”，那就使用它进行访问……成功！是不是很简单，接着你有尝试访问 ip.cn 想查证下本机的 IP 有没有变……没变？！因为 ip.cn 所在的服务器是大陆 IP 的，匹配上了第二条规则，于是进了直连代理组，接着进行访问而没有使用代理。那么，YouTube 呢，当然是可以的！所有域名解析的 IP 如果不在大陆都会被指向第三条规则。很简单对吗，来试试加点难度，理解一下下面的配置中各项的功能😀 2、编写第一个配置文件在简单模板的基础上稍加更改，添加以下功能： 增加基础配置以给 OpenWrt 软路由系统上的 Clash 插件使用。 代理节点组区分为 5 个：自建节点、油管用、奈飞用、不使用代理直连和使用代理。 规则处新增 Google 学术域名的匹配、YouTube 域名的匹配、Netflix 域名的匹配和域名所在 IP 的匹配。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768port: 7890socks-port: 7891redir-port: 7892mixed-port: 7893ipv6: falseallow-lan: truemode: Rulelog-level: infoexternal-controller: 0.0.0.0:9090# ====== 路由器插件使用所需要增加的基础配置 ======# 绑定内网的 IP 地址，我这里不绑定了，因为就是 OpenWrt 地址加 9090 端口访问bind-address: &quot;*&quot;# Clash 面板密码secret: &quot;123456&quot;# Clash 面板前端 UI 样式external-ui: &quot;./dashboard&quot;# ====== ***************** ======proxies: - {name: 自建节点（Google 学术用）, type: ss, server: proxy.example.com, port: 12345, cipher: aes-256-cfb, password: mypassword } - {name: 机场香港节点 1...... } - {name: 机场香港节点 2...... } - {name: 机场奈飞节点...... } - {name: 机场节点普通节点 1...... } - {name: 机场节点普通节点 2...... } - {name: 机场节点普通节点 3...... } - {name: 机场节点普通节点 4...... }proxy-groups: # Google 学术组 - name: 自建节点 type: select proxies: - 自建节点（Google 学术用） # type: url-test 和其下面的 url、interval 参数共同完成：此组下节点每 300 毫秒向 http://www.gstatic.com/generate_204c 发送一次请求并自动选择延迟最低的节点这一功能 - name: 油管用 type: url-test url: http://www.gstatic.com/generate_204c proxies: - 机场香港节点 1 - 机场香港节点 2 # 奈飞组 - name: 奈飞用 type: select proxies: - 机场奈飞节点 # 直连组 - name: 不使用代理直连 type: select proxies: - DIRECT # 其他所有访问走该代理组 - name: 其他所有访问走该代理组 type: select proxies: - 机场节点普通节点 1 - 机场节点普通节点 2 - 机场节点普通节点 3 - 机场节点普通节点 4# 规则rules: - DOMAIN-SUFFIX,scholar.google.com,自建节点 - DOMAIN-SUFFIX,scholar.google.com.hk,自建节点 - DOMAIN-SUFFIX,youtube.com,油管用 - DOMAIN-SUFFIX,netflix.com,奈飞用 - GEOIP,CN,不使用代理直连 - MATCH,其他所有访问走该代理组 结束。","link":"/2021/10/26/bak_clash_note_01/"},{"title":"【归档文章】Clash 学习（三）进阶配置：在 Clash 中定时更新机场节点和导入外部规则","text":"关于小猫咪的学习笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 1、定时更新机场节点注意：定时更新机场节点配置中填入的链接，一定是要能被 Clash 正常读取的配置文件形式。​不仅是类似原生 SSR 等的订阅链接无法被 Clash 正常读取，就连一般机场提供的加密的 Clash 订阅链接也不行，必须经过订阅转换为配置文件形式才能生效。 两种转换方法：① 在线订阅地址转换常用：品云订阅转换（部分地区被墙）注；推荐这个只是因为我也在用，如果出问题一起当受害者……② 自建订阅转换项目：tindy2013/subconverter使用 Docker 部署（官方文档：README-docker.md）： 123456# 下载镜像docker pull tindy2013/subconverter:latest# 部署docker run -d --restart=always -p 25500:25500 tindy2013/subconverter:latest# 测试是否部署成功curl http://localhost:25500/version 开放防火墙和安全组后在外部访问：http://IP:25500/sub?target=clash&amp;url=https%3A%2F%2Fmojie.info%2Fapi%2Fv1%2Fclient%2Fsubscribe%3Ftoken%3D4fxxxxxxxxxxxxxxxxxxx4c6f6&amp;insert=false 以获取转换完成的配置文件，简单地说明一下参数（官方详细文档：README-cn.md）： 参数名 解析 样例 target 指想要生成的配置类型。 clash url 经过 URLEncode 处理后的订阅链接。 https%3A%2F%2Fmojie.info%2…… insert 用于设置是否将配置文件中的 insert_url 插入（意义不明，我的理解是是否引入其他外部节点）。 false 12345678910111213141516171819202122232425262728293031323334353637......# 代理提供商proxy-providers: # 机场-魔戒所用订阅 Mojie-sub: # 对订阅地址的访问方式 type: http # 订阅地址 url: &quot;https://sub.id9.cc/sub?target=clash&amp;url=https%3A%2F%2Fmojie.info%2Fapi%2Fv1%2Fclient%2Fsubscribe%3Ftoken%3D4fxxxxxxxxxxxxxxxxxxx4c6f6&amp;insert=false&quot; # 订阅后节点存放用的配置文件（不同机场需使用不同文件） path: ./sub/Mojie.yaml # 更新订阅间隔时间（秒） interval: 3600 # 节点检查 health-check: enable: true interval: 600 url: http://www.gstatic.com/generate_204......# 节点组proxy-groups: # 手动选择 - name: 手动选择 type: select proxies: - 奇异之旅 - 魔戒 # 机场-魔戒 - name: 魔戒 type: select # 注意：这里使用订阅的动作为 use use: - Mojie-sub...... 重启后，到控制台就能看见自动更新的节点了： 2、导入外部规则大佬们写的规则基本都是适配大众需求的，例如流媒体等。小众规则还是自己动手吧！推荐的外部规则开源项目：Loyalsoldier/clash-rules参照格式： 123456789101112131415161718192021222324252627......# 规则提供商rule-providers: # 规则集的名字 google: # 对外部规则的访问方式 type: http # 朴素规则（无查询优化） behavior: classical # 外部规则地址 url: &quot;https://cdn.jsdelivr.net/gh/Loyalsoldier/clash-rules@release/google.txt&quot; # 规则文件存放路径 path: ./ruleset/google.yaml # 更新规则间隔时间（秒） interval: 86400# 规则rules: ... ... # 使用外部规则，中间填规则集的名字 - RULE-SET,google,奇异之旅 # 境内站点 - GEOIP,CN,直连 # 境外站点 - MATCH,奇异之旅 如果对 behavior 这个参数有困惑，你可以参考以下这个 Issue：请问用rule-providers时behavior如何选择？ classical/ipcidr/domain 三者又有什么区别？ 很可惜的是 OpenWrt 上的 Clash 暂时不支持 RULE-SET 规则，就不做具体演示了。 结束。","link":"/2021/11/08/bak_clash_note_03/"},{"title":"【归档文章】Clash 学习（四）在 Clash 中配置使用 HTTP 协议或 SOCKS5 协议的节点","text":"关于小猫咪的学习笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 只描述对节点订阅信息的解码和在 Clash 中的配置方法。 1、HTTP 协议的节点 服务器端安装脚本：CentOS7 下一键安装 GOST 并启动 HTTP 和 SOCKS5 代理服务 1curl -s https://gitee.com/senjianlu/one-click-scripts/raw/main/CentOS7%20下一键安装%20GOST%20并启动%20HTTP%20和%20SOCKS5%20代理服务/install.sh | bash -s $proxy_port $proxy_username $proxy_password官方配置文件模板中的代码片段： 1234567891011proxies: # http - name: &quot;http&quot; type: http server: server port: 443 # username: username # password: password # tls: true # https # skip-cert-verify: true # sni: custom.com HTTP 节点代理的配置应该算是最基础也最好理解的了，但还是列张表格将以下，也为后面几章复杂节点的配置解析做铺： 参数名 解析 样例 name 自定义。该节点的名称，也是主键，后续在代理组中通过这个属性来选定该节点。 myhttp type 可选 http、socks5、ss、ssr、vmess 和 trojan。节点的协议。 http server 节点所在服务器的 IP 或解析的域名。 http.proxy.com port 节点所在服务器上，代理服务所在的端口。 443 username 【选填】用户名。用以代理认证用。 myusername password 【选填】用户密码。用以代理认证用。 mypassword tls 【选填】可选 true 或 false。是否开启 HTTPS，开启的话需要服务器配置 SSL 证书。 false skip-cert-verify 【选填】可选 true 或 false。是否跳过对 SSL 证书的认证，自签证书等不被信任因此一般选 true。 true sni 【选填】一般填 server 的域名即可。面对一台服务器上有多个 SSL 证书的时候需要用到 sni 来辨别使用哪个。 http.proxy.com 举个最简单的例子，当我在某宝买到了有效期为 1 个与的 HTTP 代理时，卖家发给我的格式是这样的： 1http://99999:22222@63.225.10.10:20800 那我该怎么填？很简单先解析，HTTP 代理和 SOCKS5 代理都是一个格式： 1协议://用户名:用户密码@服务器 IP 或域名:端口 于是在 Clash 中这样配置就好了： 1234567891011proxies: # http - name: &quot;淘宝购买的节点 01&quot; type: http server: 63.225.10.10 port: 20800 username: 99999 password: 22222 # tls: true # https # skip-cert-verify: true # sni: custom.com 简单吧，当然了这是最基础的代理配置，它的功能同样简单甚至可以说是简陋，内容不会经过混淆加密，任何人截取到了通过这个代理的请求就能知道你在做什么，SOCKS5 也一样，无法确保安全性。因此使用 HTTP 和 SOCKS5 代理前请慎重考虑自己的数据是否重要！ 2、SOCKS5 协议的节点官方配置文件模板中的代码片段： 1234567891011proxies: # socks5 - name: &quot;socks&quot; type: socks5 server: server port: 443 # username: username # password: password # tls: true # skip-cert-verify: true # udp: true 和 HTTP 代理的参数一致，不再赘述配置方法。 结束。","link":"/2021/11/10/bak_clash_note_04/"},{"title":"【归档文章】Cloudflare 四种 SSL&#x2F;TLS 加密模式的功能解析及实践","text":"关于 Cloudflare 四种 SSL/TLS 加密模式的功能解析及实践。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 在没套 Cloudflare 之前有在 Nginx 中配置 HTTP 访问 301 重定向到 HTTPS 的习惯，但是在套了 CF 之后常常出现 301 重定向次数过多的情况，不明白原理地瞎调试走了很多弯路，重新实践一遍并整理为笔记方便自己回顾。 这里就以各模式作为区分，总共 4 种模式就分为 4 个小章节。注意：这四种模式仅在开启了 Cloudflare 的 CDN 后才有效，仅把 Cloudflare 作 DNS 使用时以下加密模式均不会生效！ 1、模式：关闭（不安全）这个模式会将所有用户对你站点的 HTTPS 请求重定向到 HTTP，官方描述： Setting your encryption mode to Off (not recommended) redirects any HTTPS request to plaintext HTTP. 优点：没有缺点： 容易遭受到中间人攻击 Chrome 等浏览器会显示该网站不安全 影响搜索引擎收录 实践：① HTTP 访问（未在 Nginx 配置中开启 HTTP 访问重定向到 HTTPS）：② HTTPS 访问（未在 Nginx 配置中开启 HTTP 访问重定向到 HTTPS）：注：这里我已经手动改为 https://ssl.ceshiku.cn 但是被重定向回了 HTTP。③ HTTP 访问（已经在 Nginx 配置了 HTTP 访问重定向到 HTTPS）：注：循环重定向了，比较好理解：HTTP 访问到 Nginx 被重定向到了 HTTPS，HTTPS 到 Cloudflare 又被重定向到了 HTTP，循环往复……④ HTTPS 访问（已经在 Nginx 配置了 HTTP 访问重定向到 HTTPS）：注：同 HTTP 访问一样循环重定向。 2、模式：灵活这个灵活并不是指 Cloudflare 会自动辨别对源站使用 HTTP 或 HTTPS 访问，而是指：用户到 Cloudflare 的访问是强制 HTTPS 加密的，证书由 Cloudflare 提供；而 Cloudflare 到源服务器的访问是强制 HTTP 的，因此源站不需要配置证书。我觉得翻译为半程加密会更合理一些，官方描述： Setting your encryption mode to Flexible makes your site partially secure. Cloudflare enforces HTTPS between your visitor and Cloudflare, but all connections between Cloudflare and your origin are made through HTTP. As a result, an SSL certificate is not required on your origin. 优点： 简单，源站不需要配置 HTTPS 证书 缺点： 在 Cloudflare 到源站中仍存在中间人攻击的风险 实践：① HTTP 访问（未在 Nginx 配置中开启 HTTP 访问重定向到 HTTPS）：注：成功变成了 HTTPS 访问，证书是 Cloudflare 提供的。② HTTPS 访问（未在 Nginx 配置中开启 HTTP 访问重定向到 HTTPS）：注：源站配置了证书但未使用。③ HTTP 访问（已经在 Nginx 配置了 HTTP 访问重定向到 HTTPS）：注：循环重定向：Cloudflare 到源站的 HTTP 请求被 Nginx 重定向到了 HTTPS，接着 HTTPS 请求经过 Cloudflare 又变回了对源站的 HTTP 请求……④ HTTPS 访问（已经在 Nginx 配置了 HTTP 访问重定向到 HTTPS）：注：同 HTTP 访问一样循环重定向。 3、模式：完全全程加密但不完全：如果用户发出的是 HTTP 请求，那么用户到 Cloudflare 和 Cloudflare 到源站均会使用 HTTP 协议；如果用户发出的是 HTTPS 请求，那么用户到 Cloudflare 会使用 Cloudflare 提供的证书进行加密，而 Cloudflare 到源站会使用源站的证书进行加密。官方描述： When you set your encryption mode to Full, Cloudflare enforces HTTPS between your visitor and Cloudflare and makes connections to the origin using the scheme requested by the visitor. If your visitor uses http, then Cloudflare connects to the origin using plaintext HTTP and vice versa. 优点： 使用此模式可以兼容 Nginx 配置 HTTP 重定向到 HTTPS 源站可以使用自签证书 缺点： 在 Cloudflare 到源站中仍存在中间人攻击的风险（包括通过证书劫持和伪造等方式，不同于严格模式，Cloudflare 不会对源站的证书进行审核） 实践：① HTTP 访问（未在 Nginx 配置中开启 HTTP 访问重定向到 HTTPS）：② HTTPS 访问（未在 Nginx 配置中开启 HTTP 访问重定向到 HTTPS）：注：源站配置了证书，但在浏览器端显示的是用户和 Cloudflare 之间加密所用的证书。③ HTTP 访问（已经在 Nginx 配置了 HTTP 访问重定向到 HTTPS）：注：跳转到了 HTTPS。④ HTTPS 访问（已经在 Nginx 配置了 HTTP 访问重定向到 HTTPS）： 4、模式：完全（严格）和完全模式实现的功能一样，但是新增了对证书的认证：源站如果配置了自签证书、非可信证书或过期证书，那么 Cloudflare 会回复客户端访问失败并返回 526 响应代码。官方描述： When you set your encryption mode to Full (strict), Cloudflare does everything in Full mode but also enforces more stringent requirements for origin certificates. 优点： 使用此模式可以兼容 Nginx 配置 HTTP 重定向到 HTTPS 安全，只要用户使用 HTTPS 访问可以完全杜绝中间人攻击 缺点： 四种模式中工作量最大，需要维护服务器端的证书 实践结果和第 3 种模式完全一样，不放上来了。​ 5、总结① 如果你还在困惑该选哪种模式，我帮你整理了常用需求对应的模式，请参照： ② 还有需要注意的会出现 301 重定向次数过多的 2 种情况： 关闭模式下在 Nginx 开启了强制重定向（HTTPS -(Cloudflare)-&gt; HTTP -(Nginx)-&gt; HTTPS -(Cloudflare)-&gt; HTTP……） 灵活模式下在 Nginx 开启了强制重定向（HTTP -(Cloudflare)-&gt; HTTP -(Nginx)-&gt; HTTPS -(Cloudflare)-&gt; HTTP……） ③ 最后放上完全和完全（严格）模式下可以参考的 Nginx 配置： 123456789101112131415161718192021222324252627282930313233343536373839...... server { listen 80; listen [::]:80; server_name _; root /usr/share/nginx/html; include /etc/nginx/default.d/*.conf; # 证书申请用 location ~ /.well-known { root /usr/share/nginx; allow all; } # 强制重定向到 HTTPS location / { return 301 https://$host$request_uri; } } server { listen 443 ssl; server_name _; root /usr/share/nginx/html; # SSL 配置 ssl_certificate /etc/letsencrypt/live/ssl.ceshiku.cn/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/ssl.ceshiku.cn/privkey.pem; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; # 以下填你的反代等配置 ... ... }...... 结束。","link":"/2021/11/01/bak_cloudflare_ssl_tls/"},{"title":"【归档文章】Cloudflare Workers 反代使用 GitHub 仓库搭建的图床","text":"关于使用 Cloudflare Workers 反代 GitHub 仓库搭建图床的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 虽然一直都知道存在无法在境内正常加载文章中图片的问题，但是嫌麻烦一直就拖着。最近接触到了 Cloudflare Workers，实践反代的时候发现异常简单，顺便就把图床也反代同时设定为自定义域名了，记录一下。 实现流程：用户 -(域名)-&gt; Cloudflare DNS -(解析)-&gt; Cloudflare Workers 分配的域名 -(路由激活指定的 CF Workers)-&gt; CF Workers 内部代码运行：访问 GitHub 源文件并返回 1、Cloudflare 开启 Workers 注：第一次开启 Cloudflare Workers 需要邮箱验证，步骤参照以下。设置子域：选择免费计划即可：接着确认下电子邮件即可： 选择创建服务：输入服务名称，我这里是反代图床，就填 img 了，之后选择 HTTP 处理程序而非主要用以网页生成的简介，之后创建服务：看到以下页面说明创建成功： 2、编写反代用的 Worker 代码Cloudflare Worker 中的代码用 JS 写就行，同时还有很多现成的好用的方法，具体的学习请参照官方文档：Cloudflare Workers documentation我这里要实现反代功能，那么就只需要将来源链接中的域名修改成 raw.githubusercontent.com，接着访问一下 GitHub 文件的内容并返回即可，直接上具体实现的代码： 123456789101112131415addEventListener(&quot;fetch&quot;, event =&gt; { event.respondWith(handleRequest(event.request))})async function handleRequest(request) { // Cloudflare Workers 分配的域名 cf_worker_host = &quot;img.cscheap.workers.dev&quot;; // 自定义的域名 origin_host = &quot;img.cscheap.com&quot;; // GitHub 仓库文件地址 github_host = &quot;raw.githubusercontent.com/senjianlu/imgs/master&quot;; // 替换 2 次以同时兼容 Worker 来源和域名来源 url = request.url.replace(cf_worker_host, github_host).replace(origin_host, github_host); return fetch(url);} 注意上面我除了 Cloudflare Workers 分配的域名我还添加了自定义域名，这在下一小结里会谈到，你可以自行决定是否加上。找一张有的图片测试一下代码是否生效：确定没问题之后点击保存并部署即可。 3、设定触发器和自定义域名部署完成后，你已经可以通过 Cloudflare Workers 分配给你的域名访问你 GitHub 仓库里的图片了，而且默认就是套了 CF 的 CDN 的，在境内也能访问顶多就是速度会慢一点，如图：但是我还是想把域名改为我自己博客的子域，于是在触发器里添加路由：输入自己的子域名即可：别忘了去 DNS 处添加 CNAME 解析（我这里用的是 DNSPod，不使用 Cloudflare 的 DNS 不开启小云朵也是可以使用 CF 的 CDN 的，因为走了一遍 Cloudflare Workers，但是无法享受到 CF 提供的免费 SSL 证书）：通过自己的子域名测试访问成功（没有 HTTPS 就是因为没使用 Cloudflare 的 DNS）： 4、VSCode 中多文件内容使用全部替换以我博客实际域名 senjianlu.com 为例，把之前文章中的图片链接全都替换一下：将 ](https://raw.githubusercontent.com/senjianlu/imgs/master 替换为 ](https://img.senjianlu.com 即可： 5、PicGo 中设置 GitHub 图床自定义域名以我博客实际域名 senjianlu.com 为例：这样每次上传 Ctrl + Shift + P 上传成功后，剪贴版里就是 img.senjianlu.com/xxxxxx.png 形式的图片链接了。 结束。","link":"/2021/12/17/bak_cloudflare_workers_image/"},{"title":"【归档文章】DataX 实践（一）构建 DataX 的 Docker 容器镜像并测试运行","text":"关于 Alibaba DataX 项目的实践。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 需要从 PostgreSQL 同步数据到 MongoDB，看了一圈选择了 DataX 工具，阿里的开源项目还是蛮值得信赖的。官方并未提供 Docker 镜像，但是考虑到我现在已经部署了 K3s 集群，所以决定折腾下，自己构建个镜像来用。 参考文章：Docker 运行 DataX 实现数据同步方案我的 Dockerfile 文件：DataX-docker我构建完的 Docker 镜像：rabbir/datax 1、安装和配置 DataX 运行环境 官方描述的运行环境： Linux JDK（1.8 以上，推荐 1.8） Python（推荐 Python2.6.X） Apache Maven 3.x （Compile DataX） ① 直接拉取 CentOS7 的镜像，解决 Linux 和 Python 需求（CentOS7 官方镜像自带 Python2.7.5）： 1234# 拉取镜像docker pull centos:centos7# 运行镜像docker run -it docker.io/centos:centos7 /bin/bash 之后的命令都是在容器内执行！ ② 安装 JDK1.8： 1234567891011# 安装位置cd /usr/local/# 下载压缩包wget --no-check-certificate --no-cookies --header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.tar.gz# 解压并重命名tar -zxvf jdk-8u131-linux-x64.tar.gzmv jdk1.8.0_131 jdk1.8# 删除压缩包rm -f jdk-8u131-linux-x64.tar.gz# 配置环境变量vi ~/.bashrc 新增以下两行： 12345678......# Java 相关export JAVA_HOME=/usr/local/jdk1.8export PATH=$PATH:$JAVA_HOME/binexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar...... 使配置生效： 123source ~/.bashrc# 确认 Java 版本java -version ③ 安装 Apache Maven： 1234567891011# 安装位置cd /usr/local/# 下载压缩包wget --no-check-certificate https://dlcdn.apache.org/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz# 解压并重命名tar -zxvf apache-maven-3.6.3-bin.tar.gzmv apache-maven-3.6.3 maven# 删除压缩包rm -f apache-maven-3.6.3-bin.tar.gz# 配置环境变量vi ~/.bashrc 1234567......# Maven 相关export MAVEN_HOME=/usr/local/mavenexport PATH=$PATH:$MAVEN_HOME/bin...... 使配置生效： 123source ~/.bashrc# 确认 Java 版本mvn -v 至此环境安装和配置完成。 2、下载并编译 DataX官方文档：Quick Start 1234567cd /usr/local/yum -y install git# 克隆源码git clone https://github.com/alibaba/DataX.git# 编译cd DataXmvn -U clean package assembly:assembly -Dmaven.test.skip=true 我碰到的问题：① oscarwriter JAR 包的缺失： 1[ERROR] Failed to execute goal on project oscarwriter: Could not resolve dependencies for project com.alibaba.datax:oscarwriter:jar:0.0.1-SNAPSHOT: Could not find artifact com.oscar:oscar:jar:7.0.8 at specified path /usr/local/DataX/oscarwriter/src/main/lib/oscarJDBC.jar -&gt; [Help 1] 解决方法就是去 pom.xml 中注释掉，反正也用不到。编辑源码根目录的 pom.xml 文件： 1vi pom.xml 注释掉 oscarwriter 那行： 12345......&lt;!-- &lt;module&gt;oscarwriter&lt;/module&gt; --&gt;...... Docker 容器性能受限，整体编译大概需要 10 分钟左右（我是因为出了错重新编译跳过了编译成功的包，所以只用了 3 分钟）。编译完成后，DataX 的可运行的 .py 文件会在 /usr/local/DataX/target/datax/datax/bin/ 路径下，测试一下： 123cd /usr/local/DataX/target/datax/datax/bin/# 查看配置模板python datax.py -r streamreader -w streamwriter 如下输出说明 DataX 安装完成： 3、构建 Docker 容器镜像并运行① 首先写个正常能跑的测试用配置文件： 12# 放在不同路径下vi /root/stream2stream.json 123456789101112131415161718192021222324252627282930313233343536{ &quot;job&quot;: { &quot;content&quot;: [ { &quot;reader&quot;: { &quot;name&quot;: &quot;streamreader&quot;, &quot;parameter&quot;: { &quot;sliceRecordCount&quot;: 10, &quot;column&quot;: [ { &quot;type&quot;: &quot;long&quot;, &quot;value&quot;: &quot;10&quot; }, { &quot;type&quot;: &quot;string&quot;, &quot;value&quot;: &quot;Hello DataX!&quot; } ] } }, &quot;writer&quot;: { &quot;name&quot;: &quot;streamwriter&quot;, &quot;parameter&quot;: { &quot;encoding&quot;: &quot;UTF-8&quot;, &quot;print&quot;: true } } } ], &quot;setting&quot;: { &quot;speed&quot;: { &quot;channel&quot;: 5 } } }} 跑一下： 1python datax.py /root/stream2stream.json datax.py 自带对路径的判断，因此在任何目录下去执行都没有问题，如下命令会收获一样正常运行的结果： 12cd /rootpython /usr/local/DataX/target/datax/datax/bin/datax.py stream2stream.json ② 将上述所有命令写入 Dockerfile（部分命令如环境变量的配置会有所不同）： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# 基础镜像系统版本为 CentOS:7FROM centos:7# 维护者信息LABEL maintainer=&quot;Rabbir admin@cs.cheap&quot;# Docker 内用户切换到 rootUSER root# 设置时区为东八区ENV TZ Asia/ShanghaiRUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime &gt; /etc/timezone# 安装 Git 和 WgetRUN yum -y install wgetRUN yum -y install git# 切换到 /usr/local/ 目录下WORKDIR /usr/local/# 下载解压 JDKRUN wget --no-check-certificate --no-cookies --header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.tar.gzRUN tar -zxvf jdk-8u131-linux-x64.tar.gzRUN mv jdk1.8.0_131 jdk1.8RUN rm -f jdk-8u131-linux-x64.tar.gz# 下载解压 MavenRUN wget https://dlcdn.apache.org/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz --no-check-certificateRUN tar -zxvf apache-maven-3.6.3-bin.tar.gzRUN mv apache-maven-3.6.3 mavenRUN rm -f apache-maven-3.6.3-bin.tar.gz# 添加容器内的永久环境变量RUN sed -i &quot;2 a export JAVA_HOME=/usr/local/jdk1.8&quot; /etc/profileRUN sed -i &quot;3 a export PATH=\\$PATH:\\$JAVA_HOME/bin&quot; /etc/profileRUN sed -i &quot;4 a export CLASSPATH=.:\\$JAVA_HOME/lib/dt.jar:\\$JAVA_HOME/lib/tools.jar&quot; /etc/profileRUN sed -i &quot;5 a export MAVEN_HOME=/usr/local/maven&quot; /etc/profileRUN sed -i &quot;6 a export PATH=\\$PATH:\\$MAVEN_HOME/bin&quot; /etc/profileRUN source /etc/profileRUN sed -i '1 a source /etc/profile' ~/.bashrcRUN source ~/.bashrc# 添加构建用的临时环境变量ENV JAVA_HOME /usr/local/jdk1.8ENV PATH $PATH:$JAVA_HOME/binENV CLASSPATH .:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarENV MAVEN_HOME /usr/local/mavenENV PATH $PATH:$MAVEN_HOME/bin# 克隆并编译 DataX 的源码WORKDIR /usr/local/RUN git clone https://github.com/alibaba/DataX.gitWORKDIR /usr/local/DataX/RUN sed -i &quot;s#&lt;module&gt;oscarwriter&lt;/module&gt;#&lt;!-- &lt;module&gt;oscarwriter&lt;/module&gt; --&gt;#&quot; pom.xmlRUN mvn -U clean package assembly:assembly -Dmaven.test.skip=true# 创建配置文件存放用文件夹RUN mkdir /dataWORKDIR /data# 启动命令ENTRYPOINT [&quot;/usr/bin/python&quot;, &quot;/usr/local/DataX/target/datax/datax/bin/datax.py&quot;]CMD [&quot;&quot;] 构建（镜像名和版本自行替换）： 1docker build -t rabbir/datax:latest . 因为需要读取配置文件，而 Docker 运行时是不支持将本地文件作为参数传入的，因此需要配置一下宿主机和容器内 /data 文件夹的映射，参考以下命令： 1docker run --name datax_test_container -v /rab/docker/datax/data:/data rabbir/datax:latest test/stream2stream.json 解释：配置文件在宿主机内的完整路径为：/rab/docker/datax/data/test/stream2stream.json，那么通过映射它在容器内的路径则为：/data/test/stream2stream.json，此时就只需要传入 test/stream2stream.json 作为参数就可以了。 运行完后容器会自动退出： 本章结束。","link":"/2021/11/15/bak_datax_note_01/"},{"title":"【归档文章】DataX 实践（二）从 PostgreSQL 读数据库全量同步表到 PostgreSQL 写数据库","text":"关于 Alibaba DataX 项目的实践。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 在开展 PostgreSQL 增量同步到 MongoDB 的工作之前，先尝试个简单点的全量同步，也能熟悉一下 DataX 的各个配置项和其作用。 附下 DataX 的工作原理：官方文档中也给了一个 MySQL 同步到 HDFS 的例子，和上面的流程图一起看会更容易理解：DataX 本身作为离线数据同步框架，采用 Framework+plugin 架构构建。将数据源读取和写入抽象成为 Reader/Writer 插件，纳入到整个同步框架中。 Reader：Reader 为数据采集模块，负责采集数据源的数据，将数据发送给 Framework。 Writer： Writer 为数据写入模块，负责不断向 Framework 取数据，并将数据写入到目的端。 Framework：Framework 用于连接 reader 和 writer，作为两者的数据传输通道，并处理缓冲，流控，并发，数据转换等核心技术问题。 1、基础的配置文件要实现不同的源数据库读取和目标数据库写入功能，只需要在配置文件中装载不同插件即可。插件列表：Support Data Channels这里以 PostgreSQL 读写为例，只要注意一下源列和目标列是靠索引对齐的，字段名可以不一样就行了： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061{ &quot;job&quot;: { &quot;setting&quot;: { &quot;speed&quot;: { &quot;channel&quot;: 3 }, &quot;errorLimit&quot;: { &quot;record&quot;: 2, &quot;percentage&quot;: 0.02 } }, &quot;content&quot;: [ { &quot;reader&quot;: { &quot;name&quot;: &quot;postgresqlreader&quot;, &quot;parameter&quot;: { &quot;username&quot;: &quot;{from_username}&quot;, &quot;password&quot;: &quot;{from_password}&quot;, &quot;where&quot;: &quot;&quot;, &quot;column&quot;: [ &quot;{from_column_01}&quot;, &quot;{from_column_02}&quot; ], &quot;connection&quot;: [ { &quot;table&quot;: [ &quot;{from_table}&quot; ], &quot;jdbcUrl&quot;: [ &quot;jdbc:postgresql://{from_host}:{from_port}/{from_database}&quot; ] } ] } }, &quot;writer&quot;: { &quot;name&quot;: &quot;postgresqlwriter&quot;, &quot;parameter&quot;: { &quot;username&quot;: &quot;{to_username}&quot;, &quot;password&quot;: &quot;{to_password}&quot;, &quot;column&quot;: [ &quot;{from_column_01}&quot;, &quot;{from_column_02}&quot; ], &quot;preSql&quot;: [ &quot;DELETE FROM {to_table};&quot; ], &quot;connection&quot;: [ { &quot;jdbcUrl&quot;: &quot;jdbc:postgresql://{to_host}:{to_port}/{to_database}&quot;, &quot;table&quot;: [ &quot;{to_table}&quot; ] } ] } } } ] }} 除开 Python3 能使用 .format() 方法直接替换的参数外，完整的参数介绍可以参照以下的官方文档。PostgreSQL 读插件：PostgreSQLReaderPostgreSQL 写插件：PostgreSQLWriter 2、我的需求和解决我的需求很简单：定时同步整表数据，不需要什么搜索条件。但是在我实际进行同步的时候，碰到了这个问题： 1Exception in thread &quot;taskGroup-0&quot; com.alibaba.datax.common.exception.DataXException: Code:[DBUtilErrorCode-06], Description:[执行数据库 Sql 失败, 请检查您的配置的 column/table/where/querySql或者向 DBA 寻求帮助.]. - 执行的SQL为: select id,name,price,detail from test_table 具体错误信息为：com.alibaba.datax.common.exception.DataXException: Code:[DBUtilErrorCode-12], Description:[不支持的数据库类型. 请注意查看 DataX 已经支持的数据库类型以及数据库版本.]. - 您的配置文件中的列配置信息有误. 因为DataX 不支持数据库读取这种字段类型. 字段名:[detail], 字段名称:[1111], 字段Java类型:[java.lang.Object]. 请尝试使用数据库函数将其转换datax支持的类型 或者不同步该字段 . 检查了一下，detail 字段是 JSONB 类型的，无论是读还是写插件文档中都没有标注支持该类型，考虑了一下可能只有 4 个选择了： 更改数据库字段类型 在读的过程中使用函数将 JSONB 类型改为字符串，写的时候依靠 PosrgreSQL 自动将字符串类型转为 JSONB 存入数据库 在读的过程中使用函数将 JSONB 类型改为字符串，写入临时列，等同步结束后再执行语句将临时列数据转为 JSONB 存回原列 摆烂，不同步这个字段 JSONB 存存无用信息很方便，且当前已经有很多基于 JSONB 特性写的 SQL 语句了，排除了 1。在多次尝试之后发现无法实现，排除掉了 2。 关于 2 的尝试，读的过程中类型转换是很顺利的，写入之前值已经是类似 '{&quot;111&quot;: 222}' 的格式了，但是到了正式写入：如果你不强制指定类型，那么会报 PostgreSQLWriter 插件不支持 JSON 类型写入的错误，猜测是读取了数据库中的列类型而并非直接读取值的类型；强制指定类型 &quot;detail::VARCHAR&quot; 之后又会报 PostgreSQL 插入错误，无法将 VARCHAR 类型的数据插入 JSONB 类型的列。 最终只剩方案 3，庆幸在表设计之初就准备了备用字段，现在还有 2 个能用，并且后续如果 DataX 插件支持 JSONB 类型，只需要改配置文件就行了，很方便。修改后的配置文件（加上了我自己表的结构信息）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869{ &quot;job&quot;: { &quot;setting&quot;: { &quot;speed&quot;: { &quot;channel&quot;: 10 }, &quot;errorLimit&quot;: { &quot;record&quot;: 2, &quot;percentage&quot;: 0.02 } }, &quot;content&quot;: [ { &quot;reader&quot;: { &quot;name&quot;: &quot;postgresqlreader&quot;, &quot;parameter&quot;: { &quot;username&quot;: &quot;{from_username}&quot;, &quot;password&quot;: &quot;{from_password}&quot;, &quot;where&quot;: &quot;&quot;, &quot;column&quot;: [ &quot;id&quot;, &quot;name&quot;, &quot;price&quot;, &quot;detail:VARCHAR:&quot; ], &quot;connection&quot;: [ { &quot;table&quot;: [ &quot;test_table&quot; ], &quot;jdbcUrl&quot;: [ &quot;jdbc:postgresql://{from_host}:{from_port}/{from_database}&quot; ] } ] } }, &quot;writer&quot;: { &quot;name&quot;: &quot;postgresqlwriter&quot;, &quot;parameter&quot;: { &quot;username&quot;: &quot;{to_username}&quot;, &quot;password&quot;: &quot;{to_password}&quot;, &quot;column&quot;: [ &quot;id&quot;, &quot;name&quot;, &quot;price&quot;, &quot;spare&quot; ], &quot;preSql&quot;: [ &quot;DELETE FROM test_table;&quot; ], &quot;postSql&quot;: [ &quot;UPDATE test_table SET detail = spare::JSONB;&quot;, &quot;UPDATE test_table SET spare = NULL;&quot; ], &quot;connection&quot;: [ { &quot;jdbcUrl&quot;: &quot;jdbc:postgresql://{to_host}:{to_port}/{to_database}&quot;, &quot;table&quot;: [ &quot;test_table&quot; ] } ] } } } ] }} 会慢一点，适当调高 channel 并发之后还能接受，等数据量上来了再补性能调优。 本章结束。","link":"/2021/11/16/bak_datax_note_02/"},{"title":"【归档文章】DataX 实践（三）从 PostgreSQL 读数据库增量同步表到 MongoDB 写数据库","text":"关于 Alibaba DataX 项目的实践。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 对价格字段进行增量同步。 简单阐述全量同步和增量同步区别：全量同步：就是每天定时（避开业务高峰期）或者周期性全量把数据从一个地方拷贝到另外一个地方，可以采用直接全部覆盖（使用新数据覆盖旧数据）或者走更新逻辑（覆盖前判断下，如果新旧不一致，就更新）。增量同步：就是指抓取某个时刻（更新时间）或者检查点以后的数据来同步，不是无规律的全量同步。 1、基础的配置文件MongoDB 写插件的官方文档：Datax MongoDBWriter 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758{ &quot;job&quot;: { &quot;setting&quot;: { &quot;speed&quot;: { &quot;channel&quot;: 3 }, &quot;errorLimit&quot;: {} }, &quot;content&quot;: [ { &quot;reader&quot;: { &quot;name&quot;: &quot;postgresqlreader&quot;, &quot;parameter&quot;: { &quot;username&quot;: &quot;{from_username}&quot;, &quot;password&quot;: &quot;{from_password}&quot;, &quot;where&quot;: &quot;&quot;, &quot;column&quot;: [ &quot;{from_column_01}&quot;, &quot;{from_column_02}&quot; ], &quot;connection&quot;: [ { &quot;table&quot;: [ &quot;{from_table}&quot; ], &quot;jdbcUrl&quot;: [ &quot;jdbc:postgresql://{from_host}:{from_port}/{from_database}&quot; ] } ] } }, &quot;writer&quot;: { &quot;name&quot;: &quot;mongodbwriter&quot;, &quot;parameter&quot;: { &quot;address&quot;: [ &quot;{to_host}:{to_port}&quot; ], &quot;userName&quot;: &quot;{to_username}&quot;, &quot;userPassword&quot;: &quot;{to_password}&quot;, &quot;dbName&quot;: &quot;{to_database}&quot;, &quot;collectionName&quot;: &quot;smr_{web}_{mode}_history&quot;, &quot;column&quot;: [ { &quot;name&quot;: &quot;{from_column_01}&quot;, &quot;type&quot;: &quot;string&quot; }, { &quot;name&quot;: &quot;{from_column_02}&quot;, &quot;type&quot;: &quot;string&quot; } ] } } } ] }} 2、我的需求和解决我的需求是：定时将 PostgreSQL 表中的价格字段和更新时间字段，以更新时间的时间戳作为主键，保存到 MongoDB 中。写起来还是很简单的，只要注意一下 PostgreSQL 时间戳的转换就行了。最后的配置文件： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364{ &quot;job&quot;: { &quot;setting&quot;: { &quot;speed&quot;: { &quot;channel&quot;: 10 }, &quot;errorLimit&quot;: { &quot;record&quot;: 2, &quot;percentage&quot;: 0.02 } }, &quot;content&quot;: [ { &quot;reader&quot;: { &quot;name&quot;: &quot;postgresqlreader&quot;, &quot;parameter&quot;: { &quot;username&quot;: &quot;{from_username}&quot;, &quot;password&quot;: &quot;{from_password}&quot;, &quot;where&quot;: &quot;&quot;, &quot;column&quot;: [ &quot;update_time&quot;, &quot;price&quot; ], &quot;connection&quot;: [ { &quot;table&quot;: [ &quot;test_table&quot; ], &quot;jdbcUrl&quot;: [ &quot;jdbc:postgresql://{from_host}:{from_port}/{from_database}&quot; ] } ] } }, &quot;writer&quot;: { &quot;name&quot;: &quot;mongodbwriter&quot;, &quot;parameter&quot;: { &quot;address&quot;: [ &quot;{to_host}:{to_port}&quot; ], &quot;userName&quot;: &quot;{to_username}&quot;, &quot;userPassword&quot;: &quot;{to_password}&quot;, &quot;dbName&quot;: &quot;{to_database}&quot;, &quot;collectionName&quot;: &quot;test_table_price_history&quot;, &quot;column&quot;: [ { &quot;name&quot;: &quot;time&quot;, &quot;type&quot;: &quot;int&quot; }, { &quot;name&quot;: &quot;price&quot;, &quot;type&quot;: &quot;double&quot; } ], &quot;upsertInfo&quot;: { &quot;isUpsert&quot;: &quot;false&quot; } } } } ] }} 结束。","link":"/2021/11/16/bak_datax_note_03/"},{"title":"【归档文章】使用 Docker 部署 Lsky Pro 兰空图床并配置 uPic 实现一键上传","text":"关于部署 Lsky Pro 兰空图床和配置 uPic 的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 1. 兰空图床与其他图床的横向对比目前比较主流的自建图床就只有 Lsky Pro 兰空、Chevereto 和 ImgURL Pro 这三款，而其他的图床像 Telegraph-Image 由于没有稳定的盈利模式，在我看来都不适宜长期使用。 项目 Lsky Pro 兰空图床 Chevereto ImgURL Pro 开源 ✅ 有开源版本 ✅ 有开源版本 ✅ 有开源版本 价格 付费版本：233.33 元（永久） 付费版本：59 美元（大版本） 专业版：198 元（每域名） 支持用户注册、上传 ✅ 支持 ✅ 支持 ✅ 支持 支持接口操作图片 ✅ 支持 ✅ 支持 ✅ 支持 支持 Docker 部署 ✅ 第三方支持 ✅ 官方支持 ✅ 官方支持 配置要求 ✅ 2H2G ❓未知 ❓未知 风评 ✅ 良心 ❌不佳 ✅ 不错 我的首要需求是自用、支持接口操作图片，其次是稳定，最后是文档齐全和便宜。三个图床做的都不错，最终在 选择了国人开发的风评较好的 Lsky Pro 兰空图床。 2. 使用 Docker 部署兰空图床2.1 使用 Docker 启动 这里使用的第三方的 Docker 容器镜像：HalcyonAzure/lsky-pro-docker，Dockerfile 在我看来安全性方面是没有问题的，因此这里直接使用 Docker Hub 上对应的托管镜像了。当然你也可以 Fork 后阅读源码自己构建。 使用 Docker 启动较为简单，首先在宿主机上创建用以存储图床数据的目录： 1mkdir -vp /ceshiku/docker/lsky/data 之后启动容器： 123456789docker run -d \\ --name lsky_pro \\ -p 9080:80 \\ # 2024/12/09 更新，作者或 Docker 镜像维护者更新了默认的 WEB 端口 # -p 9080:8089 \\ # -e WEB_PORT=8089 \\ -v /ceshiku/docker/lsky/data:/var/www/html \\ --restart unless-stopped \\ halcyonazure/lsky-pro-docker:latest 接着访问服务器 http://IP:9080 就可以访问图床的安装界面了。 2.2 图床安装第一步是检测运行环境，由于使用的是 Docker 容器镜像，因此环境一定是完备的：第二步配置数据库，我图方便就选 SQLite 了，生产环境推荐使用 MySQL 或 PostgreSQL：之后等待安装完成即可： 2.3 开启 HTTPS 访问我这里选的是白嫖 Cloudflare 的 SSL 证书，当然你也可以通过其他方式配置 HTTPS 访问：之后配置下 Nginx 反代 9080 端口的图床： 1vi /etc/nginx/nginx.conf 1234567891011121314151617181920212223242526272829........keepalive_timeout 65;types_hash_max_size 4096;# 允许上传最大 20mb 的文件client_max_body_size 20m;include /etc/nginx/mime.types;......# 反代配置# === img.ceshiku.cn ===server { listen 80; server_name img.ceshiku.cn; location / { proxy_pass http://127.0.0.1:9080; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-Proto https; add_header X-Cache $upstream_cache_status; }}...... 12nginx -s reloadservice nginx restart 保存后稍等片刻直到 DNS 生效，再通过域名访问就能看到 HTTPS 生效了： 2.4 图床基础配置关闭访客注册、上传：配置域名： 2.5 测试图片上传功能回到首页拖拽上传：上传成功后可以看见各个格式的引用代码： 3. macOS 下配置 uPic 实现一键上传 参考文章：Lsky 兰空图床升级 V2 指南 App Store 购买地址：uPic: 强大的图床工具作者的 V2EX 主页：gee1k 注意：uPic 上可选的 Lsky Pro 配置项只支持 v1.0 版本的兰空图床，我们上面部署的是 v2.0 以后的版本，因此只能选择自定义图床上传配置！基础配置如下：点击其他字段按钮打开进阶配置，主要用于填写用户的 Token 等登陆信息：获取用户信息： 1curl -X POST -F &quot;email=admin@ceshiku.cn&quot; -F &quot;password=xxxxxxxx&quot; https://img.ceshiku.cn/api/v1/tokens 12# 响应{&quot;status&quot;:true,&quot;message&quot;:&quot;success&quot;,&quot;data&quot;:{&quot;token&quot;:&quot;1|FWzOLxTGKhlT51m2oxxxxxxxxxxxxxxx&quot;}} 开始配置，选择 Headers 数据： Content-Type: multipart/form-data Accept: application/json Authorization: Bearer 1|FWzOLxTGKhlT51m2oxxxxxxxxxxxxxxx Authorization 的值填写格式：Bearer + token 字段的数据，注意中间有个空格。 选择图床后，上传测试：可以成功上传，结束。 4. 后记上传后的图片文件目录为： 1/ceshiku/docker/lsky/data/storage/app/uploads/ 后续需要通过 Rclone 等工具进行备份。","link":"/2023/01/23/bak_docker_lsky_pro_and_upic/"},{"title":"【归档文章】以太坊矿机搭建（一）矿机平台的硬件挑选和组装","text":"关于以太坊矿机搭建的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 趁着币价开始下跌，挖矿热潮暂退的间隙，开始组自己的第一台矿机了。并没有赚钱的打算，只是为了接触区块链最基础的一环来为自己的智能合约学习做铺垫。本章主要记录一下自己挑选硬件的过程，希望对你也能有所帮助。以硬件作小节，最后一章大致描述下硬件组装需要注意的点。 1、主板首先你得确定自己的主板型号，这样才能去寻找对应的 CPU。而如何挑选主板呢？最简单的，去明确自己的目标：想要一台几显卡的矿机。由于像 ETH 这样的显卡挖矿并不需要很大的 PCI-E 带宽，1X 就能满足要求了，因此如果你想要一台 8 卡的挖矿主机，那么你所挑选的主板上至少要有 8 条 PCI-E 1X 速率的插槽，一下子范围就缩小了。 注：一般来说 M.2 固态硬盘的插槽也可以转为 PCI-E 插槽，但是像 Z270-P 这样的主板存在 M.2 插槽和自带的 PCI-E 插槽共享通道的问题，所以购买之前最好像卖家了解清楚或是直接就不将 M.2 插槽数算入。 Reddit 上有一篇较为详细的推荐帖子：Suggested Motherboards我入的是 ASUS Z270-AR，肉眼可见的 7 条 PCI-E 插槽加 2 条 M.2 插槽，价格为 ￥476，其他的在某宝上要么缺货要么涨的有点多…… 2、CPU因为根本不吃 CPU 所以没啥好挑的，买了个帖子 Processor/CPU 里推荐的 G3930，淘宝店家也正好有，省运费。注：Intel 平台的板 U 请自行注意针脚数是否能匹配，不清楚请找卖家咨询好。 3、内存矿机平台用 Windows 系统就上 8 GB，否则 4 GB 就够用了。 4、硬盘矿机平台是 Linux 系统的话 U 盘都行，也是随便买。 5、显卡先看你挖的币最少需要多少 GB 的显存支持，例如 ETH 需要至少 8 GB，其他就看个人预算了。算力收益计算器：GPU 挖矿我推荐的 6800XT、3060Ti 和 3070Ti，如果你的预算不够当然也能去收二手卡，但是币价稳定或是小跌的情况下迟早都是会回本的，省事、有保修的新卡对我来说诱惑力更大一点。 6、电源总功率计算的话，上面的显卡算力收益计算器中将功率 * 1.1 再加个 50 W 的平台功率大概就行了。金牌以下认证的电源就没必要入了，将你矿机平台的总功率 * 1.1 得到标称功率再去选购比较稳妥。牌子的话预算少就长城，预算够就海韵、海盗船和酷冷至尊，我入的是振华。 7、机架某宝闭眼挑，如果你的总功率需要双电源的话，记得选大机架预留另一个电源的位置。 8、其他如果你的主板不是直插型的专业矿板，那么你还需要购买 PCI-E 延长线；机架的散热也需要购置风扇；如果你想准确测量矿机耗电的话，还需要购买功率显示插座。 9、组装物理搭建几乎没什么需要注意的，前提是你买的是质量较好的机架。唯一需要注意的是你主板安装时孔位的对齐，以我的板子 Z270-AR 为例：因为主板 2 孔和 3 孔位置是确定的，所以需要将较长的空隙留给主板上侧。 附上我的最终配置单（价格截至 2021 年 12 月 20 日）： 硬件 型号 品牌 价格 数量 CPU G3930 Intel ￥315 1 主板 PRIME Z270 AR ASUS ￥476 1 内存 普条 DDR4（8 GB） 金士顿 ￥165 1 硬盘 铁甲悍将（120 GB） 影驰 ￥110 1 显卡 6800XT 樱瞳（16 GB） 盈通 ￥7999 2 电源 1000W 金牌全模 振华 ￥929 1 机架 8 卡开放式（带 8 个 PCI-E 转换板和 7 个风扇） 维达 ￥930 1 总计 ￥18923 在当前币价下，一天收益大概在 45 元左右，也就是说需要大概 400 多天才能回本。 本章结束。","link":"/2021/12/20/bak_eth_miner_note_01/"},{"title":"【归档文章】以太坊矿机搭建（二）安装 Mining OS（Minerstat OS）专业挖矿系统一键挖矿","text":"关于使用以太坊矿机挖矿的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 上一章讲了硬件选配和组装，这章讲适合小白的专业挖矿系统 Mining OS（Minerstat OS）的安装、矿软件的设置和启动，当然也包括路由器上（OpenWrt 系统）设置使用代理（Clash 插件）来访问矿池。 Mining OS（Minerstat OS）是由一站式挖矿服务商 Minerstat 推出的专业挖矿系统，它有免费和收费两种版本，具体的差别可以看这里：Find the right plan for your mining operation至于为什么要选择第三方系统，而非使用 CentOS 等当前 Linux 的稳定发行版进行挖矿，是因为 Linux 下 AMD 显卡驱动、OpenCL 和 ORCm 等 GPU 计算平台的安装调试实在过于麻烦，后续接触深度学习的时候可能会补上 CentOS7 下手动调试挖矿软件的教程。 1、下载 msos-flasher 并写入 U 盘Mining OS 通过 U 盘的安装流程的：矿机插 U 盘启动 msos-flasher 系统，然后通过这个系统将 U 盘里真正的 Mining OS 系统文件解压并安装到矿机硬盘里。下载地址：SSD Flasher（其实就是 msos-flasher）等待下载完成后解压出 .img 文件，使用 Etcher 将 msos-flasher 写入 U 盘（16 GB 及以上）：稍等片刻即可，这个时候可以先进入下一章去下载真正的 Mining OS 系统。 2、下载 Mining OS（Minerstat OS）官方下载页面：Mining OS注意：如果你使用的是 AMD Vega 或 RX 6000 系列的显卡需要和我一样下载新版本：N 卡和其他 A 卡就下载普通版即可：下载完成后直接将压缩包拷贝到 msos-flasher 系统写入完成的 U 盘的根目录下：拷贝的过程中我们可以再提前进入下一章！ 3、注册 Minerstat 账号并新建 Worker（矿工）需要注意的是，如果你想使用 Mining OS 系统的话，你需要为每台矿机每个系统都绑定 Worker（即矿工），Minerstat 有自己的网页控制面板，之后 Worker 会出现在控制台中，这意味着你可以很方便地远程监视或是设置你的矿机。没有账号的话先注册：登录之后选择 Workers：根据自己矿机的硬件型号进行配置：之后点击 Add worker 并下载配置文件，文件内容就是你账号的登录密钥和矿工名字，在之后矿机系统内的配置时会用到： 4、矿机通过 U 盘启动 msos-flasher 系统并将 Mining OS 安装到硬盘拔 U 盘插到矿机上，矿机开机后进入 BIOS，通过 U 盘 UEFI 引导启动，安装过程中无需做任何操作，出现以下界面说明开始将 msOS 写入硬盘了：关于 BIOS 具体设置可以参考知乎文章：怎么设置bios从u盘启动 bios设置u盘启动方法稍等片刻后写入完成：之后输入 poweroff 关机、拔掉 U 盘并重新启动矿机即可。 5、设置矿机网络并绑定 Worker重启完成后会自动连接网络（前提是你的路由器开启了 DHCP 功能），之后会给出用来内网访问矿机的 VNC 地址：打开那个地址后，绑定刚刚 config.js 中的矿工信息即可： 1mworker $accesskey $workername 绑定后矿机会重启，之后就能在网页控制面板看到这个 Worker 了： 6、设置钱包地址点击更新钱包：将 MetaMask ETH 钱包的地址拷贝过去：之后保存即可：提币的话，最终是由你选定的矿池提给你的而非 Minerstat，所以如果你不准备用默认矿池的话，这里对钱包地址的更改一点用都没有。 当然你也可以配置完钱包地址后稍等片刻直到默认矿池刷新出你的算力收益，以确认你矿机的运转是正常的： 7、更改矿池我比较想用 ethermine.org 的池子，更改一下。打开 ethermine.org 官网并连接到 MetaMask 钱包：连接成功后打开控制台：复制上方的地址（理论上就是你 MetaMask 的钱包地址）并点击开始挖矿：获取矿池连接信息：拼接出完整的矿池连接命令： 1-worker Worker-01-AMD⁣⁣ -pool asia1.ethermine.org:4444⁣ -pool asia2.ethermine.org:4444 -wal 0xD29exxxxxxxxxxxxxxxxxxxxxxxxxxxx60.Worker-01-AMD⁣⁣ -eres 0 -log 0 -gbase 0⁣​ Minerstat 官方示例： 12345678910111213141516171819202122-worker (WORKER)⁣⁣ -pool (POOL:ETH)⁣ -wal (WALLET:ETH)⁣.(WORKER) -pass x -eres 0 -log 0 -gbase 0 -proto (AUTO)``` 填入 `Worker config` 中的 `PHOENIX-ETH` 项即可： ![PHOENIX-ETH](https://image.senjianlu.com/blog/2024-09-11/63d20141bad9a.png) 大概 5 分钟后收益就会出现了： ![矿池收益](https://image.senjianlu.com/blog/2024-09-11/63d201437b157.png) 由于算力取得是 60 分钟内的平均值，因此大概需要跑 2 小时才能显示准确的算力。 #### 8、Clash 配置使用代理访问矿池地址连不上矿池的话领不到计算任务，算力就有可能显示为 0 了。 Clash 的配置话较为简单，在原本 Clash 的 `rules` 标签中添加以下两行即可（我使用的是 [ethermine.org](https://ethermine.org/start) 的矿池）： ```yamlrules: ... ... # Minerstat 可添可不添 - DOMAIN-SUFFIX,minerstat.com,矿池 # 视你自己的情况配置域名匹配 - DOMAIN-SUFFIX,ethermine.org,矿池 ... ...然后查看连接确认一下没问题： 本章结束。","link":"/2021/12/22/bak_eth_miner_note_02/"},{"title":"【归档文章】以太坊矿机搭建（三）从 ethermine.org 矿池中将小额 ETH 收益提现","text":"关于提现挖到的 ETH的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 虽然 ethermine.org 对以太坊主网这条链上的 ETH 设定的最低起提数量为 0.005，但是需要支付 0.001 ETH 将近 20 块钱的矿工费，想想还是有些肉疼，听说走 Polygon 这条链的损耗较小，于是决定试一下。稍稍会有些麻烦，因此实操并记录一下希望能帮到你。 具体的流程图我放在下面，黄颜色标记的模块就是本教程会涉及到的： 1、首先将 Polygon 链上的 WETH（你可以理解为 ETH 的代币） 提至 MetaMask 钱包找到小额提币的地方，选择提现 WETH，即下面一个选项： 如果你和我一样并未在 MetaMask 钱包上添加过这个网络，那么请点击下面这个链接进行添加：勾选同意：直接切换并添加 Polygon 链上的默认代币 WETH： 确认一下钱包地址：应该是和你以太坊主网上的钱包地址一模一样的，没问题的话点击 Sign &amp; Save Settings 保存设置：之后等待最多 24 小时，矿池会自动把 WETH 打到你的 Polygon 的钱包地址上：我大概等了 8 个小时，就看见钱包内的 WETH 余额变化了： 2、通过 Uniswap 将 WETH 兑换为 USDT-Polygon前往 Uniswap Swap：https://app.uniswap.org/#/swap选择 WETH to USDT：授权需要一定的 MATIC 作为手续费： 如果和我一样并未持有 MATIC 的话，前往 Polygon 官方提供的 0 手续费兑换 MATIC 网址：https://wallet.polygon.technology/gas-swap 兑换一点即可：确保有了手续费之后，再进行兑换即可：大概 1 分钟左右交易就会完成，你可以去区块链浏览器进行确认，如果之前未添加过 USDT 这个代币的话记得添加下： 3、充值到 OKX 欧易充值地址：https://www.okx.com/balance/recharge选择 USDT-Polygon：确认各信息无误后进行发送（油费默认即可）：之后静待交易完成即可：因为需要 130 个区块确认，因此花费时间较久，需要 5 分钟左右才能在欧易看到充值记录。 4、提现 USDT-TRC20 到其他平台不做演示了，充进欧易的 U 会自动以余额形式呈现，不会受链的限制，想怎么提现和使用随你： 说实话，挺麻烦的，下次直接提 ETH 了……结束。","link":"/2022/02/18/bak_eth_miner_note_03/"},{"title":"【归档文章】Fiddler 学习（一）安装、配置和尝试抓取 UWP 版网易云音乐的请求域名","text":"关于 Fiddler 的使用教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 在路由器上的 Clash 中配置网易云音乐灰歌解锁的时候发现：UWP 版的网易云音乐请求指向的似乎不是 music.163.com 等域名（事实上走的是 music.163.com 域名，只是我 Clash 配置的有问题罢了😓），没法照抄网络上的 Clash 配置文件，求人不如求己还是自己抓包看下吧。 1、安装 Fiddler官方下载地址：Download Fiddler Classic然后安装：显示如上界面便说明安装成功了。 2、基础配置这一步的配置非常基础，是几乎所有人都会进行修改的，主要是为了达到 2 个目的： 解密 HTTPS 流量（当然无法完全解密，但是起码看起来会更轻松了） 允许局域网内设备连接 Fiddler（安卓等移动设备抓包时会用到） 配置选项位置如下：① 设置解密 HTTPS 流量（可能会弹出 Windows 安装证书的确认框，同意即可）：忽略服务器证书的错误，这在服务器端配置了不可信证书时会生效，比如说域名绑定的是自签证书：② 配置代理端口并允许局域网内连接：之后移动端配置代理为你主机的 IP:8888，那么所有的流量就都会走 Fiddler 了。 3、实践抓取 UWP 版网易云音乐的请求域名首先设置下网易云音乐使用 Fiddler 的端口作代理：拖动进程选择器到网易云音乐窗口，目的是只监听这一个进程的流量：清空：然后在网易云音乐执行一下操作，我这里执行的是搜索歌曲，一点按钮就能看到 Fiddler 抓取到发出的请求了：我这次只想知道 UWP 版网易云音乐是对哪个域名发出请求的，于是只要注意 Host 列即可：搜索音乐的使用的是 interface.music.163.com！当然这还不够，再试试其他操作：播放音乐走的是 *.music.126.net：视频走的是 *.vod.126.net：有一个奇怪的域名 clientlog.music.163.com，猜测是记录连接的日志用的，反正会被 *.music.163.com 通配符覆盖到，就不用管了。还有个网易云盾 ac.dun.163yun.com，想了想就不加进 Clash 配置里了：那么应该就差不多了，UWP 版的网易云音乐在 Clash 中的规则就是下面这样的： 具体的网易云灰歌教程可以参照这篇文章：CentOS7 下用 Docker 部署 UnblockNeteaseMusic 并在 Clash 中配置分流以在局域网内解锁网易云音乐变灰的歌曲不懂 Clash 的配置请去看这篇文章：Clash 学习（一）配置文件各项在实际使用中的用处和创建自己的第一个配置文件 123456789......rules: - DOMAIN-SUFFIX,music.163.com,网易云音乐 - DOMAIN-SUFFIX,music.126.net,网易云音乐 # 如果灰歌解锁服务器速度不行的话就不要代理视频了 - DOMAIN-SUFFIX,vod.126.net,网易云音乐...... 结束。","link":"/2021/11/05/bak_fiddler_note_01/"},{"title":"【归档文章】GitHub Action 自动构建项目容器镜像并 Push 到官方 Docker Hub","text":"关于使用 GitHub Action 构建容器并推送的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 首先明确 Docker 镜像的构建流程由项目根目录下的 Dockerfile 文件管理，GitHub Action 自动推送流程则由项目根目录下的 .github/workflows/main.yaml 文件控制。 以 rab_python_packages 项目为例，文件结构也可直接参考。 1、建立 Dockerfile 文件文件内容： 123456789101112131415161718192021222324252627282930313233# 基础镜像系统版本为 CentOS:7FROM centos:7# 维护者信息LABEL maintainer=&quot;Rabbir admin@cs.cheap&quot;# Docker 内用户切换到 rootUSER root# 设置时区为东八区RUN echo &quot;Asia/shanghai&quot; &gt; /etc/timezone# 在基础镜像内安装 Git 和 Python3WORKDIR /rootRUN yum -y install gitRUN curl -s https://gitee.com/senjianlu/one-click-scripts/raw/main/CentOS7%20%E4%B8%8B%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%20Python3%20%E7%8E%AF%E5%A2%83/install.sh | bash# 在 /root/GitHub 目录下克隆 rab_python_packages 项目RUN mkdir /root/GitHubRUN mkdir /root/GitHub/rab_python_packagesWORKDIR /root/GitHub/rab_python_packages# 将宿主机当前目录下的所有文件拷贝至镜像内的 /root/GitHub/rab_python_packages 文件夹中COPY . .# 配置环境RUN python3 rab_env.pyRUN python3 rab_env.py rab_chrome# 删除无用文件RUN rm -r chromedriver_linux64.zipRUN rm -r google-chrome-stable_current_x86_64.rpm# 启动容器时不指定命令则执行以下的默认命令，只取最后一行 CMD 命令生效CMD cd /root/GitHub/rab_python_packages &amp;&amp; python3 rab_logging.py 2、测试 Dockerfile在 Dockerfile 同目录下执行： 12# 镜像名自行替换docker build -t rabbir/rab_python_packages:latest . 3、建立 GitHub Action 流程在项目根目录下新建 .github/workflows/ 文件夹并创建 main.yaml 文件： 1234mkdir .githubmkdir .github/workflowscd .github/workflowsvi main.py 文件内容：注：以下文件可以直接复制使用，只需要更改倒数第 4 行的镜像名即可。 12345678910111213141516171819202122232425262728293031323334353637# 将项目构建镜像并发布至 Docker Hubname: CI to Docker Hub# 在 Push 到 main 分支后启动该流程on: push: branches: [ main ]jobs: build: runs-on: ubuntu-latest steps: # 在 GitHub Action 的服务器上 Check Out 源码（整体流程结束后会重置服务器环境因此不需要担心泄露） - name: Check Out Repo uses: actions/checkout@v2 # 登录至 Docker Hub，账户密码需要在 Settings -&gt; Secrets 中设置 - name: Login to Docker Hub uses: docker/login-action@v1 with: username: ${{ secrets.DOCKER_HUB_USERNAME }} password: ${{ secrets.DOCKER_HUB_ACCESS_TOKEN }} # 设置 Buildx 为构建镜像做准备 - name: Set up Docker Buildx id: buildx uses: docker/setup-buildx-action@v1 # 构建并发布（执行项目路径下的 Dockerfile 文件） - name: Build and push id: docker_build uses: docker/build-push-action@v2 with: context: ./ file: ./Dockerfile push: true tags: ${{ secrets.DOCKER_HUB_USERNAME }}/rab_python_packages:latest # 完成 - name: Image digest run: echo ${{ steps.docker_build.outputs.digest }} 结束。","link":"/2021/10/10/bak_github_action_push_to_docker_hub/"},{"title":"【归档文章】Gullo 2 美刀年付 NAT 主机的基础操作和玩法","text":"关于 Gullo NAT 主机的基础操作和玩法。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 这个黑五本来是准备上斯巴达和 HostHatch 的车的，但是把前两年黑五的账单付了下后，发现吃灰的小鸡实在太多了，除了腾讯云香港的几台主机建了站在稳定服役，其他 20 来台基本都只装了个 SOCKS5 代理服务端，实在浪费……正巧看到这个帖子：Gullo 128M 套 CF 做网站很爽，还有更便宜的 NAT VPS 吗，6 台不同地域的 NAT 主机总价为 12 美刀每年，折合每台才 2 刀，虽然每台主机只提供 20 个 IPv4 端口，且 IP 大概率是被墙的，但是便宜呀，果断入手玩下，顺便记录下 Gullo 控制面板一些折腾的地方。 1、开机并获取 SSH 登录信息Gullo 每台 NAT 主机的主键是其内网地址，网段为 10.10.10.1 到 10.10.255.255，SSH 登录信息都可以通过这个内网地址来获得，不过比较绕，我将买完机器后的各阶段操作都记录在下面，请自行参考。① 等待开机Gullo 家的机器有很大一部分是老板手动开的（离谱），黑五我这一单 NAT IPv4 128MB Bundle 等了将近 30 小时才审核完开机，开机成功你的注册邮箱会收到这样的邮件：收到登录信息的话你就可以直接跳到后面玩法部分了，但是如果你没收到或是漏收到了，那么跟着我往下一步步调查 SSH 登录信息吧。② 登录至 VPS 控制面板地址：https://solusvm.gullo.me/用户名我是在发来的少数 SSH 登录信息中找到的（如果你一个 NAT 机器的登录信息都没收到的话，发工单吧），密码则需要自己找回一下以重新设置：回邮箱拿到新密码登录即可： ③ 获取 NAT 机器的外网 IPv4 地址（针对没收到 SSH 登录信息的 NAT 机器）Gullo 提供的工具：NAT IPv4 Port Calculator在控制面板选定机器，并使用上面的工具通过内网地址查询外网 IPv4 地址、可使用的 20 个端口和 SSH 连接端口：④ 重设 NAT 机器的密码（针对没收到 SSH 登录信息的 NAT 机器）使用 Serial Console 临时连一下机器，选 1 小时时长即可：获取临时的 SSH 登录信息： 这里如果一直连不上，重装下 NAT 机器的系统试一下，还不行的话就发工单吧，我有一台德国的机器就永远密码错误……便宜机器问题确实多，但也正常。 登录之后，安装一下 passwd 并重设密码： 123yum -y install passwd# 重设 root 用户密码passwd root 之后在其他机器上连接即可，以 Linux 为例： 1ssh -p $port root@$host 2、挂个探针NAT 机不配接入 Zabbix，这里用的是哪吒探针，搭建教程可以参考：CentOS7 下搭建哪吒监控面板（附带监控端的安装）在面板后台新建机器，拷贝一键安装命令后直接取 NAT 主机上执行即可： 3、搭个 SOCKS5 代理服务端一键脚本：CentOS7 下一键安装 GOST 并启动 HTTP 和 SOCKS5 代理服务注意这里的端口得是你 20 个可用端口中的一个： 1curl -s https://gitee.com/senjianlu/one-click-scripts/raw/main/CentOS7%20下一键安装%20GOST%20并启动%20HTTP%20和%20SOCKS5%20代理服务/install.sh | bash -s $proxy_port $proxy_username $proxy_password 换台服务器测试一下代理是否生效： 1curl -x socks5://$username:$password@$host:$port http://ip-api.com/json/?lang=zh-CN 虽然共用的这个 IPv4 地址已经脏的不能再脏了，但就爬虫用用也还行。 4、套 Cloudflare 建个站Gullo 给每台 NAT 主机都提供了一个全端口的 IPv6 地址，建站就很方便了，直接在 DNS 中解析 AAAA 记录即可。但是考虑到部分用户是没有 IPv6 地址的，真要建站还需要套个 Cloudflare 的 CDN 做下中转。这里就拿 Nginx 的默认页面举例，由于在 1.3 之后某个版本，Nginx 已经默认启用对 IPv6 地址访问的监听，因此无需做多余配置直接在 NAT 机器上安装： 12345yum -y install epel-release# 安装 Nginxyum -y install nginx# 启动 Nginxservice nginx start 获取你 NAT 机器的 IPv6 地址：在 Cloudflare 的 DNS 处解析，类型选 AAAA，SSL/TLS 选 灵活 让 CF 提供 SSL 证书：稍等片刻后访问页面测试一下：再用只有 IPv4 地址的主机访问一下：IPv4 都支持了，那么 IPv6 更不用说了，通过 ipv6-test 测试一下： Gullo 部分机房存在阻断 Cloudflare 流量来源的问题（我实践后发现起码纽约机房是阻断的），这会导致你不套 CF 使用 IPv6 可以访问网站，但是套了后出现 522 的错误，具体的讨论可以看这个：Gullos hosting in NY blocking cloudflare ?你也可以在服务器上通过以下命令来查看 Cloudflare 的流量是否顺利的回源了： 1cat /var/log/nginx/access.log 上面的 IPv6 地址属于 Cloudflare，那么就说明回源成功了。 结束。","link":"/2021/12/02/bak_gullo_nat_vps/"},{"title":"【归档文章】Windows 下 Hugo 静态博客一键推送发布","text":"关于 Hugo 推送发布的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 为了在东京奥运会期间应对临时封路，紧跟日本人赶了2个月的功能，终于能休息一阵了 :)虽然是因为奥运会推迟而不是因为开发完成总之又能学点新东西了，方便记录先准备个一键推送博客的工具吧。 环境：Windows 10 64 位需要时间：10 分钟左右原教程：CSDN Hugo 博客的脚本快速发布博客 说着好听的一键脚本其实也就是把发布所需要输入的几行命令写进一个批处理文件里罢了，首先回顾下一般情况下我们完成一篇博客并发布的所有命令： 12345678hugo new posts/myblog01.md # 新建一片博文，当然也能去路径下之间创建.md文件hugo server -t pure --buildDrafts # 在localhost起博客看效果 pure换为你的theme名hugo --theme=pure --baseUrl=&quot;https://moyu.best&quot; --buildDrafts # 确保效果符合预期后生成public目录 Url换为你的博客地址cd publicgit add .git commit -m &quot;推送&quot;git push -u origin mastergit push -f # 如果报错了但是你能确定本地的是最新状态的话 然后开始写脚本，一般在 Windows 下直接写 .bat 脚本就行了，但是这里我们为了后期通过 Git Bash 来执行，省去每次输入 Git 账户密码的步骤，所以采用 Shell 脚本。直接上代码和注释： 12345678910111213141516171819#!/bin/bashecho -e &quot;\\033[0;32mStart to deploy!\\033[0m&quot;# Build the hugo projecthugo --theme=pure --baseUrl=&quot;https://moyu.best&quot; --buildDrafts# Go to Publiccd public# Add allgit add .# Commitgit commit -m &quot;Commit by deploy.sh&quot;# Pushgit push -u origin master# Backcd ... 然后是选择用 Git Bash 的方式执行这个批处理脚本。选定 Git Bash 即可，然后运行！可以看见效果和我们手动 push 是一样的，推送成功了。结束~后续是可以添加 msg 作为参数传入和 catch 冲突后强制 push 的，这里就不琢磨了，等个下周用上2天好好学习一下批处理脚本吧。脚本下载地址：下载（记得更改 theme 主题和博客 Url）","link":"/2020/05/17/bak_hugo_auto_build/"},{"title":"【归档文章】Windows 下 Hugo + GitHub Pages 搭建静态博客","text":"关于使用 GitHub Pages 和 Hugo 搭建静态博客的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 确确实实感觉记性越来越差，有记录包括“问题解决方法”、“配置文件修改”等信息的需求了，但同时也希望一切从简，听从V友建议选用 Hugo+GitHub Pages 免费搭建个静态博客来做树洞吧。 环境：Windows 10 64 位需要时间：1 小时左右原教程：CSDN Windows 下搭建 Hugo 博客 1、下载 Hugo在 https://github.com/gohugoio/hugo/releases 地址下找到Windows压缩文件下载如下图 64 位的： 2、添加至环境变量新建 Hugo 和 Hugo/bin 文件夹，将下载下来的 .exe 文件放入 bin 文件夹，并添加至环境变量中。 3、验证 Hugo1hugo version 检测是否安装成功，安装成功后进入 Hugo 文件夹中，输入 1hugo new site myblog myblog 替换成想要的博客文件夹名字。 4、项目结构可以看见项目结构：content 文件夹存放内容，themes 文件夹用来存放主题，config.toml 用来配置文件，这也是这次初步建立需要博客需要改的内容。 5、挑选主题在 https://themes.gohugo.io/ 选择自己喜欢的主题进行下载，这次我使用 hugo-theme-m10c 这款主题，因为选择它避免配置 config.toml 文件而花费大量时间。 6、下载主题Cmd 进入博客文件夹下，执行以下命令把 GitHub 上的主题文件 Clone 到对应文件夹下 themes/m10c 1git clone https://github.com/vaga/hugo-theme-m10c.git themes/m10c 7、本地构建此时就已经在本地运行博客做确认了，执行： 1hugo server -t m10c --buildDrafts 启动项目，然后前往 http://localhost:1313/ 就可以看到了。 8、新建一篇博客使用 Hugo 很大程度上就是看中了它将 .md 文件渲染成静态博客页面的能力，即使是发布完成后，原稿也可以保存方便脱机查看。首选 Ctrl+C 结束本地的预览，然后新建博文对应的 .md 文件。 1hugo new post/blog.md 新建的 .md 文件会存储在 content/post 中，直接前往进行编辑即可。 9、编辑博文推荐使用 VS Code 进行编辑，左上角的预览按钮，点击后可以将窗口分为左右两部分用于查看实施效果。注意：draft: true 需要改为 draft: false 图中并未做修改，如果不修改就是草稿，不会在博文页面上显示内容！写完后直接 Ctrl+S 保存即可。 10、再发布、检查新博文再次本地启动项目，可以看见已经有对应的博文了。​至此，本地博客环境就算配置完成了。​ 1hugo server -t m10c --buildDrafts 11、创建 GitHub Pages 仓库GitHub 为每个账号提供了一个免费的空间来存储静态的 HTML、JS 和 CSS，而我们就可以借此来发布博客。首先去新建仓库，注意命名，这是 GitHub 辨别是否为网络空间的依据。仓库名需满足 账户名.github.io 的命名规范，然后点击绿色的 create 按钮进行创建。 我因为已经部署完成，因此这里显示重复创建。 12、生成 public 目录创建完成后，回到 myblog 博客目录，执行以下命令来生成 public 目录，也就是 GitHub 仓库所需的静态博客的文件。（后续都用的原博客的图，路径可能有偏差，都是基础的 Git 操作） 1hugo --theme=m10c --baseUrl=&quot;地址&quot; --buildDrafts 13、Git 提交进入 public 文件夹，将所有文件添加、提交到本地。 123git initgit add.git commit -m &quot;附言&quot; 14、Git 推送将本地 public 与 GitHub 进行关联后，进行推送，第一次推送会需要输入 GitHub 的账号密码。 12git add origin http://github.com/m1801823/m1801823.github.io.gitgit push -u origin master 15、检查 GitHub 页面等待推送完成后，刷新 GitHub 页面，对应的文件就上传上来了，这时候输入 http://账户名.github.io 就可以访问了 16、DNS 解析如果自己有域名的话，也可以配置 DNS 直接让域名解析到你的静态博客上，方便告诉好友你的博客网址。这里以在 Namecheap 上购买的域名为例，不推荐阿里云和腾讯云，只因为管局备案太麻烦。 首先选择已有域名进入管理面板。 然后新增或者修改 DNS 解析记录，对应以下修改即可，只需要把 CNAME Record 的 Value 修改成你的地址即可。 最后回到 GitHub 的仓库部分，选择 Settings，拉到 Custom domain 部分修改成你的域名保存。大概 5 分钟左右，域名就会解析到你的博客，在开始的几天是不支持 HTTPS 的，只能先用 http://你的域名 进行访问。之后如果 HTTPS 加密可用，则需要更改一下模板，在 head 部分加上 1&lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;upgrade-insecure-requests&quot;&gt; 来自动将 HTTP 的不安全请求升级为 HTTPS，否则可能出现 CSS 等加载不出来的情况。 至此基于 Hugo 和 Github Pages 的静态博客搭建完成，开始养成记录的好习惯吧！","link":"/2020/01/11/bak_hugo_github_pages/"},{"title":"【归档文章】Hugo 静态博客使用 utterances 来开启评论功能","text":"关于 Hugo 博客开放评论的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 在建设这个博客的初期本来是想开放评论功能的，但是由于第一次接触 Hugo 这样静态博客，页面上的内容都是通过模板生成，实在是生疏，稍微配置了一下发现不行就放弃了。一直到现在，想想还是再试一试吧，于是就有了这篇博文。 我这里使用的是 utterances 来实现评论功能，评论会被保存到你指定 GitHub 仓库（必须是公开的）的 Issues 内，由于任何人只要通过 GitHub OAuth 登录过后就可以进行评论，且官方没有敏感词等的过滤，因此担心污染仓库的话请慎用。​而其他的评论配置和本文中的操作大同小异，基本都是在博文页面的模板中添加评论服务提供商给的评论页面元素模板，之后在配置文件中设置变量以开启评论功能。 1、安装 utterancesutterances 的安装较为简单，直接在 GitHub App 上安装即可。 关于 GitHub App 的介绍可以看这篇文章：详解 GitHub App 的玩法 GitHub App 链接：utterances点击 Install：选择一个仓库并安装（我推荐用你 Hugo 博客所在的仓库，这样管理起来更方便）：之后跳转到这个页面就说明安装成功了： 2、获取 utterances 评论的代码片段并加入到博文模板中我这里就通过勾选官方页面给的选项来生成自己的代码片段吧（就在刚刚成功的页面上）： 刚刚你配置 utterances 可读取写入的仓库名。 Issue 标题的样式，我选的是以博文的路径作为标题，后面也有用博文 Url 和博文标题可选。 评论 Issue 的标签。 当然下面还有主题可选，完成后就能获得自己的代码片段了： 12345678&lt;script src=&quot;https://utteranc.es/client.js&quot; repo=&quot;senjianlu/senjianlu.github.io&quot; issue-term=&quot;pathname&quot; label=&quot;评论&quot; theme=&quot;github-light&quot; crossorigin=&quot;anonymous&quot; async&gt;&lt;/script&gt; 3、写入博文模板各主题博文模板的路径可能不同，我 pure 主题的路径为：\\pure\\layouts\\partials\\article.html有一个专门的评论模板，那么直接去那里面添加即可，添加前：添加后：内容： 123456......{{- else if eq $comment.type &quot;utterances&quot; }}&lt;script src=&quot;{{- $comment.utterances.src }}&quot; repo=&quot;{{- $comment.utterances.repo }}&quot; issue-term=&quot;{{- $comment.utterances.issue_term }}&quot; label=&quot;{{- $comment.utterances.label }}&quot; theme=&quot;{{- $comment.utterances.theme }}&quot; crossorigin=&quot;{{- $comment.utterances.crossorigin }}&quot; async&gt;&lt;/script&gt;...... 我这里将变量都值交给了配置文件去设置，你直接写死当然也是可以的，就是后面修改起来没有那么方便了。 4、在配置文件中设置变量比较简单，在 config.toml（你博客的配置文件而非主题的配置文件）里照着之前 comment 变量依葫芦画瓢即可： 123456789101112131415[params] ... ... [params.comment] disqus = &quot;your_disqus_name&quot; type = &quot;utterances&quot; ... ... [params.comment.utterances] src = &quot;https://utteranc.es/client.js&quot; repo = &quot;senjianlu/senjianlu.github.io&quot; issue_term = &quot;pathname&quot; label = &quot;评论&quot; theme = &quot;github-light&quot; crossorigin = &quot;anonymous&quot; 注意 $comment.type 变量不要忘掉！ 5、本地渲染测试本地启动看下（pure 为我的主题名，请自行替换）： 1hugo server -t pure 选择登录：之后评论便能正常输入了：成功评论：同时 Issues + 1：本地测试通过之后，正式发布理论上也不会有任何问题的，我这里就不演示了。 需要停止评论功能的话，先停用 utterances App：之后修改 config.toml 将 $comment.type 的值改为空即可。 结束。","link":"/2020/05/17/bak_hugo_comment/"},{"title":"【归档文章】申请 Google AdSense 并为 Hugo 静态博客配置 Shortcodes 广告模板页面方便 Markdown 的书写和渲染","text":"关于使用 Hugo 博客配置 Google AdSense 的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 本博客有且只有在该文章末尾添加了测试用的广告。 1、注册 Google AdSense官方链接：Google AdSense填入链接和邮箱：接着使用 Google 账号登录以完成绑定： 2、确认网站所有权和审核在首页，获取用以认证用的代码：注：如果你的 Google 账号没有收款信息，需要先在收款人信息页面做填写，才能看到如下页面。这里提示需要放置在 &lt;head&gt; 和 &lt;/head&gt; 标记之间，那么还是直接去修改主题内的文件，我的路径为：\\themes\\pure\\layouts\\partials\\head.html重新 build 页面并发布后，在页面上确定已经添加代码并开始审核：审核结束后如果看到以下页面说明审核通过了： 3、纠正 ads.txt 文件你可能会出现这样的错误：修正方法官方也给出了：普通的项目直接在网站根目录下添加 ads.txt 文件就行了，但是通过 Hugo 渲染的模板项目 ads.txt 则需要放在静态文件目录下：/static渲染一下，public 的目录下有 ads.txt 就说明成功了： 4、选择合适的广告类型官方给了 3 种广告单元可供选择：我是给博文添加的，理论上信息流和文章内嵌类型的点击率更高：前者和文章或网页内容会有所关联，后者多数情况会以大图形式融入文章中。但是我个人是极度厌恶技术博客内插入广告的，这里只拿普通的展示广告做例子：接着就能拿到代码段了：如果你是给自己网站的前端页面添加广告的话，直接复制到 HTML 页面中的指定位置做调整就行了。 5、为 Hugo 静态博客新建 Shortcodes 广告模板以方便 Markdown 的书写和渲染Hugo Shortcodes 官方介绍：Shortcodes引入 YouTube 视频的官方案例：single-positional-example-youtube如果你只想实现广告或其他差不多的简单功能，直接和我继续操作下去也可以。明确一下，Hugo 模板的查找顺序是： /layouts/shortcodes/.html /themes//layouts/shortcodes/.html 即优先使用主目录下的模板。知道了模板存放路径，那么命名呢？命名也很简单，模板的 .html 文件名字可以自定义，在 Markdown 中书写的时候使用相同的名字就行了，例如我创建了 google-adsense.html 这个模板：那么我在文章的 .md 文件中这样调用，后期 Hugo 就会自动渲染了： 1{{&lt;/* google-adsense */&gt;}} 把刚刚的 Google AdSense 的广告代码复制过来，并将部分值设定为用参数传入， google-adsense.html 的内容就变成了这个样子： 123456789101112&lt;script async src=&quot;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-{{ index .Params 0 }}&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;&lt;!-- 测试广告 --&gt;&lt;ins class=&quot;adsbygoogle&quot; style=&quot;display:block&quot; data-ad-client=&quot;ca-pub-{{ index .Params 0 }}&quot; data-ad-slot=&quot;{{ index .Params 1 }}&quot; data-ad-format=&quot;auto&quot; data-full-width-responsive=&quot;true&quot;&gt;&lt;/ins&gt;&lt;script&gt; (adsbygoogle = window.adsbygoogle || []).push({});&lt;/script&gt; 调用： 1{{&lt;/* google-adsense 7999470995937770 3998950649 */&gt;}} 广告测试样例： 注意：广告生效需要时间，从 1 小时到 24 小时不等，期间你打开页面可能会发现广告处空白并在控制台报错： 1Failed to load resource: the server responded with a status of 400 () 参考讨论：Google adsense responding the server responded with a status of 400 ()，一般情况下耐心等待即可。 结束。","link":"/2021/12/01/bak_hugo_google_adsense/"},{"title":"【归档文章】K3s 学习（一）高可用模式在 CentOS7 服务器上构建第一组 server + agent 节点","text":"关于 K3s 的学习笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 之前是在一台 2H4G 服务器上用 Screen 跑多个项目，明明睡前看都是运行的好好的，早上起来检查却总有 1、2 个被 Kill 掉了，属实心累，正巧腾讯云送了老用户一年 2H4G 的服务器，带上学生机组个集群，后面再把项目都做成 Docker 运行应该就能保证稳定性了。 本次用来构建集群的服务器共有 4 台，另有 1 台用作面板安装。为什么不将面板部署到节点服务器是因为 K3s 安装时默认会安装 Ingress 做负载均衡，它会监听 80 和 443 端口并在 Nginx 之前就处理请求并返回“404 Page not found”，甚是烦人索性抽离出来，同时注意 Rancher 需要最小 2H4G 的配置来允许，不然会频繁 CPU 占用 100% 并出现 503 错误。因为使用了外置数据库的原因，K3s server 节点不再需要安装 3 台（3 台的限制是为了保证内置数据库同步并推举出主节点），但是我还是习惯安装三台。注：服务器间均通过内网建立连接。 开始安装前，我强烈建议您在安全组和防火墙处开放全部端口，K3s 的官方文档都结构混乱，您很难排查端口相关的错误。在后期全部安装完毕后您再进行针对性关闭危险端口也不迟！ 1、准备外部数据库连接我这里使用的外置的 MySQL 数据库，编辑环境变量以添加 server 用的数据库连接： 1vi /etc/profile 1234567...# 在最末尾添加数据库连接# 自行替换数据库连接参数# MySQLexport K3S_DATASTORE_ENDPOINT=&quot;mysql://$username:$password@tcp(127.0.0.1:3306)/$database&quot;# PostgreSQLexport K3S_DATASTORE_ENDPOINT=&quot;postgres://$username:$password@127.0.0.1:5432/$database?sslmode=disable&quot; 12# 使环境变量生效source /etc/profile PostgreSQL 连接不禁用 SSL 连接的话后续安装并启动 K3s 时会报以下错误： 1234567891011121314......-- Unit k3s.service has begun starting up. Sep 27 20:46:52 VM-9-9-centos sh[5029]: + /usr/bin/systemctl is-enabled --quiet nm-cloud-setup.service Sep 27 20:46:52 VM-9-9-centos sh[5029]: Failed to get unit file state for nm-cloud-setup.service: No such file or directory Sep 27 20:46:52 VM-9-9-centos k3s[5036]: time=&quot;2021-09-27T20:46:52.707510605+08:00&quot; level=info msg=&quot;Starting k3s v1.21.4+k3s1 (3e250fdb)&quot; Sep 27 20:46:52 VM-9-9-centos k3s[5036]: time=&quot;2021-09-27T20:46:52.714638844+08:00&quot; level=fatal msg=&quot;starting kubernetes: preparing server: creating storage endpoint: building kine: pq: SSL is not enabled on the server&quot; Sep 27 20:46:52 VM-9-9-centos systemd[1]: k3s.service: main process exited, code=exited, status=1/FAILURE Sep 27 20:46:52 VM-9-9-centos systemd[1]: Failed to start Lightweight Kubernetes. -- Subject: Unit k3s.service has failed -- Defined-By: systemd -- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-deve ...... 2、安装 server 节点在设置好数据库连接环境变量之后开始安装，使用官方提供的脚本：注：这里安装时会自动读取环境中和 K3s 有关的变量，因此不再需要指定数据库连接。 1curl -sfL https://get.k3s.io | INSTALL_K3S_VERSION=v1.20.8+k3s1 sh -s - server 境内服务器使用 cnrancher.com 的源 1curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn INSTALL_K3S_VERSION=v1.20.8+k3s1 sh -s - server安装完后查看节点： 1k3s kubectl get nodes 出现以下信息则说明安装完成。 12NAME STATUS ROLES AGE VERSIONvm-9-9-centos Ready control-plane,master 18m v1.21.4+k3s1 获取以下 node-token 方便之后部署其他节点： 1cat /var/lib/rancher/k3s/server/node-token 1K1082501c0eaxxxxxxxx77059a4fff524xxx589b9::server:1f2d8a3xxxxx7a1e2e4xxx60 副 server 节点的安装不仅需要使用同一个数据库，还需要配置 node-token： 1234# K3s server 用 MySQL 数据库连接export K3S_DATASTORE_ENDPOINT=&quot;mysql://$username:$password@tcp(127.0.0.1:3306)/$database&quot;# 主节点的 Tokenexport K3S_TOKEN=&quot;K1082501c0eaxxxxxxxx77059a4fff524xxx589b9::server:1f2d8a3xxxxx7a1e2e4xxx60&quot; 3、安装 agent 节点仍然是先配置环境变量： 1vi /etc/profile 注意：agent 节点的环境变量中不需要配置数据库的连接信息！ 123456...# 在最末尾添加 server 节点的 node-tokenexport K3S_TOKEN=&quot;K1082501c0eaxxxxxxxx77059a4fff524xxx589b9::server:1f2d8a3xxxxx7a1e2e4xxx60&quot;# server 节点的地址，端口默认为 6443# 必须使用 HTTPS 协议：Only https:// URLs are supported for K3S_URL ip addressexport K3S_URL=&quot;https://10.0.12.0:6443&quot; 12# 使环境变量生效source /etc/profile 使用和 server 一样的脚本进行安装，但是设置了 K3S_URL 这个环境变量，因此默认选择为安装 agent 程序： 12# agent 节点安装curl -sfL https://get.k3s.io | INSTALL_K3S_VERSION=v1.20.8+k3s1 sh - 境内服务器使用 cnrancher.com 的源 1curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn INSTALL_K3S_VERSION=v1.20.8+k3s1 sh -安装完成后理论上会自己启动，这时回 server 节点再检查下总节点个数就能看到新的 agent 节点了： 1234[root@VM-9-9-centos CA]# kubectl get nodesNAME STATUS ROLES AGE VERSIONvm-9-8-centos Ready &lt;none&gt; 3m18s v1.21.4+k3s1vm-9-9-centos Ready control-plane,master 10h v1.21.4+k3s1 4、节点卸载server 节点 1/usr/local/bin/k3s-uninstall.sh agent 节点 1/usr/local/bin/k3s-agent-uninstall.sh 注意：卸载完之后清理残留以防止重装后出现“Unable to connect to the server: x509: certificate signed by unknown authority”的错误，如果出现的话请卸载、清理并重装以尝试解决！ 1rm -rf $HOME/.kube 5、一些可能用的到指令节点状态查看： 1kubectl describe node $hostname 本章结束，下章安装 Rancher Labs 作为管理界面。","link":"/2021/09/27/bak_k3s_note_01/"},{"title":"【归档文章】K3s 学习（二）安装 Rancher Labs（手动安装版本，不推荐）","text":"关于 K3s 的学习笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 第一章安装完一个 server 和一个 agent 节点之后，就相当于拥有了一个迷你的 K3s 集群，现在开始安装管理面板。注意：请参考成功率更高的 Docker 安装 Rancher Labs，该文章已作废！ 谨慎考虑是否参考，能确定的是在 2H4G 轻量服务器下，手动安装会出现很多奇奇怪怪的错误，光我自己安装 3 次一样的步骤就出现 2 次安装结束检查状态出现“error: deployment “rancher” exceeded its progress deadline”的问题，并且日志的排查相当麻烦，尝试前请一定建立云服务器快照以便回滚！ 注意：如果没有在 K3s 安装时修改 Ingress 监听端口，请不要在 server 或 agent 同服务器上安装，会造成 80 和 443 端口上起的服务无法正常访问！ 1、首先安装 Kubernetes 的软件包管理工具 Helm这也是 Rancher 安装官方文档所提示必要的模块，安装步骤参考 Installing Helm： 123456# 下载压缩包wget https://get.helm.sh/helm-v3.7.0-linux-amd64.tar.gz# 解压tar -zxvf helm-v3.7.0-linux-amd64.tar.gz# 二进制文件直接放入环境变量中即可使用mv linux-amd64/helm /usr/local/bin/helm 完成后确定下是否安装成功： 12[root@VM-8-6-centos ~]# helm versionversion.BuildInfo{Version:&quot;v3.7.0&quot;, GitCommit:&quot;eeac83883cb40xxxxxxxxxxxec6373570374ce770b&quot;, GitTreeState:&quot;clean&quot;, GoVersion:&quot;go1.16.x&quot;} 成功的情况添加含有 Rancher Chart 的 Helm Chart 仓库： 1helm repo add rancher-stable https://releases.rancher.com/server-charts/stable 境内服务器使用阿里云的源 1helm repo add rancher-stable http://rancher-mirror.oss-cn-beijing.aliyuncs.com/server-charts/stable 2、为 Rancher 创建 Namespace1kubectl create namespace cattle-system 3、使用自签证书 安装 Rancher 这一步官方给了 3 个选项： Rancher 生成的自签名证书 Let’s Encrypt 使用您自己的证书（可以是自签也可以是腾讯云等免费申请来的或是付费购买的） 我选择了最后一种，自签发 10 年并在本地安装证书以信任，教程在这：CentOS7 下使用 OpenSSL 生成 CA 自签发证书并解决 Windows 下信任证书后 Chrome 出现 ERR_CERT_COMMON_NAME_INVALID 的问题。 先配置环境变量： 1vi /etc/profile 1234......# 指定 Rancher 的安装使用 KUBECONFIG 配置文件防止出现“dial tcp [::1]:8080: connect: connection refused”的错误export KUBECONFIG=/etc/rancher/k3s/k3s.yaml 1source /etc/profile 接着执行安装命令：注意：hostname 选项必须与服务器证书中的 Common Name 或 Subject Alternative Names 条目匹配！ 12345678910111213# 使用 Helm 安装 Rancher# replicas 为 Rancher 部署所使用的复制数量，少于 3 个节点时填写准确节点数# 自签节点 privateCA 变量设置为 truehelm install rancher rancher-stable/rancher \\ --namespace cattle-system \\ --set hostname=rancher.k3s.com \\ --set replicas=3 \\ --set ingress.tls.source=secret \\ --set privateCA=true# 配置 SSL 证书kubectl -n cattle-system create secret tls tls-rancher-ingress \\ --cert=/etc/nginx/ssl/rancher.crt \\ --key=/etc/nginx/ssl/rancher.key 验证是否安装成功： 1234# Rancher 是否成功部署kubectl -n cattle-system rollout status deploy/rancher# Rancher 当前状态kubectl -n cattle-system get deploy rancher 确定完成后用 HTTPS://域名 进行访问。 结束。","link":"/2021/09/28/bak_k3s_note_02_01/"},{"title":"【归档文章】K3s 学习（二）安装 Rancher Labs（Docker 安装，推荐）","text":"关于 K3s 的学习笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 第一章安装完一个 server 和一个 agent 节点之后，就相当于拥有了一个迷你的 K3s 集群，现在开始安装管理面板。 考虑到作为 Docker 容器运行的 Rancher 重启较为安全简单，不再使用自签证书而是使用腾讯云签发的 1 年有效期的亚洲诚信证书。 注意：如果没有在 K3s 安装时修改 Ingress 监听端口，请不要在 server 或 agent 同服务器上安装，会造成 80 和 443 端口上起的服务无法正常访问！ 1、使用 Docker 安装 Rancher Labs执行： 1234567891011121314docker run -d --privileged --restart=unless-stopped \\ # 容器 80、443 端口分别映射宿主机 8080 和 8443 端口 -p 8080:80 -p 8443:443 \\ # 证书 -v /rab/ssl/rancher.k3s.com.pem:/etc/rancher/ssl/cert.pem \\ -v /rab/ssl/rancher.k3s.com.key:/etc/rancher/ssl/key.pem \\ # 数据挂载到宿主机 -v /rab/docker/rancher/rancher:/var/lib/rancher \\ -v /rab/docker/rancher/auditlog:/var/log/auditlog \\ # Rancher 选择为 2.5.x 版本 --privileged \\ rancher/rancher:v2.5.5 \\ # 非自签 SSL 证书 --no-cacerts 查看状态： 1docker stats 12CONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDSe404cfxxx811 7.35% 1.5 GiB / 3.7 GiB 40.54% 192 MB / 3.09 MB 466 MB / 489 MB 21 成功。 2、Nginx 反代（可选）注意：反代不要选择 HTTP 所在端口，Rancher 会自动跳转至 HTTPS 造成无法访问的情况！配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142......# 防止出现“nginx: [emerg] unknown &quot;connection_upgrade&quot; variable”的错误map $http_upgrade $connection_upgrade { default upgrade; '' close;}......server { listen 80; server_name rancher.k3s.com; # 强制跳转 HTTPS location / { return 301 https://$server_name$request_uri; }}server { listen 443 ssl; server_name rancher.k3s.com; # SSL 配置 ssl_certificate /rab/ssl/1_rancher.k3s.com_bundle.crt; ssl_certificate_key /rab/ssl/2_rancher.k3s.com.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; location / { proxy_set_header Host $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-Port $server_port; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass https://127.0.0.1:8443; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; }}...... 3、重启 Nginx 并访问域名 第一次访问会需要配置管理员密码，后续如果忘记请执行以下命令获取新密码： 1docker exec -ti $container_id reset-password 返回结果中会有新的密码 12New password for default admin user (user-xxxxx):$new_password 本章结束。","link":"/2021/09/29/bak_k3s_note_02_02/"},{"title":"【归档文章】K3s 学习（三）Rancher 导入现有 K3s 集群并创建第一个容器应用","text":"关于 K3s 的学习笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 将 server + agent 的集群导入 Docker 安装的 Rancher 中以进行管理。 1、从面板导入现有集群添加集群：导入：输入集群名词后创建：复制命令前往集群执行：我是在节点的主 server 节点执行的，执行完后返回的信息： 123456789clusterrole.rbac.authorization.k8s.io/proxy-clusterrole-kubeapiserver createdclusterrolebinding.rbac.authorization.k8s.io/proxy-role-binding-kubernetes-master creatednamespace/cattle-system createdserviceaccount/cattle createdWarning: rbac.authorization.k8s.io/v1beta1 ClusterRoleBinding is deprecated in v1.17+, unavailable in v1.22+; use rbac.authorization.k8s.io/v1 ClusterRoleBindingclusterrolebinding.rbac.authorization.k8s.io/cattle-admin-binding createdsecret/cattle-credentials-5xxdxx7 createdclusterrole.rbac.authorization.k8s.io/cattle-admin createddeployment.apps/cattle-cluster-agent created 再回到页面上看见正在等待： 在这一步我等了 10 分钟左右还没有导入成功，看了下日志： 1234[root@server-01 ~]# kubectl -n cattle-system logs -l app=cattle-cluster-agent -fINFO: Environment: CATTLE_ADDRESS=10.42.2.3 CATTLE_CA_CHECKSUM= CATTLE_CLUSTER=true CATTLE_FEATURES= CATTLE_INTERNAL_ADDRESS= CATTLE_IS_RKE=false CATTLE_K8S_MANAGED=true CATTLE_NODE_NAME=cattle-cluster-agent-69b856b99c-rp874 CATTLE_SERVER=https://rancher.k3s.comINFO: Using resolv.conf: search cattle-system.svc.cluster.local svc.cluster.local cluster.local nameserver 10.43.0.10 options ndots:5ERROR: https://rancher.k3s.com/ping is not accessible (Could not resolve host: rancher.k3s.com) 似乎是无法访问到域名，但是 curl 试一下： 12[root@server-01 ~]# curl https://rancher.k3s.com/pingpong 又是能访问到的，猜测可能是 DNS 出了问题，回头看下日志有这么一段： 1...nameserver 10.43.0.10... 果然是 DNS 的问题，节点不知道 rancher.k3s.com 指向了哪个 IP，于是开始着手修复。官方关于这个错误的文档：Agent 无法连接 Rancher server在你的主节点执行： 1234567891011121314151617kubectl -n cattle-system patch deployments cattle-cluster-agent --patch '{ &quot;spec&quot;: { &quot;template&quot;: { &quot;spec&quot;: { &quot;hostAliases&quot;: [ { &quot;hostnames&quot;: [ &quot;rancher.k3s.com&quot; ], &quot;ip&quot;: &quot;10.0.8.6&quot; } ] } } }}'再回到 Rancher 页面应该就导入成功了： 2、创建一个容器应用我这里选择了新建一个 Nginx 容器，也正好能测试下外网对容器内服务的访问情况。选择命名空间：部署服务：填写对应的信息，这里的 Docker 镜像会默认从 hub.docker.com 下载，例如我这里填的是 nginx，那么后台会执行 docker pull nginx 这个操作。下拉点击创建后，就可以看见这个服务因为没有容器而更新了：稍等片刻更新完成： 3、容器的访问点进刚刚创建的服务内，因为选择的是创建一个无状态服务，因此会随机在一个节点（服务器）上建立服务，这里看到是 server-02 这个节点：用 server-02 节点的公网 IP 搭配映射的 30080 端口进行访问： 结束。 附加：既然开始碰到内网 DNS 的问题，顺便说一下，一般情况下 K3s 都会在内网建立 DNS 服务器来保证各节点之间的访问，由于是练手我还是准备一步一步来，先手动确保各服务器之间的连接，总体分为两步你也可以参考： 修改 hosts，将域名和 IP 绑定，之前我是用外网做 Rancher 和集群的连接的，趁着这个机会也改到内网连接吧，集群中的每台服务器都执行： 123echo &quot;10.0.8.6 rancher.k3s.com&quot; &gt;&gt; /etc/hosts/etc/init.d/network restartping rancher.k3s.com 确认域名解析到 Rancher 面板所在服务器的内网地址之后此步完成。2. K3s 集群内部是通过 coreDNS 解析的关系，还需要在 coreDNS 中修改域名解析。注意：在 server 主节点修改即可，会自动同步到其他节点。​ 1kubectl edit configmap coredns -n kube-system 在 NodeHosts 中新增解析： 12345678910...... NodeHosts: | 10.0.8.12 server-01 10.0.8.17 server-02 # 此行解析为新增的 10.0.8.6 rancher.k3s.comkind: ConfigMap....... 在其他节点确认修改成功： 1kubectl -n kube-system get configmap coredns -o yaml","link":"/2021/10/01/bak_k3s_note_03/"},{"title":"【归档文章】K3s 学习（四）CentOS7 下挂载腾讯云 COS 为 K3s 集群提供持久化存储 PV","text":"关于 K3s 的学习笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 考虑到之后的项目有日志记录和分析的功能需求，提前准一下用以日志存储的 PV，虽然说挂载到服务器本地路径也可以，但这样的话服务器到期时就会有点麻烦，不如直接使用 COS 做存储，后期只需要切换服务器挂载即可。 简单介绍 PV 和 PVC：需要一一对应，具体使用时的关系可以参考以下图片： 1、安装腾讯云 COSFS 工具官方文档：COSFS 工具我这里选择了 Rancher 所在的服务器进行安装和后续挂载，只是考虑到这个服务器会持续续费。安装依赖： 1yum -y install libxml2-devel libcurl-devel 下载安装包： 1wget https://github.com/tencentyun/cosfs/releases/download/v1.0.19/cosfs-1.0.19-centos7.0.x86_64.rpm 安装： 1rpm -ivh cosfs-1.0.19-centos7.0.x86_64.rpm --force 2、配置密钥等信息并将 COS 作为存储盘挂载服务器上在服务器所在同地域新建存储桶以实现内网访问：获取自己的 API 密钥： 注意：用这个 API 密钥可以访问和操作你账户内的所有资源，包括服务器和 CDN 等，因此如果你对安全性有要求，可以参照以下步骤一来创建只有 COS 操作权限的密钥。​选择用户列表并选择新建用户：选择快速创建之后，输入用户名并修改权限：取消管理员权限并搜索 COS 相关权限：勾选前 9 条 COS 相关操作权限：之后点击创建用户并打开用户详情页面，点击 API 密钥新建即可： 复制密钥并写入配置文件：注：参数自行替换，给配置文件设置 640 权限防止密钥泄露。 12echo $BucketName_APPID:$SecretId:$SecretKey &gt; /etc/passwd-cosfschmod 640 /etc/passwd-cosfs 运行工具以将 COS 存储桶挂载：注：path 为本地路径，Region 参数可以在你的 COS 存储桶页面访问域名处取得。 1cosfs $BucketName_APPID $path -ourl=http://cos.$Region.myqcloud.com -odbglevel=info -oallow_other 测试是否挂载成功： 1vi $path/test.txt 之后保存，然后去存储桶文件列表界面查看：成功。 3、安装并配置挂载文件夹的 NFS 服务给挂载文件夹所在的服务器和所有 K3s 节点服务器安装 NFS（客户端和服务端均需要）： 1yum -y install nfs-utils 开始配置服务端，接下来的步骤只需要在挂载文件夹所在的服务器上做即可，启动服务并设置为开启自启： 1234systemctl start rpcbindsystemctl start nfssystemctl enable rpcbindsystemctl enable nfs 配置共享： 123456# 路径和内网网段自行替换echo &quot;$path 10.0.0.0/22(fsid=0,rw,sync,no_root_squash,no_all_squash)&quot; &gt; /etc/exports# 重新载入配置文件exportfs -r# 重启服务systemctl restart nfs 之后检查一下本地的共享目录： 1showmount -e localhost 无误之后此步结束。 4、Rancher 界面新增 PV 存储注意：因为 PV 和 PVC 是一对一的关系，而容器在选择 PVC 作为存储路径时候可以选择 PVC 下的子目录，即支持 PVC 和容器一对多，因此这里创建一个较大的 PV 给多个中间件容器同时使用（只有同命名空间下的容器才能使用该命名空间下的 PVC）：选择 NFS Share 和多节点读写，路径为你刚刚的挂载路径，IP 则填写内网 IP：保存之后稍等片刻就能看见状态可用：然后去 K3s 的任意 server 节点执行以下命令查看下是否添加 PV 成功： 1kubectl get pv 5、新建 PVC添加 PVC：使用现有的持久卷并选择多主机读写：创建成功。 6、建立容器测试访问选择老朋友 Nginx 容器，数据卷处添加现有的同命名空间的 PVC，把 HTML 文件所在文件夹映射一下：等待状态变为 Active：随便拷贝个网页放入存储桶相应文件夹下：访问下页面： 7、建立容器测试写入编辑下刚刚建立的容器，映射下日志文件夹：之后重启等待状态变为 Active：检查下存储桶内，自动创建 log 文件夹和日志文件： 本章结束。","link":"/2021/10/10/bak_k3s_note_04/"},{"title":"【归档文章】K3s 学习（五）四个月的使用中出现的问题、集群的重装升级和进阶配置","text":"关于 K3s 的学习笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 从 2021 年 10 月初开始将项目迁移到 K3s 集群，掐指一算到现在也四个月了，使用过程中基本是大问题没有、小问题不断……直到早上集群监控失效，搜索发现没有简单解法之后不得不选择重装。 复盘下操作：在一个低配置节点（2H4G 服务器）上部署新的 Docker 容器，本以为和平常一样，但是当发现服务报 Error 的时候实际上已经吃满 CPU 长达 3 到 4 分钟了，之后整个集群的监控就失效了。 使用中出现的问题1、Rancher 页面上显示异常的容器重启次数常见 100+ 重启次数，但是在页面刷新后就正常了。 2、监控 API 未就绪也是我这次碰到的问题，集群监控的失效，导致无法查看各节点资源的实际占用情况，也无法新增对容器的监控。 重装集群 详细教程可以参考我这三篇文章： K3s 学习（一）高可用模式在 CentOS7 服务器上构建第一组 server + agent 节点 K3s 学习（二）安装 Rancher Labs（Docker 安装，推荐） K3s 学习（三）Rancher 导入现有 K3s 集群并创建第一个容器应用 本次留下的命令和步骤仅作笔记用。 1、记录下当前集群中一些重要内容包括：命名空间、服务发现（我基本就当做 DNS 来用）​和PVC（我挂载了腾讯云的 COS）​。 2、重装服务器在云服务器厂商处建立快照，并重新安装操作系统，同时云数据库也做清空。 3、配置 server 服务器设置数据库连接用的环境变量： 12# 修改 profile 文件vi /etc/profile 123456......# MySQL 数据库export K3S_DATASTORE_ENDPOINT=&quot;mysql://$username:$password@tcp(127.0.0.1:3306)/$database&quot;# 主节点的 Tokenexport K3S_TOKEN=&quot;K1082501c0eaxxxxxxxx77059a4fff524xxx589b9::server:1f2d8a3xxxxx7a1e2e4xxx60&quot; 在 server 节点上执行以下命令获取 K3S_TOKEN： 1cat /var/lib/rancher/k3s/server/node-token 12# 使环境变量生效source /etc/profile 安装 server 节点： 1curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh -s - server 4、配置 agent 服务器设置 K3S_TOKEN 和 server 节点的链接环境变量： 12# 修改 profile 文件vi /etc/profile 1234567......# 在最末尾添加 server 节点的 node-tokenexport K3S_TOKEN=&quot;K1082501c0eaxxxxxxxx77059a4fff524xxx589b9::server:1f2d8a3xxxxx7a1e2e4xxx60&quot;# server 主节点的地址，端口默认为 6443# 必须使用 HTTPS 协议：Only https:// URLs are supported for K3S_URL ip addressexport K3S_URL=&quot;https://10.0.12.0:6443&quot; 在 server 节点上执行以下命令获取 K3S_TOKEN： 1cat /var/lib/rancher/k3s/server/node-token 12# 使环境变量生效source /etc/profile 安装 agent 节点： 1curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh - 5、确认集群安装完成1kubectl get nodes 6、安装 Rancher 面板在 Rancher 服务器上运行： 1234567891011docker run -d --name rancher \\ --privileged \\ --restart=unless-stopped \\ -p 8080:80 -p 8443:443 \\ -v /rab/ssl/rancher.k3s.com.pem:/etc/rancher/ssl/cert.pem \\ -v /rab/ssl/rancher.k3s.com.key:/etc/rancher/ssl/key.pem \\ -v /rab/docker/rancher/rancher:/var/lib/rancher \\ -v /rab/docker/rancher/auditlog:/var/log/auditlog \\ --privileged \\ rancher/rancher:v2.6.3 \\ --no-cacerts 在主节点上更新 DNS，以保证能将现有集群添加到 Rancher 中（IP 为 Rancher 服务所在的 IP）： 1234567891011121314151617kubectl -n cattle-system patch deployments cattle-cluster-agent --patch '{ &quot;spec&quot;: { &quot;template&quot;: { &quot;spec&quot;: { &quot;hostAliases&quot;: [ { &quot;hostnames&quot;: [ &quot;rancher.k3s.com&quot; ], &quot;ip&quot;: &quot;10.0.12.1&quot; } ] } } }}' 进阶配置1、针对 Docker 容器吃满资源的情况做限制在创建命名空间的时候设置即可，这样该空间下的所有容器都会被限制（1000 mCPUs 代表 1 核）： 更多的待添加…… 暂时结束。","link":"/2022/02/10/bak_k3s_note_05/"},{"title":"【归档文章】KVM 虚拟化的服务器建立 SWaP 分区以增加虚拟内存","text":"关于使用 SWaP 增加虚拟内存的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 1. 关于 SWaP 虚拟内存分区1.1 什么是 SWaP它可以是一个分区，也可以是一个文件，是操作系统中一个存放从内存中置换（swap 动作）出的数据的地方，也就是所谓的虚拟内存。 1.2 为什么需要 SWaP 解决服务器上系统资源占用峰值程序崩溃的问题：当物理内存不够用时候，会根据特定的算法，把一部分内存交换到 SWaP 分区。 保证服务器在即将到来的大内存请求时有足够的剩余资源：kswapd 进程会周期性地对内存进行检查，如果发现占用高于水位线，则触发 swap（动作），以保证系统剩余的内存不会很少。 1.3 什么场景下需要 SWaP 系统资源占用峰值时会占满 100% 的内存且持续时间并不长。 对服务器上的软件、服务运行稳定性有要求。 磁盘足够的任何情况下，有什么理由不添加虚拟内存呢？ 1.4 对于 SWaP 分区该设置多大的建议 Red Hat 官方文档：Chapter 15. Swap Space 服务器内存大小 建议的 SWaP 分区大小 ≤ 2 GB 2 倍内存大小 &gt; 2 GB 且 ≤ 8 GB 1 倍内存大小 &gt; 8 GB 且 ≤ 64 GB 至少 4 GB &gt; 64 GB 至少 4 GB 1.5 通过 OpenVZ 虚拟化出来的服务器不可以添加虚拟内存在其他网站上流传的所谓 OpenVZ 虚拟 VPS 下增加 SWaP 分区的脚本，不过也只是欺骗 free 工具使其显示错误的数据罢了： 123456# !/bin/bash# 网传的自我安慰脚本SWAP=&quot;${1:-512}&quot;NEW=&quot;$[SWAP*1024]&quot;; TEMP=&quot;${NEW//?/ }&quot;; OLD=&quot;${TEMP:1}0&quot;umount /proc/meminfo 2&gt; /dev/nullsed &quot;/^Swap\\(Total\\|Free\\):/s,$OLD,$NEW,&quot; /proc/meminfo &gt; /etc/fake_meminfo 可以从两个方面得到验证： 执行脚本后磁盘可用空间并没有减少，这和 SWaP 的工作原理不符。 压测时系统 SWaP 空间占用始终为零。 2. 创建并配置 SWaP 分区确定当前无 SWaP 分区，如果有的话清理一下： 1234567# 一般情况下 SWaP 分区操作都在服务器根目录下执行cd /free -m# 查看 SWaP 分区文件目录swapon --show# swapfile 为之前的分区文件名swapoff /swapfile 然后创建新的 SWaP 分区： 12345678# 创建分区文件，新的分区文件名为 swapfile，count 的单位为 kbsudo dd if=/dev/zero of=/swapfile bs=1k count=2048000# 建立 SWaPmkswap /swapfile# 启动 SWaPswapon /swapfile# 查看虚拟内存是否创建成功free -m 设置 SWaP 分区开机自动挂载，只需要修改 /etc/fstab 文件，在最后添加一行内容即可： 12sudo chmod 777 /etc/fstabsed -i '$a /swapfile swap swap defaults 0 0' /etc/fstab 你可以对磁盘测下速，测出来的 IO 也就是你虚拟内存的带宽： 1time dd if=/dev/zero of=/test.disk bs=8k count=30000 而实际的内存带宽测速结果： 1234567# 下载和编辑 mbw 测试软件git clone http://github.com/raas/mbwcd mbwyum -y install gccmake# 测试./mbw -q -n 10 256 即使是这种超售严重、内存带宽打折扣的廉价 VPS 两者速度都差了 10 倍。 3. 后记在我这里添加 SWaP 分区只是作为不让程序因为内存不足而崩溃的一种兜底手段，如果监控上显示 SWaP 分区长时间被占用，绝大多是情况下我会去主动降低这台服务器的负载或是去升级配置，系统的稳定远比坚守原配置带来的节约值钱得多。","link":"/2023/01/23/bak_kvm_add_memory_by_swap/"},{"title":"【归档文章】PVE 下 LEDE + 爱快 双软路由部署（废弃）","text":"关于部署 LEDE + 爱快双软路的教程。此教程由于初版结构混乱，已废弃，请参考新版（更新于 2021-10-24）：PVE 下 OpenWrt 纯净系统 + 爱快双软路由部署配置文件的整理 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 起因仅仅是不满足现在的科学上网速度，于是就花了点时间研究了下软路由，当然性能够的路由器是可以直接安装 LEDE 的，但是手头正好闲下来一块亮机的 200ge，索性就再组台小机器来当软路由吧。不过我不推荐 200ge 作为软路由的cpu，不仅功耗大，而且只有2个核心，LEDE 和爱快各占用一个以后就不能再安装群晖或是其他虚拟机，容易造成性能浪费的情况。 环境：ProXmoX VE需要时间：3小时左右原教程：【悟空5kong】PVE下部署 LEDE+黑群晖 NAS 双系统（J1900 软路由）上集- PVE (Proxmox VE) 安装双软路由 爱快+LEDE 保姆级教程下集- PVE (Proxmox VE) 安装双软路由 爱快+LEDE 保姆级教程 配置单和价格 所需的软件及下载地址所有文件 (Google Drive)：PVE 下 LEDE+爱快 双软路由部署 所需文件 从这里正式开始操作系统的安装和配置过程。​注意：除了软路由本机，你还需要一台自己的电脑包括显示器鼠标和键盘。同时如果你是拨号上网，你还需要知道自己的运营商账号密码！注：操作系统及软路由的安装都较为简单，繁琐的主要是配置的过程，涉及到网卡上网口的切换以及同步 DNS 和网关的修改，推荐在看博文之前首先过一遍视频教程，PVE 和 LEDE 的安装参照悟空，而爱快和 LEDE 的网口映射参照 Video Talk。 1、安装 PVE 系统首先安装 PVE 系统，安装过程类似于 Windows 操作系统：下载 .iso 文件拷贝进 U 盘，然后开机过程中按 Del 键进入 BIOS，选择 U 盘启动来进行安装。 Management Interface（网卡）：选默认的第一个，之后也做PVE的管理网口 Hostname（域名）：可以瞎填 IP Address：10.10.10.254 以后通过这个IP访问PVE系统，需要和网关同一网段 Netmask（子网掩码）：255.255.255.0 即可，基本默认都是这个 Getway（网关）：10.10.10.253 爱快的后台地址 DNS Server：10.10.10.253 和网关设置一样的即可如果不想麻烦推荐和图片一样设置，后续配置可以照抄。 重启过程中拔下u盘，重启后出现以下界面即说明PVE操作系统已经安装完成。 2、连接网线等在 PVE 系统安装完成后，需要将电脑连接到软路由进行接下来的操作，网线的连接比较简单：一头连接正在使用的电脑，另一头连接刚刚配置的 PVE 连接网口，一般情况下是主板的网口，如果配置的是网卡上的网口，那么离 PCIe 连接口最远的一般就是一号网口。物理连接完成后，还需要配置本机的 IP 和网关等才能进入 PVE 后台。 IP 地址：保证和 PVE 虚拟机的 IP 在同一网段 子网掩码：默认的 255.255.255.0 默认网关：和 PVE 的相同 DNS：不配置自动获取即可 打开浏览器，输入 PVE 安装完成后显示的地址，注意是 https://10.10.10.254:8006/ 前缀和端口号不要忘记。注：可能有安全提示，直接跳过即可。 用户名：root 密码：PVE 安装时设置的密码 语言：默认英文，选择为中文 进入系统的网口选项下，可以看见有一个桥接网口已经建立，端口从属显示与 enp1so 对应，就是第一个网口，意味着第一个网口就被占用了。接下来打开所有物理网口的自动启动。为其他所有的空余网口建立虚拟网口为桥接做准备。建立的过程很简单，记住上面物理网口的名称，创建一个虚拟网口，只需要再桥接端口填入物理网卡名称即可。所有的网口都同样操作即可。一一对应检查完后网口就配置完成了。 3、创建虚拟机原理和 Windows 上使用 VMware Workstation Player 等创建虚拟机一样。首先来创建 LEDE 对应的虚拟机，这一部分参考悟空的视频教程更加简单。点击创建虚拟机按钮。第一步没有需要特殊配置的。选择不使用任何介质，这里的安装方法是 SSH 连接至 PVE 后直接命令行安装，然后将这个虚拟机挂载在安装完成的文件夹上，更加快捷。硬盘不需要任何操作，反正等下不用这个盘。CPU 核心一核就够了。内存推荐 2G。桥接网口选择管理口即可，模型推荐 E1000，Video Talk 之后爱快等都会用E100进行配置。检查无误点击完成即可。接着进行添加网卡的操作，为所有虚拟网口在这台虚拟机中配置桥接。接着在本机上下载安装 MobaXterm，准备连接 PVE 系统。打开新建一个连接，截图是编辑但也啥差别。输入密码，点击 Yes 连接成功。拖拽虚拟机安装文件和转换工具进软路由系统中。接下来 1ls 确保文件转移成功，接着为 img2kvm 添加可执行权限，并开始执行 .img 文件的转换 12chmod +x img2kvm./img2kvm lede.img 101 vm-101-disk-1 101 是虚拟机的序号接下来回到浏览器的PVE后台界面，可以看到多出来一个未使用的磁盘，这就是刚刚转换完的，无视后缀是 disk-1 还是 disk-2 ，双击，选择添加即可。接着选择 “选项”，“引导顺序” 更改为刚刚挂载上的新硬盘即可。注意：接下来直接重启软路由，断电重启也可以！然后回来点击虚拟机，可能 LEDE 显示会没有反应，点击随意按一个键就可以了。至此，最有可能出错的 LEDE 安装完成，配置的事等到爱快配置完后进行。​如果你是光纤，不需要拨号，那可以跳过接下来的爱快的安装与配置。 4、安装爱快软路由一样新建虚拟机，此界面的名称可以自由更改，其他保持默认即可。存储不用改，.iso 介质选刚刚上传的 iKuai 就可以了，类型 Linux 版本也不用变。硬盘 2G 就够了，配置如图。CPU 配置也是一核就够了。内存的设置要注意，新版本爱快最低 4G 内存，如果你的内存不够，需要选择较低版本。网络的配置和 LEDE 一样，管理口对应的虚拟网口和 E1000。核对后直接完成即可。创建完成后，去虚拟机的硬件管理界面，当前只有一个默认网口，也是当时配置的PVE的管理网口，同时它也是只是一个 LAN 口，LAN 口通俗来讲就是出网的口，而 WAN 口是进网的口，爱快的作用是拨号，因此我们需要新建一个 WAN 口：选择添加网络设备。选择最后一个端口，物理上就是离 PCIe 连接口最近的网口。接着启动虚拟机即可。爱快的安装还没有结束，进入虚拟机页面，还需要选择安装，如图输入，等待安装完成后的自动重启。如果重启后没有画面或是端口显示断开，按下回车刷新就行了。进入系统后，设置 LAN 口 IP：10.10.10.253接着在浏览器地址栏输入 10.10.10.253 便可进去 iKuai 的后台了，账号密码均为 admin登录后会提示修改管理员密码，改不改都无所谓登录进去以后可以看到我们预先配置的两个网口，LAN 口是绿色的说明正在被正常使用，这个口就是我们设置的 PVE 管理口兼 LAN 口，而 WAN 口还是灰色的，需要我们点进去绑定以下刚刚新建的网卡。注意：此时将家庭数据中心拉出来的网线接到设置的 WAN 口对应的物理网口上！准备进行拨号上网！填入运营商账号密码，然后拨号。这边显示已连接说明爱快已经拨号上网成功了。接下来配置 DHCP 服务端，选择 DHCP 设置 DHCP 服务端，进行填写。注：DHCP 协议的功能为集中的管理、分配 IP 地址。 客户端地址：覆盖网段内的所有 IP 即可。 子网掩码：默认的 255.255.255.0 网关：10.10.10.252 就是 LEDE 的后台地址 DNS：如果以科学上网为主选 8.8.8.8 不然就用网络所属运营商的 保存后刷新页面，确认服务正常，爱快软路由的配置就全部完成了。总之，爱快主要负责拨号上网和提供 DHCP 服务，在配置完成之后，可以先验证下本机是否有网络在进行下一步操作。​ 5、配置 LEDE 软路由首先回到 LEDE 的系统界面，输入以下命令去更改 LEDE 的 IP 地址。 1vi /etc/config/network 方向键控制光标找到这一行，按以下 “i” 键进入编辑模式，更改成 10.10.10.252 就是你想要的 LEDE 的后台 IP 地址。编辑完成后，按下 “Esc” 键，左下角有冒号出来后，输入 “wq” 保存并退出。之后输入 1reboot 重启 LEDE 软路由。​接着就可以在本机的浏览器上输入 10.10.10.252 进入 LEDE 软路由的后台了，默认密码是 koolshare进入后台后首先来配置网口。选择 LAN 口这一行，点击 编辑。首先在物理设置部分将所有的网口都勾选上，因为有爱快的情况下 LEDE 不需要 WAN 口。然后回到基本设置，如图设置。 IP：LEDE 后台地址 10.10.10.252 网关：爱快的后台地址 10.10.10.253 DNS 服务器：和刚刚一样填写即可 接着下滑，到 DHCP 服务器部分，因为 LEDE 是作为爱快下的二级路由存在的，我希望所有的 DHCP 服务都由 LEDE 来提供而不是不具有科学上网功能的爱快来提供，因此要去掉 忽略此接口 的勾选。然后还要去高级设置中，再把 强制 的勾勾上。接着保存即可。​由于 LEDE 用不到 WAN 口，所以将 WAN 口和 WAN6 的接口绑定到空的接口上就可以了。至此 LEDE 的安装和配置就全部完成了，修改以下本机的网络设置，将 IP 和 DNS 都勾选至自动获取，看看能不能上网吧！ 6、科学上网确保可以上网后，我们回到 LEDE 的后台，准备进行科学上网等的配置操作。点击左侧菜单中的 酷软中心，进入的时候如果提示更新，千万不要去更新，新版本会有大量的软件无法使用。一般情况下，即使你不更新进入酷软中心，也无法再在商城找到科学上网的工具，在 19 年 6 月份的更新中，酷软就将这几个插件删去了。你可以选择去下载网友提供的包离线安装，但很大几率上是不兼容新版本系统的，这里推荐使用酷软的系统备份还原，直接将系统回复至有插件的版本。选择 系统 备份/升级选择我上面提供的老版本，再点击上传备份。上传之后系统会自动重启。等待重启完成后，再进入酷软中心就可以看到消失的科学上网插件了！节点的配置就不再阐述了，SSR 和 SS 订阅的稳定性在我实际用下来后觉得并不好，不如只在电脑端开启相应代理，而 V2Ray 则比较稳定，基本全天 24 小时节点都不会出现断连情况。 推荐2家供应商：忍者云 有线路提供 V2Ray 代理，稳定奇幻之旅 便宜实在 至此，PVE 下 LEDE+爱快 双软路由的部署就全部完成了，好好享受世界吧！","link":"/2020/01/13/bak_lede_ikuai_bak/"},{"title":"【归档文章】Linux 命令（1）系统硬件、网络相关 | SSH 连接、文件相关 | 防火墙端口开启关闭","text":"关于 Shadowsocks 协议节点的搭建教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 Linux 命令笔记，方便查找。 系统硬件1、内存 SWaP 查看1free -m 2、系统内核查看1uname -a 3、SELinux 关闭12# 临时关闭setenforce 0 修改 /etc/selinux/config 文件： 12# 永久关闭vi /etc/selinux/config 将 SELINUX=enforcing 修改为 SELINUX=disabled： 12# SELINUX=enforcingSELINUX=disabled SSH 连接、文件相关1、跨服务器文件传输1scp $file user@host:$file_to 防火墙端口开启关闭1、Firewalld 防火墙相关1234567891011# 查看当前开放的所有端口firewall-cmd --list-all# $port 为你需要开放的端口firewall-cmd --add-port=$port/tcp --permanent # $port 为你需要关闭的端口firewall-cmd --zone=public --remove-port=$port/tcp --permanent# 加载防火墙配置firewall-cmd --reload# 彻底关闭systemctl stop firewalld.servicesystemctl disable firewalld.service 2、Iptables 防火墙相关1234567891011# 查看当前防火墙规则iptables -L -n# 开放端口iptables -A INPUT -p tcp --dport $port -j ACCEPTiptables -A OUTPUT -p tcp --dport $port -j ACCEPT# 存储防火墙配置service iptables save# 彻底关闭systemctl stop iptables.servicesystemctl disable iptables.servicechkconfig iptables off 代理相关1、设置临时代理（只在当前终端中生效，SSH 断开后失效）1234# HTTP 代理export http_proxy=http://$username:$password@$host:$port# SOCKS5 代理export http_proxy=socks5://$username:$password@$host:$port 2、为 Git 设置代理（git clone 等操作会使用该代理）123456789# 设置 SOCKS5 代理git config --global http.proxy socks5://$username:$password@$host:$portgit config --global https.proxy socks5://$username:$password@$host:$port# 查看代理git config --global --get http.proxygit config --global --get https.proxy# 取消代理git config --global --unset http.proxygit config --global --unset https.proxy","link":"/2021/07/20/bak_linux_command_01/"},{"title":"【归档文章】Mac 下 pip3 install psycopg2 出现的错误和解决","text":"关于解决 pip3 install psycopg2 时错误的笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 Mac 上配置开发环境时遇到的问题，留个记录。 1、Error: pg_config executable not found 具体错误为： 1234567891011121314......Error: pg_config executable not found.Please add the directory containing pg_config to the PATHor specify the full executable path with the option: python setup.py build_ext --pg-config /path/to/pg_config build ...or with the pg_config option in 'setup.cfg'.Complete output from command python setup.py egg_info:running egg_info...... 解决方法较为简单，安装下 PostgreSQL 或者 PostgreSQL 的开发环境即可： 1brew install postgresql 没有 brew 的先安装： 1/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot; brew 在 GitHub 上的项目仓库：Homebrew/brew 之后记得重新开一个终端以加载新的环境变量！ 2、error: command ‘clang’ failed with exit status 1 具体错误为： 1234567......ld: library not found for -lsslclang: error: linker command failed with exit code 1 (use -v to see invocation)error: command '/usr/bin/clang' failed with exit status 1......解决方法是安装 openssl@3： 12# 安装 openssl@3brew reinstall openssl 如果你之前用其他工具安装过的话，只需要将其目录添加至环境变量中即可： 12export LDFLAGS=&quot;-L/opt/homebrew/opt/openssl@3/lib&quot;export CPPFLAGS=&quot;-I/opt/homebrew/opt/openssl@3/include&quot; 具体参照这篇讨论：Can’t install psycopg2 package through pip install on MacOS 同样之后你需要重新打开一个终端。​ 结束。","link":"/2022/01/22/bak_mac_pip3_install_psycopg2_error/"},{"title":"【归档文章】MongoDB 学习笔记（一） CentOS7 下安装 MongoDB","text":"关于 MongoDB 数据库的学习笔记 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 在和舍友交流之后才发现拿 JSONB 存储历史价格信息的我可能是个天才吧……回去检查了一下 PostgreSQL 中的对应字段，果然达到了 65535 字节的最大限制，赶紧着手迁移数据。 选 MongoDB 最主要的原因是它的一个集合（与 PostgreSQL 中的表同概念）可以被当作一个队列，无限制的插入 JSON 格式的数据，放下图方便理解：这对存储未知长度的历史价格数据真的很友好，并且根据日期建立索引后，查询的速度也会很快。 话不多说开始安装，官方文档：Install MongoDB Community Edition on Red Hat or CentOS 1、配置 repo 仓库为 Yum 安装提供源创建 mongodb-org-5.0.repo： 1vi /etc/yum.repos.d/mongodb-org-5.0.repo 内容： 123456[mongodb-org-5.0]name=MongoDB Repositorybaseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/5.0/x86_64/gpgcheck=1enabled=1gpgkey=https://www.mongodb.org/static/pgp/server-5.0.asc 2、使用 Yum 进行安装执行： 1sudo yum install -y mongodb-org 安装完成会输出如下信息： 你也可以使用以下命令验证是否安装成功： 12rpm -qa |grep mongodbrpm -ql mongodb-org-server 3、启动 MongoDB启动： 1systemctl start mongod.service 看下数据库进程是否启动成功了： 1ps -ef|grep mongod 4、配置管理员密码进入数据库中： 12# 进入数据库中mongo 修改 root 用户的密码： 12345# 切换到 admin 数据库中&gt; use adminswitched to db admin&gt; db.createUser({user:&quot;root&quot;, pwd:&quot;mypassword&quot;, roles:[&quot;root&quot;] })Successfully added user: { &quot;user&quot; : &quot;root&quot;, &quot;roles&quot; : [ &quot;root&quot; ] } 编辑 mongodb.conf 使登录需要验证身份： 1vi /etc/mongod.conf 修改如下内容： 12345678......# 解除注释security: # 新增这一行 authorization: &quot;enabled&quot; # disable or enabled...... 重启下数据库： 1sudo service mongod restart 如果你想验证是否已经开启了密码验证，首先 mongo 进入数据库，接着： 12345678910111213141516171819202122232425# 切换到 admin 数据库&gt; use adminswitched to db admin# 新建 test_collection 集合&gt; db.createCollection(&quot;test_collection&quot;)# 因为没有认证所以失败{ &quot;ok&quot; : 0, &quot;errmsg&quot; : &quot;command create requires authentication&quot;, &quot;code&quot; : 13, &quot;codeName&quot; : &quot;Unauthorized&quot;}# 登录&gt; db.auth(&quot;root&quot;, &quot;mypassword&quot;)1&gt; db.createCollection(&quot;test_collection&quot;)# 这次创建 test_collection 集合就成功了{ &quot;ok&quot; : 1 }关于 MongoDB 详细的权限管理可以参考我的这篇文章：[MongoDB 学习笔记（四） MongoDB 权限管理及实践](https://senjianlu.com/2021/11/21/bak_mongodb_note_04/)#### 5、配置远程访问编辑配置文件：```bashvi /etc/mongod.conf默认 bindIp 为 127.0.0.1，即只允许本地连接，修改为 0.0.0.0 即可： 12345678......# network interfacesnet: port: 27017 bindIp: 0.0.0.0 # Enter 0.0.0.0,:: to bind to all IPv4 and IPv6 addresses or, alternatively, use the net.bindIpAll setting....... 之后重启数据库： 1sudo service mongod restart 别忘了开发防火墙和云服务器厂商安全组。 远程连接方法： 1mongo $mongodb_host:27017/$database -u $username -p $password 本章结束。","link":"/2021/11/16/bak_mongodb_note_01/"},{"title":"【归档文章】MongoDB 学习笔记（二） MongoDB 层级关系的梳理和基础操作","text":"关于 MongoDB 数据库的学习笔记 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 第一次接触 MongoDB 这种非关系型数据库的表结构设计。 MongoDB 的层级名词翻译过来会有点难理解，所以我将它和 PostgreSQL 数据库的对应起来： PostgreSQL MongoDB Database（数据库） Database（数据库） Table（表） Collection（集合） Tuple/Row（行） Document（文档） Column（列） Field（字段） 参考文章：MongoDB 的文档、集合、数据库 一、Database 数据库多个文档构成集合，多个集合组成数据库。一个 MongoDB 实例可以承载多个数据库，每个数据库可以拥有 0 到多个集合。官方文档：Databases 1、说明 每个数据库有相应的数据文件和命名空间文件。文件的前缀是数据库的名称，后缀 .ns 表示命名空间文件，后缀以 0、1 等数字结尾的，表示数据文件。 数据文件的大小从 64MB 开始，新的数据文件大小是上一个文件的 2 倍。所以能看到，下图中 chen.0 的大小是 64MB，chen.1 的大小是 128MB，chen.2 的是 256MB。 文件使用MAP进行内存映射，会将所有的数据文件映射到内存中，但是只是虚拟内存，只有访问到这块数据时才会交换到物理内存中。 每个数据文件会被分成一个一个的数据块，块与块之间用双向链表链接。 在命名空间文件中，保存了每个命名空间的存储信息元数据，包括其大小、块数、第一块的位置、最后一块的位置、被删除的块的链表以及索引信息。 2、常用命令① 查看所有数据库： 1show dbs ② 查看当前数据库： 1db ③ 切换到指定数据库：注：当数据库不存在的时候，不会立刻创建数据库的数据文件和命名空间文件，只有在第一次向数据库中插入一个文件的时候才去创建对应的数据库。在这一点上，集合也有类似的特性。 1use $database_name ④ 删除当前在使用的这个数据库：注：在删除当前使用的数据库之后，db 任然指向被删除的那个数据库名称，可以通过 use 切换；如果不切换就做数据插入操作，会重新建立相同名字的一个数据库，但是已经不是原来的数据库了，尽管有相同的名称，也有可能有相同的集合和文档。 1db.dropDatabase() 3、其他系统保留数据库： admin：root 数据库 local：这个数据库中的数据永远不会被复制，可以用于存储限于本地数据单台服务器的任意集合 config：分片时，config 数据库在内部使用，保存分片信息 二、Collection（集合）集合是一组文档的集，结构层级相当于关系型数据库中的数据表。官方文档：Collections 1、说明和关系型数据库的表不同，集合内的文档结构可以各不相同，只要是 JOSN 格式即可。例如： 12{&quot;title&quot;: &quot;hello!&quot;}{&quot;recommend&quot;: 5} 这两个文档是可以存放在同一个集合中的，但最好还是确保同集合内文档的格式统一。 2、常用命令① 查看当时数据库下所有集合： 1show collections ② 创建集合： 1db.createCollection(&quot;$collection_name&quot;) 带参数创建：注：参数意为创建固定集合 test_collection_02，整个集合空间大小 6142800B, 文档最大个数为 10000 个。 1db.createCollection(&quot;test_collection_02&quot;, {capped: true, autoIndexId: true, size: 6142800, max: 10000 } ) 但在实际操作中，你并不需要特意的去创建，如果你插入一些文档时指定集合不存在，MongoDB 会自动为你创建： 1db.test_collection_03.insert({&quot;name&quot;: &quot;自动创建集合测试&quot;}) 检查一下： ③ 删除集合： 1db.$collection_name.drop() ④ 更多指令： 1db.$collection_name.help() 注：下图中截取了一小部分。 三、Document（文档）文档是 MongoDB 的核心概念，也是数据的基本单元，非常类似于关系数据库中的行。在 MongoDB 中，文档表示为键值对的一个有序集。举一些例子： 123{&quot;title&quot;: &quot;hello!&quot;}{&quot;title&quot;: &quot;hello!&quot;, &quot;recommend&quot;: 5}{&quot;title&quot;: &quot;hello!&quot;, &quot;recommend&quot;: 5, &quot;author&quot;: {&quot;firstname&quot;: &quot;paul&quot;, &quot;lastname&quot;: &quot;frank&quot;}} 从上面的例子可以看到，文档的值有不同的数据类型，甚至可以是一个完整的内嵌文档（最后一个示例的 author 值是一个完整的文档，文档里面定义了 firstname 和 lastname 。当然还可以包含更多其他信息甚至于在内嵌文档中还可以有内嵌文档）。 1、说明 文档区分大小写和数据类型，所以以下两组文档是不同的： 123456// 值类型不同{&quot;recommend&quot;: &quot;5&quot;}{&quot;recommend&quot;: 5}// 键大小写区分{&quot;Recommend&quot;: &quot;5&quot;}{&quot;recommend&quot;: &quot;5&quot;} MongoDB 的文档中的键值对是有序的，因此下面的文档是不同的： 12{&quot;title1&quot;: &quot;hello!&quot;, &quot;title2&quot;: &quot;Mongo&quot;}{&quot;title2&quot;: &quot;Mongo&quot;, &quot;title1&quot;: &quot;hello!&quot;} MongoDB 的文档中不能有重复的键，因此下面的文档是非法的： 1{&quot;title&quot;:&quot;hello!&quot;,&quot;title&quot;:&quot;Mongo&quot;} 2、常用命令① 查看集合内的所有文档： 123456# 搜索一个文档，在我的测试中返回的是最先插入的文档db.$collection_name.findOne().pretty()# 不带搜索条件以查询整个集合所有的文档，.pretty() 作用为格式化输出db.$collection_name.find().pretty()# 带搜索条件db.$collection_name.find($query, $projection) 参数 说明 示例 query 【选填】使用查询操作符指定查询条件 {“recommend”: {$lt: 50}} projection 【选填】使用投影操作符指定返回的键，不填则返回符合搜索条件的文档的所有键值对 查询方法在后面会展开来讲，现在先放菜鸟的教程链接供参考：MongoDB 查询文档 ② 向集合中插入文档： 1db.$collection_name.insert($document_value) ③ 删除文档： 1234# 删除集合中的所有文档db.$collection_name.remove()# 删除满足要求的文档（2.6 及以后的版本适用）db.$collection_name.remove($query, {justOne: $justOne_value, writeConcern: $writeConcern_value}) 参数 说明 示例 justOne 【选填】如果设为 true 或 1，则只删除一个文档；如果不设置该参数，或使用默认值 false，则删除所有匹配条件的文档 true writeConcern 【选填】抛出异常的级别 ④ 更新文档： 1db.$collection_name.update($query, $update, {upsert: $upsert_value, multi: $multi_value, writeConcern: $writeConcern_value}) 参数 说明 示例 update 【必填】update 的对象和一些更新的操作符，如 $, $inc 等，也可以理解为 sql update 查询内 set 后面的操作 {$set: {“title”: “MongoDB”}} upsert 【选填】如果不存在满足搜索条件的记录，是否将 update 的文档作为新文档插入。默认是 false 即不插入，true 则为插入 true multi 【选填】 是否更新多条记录。默认是 false，只更新找到的第一条记录；如果这个参数为 true，就把按条件查出来的所有记录全部更新 true 本章结束。","link":"/2021/11/20/bak_mongodb_note_02/"},{"title":"【归档文章】MongoDB 学习笔记（三） MongoDB 数据库远程连接 GUI 工具 MongoDB Compass 的使用","text":"关于 MongoDB 数据库的学习笔记 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 本来是准备买 Navicat 的，但是不巧错过了永久版 7 折的优惠……意外发现 MongoDB 官方居然也有可视化工具：MongoDB Compass，社区版是免费的，尝试一下并留个笔记。 1、下载和安装 MongoDB Compass下载地址：Download MongoDB Compass选择全功能版本、然后选择自己的操作系统：下载完后是个可执行的 .exe 文件，转移到你需要的路径后直接打开，会在桌面创建快捷方式：看情况勾选隐私选项： 各选择内容：✅ 启用产品反馈工具启用一个工具，用于直接从 Compass 发送反馈或与我们的产品和开发团队交谈。🔲 启用地理可视化允许 Compass 向第 3 方地图服务发出请求。✅ 启用崩溃报告允许 Compass 发送包含堆栈跟踪和未处理异常的崩溃报告。🔲 启用使用统计允许 Compass 发送匿名使用统计信息。✅启用自动更新允许 Compass 定期检查新的更新。 2、连接远程数据库官方给了一键连接形式：但是由于我在服务器端设定了只允许来自 localhost 的连接，因此需要建立 SSH 隧道连接到服务器、再连接服务器本地的 MongoDB 数据库，如果你和我的配置一样，那么可以参照我以下的连接方式。先选择 Fill in connection fields individually：数据库连接信息按照自己的填，我开启了强制认证，因此需要填写用户和密码：比较重要的是连接服务器这里，也是按自己的配置填写，我用的私钥登录：点击 Connect 连接后就能看见你的数据库信息了： 如果出现以下错误信息： 1An error occurred while loading navigation: command hostInfo requires authentication 那么说明你已经开启了数据库的强制认证，登录的话需要填写正确的账号密码，实在忘记的话就尝试去找回吧。 3、基础操作操作很简单，应该稍微介绍一下就行了。① 左上角 Local 退回到数据库选择页面，右侧的 Database 面板可以选择新建数据库或是进入数据库：② 进入数据库后可以选择新建集合或是进入集合： 部分情况下你可能会发现数据库内的集合对不上，那么请刷新一下，这也是我使用时常出现的 BUG： ③ 进入集合就可以对文档做增删改查了：④ Performance 面板可以查看数据库的运行状态，包括内存占用等信息，用来监视 MongoDB 这种吃内存的怪物还是蛮方便的： MongoDB 暂时只是用来存下历史价格数据，等后期真正使用数据时再做探索。本章结束。","link":"/2021/12/11/bak_mongodb_note_03/"},{"title":"【归档文章】MongoDB 学习笔记（四） MongoDB 权限管理及实践","text":"关于 MongoDB 数据库的学习笔记 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 注意：默认的 root 用户只在 admin 数据库中有效，如果你需要在其他数据库使用该用户仍需要自己创建： 1db.createUser({user:&quot;admin&quot;, pwd:&quot;123456&quot;, roles:[&quot;readWrite&quot;, &quot;dbAdmin&quot;] }) 用户权限角色说明 角色 说明 root 只在 admin 数据库中可用。超级账号，超级权限 Read 允许用户读取指定数据库 readWrite 允许用户读写指定数据库 dbAdmin 允许用户在指定数据库中执行管理函数，如索引创建、删除，查看统计或访问 system.profile userAdmin 允许用户向 system.users 集合写入，可以找指定数据库里创建、删除和管理用户 clusterAdmin 只在 admin 数据库中可用，赋予用户所有分片和复制集相关函数的管理权限 readAnyDatabase 只在 admin 数据库中可用，赋予用户所有数据库的读权限 readWriteAnyDatabase 只在 admin 数据库中可用，赋予用户所有数据库的读写权限 userAdminAnyDatabase 只在 admin 数据库中可用，赋予用户所有数据库的 userAdmin 权限 dbAdminAnyDatabase 只在 admin 数据库中可用，赋予用户所有数据库的 dbAdmin 权限","link":"/2021/11/21/bak_mongodb_note_04/"},{"title":"【归档文章】Nextcloud 前端页面插入 JS 代码以使用 Google Analytics 分析","text":"关于 Nextcloud 启用 Google Analytics 的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 作为长期手搓 JS 的后端，对前端的安全规则几乎是一点都不熟悉，Java Spring 都是 Security 一把梭，这次给 PHP 语言编写的 Nextcloud 添加几行代码真的是要了我的老命了，赶紧记录一下别后面忘了再来一遍……注：我是在虚拟主机上直接运行官方的 setup-nextcloud.php 安装，如果是服务器上下载安装应该目录类似，请自行查找文件。 首先需要明确的是 Nextcloud 使用了严格的 CSP (Content Security Policy) 配置，如果你想从外部引用任何 CSS 或者 JS 都应该第一时间去做对该来源信任的配置，本文就以添加 Google Analytics 的 Script 元素为例。 1、从 Google Analytics 官网获取站点的统计代码样例如下： 123456789&lt;!-- Global site tag (gtag.js) - Google Analytics --&gt;&lt;script async src=&quot;https://www.googletagmanager.com/gtag/js?id=G-xxxxxxxxxx&quot;&gt;&lt;/script&gt;&lt;script&gt; window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-xxxxxxxxxx');&lt;/script&gt; 2、修改 Nextcloud 的 CSP 配置配置文件路径： 1站点根目录/lib/public/AppFramework/Http/ContentSecurityPolicy.php 添加以下几行，功能包括：① 允许执行页面内嵌的标签和事件监听函数；② 信任 Google 脚本和连接源。 3、添加 Google Analytics 代码到网站头头生成 PHP 文件路径： 1站点根目录/lib/private/legacy/template/functions.php 找到头生成方法，并添加方法： 123456789/** * Global site tag (gtag.js) - Google Analytics */function emit_google_analytics_script() { $g_a_s_01 = '&lt;script nonce=&quot;' . \\OC::$server-&gt;getContentSecurityPolicyNonceManager()-&gt;getNonce() . '&quot; defer src=&quot;https://www.googletagmanager.com/gtag/js?id=G-xxxxxxxxxx&quot;&gt;&lt;/script&gt;'; $g_a_s_02 = '&lt;script nonce=&quot;' . \\OC::$server-&gt;getContentSecurityPolicyNonceManager()-&gt;getNonce() . '&quot; defer&gt;window.dataLayer = window.dataLayer || [];function gtag(){dataLayer.push(arguments);}gtag(&quot;js&quot;, new Date());gtag(&quot;config&quot;, &quot;G-xxxxxxxxxx&quot;);&lt;/script&gt;'; print_unescaped($g_a_s_01.&quot;\\n&quot;); print_unescaped($g_a_s_02.&quot;\\n&quot;);} 之后在 emit_script_loading_tags() 方法中调用添加 Google Analytics 的代码： 123456789/** * Print all &lt;script&gt; tags for loading JS * @param array $obj all the script information from template */function emit_script_loading_tags($obj) { ... emit_google_analytics_script(); ...} 完成后刷新页面，就能去 Google Analytics 看到访问了，结束。","link":"/2021/09/12/bak_nextcloud_google_analytics/"},{"title":"【归档文章】Nginx 强制跳转 HTTPS 配置无误且使用了 Cloudflare 后出现 ERR_TOO_MANY_REDIRECTS 301 将您重定向的次数过多的解决方法","text":"关于套了 Cloudflare 后 ERR_TOO_MANY_REDIRECTS 301 问题的解决。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 新项目初始因为用的是 Cloudflare 的 DNS 解析，下意识的开启了 CDN，在这之后才开始配置 Nginx，明明配置的没问题但是 HTTP 强制跳转 HTTPS 就是会报 ERR_TOO_MANY_REDIRECTS 301 将您重定向的次数过多的错误，百思不得其解。后来在查询解决方案的时候试着加上了 Cloudflare 关键词，然后看到了这篇文章：一种可能导致 ERR_TOO_MANY_REDIRECTS 的原因，感觉就是这个原因，试了下果然解决了，优化下标题 SEO 希望能给更多人看到。虽然很简单还是放下具体的操作步骤。 关于 Cloudflare 四种 SSL/TLS 模式的区别：Cloudflare 四种 SSL/TLS 加密模式的功能解析及实践 1、确定你的 Nginx 配置是没有问题的。1234567891011121314151617181920212223242526272829303132333435# HTTP 80 端口server { listen 80; server_name example.com; root /usr/share/nginx/html; index index.html; # 强制跳转 HTTPS location / { return 301 https://$server_name$request_uri; }}# HTTPS 443 端口server { listen 443 ssl; server_name example.com; root /usr/share/nginx/html; index index.html; # SSL 配置 ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; location / { # 服务所在端口 proxy_pass http://127.0.0.1:8080; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; proxy_set_header Host $host; }} 这样的配置至少 HTTP 强制跳转 HTTPS 就已经是没有问题的了，在防火墙和安全组打开 80 和 443 端口之后不会出现重定向不到的问题。修改完记得重启 Nginx 服务。 12nginx -s reloadservice nginx restart 2、Cloudflare 配置修改 SSL/TLS 为端到端加密。原因在开头文章中已经讲的很明确了： 原因因为在 Cloudflare 的 SSL/TLS 设置选项中，如果你选择了 Flexible ，那么所有对你的服务器的请求都是通过 HTTP 发送的，而如果服务器上已经设置了将 HTTP 重定向到 HTTPS 的话，就会发生重定向循环。 如图更改即可。 3、注意事项：上述操作结束后，如果服务器 Nginx 配置项中一个域名同时有 HTTP 和 HTTPS 两个 server 配置内容的话，所有 HTTP 访问会无视其对应配置而改为 HTTPS 协议并遵循 HTTPS 的 server 配置内容，这会引起最大的问题就是类似 Let’s Encrypt SSL 证书申请时所采取的：在服务器某一位置生成认证文件并用 HTTP 协议访问它以完成验证这一措施失效。也就是说，强制 HTTPS 跳转和 Let’s Encrypt SSL 证书自动续签你只能选其一。","link":"/2021/07/17/bak_nginx_cloudflare_301_too_many_redirects/"},{"title":"【归档文章】Let&#39;s Encrypt 证书的申请、自动更新和 Nginx 的配置","text":"关于 Let’s Encrypt 证书相关的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 腾讯云虽然免费提供诚信亚洲的 SSL 证书申请，但是一年一申请还是有些麻烦，再加上只是给边缘项目域名加上 HTTPS 防止前端引用资源的时候报不安全，稍微折腾一下一劳永逸感觉会更方便一点，这样在后续的其他项目也能直接用。 教程的顺序为我自己操作的顺序：申请证书 → 配置 Nginx HTTPS 访问和放行 HTTP 下的证书路由 → 自动续签证书配置 1、首先申请证书由于我使用的是 CentOS7 系统，因此可以 yum 直接安装 Certbot： 1yum -y install certbot 虽然一般教程接下来都是直接执行如下命令申请证书（example.com 替换为你自己的域名，也可是二级域名） 1certbot certonly --webroot --agree-tos -v -t --email example@gmail.com -w /usr/share/nginx/ -d example.com 但是还是有几点需要在执行之前确认： 防火墙和安全组放行 80 端口（后续配置 HTTPS 访问再自行放行 443 端口） 确保 example.com 域名已经解析到了你在申请证书的服务器 IP 上 确保 Nginx 配置无误，指：http://example.com/.well-known/acme-challenge/ 下临时生成的认证文件可以被访问到。 2、Nginx 配置可以像我下面这样（我选的验证文件临时目录为 /usr/share/nginx，server_name 等可以自行替换）： 123456789101112131415server { listen 80; listen [::]:80; server_name _; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; # Let's Encrypt 证书认证（优先级最高放在最前面） location ~ /.well-known { root /usr/share/nginx; allow all; } } 在配置好后重启 Nginx： 12nginx -s reloadservice nginx restart 然后执行上面证书申请的命令应该就可以申请到了，任何错误请依次确认上述 3 点事项。注：如果使用的是 Cloudflare DNS 解析，请在 SSL/TLS 处选为灵活模式，以防止强制 HTTPS 转换导致的文件无法验证。 3、证书自动续签。Certbot 提供了方便的一键续签命令： 1certbot renew 在证书到期时间小于 30 天的情况下，执行以上指令后会在原位置更新证书，接下来只要手动 Nginx 重新加载配置并重启就能使用新的证书了。Certbot 很贴心的提供了钩子，以方便在 renew 操作前后执行其他命令，于是便可以直接使用下面的命令同时完成续签和重启 Nginx 操作： 1certbot renew --pre-hook &quot;service nginx stop&quot; --post-hook &quot;service nginx start&quot; 接着以官方建议的每天 2 次频率将其加入到任务计划中： 1crontab -e 1234...# 每 12 小时执行一次0 */12 * * * certbot renew --pre-hook &quot;service nginx stop&quot; --post-hook &quot;service nginx start&quot;... 1service crond restart 理论上是没问题的，大概 60 天以后回来记录下自动续签是否生效。","link":"/2021/07/16/bak_nginx_letsencrypt_apply_and_auto_renew/"},{"title":"【归档文章】Nginx 学习（一）proxy_pass 反代路由的替换和 root 与 alias 的区别","text":"关于 Nginx 的学习笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 因为一开始没整理归类文件的习惯，把手头的主力开发机弄得很乱，索性就备份了些重要文件重装了电脑，然后就把服务器的 Nginx 配置文件全丢了……剩下服务器上一堆没注释的配置连自己都看晕了，就重新学下吧。 Nginx 反代路由的替换在同一服务器部署多项目是还是很常用的，比方说我有一个将 https://ceshiku.cn/tiny-server-proxy/ 反代到本地的 57191 端口的需求，但是又不想影响到主路由和其他项目地址例如 https://ceshiku.cn/test/ 的解析。我肯定不能这么写： 123location ^~ /tiny-server-proxy { proxy_pass http://localhost:57191;} 为什么呢，如果我这么写的话，那当我访问 https://ceshiku.cn/tiny-server-proxy/status 的时候，虽然能被代理到指定端口上运行的项目，但是实际上项目收到的请求路由是这样的：很明显多出来的 /tiny-server-proxy/ 其实是我不需要的，那我改一下： 123location ^~ /tiny-server-proxy/ { proxy_pass http://localhost:57191;} 结果收到的路由呢，如下：依旧是多了 /tiny-server-proxy/ 这个路径，可见在路由匹配上下功夫是没有用的，只能在 proxy_pass 后反代的端口上做更改： 123location ^~ /tiny-server-proxy/ { proxy_pass http://localhost:57191/;} 再试一下，果然可以了：那么 Nginx 反代到端口项目时路由部分路径替换的问题就解决了。 那么碰到动静分离的项目，想要访问静态资源时替换路径有该怎么操作呢，这个时间就要搬出除了 root 之外 Nginx 另一个资源映射语法了：alias 1234567location ^~ /t/ { root /www/root/html/;}location ^~ /t/ { alias /www/root/html/;} 当路由和文件夹配置完全一样的情况下，当请求链接是 /t/a.html 的情况下，两个配置分别会：root 的配置会返回 /www/root/html/t/a.html 的文件，alias 的配置会返回 /www/root/html/a.html 的文件，alias 所起的作用就和刚刚往反代端口后加的斜杠类似，做到因为把 location 后面配置的路径完全舍弃。但是用的时候还需要注意：alias 只能位于 location 块中（root 可以不放在 location 中）。","link":"/2020/12/31/bak_nginx_note_01/"},{"title":"【归档文章】Nginx 学习（二）处理用户仅使用 IP 访问时服务器返回 SSL 证书泄露域名等问题","text":"关于 Nginx 的学习笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 给网站套上 Cloudflare 防止被打和缓存部分静态文件应该是常规操作了，但是想起来之前好像见到过的帖子：第一次知道 HTTPS 会暴露服务器 IP，在新的服务器上试验了一下发现在访问 https:// 服务器 IP 的时候真的会返回 Nginx 配置中的第一封 SSL 证书而泄露域名，在这种全网扫 IP 成本极低的年代真的是很危险……于是还是决定稍作配置以排除掉这个危险因素。 1、80 端口常规配置在用户用 IP 直接访问时返回 500 错误。 1234567891011# ========= 基础配置 =========# 禁止 IP 直接访问server { listen 80; listen [::]:80; server_name _; location / { return 500; }} 直接访问 http:// 服务器 IP:80 端口效果： 2、443 端口配置参考文章：【小教程】Nginx 默认拒绝发送证书设置教程 123456789101112131415# 防止发送 SSL 证书server { listen 443 ssl http2 default_server; server_name _; ssl_protocols TLSv1.2 TLSv1.3; # 启用拒绝 TLS 握手 ssl_reject_handshake on; # SSL Session 缓存，不设置的话无缓存配置不生效 ssl_session_cache shared:SSL:10m; ssl_session_timeout 10m; # log 位置自行替换 access_log /rab/log/nginx/access.log;} 这样配置之后的访问效果：ERR_SSL_UNRECOGNIZED_NAME_ALERT 就是我们想要的效果。 至此配置结束。","link":"/2021/07/16/bak_nginx_note_02/"},{"title":"【归档文章】Nginx 学习（三）配置基础的用户登录验证以保护站点","text":"关于 Nginx 的学习笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 临时分享下文件可用，没有认证时间限制所以无法实现类似认证一次 6 小时后超时这种功能，每次访问页面或是 API 调用都需要验证。 官方文档：Restricting Access with HTTP Basic Authentication 1、安装 httpd-tools 模块以启用 htpasswd1yum -y install httpd-tools 2、配置用户信息我这里储存用户账号密码的文件选在在 /etc/nginx/conf.d/ 下保存 12cd /etc/nginx/conf.d/htpasswd -c pass.db $username 输入密码： 12New password: $passwordRe-type new password: $password 确认一下是否添加成功，密码会被加密： 1cat pass.db 3、修改 Nginx 配置文件1234567891011121314151617......server { listen 80; server_name example.com; # 强制跳转 HTTPS location / { # 认证 auth_basic &quot;User Authentication&quot;; auth_basic_user_file /etc/nginx/conf.d/pass.db; # 301 跳转 return 301 https://$server_name$request_uri; }}...... 之后重启再访问页面就能看到： 结束。","link":"/2021/10/01/bak_nginx_note_03/"},{"title":"【归档文章】定制 OpenWrt 软路由系统（一）从源码开始编译第一个系统固件","text":"关于 OpenWrt 软路由系统的学习笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 第一次完全按照视频教程装了爱快和 LEDE 双软路由系统，当时只是为了实现功能而完全没有考虑安全性和整个系统是否过于臃肿的问题，但是在使用了近 2 年之后，看了下 LEDE 页面完全没有点开过的大半菜单选项，于是决定根据需求定制下属于自己的 OpenWrt 系统固件。对于 OpenWrt 系统我的需求就两个：1、干净整洁；2、可以实现路由器端的科学上网，这里我选用的插件是 Clash。​小提一句，LEDE 是 OpenWrt 在 2016 年 5 月后被新建的一条分支，但是由于之后 OpenWrt 的大量开发人员选择参与 LEDE 项目，经历长时间的两边维护后，于 2018 年 2 月 LEDE 又合并回了 OpenWrt 的主分支内，因此现在编译 OpenWrt 即可，不用再去管 LEDE 了。 本章主要参考教程为：打造一个专属于你的软路由系统，让它好用十倍！ 1、安装一个 Ubuntu 系统截至 2021-10-23 GitHub 项目的 README.md 上已经开始推荐 Ubuntu 20.04 LTS x64 系统，因为升级了 Windows11 的关系，直接使用 WSL2 安装个 Linux 虚拟机即可。 关于 Windows 11 如何开启 WSL2 并安装 Linux 子系统，稍微记录一下。 Win + X 键打开 Windos 终端（管理员）并执行： 1234# 开启 Linux 子系统功能dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart# 开启虚拟机功能dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart 在微软商店搜索并下载 Ubuntu 20.04 TLS 系统（发行版可根据自己需求更换）： 安装、打开，然后设置用户密码： 设置磁盘映射，Linux 子系统默认的路径如下（用户和 Linux 发行版自行替换）：注意：在这个目录下你会看到一个磁盘映射文件，因为涉及到文件编码格式的不同，官方是不推荐跨系统做文件管理的，但单纯的从 Linux 子系统中拷贝编译后的文件出来是没问题的。​ 1C:\\Users\\$用户\\AppData\\Local\\Packages\\CanonicalGroupLimited.Ubuntu20.04onWindows_79rhkp1fndgsc\\LocalState 2、更新软件源并安装编译所需依赖需要注意的是部分包境内下载速度缓慢，这一步最好在全局科学情况下执行。更新软件源： 1sudo apt-get update 安装编译所需依赖： 1sudo apt-get -y install build-essential asciidoc binutils bzip2 gawk gettext git libncurses5-dev libz-dev patch python3 python2.7 unzip zlib1g-dev lib32gcc1 libc6-dev-i386 subversion flex uglifyjs git-core gcc-multilib p7zip p7zip-full msmtp libssl-dev texinfo libglib2.0-dev xmlto qemu-utils upx libelf-dev autoconf automake libtool autopoint device-tree-compiler g++-multilib antlr3 gperf wget curl swig rsync 3、克隆代码1git clone https://github.com/coolsnowwolf/lede 4、执行编译前准备工作也都是官方文档的代码，直接拷贝执行： 123cd lede./scripts/feeds update -a./scripts/feeds install -a 5、接下来配置软路由系统这一步是较为关键的，直接决定了编译出来系统的架构和里面所包含的插件，因为是第一章只编译一个最基础的软路由系统固件，因此不会包含插件信息单单只做架构为 x86 的配置。执行： 1make menuconfig 到图形化界面，发现前 3 项已经配置好了 x86_64 的架构设置，那么就不用动了，保存退出即可。 6、下载 dl 库1make -j8 download V=s 7、打包编译-j1 参数意为单线程编译，官方文档推荐第一次使用单线程，但其实后续编译不再需要下很多包因此速度会提升很多，继续使用单线程也无妨。执行： 1make -j1 V=s 这里需要注意的是，如果你和我一样使用的是 WSL 或者 WSL2 进行编译，由于部分 PATH 中路径包含带空格的 Windows 路径，很可能会导致编译失败，因此请执行下面的命令： 1PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin make -j1 V=s 我的 CPU 是 3700X，这一步的单线程编译了 6 个小时左右，最后如下图显示就说明编译结束了： 8、拷贝编译完的固件Window11 的 ESL2 会自动生成磁盘映射方便访问，直接进入即可。路径如下（用户名请自行替换）： 1\\\\wsl.localhost\\Ubuntu-20.04\\home\\$用户\\lede\\bin\\targets\\x86\\64 选 openwrt-x86-64-generic-squashfs-combined-efi.img 即可：因为我的软路由系统是跑在 PVE 平台上的，因此使用 Xftp 上传下即可，因为是 .img 文件，还需要做一次 img2kvm 直接写成可挂载硬盘的操作，直接上传至 /root 目录下即可。 附带说一句，PVE 下用以存储 .iso 文件的路径如下： 1/var/lib/vz/template/iso/ 这个目录下的操作系统镜像文件可以在 PVE 控制面板新建虚拟机时直接进行选择。 9、测试安装先在 PVE 端创建个操作系统不使用任何介质、先不配置任何网络设备的空虚拟机：再使用 img2kvm 工具将编译后的系统镜像写成可挂载硬盘： 1./img2kvm openwrt-x86-64-generic-squashfs-combined-efi.img 103 vm-103-disk-1 写完之后会看见一个新盘被挂载到了虚拟机，直接添加，然后在选项 → 引导顺序中更改为从新盘启动：接着启动虚拟机并切换至控制台准备更改管理面板 IP（这里可能需要按下回车）：更新配置文件： 1vi /etc/config/network 将第 15 行的 192.168.1.1 更改为你需要的 IP 地址即可：之后重启。最后看下你之前 LEDE 软路由的网络设备是什么样的配置，抄一份在硬件处添加：接着重启并访问配置了的 IP 地址：这里的密码需要去控制台里更改： 1passwd root 接着登录即可：看到还是有一些插件被默认添加了，下一章对插件的自定义会尝试去除。 本章结束。","link":"/2021/10/23/bak_openwrt_note_01/"},{"title":"【归档文章】定制 OpenWrt 软路由系统（二）删除多余插件并安装 Clash","text":"关于 OpenWrt 软路由系统的学习笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 首先明确需要，当前我只需要 Clash 一个插件，并且官方文档是优先用 opkg 命令在 OpenWrt 系统下安装的，因此决定首先在编译前的配置文件生成步骤把不需要的插件（组件）都取消勾选、重新编译出干净的系统，再进行 Clash 的安装。 顺带贴一下 Clash 和 OpenClash 这两个插件的区别（来源于悟空的 YouTube 视频）：这里我的机场主要都是 SSR 协议，因此必须选择 clashr 的内核（目前 clashr 内核已经合并到了 clash 内核内），而能更改内核的 Clash 路由器插件也只有 Clash 这个版本的了。 1、首先重新配置软路由系统镜像内的插件1234# 清空之前的配置rm -rf ./tmp &amp;&amp; rm -rf .config# 生成配置文件make menuconfig 对照着页面上的插件按钮和左下角的链接，在 LuCI → Applications 内将不需要的插件一个个删除：嫌麻烦的话可以直接参照下方列表进行删除： 1234567891011121314151617181920# 服务 → 上网时间控制luci-app-accesscontrol# 服务 → 广告屏蔽大师 Plus+luci-app-adbyby-plus# 服务 → 动态 DNSluci-app-ddns# 网络存储 → qBittorrentluci-app-qbittorrent# 服务 → 解锁网易云灰色歌曲luci-app-unblockmusic# 服务 → UPnPluci-app-upnp# 服务 → UU 游戏加速器luci-app-uugamebooster# 服务 → KMS 服务器luci-app-vlmcsd# 服务 → 网络唤醒luci-app-wol# 服务 → 迅雷快鸟luci-app-xlnetacc 之后保存退出。 2、二次编译由于我是在 WSL2 下进行编译的，防止存在带空格的 Windows 目录而导致的编译失败，使用以下命令： 1PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin make -j$(($(nproc) + 1)) V=s 3、安装新编译后的系统写成一个新的启动盘 disk-2： 1./img2kvm openwrt-x86-64-generic-squashfs-combined-efi.img 103 vm-103-disk-2 之后更改虚拟机的引导顺序为使用新盘启动，然后将软路由断电重启。重启后修改一下 IP 和用户密码，然后再重启，结束后再进去页面菜单应该就相当干净了。 4、配置 OpenWrt 系统的网络这一步仅供参考，目的是为了使这个 OpenWrt 系统能连上网以便进行后续 opkg 的升级和插件安装，每个人的网络拓跋不一样，我的前置路由是用以拨号的爱快，因此只需要修改下这个 OpenWrt 的网关和 DNS 即可：再强制 DHCP 功能由其提供：成功联网： 5、安装 Clash 插件将 luci-app-clash 的 .ipk 安装文件上传：然后更新软件包以方便 Clash 下载依赖，点击刷新列表： 如果出现以下错误 1234567......Downloading https://mirrors.cloud.tencent.com/lede/releases/18.06.9/packages/x86_64/luci/Packages.sigSignature check failed.Remove wrong Signature file....... 在 OPKG 配置处用 # 注销掉 option check_signature 即可： 接着执行安装：看见日志最后有 Configuring luci-app-clash. 就说明安装成功了，如果失败的话请多尝试几次，我至少也是执行了 2 次才成功的。 当前你也可以选择使用命令行执行安装： mv /tmp/upload/luci-app-clash_v1.7.5.7_all.ipk /tmp cd /tmp opkg update opkg install luci-app-clash_v1.7.5.7_all.ipk # 无视部分报警安装（极端情况下可以使用，能用此命令安装成功基础功能也就能使用） opkg install luci-app-clash_v1.7.5.7_all.ipk --force-depends 6、测试使用使用之前还需要配置下内核，安装包内不带内核需要自行下载：https://github.com/frainzy1477/clash_dev/releases/tag/v1.1.0下载完成之后上传：接着从你的机场复制订阅链接并下载配置：选择并使用配置：再启用客户端：此时就已经完成了 Clash 的启动了： 如果你出现国内网站能够访问，但是国外网站不能访问的情况，你又同时能确定线路没问题，那么请尝试更改本机获取 IP 的方式，从固定 IP 改为 DHCP 获取，或许能解决这个问题。 结束。","link":"/2021/10/24/bak_openwrt_note_02/"},{"title":"【归档文章】定制 OpenWrt 软路由系统（三）编译适用于自己 OpenWrt 软路由系统的 Clash 插件","text":"关于 OpenWrt 软路由系统的学习笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 这里插件的编译还是以 Clash 为例，官方版本为 v1.7.5.7，但实际上已经能编译出更新的版本，当前这里的编译请主要参考流程，插件除非是因为 OpenWrt 系统更新已经到了不能用的程度，否则是没有必要手动去编译的。一般情况下编译都是简单顺利的，但是你仍然要抱有出错并靠自己解决的觉悟，新特性和系统稳定总是很难兼得。​ 官方文档：compile他这里用到了 OpenWrt 的 SDK 进行编译，实际上我们并不需要这么做，因为我们有 OpenWrt 的源码，因此只需要使用 OpenWrt 的源码进行编译就行了，注意这里的编译并不是指将插件直接编译到完整的 OpenWrt 系统内，而是使用 OpenWrt 的源码单独编译一个 .ipk 的插件安装文件出来。 1、下载插件源码以 luci-app-clash 为例，克隆代码： 1234# 进入 lede 文件夹cd lede# 克隆到 package 目录下git clone https://github.com/frainzy1477/luci-app-clash.git package/luci-app-clash 2、设置编译模式执行： 1make menuconfig 我的插件是 luci-app-clash，属于 LuCI 目录，视情况选择：第二个选项就是（这里要参照你自己插件的目录层级关系，可能要再进一层到 Applications 中去）：这里只编译这个插件，选 M 编译模式（Y 模式为编译进系统，N 为去除这个插件）：之后保存退出。 3、跟随插件官方文档配置编译环境每个插件所需的环境都不一样，比如说这次编译的 Clash，官方文档提到了要安装 po2lmo 以支持中文语言，照做即可：注：我已经事先编译过一次了，所以输出可能和你第一次执行有些不一样。 4、开始编译插件执行： 1make package/luci-app-clash/compile V=99 多线程而且只编译一个插件是很快的，检查下输出看下插件安装文件所在位置：倒数第四行，写着文件被打包在了哪里： 12345......Packaged contents of /home/rabbir/lede/build_dir/target-x86_64_musl/luci-app-clash-v1.8.0/ipkg-all/luci-app-clash into /home/rabbir/lede/bin/packages/x86_64/base/luci-app-clash_v1.8.0_all.ipk...... 直接前去获取即可：安装过程不演示了，实际上我也并未安装，因为旧版本是可用的没有必要，并且我无法确定 1.0 版本的 Clash 内核能否和当前 v1.8.0 的 Clash 插件适配。 结束。","link":"/2021/10/25/bak_openwrt_note_03/"},{"title":"【归档文章】Windows 下 PicGo + GitHub 搭建个人图床工具","text":"关于使用 GitHub 仓库搭建图床并使用 PicGo 工具的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 虽然也有免费的可以用，但是既然软路由已经配置了方便的上网环境，GitHub 访问起来比以前便利了许多，那就把图床直接部署在 GitHub 上好了，虽然隐私性是一缺点，但是主要也是给博客使用，也就无所谓了。 环境：Windows 10 64 位需要时间：0.5 小时左右原教程：CSDN PicGo+GitHub 搭建个人图床工具 1、在 GitHub 上新建仓库，并在 settings 中设置为 Public 2、创建 token，为了给 PicGo 客户端配置，使其能上传给对应 GitHub 仓库。描述可以随便填写，但是 repo 权限中至少要勾选 public_repo（图上我是全勾的因为我还有个私人图床需要开启对私有仓库的访问权限）。注意：token 只出现一次！所以一定要保存！ 3、下载&amp;安装 PicGo。 PicGo （目前 2.2.1）是一个开源的图床工具，非常优秀。 Git 地址：https://github.com/Molunerfinn/PicGoWindows 版下载地址：https://github.com/Molunerfinn/PicGo/releases 4、配置 PicGo 仓库名：账号名+仓库名 分支名：master Token：刚刚保存的 token 存储路径：img/ 自定义域名：https://raw.githubusercontent.com/账号名/仓库名/master 配置点击设为默认图床，然后确定即可。 至此，Windows 下 PicGo+GitHub 的个人图床工具搭建完成，通过微信或者 QQ 截图完成，默认剪贴板中是图片的情况下，直接 Ctrl+Shift+P 即可将图片上床图床，而 .md 格式的图片链接也会替换至剪贴板，直接粘贴在所需地方即可。​","link":"/2020/01/12/bak_picgo_github/"},{"title":"【归档文章】Plesk（虚拟主机空间）下安装 Nextcloud 网盘系统","text":"关于安装 Nextcloud 的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 维基主机家 CN2 虚拟空间上的 Nextcloud 管理员密码忘了，并且因为当初没有配置邮箱信息，导致没法收到重置密码邮件，反正也没啥重要文件索性重装下，以此记录下流程。注：所有安装流程截图均以 Plesk 为例，不同虚拟主机请自行探索实际操作方法。 1、下载 Nextcloud 安装包官方下载地址：Download for server选择 Web Installer：接着上传到虚拟主机空间内，放在对应域名文件夹的根目录下即可： 2、配置域名解析和为安装清空至少 500MB 空间域名解析自行配置。安装需要至少 500MB 空间，云服务商的空间监控一般是不包括垃圾站内文件的，但是实际垃圾站内容量也会算进虚拟空间总限制容量内，因此也请清空。 像下图一样的情况实际上就是安装失败，日志内容大概为： 1234567Warning: ZipArchive::extractTo(): Invalid or uninitialized Zip object in /var/www/vhosts/.../.../setup-nextcloud.php on line 156 Warning: ZipArchive::close(): Invalid or uninitialized Zip object in /var/www/vhosts/.../.../setup-nextcloud.php on line 157 Warning: scandir(tmp-nextcloud1635676707/nextcloud): failed to open dir: No such file or directory in /var/www/vhosts/.../.../setup-nextcloud.php on line 161 Warning: scandir(): (errno 2): No such file or directory in /var/www/vhosts/.../.../setup-nextcloud.php on line 161 Warning: array_diff(): Expected parameter 1 to be an array, bool given in /var/www/vhosts/.../.../setup-nextcloud.php on line 161 Warning: Invalid argument supplied for foreach() in /var/www/vhosts/.../.../setup-nextcloud.php on line 161 Warning: rmdir(tmp-nextcloud1635676707/nextcloud): No such file or directory in /var/www/vhosts/.../.../setup-nextcloud.php on line 164 三个原因都有可能造成失败： 空间不够。 与安装界面断连导致程序异常出错，这在使用境外虚拟空间安装时很常见。 部分文件下载出错，主要以下面几个文件为主： 文件 路径 下载地址 nc.zip . https://download.nextcloud.com/server/releases/latest.zip 因此请提前清理好空间并准备好代理。当然对以上文件，你可以提前下载了放在目录下（目录 . 意为 setup-nextcloud.php 所在目录）。 3、开始安装访问：你的域名 + /setup-nextcloud.php选择 Next：选择目录，我这里选了 . 即为安装在当前 pan.cscheap.com/ 目录下：安装成功：配置管理员账户密码并使用 SQLite：完成！ 当然你也可以使用外置的数据库，我不使用的原因是这家的数据库容易出现断连，导致安装不断卡在管理员账号配置阶段。Plesk 新建数据库方式如下：输入数据库名后缀、用户名后缀和密码：创建成功后前往 Nextcloud 管理员配置界面选择外置数据库即可： 最后提醒虚拟空间的网盘请定时压缩备份到本地，这是维基主机 2021 年 6 月份出的事故，补偿虽然蛮到位的，但是数据对某些人是无价的： 结束。","link":"/2021/10/31/bak_plesk_install_nextcloud/"},{"title":"【归档文章】PostgreSQL 学习笔记（一） 数据库的安装与环境配置","text":"关于 PostgreSQL 数据库的学习笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 由于在学校针对作业和毕设 MySQL 已经很够用了，因此也没有做更多对数据库的功课，只知道 Oracle 数据库适合企业，MySQL 适合小型项目，但是工作以后的第一个项目就接触的是陌生的 PostgreSQL 数据库，才发现原来还有这么好用的开源数据库，正好趁新冠肺炎这个被动假期时间把它好好学一遍。 主要书籍是 《PostgreSQL 修炼之道：从小工到专家》JD链接：PostgreSQL 修炼之道：从小工到专家PDF 下载 (Google Drive)：PostgreSQL 修炼之道从小工到专家.pdf无论如何工具书还是入正比较好，个人是因为快递延缓发货，一边等书一边 PDF 先学习起来。况且只在读完两章后就感叹唐成老师这本书写的真的很好，对 PostgreSQl 的特性和基础 SQL语句的解释都很详细，即使是从没这方面基础的也可以收获很多。 关于 PostgreSQL 的介绍，书中已经写的很详细了，就不再做过多的赘述。吸引我的地方无非几点： 免费开源（最重要的原因） 有稳定的更新和问题反馈渠道 占用低，即使是阿里的轻量都能跑 Django+PostgreSQL Navicat for PostgreSQL 价格低，150/3 月，1000 买断，真香 而再看使用上的优点则太多了： 支持数据库中创建对象，对多个项目用同数据库的太友好！ 支持列表 list 类型数据的存取 支持 JSON、xml 类型数据的存取 INSERT INTO table VALUES () ON CONFLICT() DO UPDATE/NOTHING 约束时处理（专属神器，太好用了，不知道省了多少时间） 列举几个我没有系统学习之前，用的时候发现的优点，我想在其中总有一个点会戳中后端开发人员的心。 1、首先是 PostgreSQL 的安装PostgreSQL 支持 Linux、Mac OS 和 Windows 下安装，而且方法相当简单，由于我是为了部署项目数据库，因此这里以 CentOS7 为例。注：这里安装的是 9.2.24 版本的,如果需要 12+ 版本的可参考这个博文 PostgreSQL 学习笔记（一） 补足：12.8 版本数据库的安装运行 1yum install postgresql-server.x86_64 当然在安装前可以先运行 1psql --version 查看下云服务等是否自带了低版本 Postgresql 数据库。安装之后，记得先初使用化数据库再启动 123service postgresql initdbservice postgresql startservice postgresql status 显示 running 就说明数据库已经安装完成了。 2、登录到数据库PostgreSQL 在安装时默认会添加用户 postgres，运行 1su - postgres 先切换到 postgres 用户下，再输入 1psql 就进入到 PostgreSQL 数据库中了。 这里推荐先把 postgres 用户的密码改掉： 1ALTER USER postgres WITH PASSWORD &lt;password&gt;; 注意：这里的命令是在数据库中运行的，即 postgres=#: 下。​ 3、远程连接如果你要在 Navicat 等工具中使用这个数据库，还需要做些配置。首先是 postgresql.conf 文件的配置 1vi /var/lib/psql/data/postgresql.conf 修改 123listen_addresses = '*' port = 5432max_connections = 100 保存退出即可。然后再修改 pg_hba.conf 这个文件，路径和刚刚相同 1vi /var/lib/psql/data/pg_hba.conf 在最后添加这条 1host all all 0.0.0.0/0 md5 当然开放访问的 IP 视自己情况而定，这里因为腾讯云服务器安全组全开而且机器连防火墙都没开我也就自暴自弃了，后面会再专做一个项目部署时端口等的初步设置以保障最基础的安全性。 都保存以后重启 PostgreSQL 服务，再尝试远程连接吧！ 1service postgresql restart 至此，PostgreSQL 的学习环境就已经安装完成了，如果想升级为开发环境，就像之前强调的一是防火墙要开，端口要适当开放；二是版本最好升级到 10+，以使用最新的特性。 附上书的目录：基础篇涉及到所有支持存储的数据类型，并且所有 PostgreSQL 的基础操作也都做了详解，是肯定要认真学习并做好笔记的。提高篇的 PostgreSQL 特有正则表达式很值得学习，索引、序列和锁由于自身之前用的不多，也再过一遍好了。而之后的数据库优化和第三方开源软件及架构在这次学习中只会做了解，在项目进行或是完成后再结合实际情况学习可能效果会更好。","link":"/2020/02/02/bak_postgresql_note_01/"},{"title":"【归档文章】PostgreSQL 学习笔记（一） 补足：CentOS7 下 12.8 版本数据库的安装","text":"关于 PostgreSQL 数据库的学习笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 虽然我很早之前就完成了数据库版本的升级（9.2.4 -&gt; 12.8），但是由于考虑到教程对新手的友好就一直没有去更新第一章，这次作为补足放出吧。新的特性可以参照这篇文章：PostgreSQL 12 新特性汇总，对于这种大型开源项目并有专业的团队和完善的社区做维护，我是推荐无脑上新版本的。参考文章：在CentOS 7上安装&amp;配置PostgreSQL 12 1、导入 yum 源并安装 PostgreSQL 服务导入 yum 源： 1sudo yum install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm 安装 PostgreSQL 服务： 1sudo yum install -y postgresql12 postgresql12-server 2、初始化和启动数据库初始化：注：如果你是在安装主从同步中的从数据库的话，请不要初始化数据库。 1sudo /usr/pgsql-12/bin/postgresql-12-setup initdb 启动数据库： 1234# 启动数据库服务sudo systemctl start postgresql-12# 设置为开机自启动sudo systemctl enable postgresql-12 3、修改初始用户 postgres 的密码Linux 系统中切换到 postgres 用户，并进入 psql 命令行： 12su postgrespsql 执行 SQL 语句： 1ALTER USER postgres WITH PASSWORD 'new_postgres_password'; 退出 psql 命令行使用：Ctrl + D 4、配置数据库允许远程访问首先开放防火墙和端口，这里就不做演示了，默认 PostgreSQL 服务会启动在 5432 端口上。① 修改允许访问的 IP： 1vi /var/lib/pgsql/12/data/postgresql.conf 将 listen_addresses 解注并将值改为 *： 12345......listen_addresses='*'...... ② 允许所有 IP 使用密码验证访问： 1vi /var/lib/pgsql/12/data/pg_hba.conf 在尾部添加： 123......host all all 0.0.0.0/0 md5 稍微讲下默认配置中用到的认证模式： trust: 信任任何连接，不需要输入密码，即使数据库中没有这个用户。 peer: 信任任何连接，不需要输入密码，但是需要数据库中存在这个用户。 md5: 需要输入密码，且需要数据库中存在这个用户。 想详细了解数据库的认证方式可以参考官方文档：The pg_hba.conf File 之后重启数据库： 1sudo systemctl restart postgresql-12 结束。","link":"/2021/11/15/bak_postgresql_note_01_supplement/"},{"title":"【归档文章】PostgreSQL 学习笔记（二）psql 工具的使用","text":"关于 PostgreSQL 数据库的学习笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 psql 是 PostgreSQL 中的一个命令行工具，类似与 Oracle 中的 sqlplus，但是与之不同的是 psql 支持运行数据库命令或者直接运行 SQL 语句并把结果返回。既然是从头开始学习，当然也把这一部分再巩固下为佳。 进入 psql 命令行的方法12su - postgrespsql 当显示 postgres=# 时就说明已经进入 psql 工具下了。 基础命令1、查看所有数据库1\\l 2、切换数据库1\\c testdb 3、查看此数据库下的表1\\d 4、查看表的属性1\\d [表名] \\d 的用法很多，不仅可以查看表，也可以查看表的索引或是带上通配符查询 12\\d student_pkey\\d s* 而扩展的 \\d 命令则包含了更多功能 12345\\dn # 列出所有schema\\db # 显示所有表空间\\du # 列出所有的数据库用户\\dp [表名] # 显示表权限分配情况...... 更多的指令在输入 \\d 后再补两个 Tab 键即可查询出来，同期 \\t 之类的也类似。 psql 的学习到这目前就够用了，因为开发中主要还是用 Navicat 来的高效一点，既然刚刚涉及到权限查看了，正好手头上有个多表不同用户的项目，那就下一章先学下权限管理好了。","link":"/2020/02/03/bak_postgresql_note_02/"},{"title":"【归档文章】PostgreSQL 学习笔记（三）用户权限的管理控制","text":"关于 PostgreSQL 数据库的学习笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 在学习具体的权限管理之前，需要先了解一下 PostgreSQL 中权限的几个层次： 特殊权限，包含超级用户的权限、创建数据库的权限、创建用户以及 Login 的权限。 在数据库中创建模式 (SCHEMA) 的权限。 在模式中创建数据库对象的权限，如创建表、索引等。 查询单表，和插入、更新或删除表中数据的权限。 最低的则是只能操作表中部分字段的权限。 五种权限中，比较难理解的可能就是为什么要把创建数据库等设置为特殊权限。在这之前，我们需要先学习 PostgreSQL 中是如果对权限进行管理的。 PostgreSQL 使用角色的概念管理数据库权限，为了方便管理，往往给一个角色赋予一系列的权限，而如果某个用户需要这些权限，则只需要直接把角色赋给用户即可。稍微有点绕的是在这里，PostgreSQL 中角色和用户又是没有区别的，一个用户就是一个角色，因此可以把一个用户的权限赋给另一个用户，稍稍有点难理解，但是实际操作中不会有什么阻碍。 1、创建用户指令如下： 12创建角色：CREATE ROLE username [ [ WITH ] option [...] ]创建用户：CREATE USER username [ [ WITH ] option [...] ] 在这里我一般情况下使用 CREATE USER，因为这样默认出来的用户是有 “Login” 权限的，不需要再去额外设置一下了。用户的其他属性用两种方法创建出来不会有任何不同。上面命令中的 “option” 就是用户创建时被赋予的权限了，可以是如下内容： 举个实际的例子，比如我现在有一个新的项目要启动，需要创建对应的用户和数据库： 12CREATE USER new_project_user CREATEDB;ALTER USER new_project_user PASSWORD '12345'; # 修改登录密码 这样一个可创建项目数据库的用户就创建完成了！当然这种情况下，创建的用户其他是没有其他数据库及表的访问权限的。 2、修改权限之前说过的5项权限中，存在包含超级用户、创建数据库权限和 Login 在内的特殊权限，在修改权限或者说管理权限时，使用的命令是与一般权限不同的： 1ALTER ROLE username [ [WITH] option [ ... ] ] 而一般的针对数据库中建模式、数据库中建表等的则使用 “GRANT”、”REVOKE” 命令： 123GRANT role_name [, ...] TO role_name [, ...] [ WITH ADMIN OPTION ]# 上面这种是书中记载的，可能难以理解，换种形式如下GRANT some_privileges ON database_object_type object_name TO username “some_privileges” 代表一种权限，例如 “SELECT”、”UPDATE” “database_object_type” 代表一种数据库对象类型，例如 “TABLE”、”SEQUENCE” “object_name” 代表表名 “username” 则就是用户名了 比如说我现在需要将 “testdb” 模式中的 “student” 表查看权限赋予刚刚我们创建的 “new_project_user” 用户： 1GRANT SELECT ON table student TO new_project_user; 这个时候再用 Navicat 连接后去查看 “student”表，可以正常访问了。 具体的权限贴在下放以作记录，如果需要同时赋予多个权限，除了 “ALL PRIVILEGES” 以外，只需要在多个权限中用 “,” 隔开就行了。 3、后面学习时候的修修补补 只有创建数据库的权限是特殊权限，而如果要将某个数据库的权限全赋给某个用户，同样使用的是 “GRANT” 命令，例如： 1GRANT ALL PRIVILEGES ON DATABASE testdb TO new_project_user; “REVOKE” 是删除权限的命令，忘记举例： 1REVOKE CREATE ON SCHEMA public from new_project_user;","link":"/2020/02/03/bak_postgresql_note_03/"},{"title":"【归档文章】PostgreSQL 学习笔记（四）安装 plpythonu 以使用 Python3 语言编写函数","text":"关于 PostgreSQL 数据库的学习笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 我不想写 SQL。 1、首先安装 plpython3u 包PostgreSQL 版本请自行更改，安装之前先前往 pkgs.org 搜索以确定有对应的包。 1yum install postgresql12-plpython3 2、为数据库添加扩展切换到你需要安装 Python3 语言扩展的数据库并执行： 1CREATE EXTENSION plpython3u; 3、测试是否安装成功创建函数： 12345678CREATE OR REPLACE FUNCTION &quot;public&quot;.&quot;python3_test&quot; (a integer, b integer) RETURNS INT LANGUAGE plpython3uAS $$ if a &gt; b: return a return b$$; 测试一下： 123SELECT python3_test(1, 2)&gt; OK&gt; 时间: 0.058s python3_test 2 没有问题。 4、导入 Python3 包和在本数据库执行查询语句注意：Python3 语句严格使用 4 空格进行缩进！ 12345678910111213CREATE OR REPLACE FUNCTION &quot;public&quot;.&quot;python3_test&quot;(str text) RETURNS INT LANGUAGE plpython3uAS $$ import random # 获取字符串长度 # 使用 plpy.execute() 直接在本数据库执行 SQL 语句 select_result = plpy.execute(&quot;SELECT CHAR_LENGTH('{}');&quot;.format(str)) str_length = int(select_result[0][&quot;char_length&quot;]) # 随机数 random_int = random.randint(0, str_length) return random_int$$; 运行： 123SELECT python3_test('1234567890')&gt; OK&gt; 时间: 0.033s python3_test 7 5、第三方 Python 模块的安装和导入注：这里不修改配置文件，直接用最简单的方法在函数中添加包路径。第三方模块的安装直接使用 pip3 install 即可，和平时使用 Python3 无异；导入则需要先找到模块安装路径，这里以 requests 为例： 12345678910[root@VM-8-12-centos ~]# pip3 show requestsName: requestsVersion: 2.26.0Summary: Python HTTP for Humans.Home-page: https://requests.readthedocs.ioAuthor: Kenneth ReitzAuthor-email: me@kennethreitz.orgLicense: Apache 2.0Location: /usr/local/lib/python3.6/site-packagesRequires: urllib3, charset-normalizer, certifi, idna 那么 pip3 默认的安装路径则为：/usr/local/lib/python3.6/site-packages，在函数中进行导入： 1234567891011CREATE OR REPLACE FUNCTION &quot;public&quot;.&quot;python3_test&quot;(url text) RETURNS INT LANGUAGE plpython3uAS $$ import sys sys.path.append(&quot;/usr/local/lib/python3.6/site-packages/&quot;) import requests # 访问 response = requests.get(url) return response.status_code$$; 运行： 123SELECT python3_test('https://baidu.com')&gt; OK&gt; 时间: 0.526s python3_test 200 6、打印日志和返回表结构的数据123456789101112131415161718192021222324252627CREATE OR REPLACE FUNCTION &quot;public&quot;.&quot;python3_test&quot;(str text) RETURNS TABLE(_varchar VARCHAR, _numeric NUMERIC, _boolean BOOLEAN) LANGUAGE plpython3uAS $$ import sys sys.path.append(&quot;/usr/local/lib/python3.6/site-packages/&quot;) # 类 class return_class(): def __init__(self, _varchar, _numeric, _boolean): self._varchar = _varchar self._numeric = _numeric self._boolean = _boolean # 打印日志 plpy.debug(&quot;debug&quot;) plpy.log(&quot;log&quot;) plpy.info(&quot;info&quot;) plpy.notice(&quot;notice&quot;) plpy.warning(&quot;warning&quot;) # 返回表结构（在声明了返回表的列名后只要以列为单位生成对象并放入数组返回即可） return_classes = [] a_class = return_class(str, 1.00, True) a_class._numeric = 0.01 return_classes.append(a_class) return_classes.append(return_class(&quot;bb&quot;, 1.23, True)) return_classes.append(return_class(&quot;cc&quot;, 3.21, False)) return return_classes$$; 运行： 123456SELECT * FROM python3_test('test_log_table')&gt; INFO: info&gt; NOTICE: notice&gt; WARNING: warning&gt; OK&gt; 时间: 0.115s _varchar _numeric _boolean test_log_table 0.01 t bb 1.23 t cc 3.21 f 结束。","link":"/2021/09/25/bak_postgresql_note_04/"},{"title":"【归档文章】PostgreSQL 学习笔记（五）找回被遗忘的 postgres 密码","text":"关于 PostgreSQL 数据库的学习笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 这应该也算学习笔记吧…… 1、信任所有的本地连接修改配置文件： 1vi /var/lib/pgsql/12/data/pg_hba.conf 从 md5 的认证方式改为 trust 12345678......# &quot;local&quot; is for Unix domain socket connections onlylocal all all trust# IPv4 local connections:host all all 127.0.0.1/32 trust...... 如果你更改过 PostgreSQL 数据库的端口的话，也需要改回到 5432，否则直接访问会显示认证失败：psql: error: FATAL: Ident authentication failed for user “postgres” 1vi /var/lib/pgsql/12/data/postgresql.conf 改回 5432 端口： 1port = 5432 # (change requires restart)之后重启数据库： 1sudo systemctl restart postgresql-12 2、切换至 postgres 用户并连接数据库切换用户： 1su - postgres 连接数据库： 1-bash-4.2$ psql 3、修改密码1ALTER USER postgres WITH PASSWORD 'newpassword'; 4、恢复原配置并重启恢复之前的配置后进行重启： 1sudo systemctl restart postgresql-12 结束。","link":"/2021/10/25/bak_postgresql_note_05/"},{"title":"【归档文章】PostgreSQL 学习笔记（六）对 JSONB 类型字段的增删改查操作","text":"关于 PostgreSQL 数据库的学习笔记。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 苦 JSONB 久矣。 介绍下实验用表 item 的表结构： 名 类型 长度 小数点 不是 null 键 注释 id int4 32 0 √ 🔑 商品 ID name varchar 255 0 商品名 property jsonb 0 0 属性 表中数据： id name property 1 毛巾 {“price”: 5.88, “num”: 20, “type”: “厨卫”, “discount”: false} 2 饼干 {“price”: 3.00, “num”: 55, “type”: “食品”, “discount”: true} 注：当然实际开发中绝对不会把价格等信息写在 JSONB 中，这里的结构和数据仅作测试用。 然后考虑了一下介绍各操作的顺序，对于 JSON 类型，增加、删除、修改、查看的顺序居然意外的合理，那就按这个顺序来吧。 1、增加操作① 为 JSONB 类型数据新增键值对的操作符为 ||，即双竖杠。具体操作： 1UPDATE item SET property = property::JSONB || '{&quot;discount_percent&quot;: &quot;90%&quot;}'::JSONB WHERE id = 2; 这里为饼干新增了具体折扣数值这个属性，双冒号 :: 起到了类型转换的作用。 id name property 2 饼干 {“num”: 55, “type”: “食品”, “price”: 3.00, “discount”: true, “discount_percent”: “90%”} ② 使用 jsonb_insert 这个函数。官方对这个函数的介绍： 1jsonb_insert(target jsonb, path text[], new_value jsonb [, insert_after boolean]) 第一个参数 target 为需要插入新属性的 JSONB 类型的对象；第二个参数 path 为路径，列表类型，用 [] 或 {} 包裹元素都可以，键一般就写在这个列表的最后一位；第三个参数 new_value 就是该键值对的值了；第四个参数是个可选参数 insert_after，用以判断是将值插在指定位置之前还是之后，这个在路径最后一位为索引而非键的情况下常用，默认为 false。 具体操作： 1234567-- 新建键值对UPDATE item SET property = jsonb_insert(property, '{oriented}', '[&quot;老人&quot;, &quot;小孩&quot;]'::JSONB, false) WHERE id = 1;-- 为键值对的值做添加，添加在索引 1 的元素后面，即最终顺序为：[&quot;老人&quot;, &quot;小孩&quot;, &quot;青年&quot;]UPDATE item SET property = jsonb_insert(property, '{oriented, 1}', '&quot;青年&quot;'::JSONB, true) WHERE id = 1;-- 由于 jsonb_insert 无法自动设置父节点，因此在创建 country 下的 city 属性时，首先得确保 country 属性存在！UPDATE item SET property = jsonb_insert(property, '{country}', '{&quot;country&quot;: &quot;China&quot;}'::JSONB, false) WHERE id = 1;UPDATE item SET property = jsonb_insert(property, '{from, city}', '&quot;Changzhou&quot;'::JSONB, false) WHERE id = 1; id name property 1 毛巾 {“num”: 20, “from”: {“city”: “Changzhou”, “country”: “China”}, “type”: “厨卫”, “price”: 5.88, “discount”: false, “oriented”: [“老人”, “小孩”, “青年”]} 2、删除操作删除的操作符为 -，即减号。具体操作： 1234-- 单个属性UPDATE item SET property = property::JSONB - 'discount_percent' WHERE id = 2;-- 多个属性UPDATE item SET property = property::JSONB - '{&quot;discount&quot;, &quot;type&quot;}'::text[] WHERE id = 1; id name property 1 毛巾 {“num”: 20, “from”: {“city”: “Changzhou”, “country”: “China”}, “price”: 5.88, “country”: {“country”: “China”}, “oriented”: [“老人”, “小孩”, “青年”]} 2 饼干 {“num”: 55, “type”: “食品”, “price”: 3.00, “discount”: true} 3、更新操作使用 jsonb_set 这个函数。官方对这个函数的介绍： 1jsonb_set(target jsonb, path text[], new_value jsonb[, create_missing boolean]) 第一个参数 target 为需要修改的 JSONB 类型的对象；第二个参数 path 为路径，列表类型，用 [] 或 {} 包裹元素都可以，键一般就写在这个列表的最后一位；第三个参数 new_value 就是该键值对的值了；第四个参数是个可选参数 create_missing，是否在没有该值时创建，由此你也知道了 jsonb_set 在插入操作时也可使用，默认为 true。 具体操作： 12345678-- 插入新值UPDATE item SET property = jsonb_set(property, '{discount_percent}', '&quot;100%&quot;'::JSONB, true) WHERE id = 1;-- 修改旧值UPDATE item SET property = jsonb_set(property, '{price}', '4.88'::JSONB, false) WHERE id = 1; -- 对更深层的值进行修改UPDATE item SET property = jsonb_set(property, '{&quot;from&quot;, &quot;city&quot;}', '&quot;Suzhou&quot;'::JSONB, false) WHERE id = 1; -- 用一个新的 JSONB 类型数据来更新表中的字段，重复的键会使用新的数据，不重复的键值对会被添加（这里是添加符号 || 的另一种用法）UPDATE item SET property = property || '{&quot;num&quot;: 108, &quot;sell_num&quot;: 1}'::JSONB WHERE id = 1; id name property 1 毛巾 {“num”: 108, “sell_num”: 1, “from”: {“city”: “Suzhou”, “country”: “China”}, “price”: 4.88, “oriented”: [“老人”, “小孩”, “青年”], “discount_percent”: “100%”} 4、查找操作查找作为最基础的操作，可写的也最多，几乎所有能返回 Boolean 的函数都能作为查找条件，这里就只写几个我最常用的例子吧！① 查找出存在这个属性的数据： 123456-- 包含指定属性SELECT * FROM item WHERE property::JSONB ? 'from';-- 只需包含列表中的任意属性SELECT * FROM item WHERE property::JSONB ?| array['discount_percent', 'discount'];-- 需要包含列表中的所有属性SELECT * FROM item WHERE property::JSONB ?&amp; array['discount_percent', 'discount']; ② 查找某属性值符合条件的数据： -- 某属性等于某个值 SELECT * FROM item WHERE property::JSONB @&gt; '{&quot;discount&quot;: true}'::JSONB; -- 更深层的属性相等 SELECT * FROM item WHERE property::JSONB @&gt; '{&quot;from&quot;: {&quot;country&quot;: &quot;China&quot;}}'::JSONB; -- 大于某个值 SELECT * FROM item WHERE (property::JSONB -&gt;&gt; 'price')::NUMERIC &gt;= 4; -- 更深层的值大于 SELECT * FROM item WHERE (property::JSONB #&gt;&gt; '{&quot;from&quot;, &quot;zip_code&quot;}')::INT &gt;= 213000; -- 列表包含（属于列表类型操作） SELECT * FROM item WHERE property::JSONB -&gt; 'oriented' @&gt; '&quot;老人&quot;'; 如果上面这些操作无法满足你，那么请前往官方文档：JSON Functions and Operators 继续学习。 结束。","link":"/2021/11/02/bak_postgresql_note_06/"},{"title":"【归档文章】PVE 下 OpenWrt 纯净系统 + 爱快双软路由部署配置文件的整理","text":"关于 PVE 下 OpenWrt 纯净系统 + 爱快双软路由部署配置文件的整理。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 被自己写的第一篇教程无语到了……重新确定下拓扑，黑群晖系统不动，将其他两个软路由重新部署下。 首选说明几个重要的 IP 地址： 系统 IP PVE 10.10.10.254 爱快 10.10.10.253 LEDE（已废弃） 10.10.10.252 OpenWrt 10.10.10.250 PVE 的配置1、主机网络的配置查看方式： 1vi /etc/network/interfaces vmbr0 对应的就是板载网口。address 配置了 PVE 的 IP，于是就成了 PVE 管理面板的专属网口，连接其他网口是无法访问 PVE 的管理面板的。netmask 子网掩码不用多说了，照着填就行了。gateway 网关为你爱快所在的 IP 地址。注：即使配置了网关现在 PVE 也是无法连接外网的，考虑到没有需求我也没再折腾。 2、管理面板的配置网桥和网口一一配对，PVE 管理口配置 CIDR 和网关。到这拓扑就一定要确定了，结合我上面的拓扑也能知道我将 PVE 的管理口 vmbr0 同时设定为爱快主路由和 OpenWrt 旁路由的连接口，而 vmbr4 则作为 WAN 口接入入网线。 爱快的配置1、管理面板的配置net0 作为和 OpenWrt 连接的网口，net1 作为 WAN 口。 2、爱快内部配置默认就配置好了的 LAN 口（比对 MAC 地址发现就是上面的 net0）：需要自己配置的 WAN 口，只需要配置绑定剩下的 WAN 口并拨号即可：DHCP 服务端，这里把网关配置为 OpenWrt 地址即可： OpenWrt 的配置1、管理面板的配置除了那个 WAN 口（vmbr4）其他都配置上。 2、OpenWrt 内部配置只保留 LAN 口配置：LAN 口内的基本设置中，将网关指回给爱快：物理设备中勾选所有网口： 结束。","link":"/2021/10/24/bak_pve_openwrt_ikuai/"},{"title":"【归档文章】PVE 下黑群晖的安装和硬盘直通组 RAID1","text":"关于 PVE 下黑群晖安装的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 突然发现 PVE 下安装的 LEDE 和爱快 不是占用的 CPU 物理核心，所设置的 1 核只是限制了最高占用，于是就决定再利用下多下来的 2G 内存，安装个黑群晖做台式和笔记本之间的文件共享。 环境：ProXmoX VE需要时间：0.5 小时左右原教程：【悟空5kong】PVE 下部署 LEDE+黑群晖 NAS 双系统（J1900 软路由） 配置方面在已经成型的软路由基础上，新增了两块西数 1T 的紫盘。注意：紫盘主要用作监控存盘，只有 5400 转，普通家用上 7200 转的蓝盘组 RAID1 即可。 所需的软件及下载地址所有文件 (Google Drive)：PVE 下 黑群晖安装所需文件 黑群晖的安装和配置比较简单，不需要设置网卡之类的，所以直接开始就行了。​ 1、首先在 PVE 下新建虚拟机作为黑群晖的容器先将 .iso 光盘镜像文件 (XPEnoboot_DS3615xs_5.2-5967.1..iso) 上传，这个将作为虚拟机的启动引导。接着创建虚拟机，并将其编号按顺序设置为 102，注意这个编号要记住，之后挂载硬盘的时候会用到。操作系统界面选择刚刚上传的 .iso 文件作为引导。硬盘的配置默认即可，如果你的系统硬盘只有 32G 的话可以缩小，反正也不会用来做存储盘。如果黑群晖只用来做文件存储而不装大量套件的话，CPU 设置一核心即可。亲测即使是传输大量照片等小文件的情况下，200ge 的一核占用也只在 50% 左右。内存同理，看需求情况，但是2G确实已经很够用了。这一步需要注意：桥接的端口千万不要设置在之前进网的 WAN 口上，而设置在其他任意端口都没有问题！网卡则选择 E1000 因为部分黑群晖系统不支持半虚拟化的识别。确认无误完成即可。 2、接着开始机械磁盘的挂载视频教程中并没有这一步，但是这一步是需要放在安装黑群晖系统之前的，不然安装完再挂载会出现进不去系统等玄学问题。用 Xshell6 连接PVE后台，当然用上一篇的 MobaX 是一样的。进去后直接输入 1ls -l /dev/disk/by-id/ 查看当前系统连接的硬盘情况。只需要 ata 开头的即可，我挂载的是西数的机械，因此就是下面那两块了。接着复制这两块硬盘的完整信息。 ata-WDC_WD10EJRX-89N74Y0_WD-WCC4J3FCD95Sata-WDC_WD10EJRX-89N74Y0_WD-WCC4J4LZF6VT 然后在其前面加上 “qm set 102 –sata2 “ 运行即可。注：102 代表的是你虚拟机的编号；sata2 则是之后会显示在黑群晖盘符，自己设置即可之后再回虚拟机的硬件页面，就可以看见新增的这两块硬盘了。 3、然后开始安装黑群晖系统首先更改启动顺序，将 CD 设置为第一启动项，即我们刚刚上传的 .iso接着点击启动虚拟机，启动完成后注意下后台地址。浏览器地址栏输入，进入后台页面。这里选择手动安装，并上传 .pat 文件，文件我也提供了下载。弹出的会清空硬盘直接同意即可，这里注意二次确认清空盘的个数是否和你挂载的盘加上一个系统盘的总个数相同。等待其安装完成自动重启即可。之后的配置就比较简单了，用户名密码自己设置即可，由于是黑群晖，联网内容全部跳过。至此，黑群晖的安装配置就完成了。​ 4、最后就是组 RAID这个比较简单。点击左上角的菜单，再选择存储空间管理员。选择存储空间选择自定义选择组成群组选择你需要组 RAID 的两块硬盘，我这里因为组完了也上传了文件，就用的论坛的图。跳出的删除数据提醒，直接确认即可。我们这里选你需要的 RAID 模式，推荐 RAID1直接应用即可然后你就可以看见新建的正常的存储空间了。 5、为其配置局域网的共享文件夹填入文件夹名族，确认即可。选择 此电脑 右键，选择 映射网络驱动器填入你的期望盘符和网络文件夹路径即可。注：路径的格式由 IP+文件夹名组成 黑群晖的安装真的比软路由简单太多了，只需要拿钱堆硬盘就可以了。​顺便说一句，在组 RAID 方面，群晖提供了很方便的操作，勤整理，RAID0 和 RAID1 分开是一个很好的习惯。附上对 RAID5 等安全性怀疑的讨论：RAID5 磁盘阵列真的不安全么？没有什么存储方案是一劳永逸的。","link":"/2020/01/22/bak_pve_synology/"},{"title":"【归档文章】Python3 通过使用 SOCKS5H 来解决爬虫 SSL 错误和境内 DNS 污染的问题","text":"关于使用 Python3 通过代理访问 Steam API 时出错的踩坑记录。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 如果你急于解决爬虫 HTTP 代理池访问 HTPPS 出错，并且自己有境外服务器的话，我直接给出解决方案：服务器搭建 SOCKS5 代理并在代码中以 socks5h://账号:密码@IP:端口 的格式使用以 Python3 为例： 123456proxy = { &quot;http&quot;: &quot;socks5h://username123:passwd456@128.129.139.201:13233&quot;, &quot;https&quot;: &quot;socks5h://username123:passwd456@128.129.139.201:13233&quot;}response = requests.get(url,proxies=proxy,verify=False)print(response.content) 注意： 代理的协议选择要使用 SOCKS5H，下面我会放使用 HTTP 和 SOCKS5 产生的错误供参考。 1、使用 HTTP 代理时： 1234567url = &quot;https://steamcommunity.com/market/priceoverview/?appid=730&amp;currency=1&amp;market_hash_name=Clutch%20Case&quot;proxy = { &quot;http&quot;: &quot;http://128.129.139.201:13233&quot;, &quot;https&quot;: &quot;http://128.129.139.201:13233&quot;}response = requests.get(url,proxies=proxy,verify=False)print(response.content) requests.exceptions.ProxyError: HTTPSConnectionPool(host=’steamcommunity.com’, port=443): Max retries exceeded with url: /market/priceoverview/?appid=730&amp;currency=1&amp;market_hash_name=Clutch%20Case (Caused by ProxyError(‘Cannot connect to proxy.’, ConnectionResetError(10054, ‘远程主机强迫关闭了一个现有的连接。’, None, 10054, None))) 2、使用 HTTPS 代理时： 1234567url = &quot;https://steamcommunity.com/market/priceoverview/?appid=730&amp;currency=1&amp;market_hash_name=Clutch%20Case&quot;proxy = { &quot;http&quot;: &quot;http://128.129.139.201:13233&quot;, &quot;https&quot;: &quot;https://128.129.139.201:13233&quot;}response = requests.get(url,proxies=proxy,verify=False)print(response.content) requests.exceptions.ProxyError: HTTPSConnectionPool(host=’steamcommunity.com’, port=443): Max retries exceeded with url: /market/priceoverview/?appid=730&amp;currency=1&amp;market_hash_name=Clutch%20Case (Caused by ProxyError(‘Cannot connect to proxy.’, ConnectionResetError(10054, ‘远程主机强迫关闭了一个现有的连接。’, None, 10054, None))) 3、使用 SOCKS5 代理时： 1234567url = &quot;https://steamcommunity.com/market/priceoverview/?appid=730&amp;currency=1&amp;market_hash_name=Clutch%20Case&quot;proxy = { &quot;http&quot;: &quot;socks5://128.129.139.201:13233&quot;, &quot;https&quot;: &quot;socks5://128.129.139.201:13233&quot;}response = requests.get(url,proxies=proxy,verify=False)print(response.content) socks.GeneralProxyError: Socket error: 0x05: Connection refusedrequests.exceptions.ConnectionError: SOCKSHTTPSConnectionPool(host=’steamcommunity.com’, port=443): Max retries exceeded with url: /market/priceoverview/?appid=730&amp;currency=1&amp;market_hash_name=Clutch%20Case (Caused by NewConnectionError(‘&lt;urllib3.contrib.socks.SOCKSHTTPSConnection object at 0x03C29450&gt;: Failed to establish a new connection: 0x05: Connection refused’)) 4、最后使用 SOCKS5 代理，但是协议处变为 SOCKS5H： 1234567url = &quot;https://steamcommunity.com/market/priceoverview/?appid=730&amp;currency=1&amp;market_hash_name=Clutch%20Cahhse&quot;proxy = { &quot;http&quot;: &quot;socks5h://128.129.139.201:13233&quot;, &quot;https&quot;: &quot;socks5h://128.129.139.201:13233&quot;}response = requests.get(url,proxies=proxy,verify=False)print(response.content) proxy 200 b’{“success”:true,”lowest_price”:”$0.18”,”volume”:”210,212”,”median_price”:”$0.18”}’ 返回了我需要的数据，成功。 在处理这个问题的时候，感觉把学的网络全还给了老师。HTTP 属于应用层，而 SOCKS5 属于会话层，这就意味着 SOCKS5 所能代理的范围会比 HTTP 协议更广。而 SOCKS5H 与 SOCKS5 的区别则是：SOCKS5 在本地解析 Hostname，而 SOCKS5H 则有 SOCKS5 代理所部署的服务器解析 Hostname。换句话说，SOCKS5 适合本地能够解析目标主机域名（比如 GitHub）但是访问速度慢的域名来提高下载速度，而 SOCKS5H 则可以用来代理本地不能解析的网站（比如 Google），由服务器解析目标主机域名。 顺便附上服务端代理的搭建脚本：HTTP 代理：CentOS7 下一键安装 Tinyproxy 代理SOCKS5 代理：CentOS7 下一键安装 SOCKS5 代理同时安装 HTTP 和 SOCKS5 代理：CentOS7 下一键安装 GOST 并启动 HTTP 和 SOCKS5 代理服务 结束。","link":"/2020/01/10/bak_python3_steam_ssl_error/"},{"title":"【归档文章】基于以太坊 ETH 的智能合约学习（一）下载和使用小狐狸钱包 MetaMask（Chrome 插件版）并添加 BSC 主网络进行 BNB 转账","text":"关于 MetaMask 的使用教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 翻出了刚开始交易时候的收益图，不到 1600 USDT 均价的 ETH 忍痛割肉，现在涨到了 4000 U 左右，抱着困惑去重新了解了一遍 Ethereum 的愿景是什么、怎么运作和如何基于它开发自己的智能合约，突然觉得这才互联网该有的样子：数以千计的以太坊客户端构建出稳定的运行环境，降低开发者的入行门槛；严格计算工作量来逼迫开发者精简功能和优化算法；去中心化以尽可能减少监管带来的影响……听起来真的是很美好，但是实践总是检验真理的唯一标准，何况 ETH 还推出了测试链供开发和调试，尝试自己写一下合约也是为未来做准备吧。 本章只记录如何安装和使用 Chrome 插件版的 MetaMask 小狐狸钱包，它就是一个虚拟币的钱包，即使你不做智能合约的开发，单纯的进行币币交易那么也可以使用它。​ 1、下载和安装 MetaMaskChrome 插件市场：Chrome 网上应用店MetaMask 插件地址：MetaMask直接点击添加至 Chrome 即可：确认一下：稍等片刻就添加好了： 顺带一提，官方只提供了三种安装方式，Chrome 插件、IOS 客户端和安卓客户端：而点击了 Install MetaMask for Chrome 按钮后是直接跳转到 Chrome 插件市场的，也就是说官方并未提供过所谓的插件压缩包供手动安装使用。如果你无法科学访问 Google 服务但是想使用 MetaMask，请去解决科学的问题而不是使用别人提供的插件压缩包。 2、开始使用 MetaMask点击一下小狐狸：第一次使用需要创建或是绑定钱包地址，你会看到如下页面：开始使用后选择创建钱包账户和助记词：选择同意：初始化密码：视频教程直接跳过即可：记录下助记词： 注意：助记词相当重要，请抄下后物理存储，并且不要告诉任何人，它是找回你 MetaMask 钱包账户的唯一关键。​ 之后会有一次助记词的确认，我这里忘记截图了，确认后就能看到：全部完成：之后你再点击小狐狸插件，就可以直接看到钱包内容了： 3、从交易所将 ETH 提至钱包有币了再写。 4、添加币安智能链并将 BNB 提至钱包在没有配置其他链（网络）之前，你只能在 MetaMask 钱包上进行以太坊主网络上币的转账等操作，而无法提取币安链上的 BNB 或波场链上的 USDT (TRC20) 到钱包。这里以添加币安的链为例子，你在玩链游的时候可能会用到。关于币安链和以太坊链的不同：币安智能链与以太坊有何不同？官方文档：在币安智能链中关联MetaMask钱包① 添加网络：② 填入币安链的网络信息： 官方文档中有记载： 保存后看见 Smart Chain 网络就说明成功了：③ 提取 BUSD 和 BNB 到钱包选择 BUSD 提现：将 MetaMask 钱包上的地址复制到提币地址处：选择 BSC 网络：校验： 校验也可以跳过，你可以通过确认 MetaMask 以太坊网络钱包地址和币安的相同来校验，虽然无法跨链转币，但是你可以通过相同的地址来找回币，具体参考币安官方文档对币安智能链的解释。 输入数量后点击提现并通过验证码确认：大概 2 分钟后币就到 MetaMask 钱包了： 如果你的钱包里之前没有 BUSD 的话，可能需要添加下 Token：输入 BUSD 的合约地址：0xe9e7cea3dedca5984780bafc599bd69add087d56 并添加：确认即可： BNB 同理：注：如果确认 BUSD 转账成功了，可以直接把地址保存到地址簿中，下次直接使用即可。 结束。","link":"/2021/12/12/bak_smart_contracts_note_01/"},{"title":"【归档文章】基于以太坊 ETH 的智能合约学习（二）使用官方的 Remix IDE 一键发币体验整体流程","text":"关于使用 Remix IDE 发币的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 从零开始学习 Solidity 语言的时候突然回想起上大学对着键盘敲 C 的日子，老师明知道台下一半的学生出了校园甚至是这门课结束了就再也不会碰 C，却依然很负责任的教书，不甚唏嘘。本来想从第二章就介绍以太坊链的一些专有名词、Solidity 的语法的，考虑了一下还是先一起走一遍发币流程吧，也不会浪费太多时间，而且只想浅尝辄止体验一下的读者学完本章也能如愿了。 参考教程：10 分钟发行自己的加密货币，零基础教学 | 2021 （ETH， BTC）本章的内容也是对上述视频的实践和拓展（除了 MetaMask 钱包那部分，已经在上一章详细讲过了），我推荐先看一遍视频来了解我们总共需要做哪些事情。 1、明确我们要做什么虽然标题为一键发币看起来非常方便非常简单，但在这之前还是要理一下“发币”的动作如何实现，这对你之后的操作会很有帮助。很简单，实现方式就是在以太坊链上发布一份智能合约，而这份合约内的代码要包含以下两个功能即可： 根据我对其名字、数量等信息的设定而生成代币 将这些代币全转到我的钱包内 而代码在哪里、如何运行就不用你操心了，至少在这章不需要，全交给以太坊虚拟机即可。 2、切换至以太坊测试链并领取测试用 ETH由于暂时挖的 ETH 还不够部署合约，因此这里使用官方提供的 Ropsten 测试链，之后的发币操作也是在这条链上执行的。在 MetaMask 上显示测试链：之后切换到 Ropsten 测试网络：前往 https://faucet.metamask.io 领取免费的测试用 ETH，点击 request 1 ether from faucet 按钮后连接 MetaMask 钱包：连接完成后就能看到下方的的交易记录了，一枚测试用以太坊就打入了你的钱包： 如果领取失败的话，尝试关闭代理或使用私人代理，机场节点的 IP 一般都无法领取。视频教程中的 https://faucet.ropsten.be 领取站点的钱包在我进行操作时已经没有 ETH 余额了，所以没用。 3、打开 Remix 智能合约开发环境并克隆现成的代币合约代码像写 Java 你会用 IDEA、写 Python 我会用 VS Code 一样，智能合约也有适合它的 IDE：Remix。智能合约的运行依赖 Solidity 环境，如果你想用 VS Code 写的话当然也行，不过需要花费很多时间来安装 Solidity 的编译环境，Solidity 官方是推荐使用 Remix 进行合约开发的：且以太坊官方也提供了在线 Remix：remix.ethereum.org，那么我这里就直接用了。 如果你想在自己的云服务器上安装 Remix 的话可以看我这篇文章：基于以太坊 ETH 的智能合约学习（二） 补足：CentOS7 下使用 Docker 安装 remix-ide 智能合约开发环境 访问 https://remix.ethereum.org：选择从 GitHub 导入代码：这里用到的是这个仓库：ConsenSys/Tokens而合约最主要的两份代码是：主实现代码：https://github.com/ConsenSys/Tokens/blob/fdf687c69d998266a95f15216b1955a4965a0a6d/contracts/eip20/EIP20.sol接口类：https://github.com/ConsenSys/Tokens/blob/fdf687c69d998266a95f15216b1955a4965a0a6d/contracts/eip20/EIP20Interface.sol都导入到项目中： 参考以太坊 ERC20 Token 合约代码分析一文，稍微对主实现代码做下解释： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980/*Implements EIP20 token standard: https://github.com/ethereum/EIPs/blob/master/EIPS/eip-20.md.*/pragma solidity ^0.4.21;import &quot;./EIP20Interface.sol&quot;;contract EIP20 is EIP20Interface { uint256 constant private MAX_UINT256 = 2**256 - 1; mapping (address =&gt; uint256) public balances; mapping (address =&gt; mapping (address =&gt; uint256)) public allowed; /* NOTE: The following variables are OPTIONAL vanities. One does not have to include them. They allow one to customise the token contract &amp; in no way influences the core functionality. Some wallets/interfaces might not even bother to look at this information. */ // Token 的必填属性：Token 名称、小数位数（一般为 18 位）和 Token 的简称 string public name; //fancy name: eg Simon Bucks uint8 public decimals; //How many decimals to show. string public symbol; //An identifier: eg SBX function EIP20( // 部署合约时需要填入的变量 uint256 _initialAmount, string _tokenName, uint8 _decimalUnits, string _tokenSymbol ) public { // 将用户输入的变量实际赋值给合约 // 合约创建者默认拥有所有的 Token（将币的总数赋予合约创建者的地址，这样在你添加这个 Token 种类后，币就全在你钱包里了） balances[msg.sender] = _initialAmount; // Give the creator all initial tokens // 发行总量，要根据小数点精确度来计算，比如发行 100 个，小数点后位数为 2，则需要填写 10000 totalSupply = _initialAmount; // Update total supply name = _tokenName; // Set the name for display purposes decimals = _decimalUnits; // Amount of decimals for display purposes symbol = _tokenSymbol; // Set the symbol for display purposes } // 发送 Token 的动作（一般由合约创建者执行） function transfer(address _to, uint256 _value) public returns (bool success) { require(balances[msg.sender] &gt;= _value); balances[msg.sender] -= _value; balances[_to] += _value; emit Transfer(msg.sender, _to, _value); //solhint-disable-line indent, no-unused-vars return true; } // 转账 Token 的动作（一般由合约创建者执行） function transferFrom(address _from, address _to, uint256 _value) public returns (bool success) { // 获取 Token 来源方授权交易的总数 uint256 allowance = allowed[_from][msg.sender]; require(balances[_from] &gt;= _value &amp;&amp; allowance &gt;= _value); balances[_to] += _value; balances[_from] -= _value; if (allowance &lt; MAX_UINT256) { allowed[_from][msg.sender] -= _value; } emit Transfer(_from, _to, _value); //solhint-disable-line indent, no-unused-vars return true; } function balanceOf(address _owner) public view returns (uint256 balance) { return balances[_owner]; } function approve(address _spender, uint256 _value) public returns (bool success) { allowed[msg.sender][_spender] = _value; emit Approval(msg.sender, _spender, _value); //solhint-disable-line indent, no-unused-vars return true; } function allowance(address _owner, address _spender) public view returns (uint256 remaining) { return allowed[_owner][_spender]; }} 4、编译代码点击左侧的 Solidity compiler 按钮，并选择代码指定版本的编译器，点击编译：看到小绿钩出现代表编译完成了： 5、部署合约点击左侧的 Deploy 按钮，并检查你的 MetaMask 钱包当前是测试网络下的：环境选择 Injected Web3 来连接 MetaMask 钱包：连接完成后你就是合约创建者了：其他的油费之类的不用管，直接做合约的进阶配置，还记得我在前面源码中标了注释的参数吗？就是要填那些！展开：参数和其解释： 参数 解释 样例 _INITIALAMOUNT 发行总量（需要计算小数点位数）。 10000（100 个币，小数点后为 2 位） _TOKENNAME 币的名称。 SENJIANLU COIN _DECIMALUNITS 小数点位数。 2 _TOKENSYMBOL 币的简称。 SEN 填写完成，确定没问题后点击 transact 按钮：MetaMask 钱包会弹出并提示你部署这个合约需要的费用（没弹出的话请手动点击钱包）：确认之后，稍等片刻看见钱包内余额少了，说明部署成功了： Remix 的控制台内也会打印成功信息： 点击 MetaMask 中的 活动：点进刚刚的合约中，拉到下面点进最近的一条日志中：这里的 To 就是你创建的智能合约（发的币）的地址了，复制一下：把这个合约地址（可以理解为币的种类）导入钱包即可：成功：说一句，转账币的操作消耗的是发起者的 ETH，因此玩的话还请留点测试 ETH 在钱包中。 结束。","link":"/2021/12/28/bak_smart_contracts_note_02/"},{"title":"【归档文章】基于以太坊 ETH 的智能合约学习（二） 补足：CentOS7 下使用 Docker 部署 remix-ide 智能合约开发环境","text":"关于部署 Remix IDE 智能合约开发环境的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 如果你不喜欢官方的 Remix 或是想使用自己的域名来访问在线 Remix，那么就请继续看下去吧！我并不推荐使用 npm 的安装方式，一方面是麻烦，另一方面官方 GitHub 仓库文档也只介绍了 Docker 启动。况且不同于 code-server，Remix 上编写的智能合约脚本不怎么吃系统资源，不用考虑性能问题。 官方 GitHub 项目地址：ethereum/remix-ide 1、下载 Docker 容器镜像1docker pull remixproject/remix-ide:latest CentOS 服务器上没有安装过 Docker 的话，执行以下命令进行安装和启动： 1234yum -y install docker# 启动 Docker 服务和设置为开机自启动systemctl start docker.servicesystemctl enable docker.service 2、启动容器将容器内的 80 端口映射到宿主机的 8089 端口，并设置容器为开机自启动： 1docker run -d -p 8089:80 --name remix --restart=always remixproject/remix-ide:latest 3、配置域名访问和开启 HTTPS① 开启域名访问，我准备使用的域名是 remix.example.com，配置文件中的相关内容请自行替换。修改宿主机的 Nginx 配置文件： 1vi /etc/nginx/nginx.conf 新增如下内容： 1234567891011121314151617......server { listen 80; server_name remix.example.com; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; # 反代 8089 端口的 Remix location / { proxy_pass http://localhost:8089; }}...... 之后保存并重启 Nginx： 12nginx -s reloadservice nginx restart 之后去你域名服务商的 DNS 处解析域名到该服务器就 OK 了，访问一下看看：② 配置 SSL 证书以支持 HTTPS 访问 你可以选择申请 Let’s Encrypt 的免费 SSL 证书来开启 HTTPS，具体教程参考：Let’s Encrypt 证书的申请、自动更新和 Nginx 的配置当然你也可以套 Cloudflare 的 CDN 并开启 SSL/TLS 的灵活模式，以跳过繁琐的申请过程并使用由 Cloudflare 提供的免费证书。 修改 Nginx 的配置文件： 12345678910111213141516171819202122232425......server { listen 80; server_name remix.example.com; return 301 https://$host$request_uri;}server { listen 443 ssl; server_name remix.example.com; # SSL 配置 ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_certificate cert/remix.example.com_bundle.crt; ssl_certificate_key cert/remix.example.com.key; # 反代 8089 端口的 Remix location / { proxy_pass http://localhost:8089; }}...... 之后再用 HTTPS 协议访问试一下： 结束。","link":"/2021/12/30/bak_smart_contracts_note_02_supplement/"},{"title":"【归档文章】Rust 开服（一）Ubuntu18 下通过 LinuxGSM 搭建 Rust Server 游戏服务器端","text":"关于在 Rust（腐蚀）开服的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 LinuxGSM (Linux Game Server Managers) 是开源的 Linux 服务器游戏服务器开设工具，简单好用，可以节省大量时间因此选用。注：一般情况下我都是更倾向用熟悉的 CentOS7 系统，但是在尝试搭建一遍过后，卡在了 Yum 无法安装 Python3.6 的问题上，因此本教程选择 Ubuntu18 系统。 注意：最低的服务器配置需求为 2H4G，低于 4G 内存请不用尝试了。且如果你使用的是境内服务器，我推荐你设置好代理，以保证安装脚本能顺利的从 GitHub 下载所需文件： 1234# 仅供参考格式用export http_proxy=socks5://99999:22222@63.225.10.10:20800git config --global http.proxy socks5://99999:22222@63.225.10.10:20800git config --global https.proxy socks5://99999:22222@63.225.10.10:20800 如果你没有代理，也可以试试修改 hosts，但这并不能保证 100% 解决你的问题： 1vi /etc/hosts 123...···199.232.4.133 raw.githubusercontent.com 1、安装所需依赖和下载 LinuxGSM先更新软件源： 1sudo apt-get update &amp;&amp; sudo apt-get upgrade 接着安装 LinuxGSM 所需依赖： 1sudo dpkg --add-architecture i386; sudo apt update; sudo apt install curl wget file tar bzip2 gzip unzip bsdmainutils python util-linux ca-certificates binutils bc jq tmux netcat lib32gcc1 lib32stdc++6 libsdl2-2.0-0:i386 steamcmd lib32z1 官方文档推荐为每个游戏服务器都新建一个系统用户，我这里新建了 rustserver 用户： 12345678# 切换到 root 管理员用户下sudo su# 新建用户adduser rustserver# 修改密码passwd rustserver# 切换到这个用户su - rustserver 之后的操作都是在这个用户和 /home/rustserver 目录下执行的。 下载 LinuxGSM： 1234# 下载 LinuxGSMwget -O linuxgsm.sh https://linuxgsm.sh# 赋予其执行权限chmod +x linuxgsm.sh 2、安装 Rust 服务器准备服务器安装所需内容： 123bash linuxgsm.sh rustserver# 赋予其执行权限chmod +x rustserver 开始安装 Rust 服务器： 1./rustserver install 中途需要确认的地方输入 Y 回车即可（这里用的是 CentOS7 服务器的截图，可能和 Ubuntu18 有些不同，但是流程是一样的一路确定下去即可）：看到以下信息则说明安装完成： 3、配置 Rust 服务器配置文件的路径在安装日志中存在，因此直接拷贝即可。修改下服务器的描述信息： 1vi /home/rustserver/serverfiles/server/rustserver/cfg/server.cfg 123456......# A text description of your server. For a new line add: \\nserver.description &quot;Belong to senjianlu.com&quot;...... 修改游戏配置： 1234cd /home/rustserver/lgsm/config-lgsm/rustserver# 拷贝一份默认配置并覆盖当前的空配置文件cp _default.cfg rustserver.cfgvi rustserver.cfg 123456789101112131415161718192021222324252627......## Predefined Parameters | https://docs.linuxgsm.com/configuration/start-parameters# 允许所有 IP 地址连接此服务器ip=&quot;0.0.0.0&quot;# 服务器端口port=&quot;28015&quot;# 管理端口rconport=&quot;28016&quot;appport=28082# 管理员密码rconpassword=&quot;xxxxxxxxx&quot;rconweb=&quot;1&quot; # Value is: 1 for the Facepunch web panel, Rustadmin desktop and Rustadmin Online; 0 for RCON tools like Rusty.# 服务器名称servername=&quot;senjianlu&quot;gamemode=&quot;vanilla&quot; # Values: vanilla, softcore ( Doc: https://wiki.facepunch.com/rust/server-gamemodes )serverlevel=&quot;Procedural Map&quot; # Values: Procedural Map, Barren, HapisIsland, SavasIslandcustomlevelurl=&quot;&quot; # Custom level url. +server.levelurl \\&quot;${customlevelurl}\\&quot;seed=&quot;&quot; # range: 1-2147483647, used to reproduce a procedural map.salt=&quot;&quot; # range: unknown, used to recover a known setting from an existing map.# 最大玩家数maxplayers=&quot;10&quot;worldsize=&quot;3000&quot; # default: 3000, range: 1000-6000, map size in meters.saveinterval=&quot;300&quot; # Auto-save in seconds.tickrate=&quot;30&quot; # default: 30, range: 15-100....... 保存后此步结束。 4、启动服务器1234# 回到用户目录下cd /home/rustserver# 启动服务器./rustserver start 看到如下信息说明服务器启动完成： 几个需要注意的点：① 记得开发防火墙和安全组的对应端口，我这里贪省事直接关闭了防火墙： 1sudo ufw disable ② 服务器的启动需要时间，大概在 5 到 10 分钟左右。如何判断服务器是否启动成功可以通过监控，在 2H4G 的云服务器，RustDedicated 大概会吃 50% 的 CPU 资源和 90% 的内存资源，长时间稳定这个占用的话基本就算是启动成功了。③ 如果发现 kswapd0 长时间占用几乎 100% 的 CPU 资源，那说明你服务器的内存不足以启动 Rust 服务器，系统开始使用硬盘做虚拟内存了，你可以选择多花钱升级服务器的内存或者提前设置好虚拟内存供开服使用，教程在这里：CentOS7 下建立 SWaP 分区以增加虚拟内存（命令可以完全照搬，CentOS7 和 Ubuntu18.04 通用） 最后到游戏中，按下 F1 并输入： 12# IP 和端口自行替换connect 127.0.0.30:28015 连接到服务器即可！ 结束。","link":"/2021/09/24/bak_ubuntu18_rust_server_01/"},{"title":"【归档文章】IPLC 食用（一）wikihost（维基主机）家 IPLC 线路流量转发的使用体验","text":"关于 wikihost（维基主机）家 IPLC 线路流量转发。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 随着对延迟和防审查的要求越来越高，挪给代理这一块的预算也相应增多了，看了下 IPLC NAT 机器的价格感觉能接受了，于是决定开始升级个人用的代理节点了。这个系列单纯就用来记录我已经使用过一段时间的 IPLC 线路（机器）提供商，没有任何推荐或 AFF 内容，请确定好自己的需求并货比三家后再购买。 本章商家：wikihost（维基主机） 关于 IPLC 百科上的介绍：IPLC 是 “International Private Leased Circuit” 的缩写，即“国际私用出租线路”，是指用户专用的跨国的数据、话音等综合信息业务的通信线路。通俗地说，也就是指传统的专线，如 DDN、E1 等，用于互连两点之间的通信，只不过 IPLC 是跨国跨境的而已。 简单来讲就是点到点的不过墙线路，延迟、隐私保护都极为优秀。 1、价格信息注意：维基家的流量转发计价方式为一次性设置费 + 流量按量付费 + 端口占用费，而带宽方面 IPLC 转发均为 80 Mbps。① 一次性设置费（高价版本每个月会赠送一点 IPLC 流量）：② IPLC 流量费用：③ 端口占用费： 2、配置（流量转发）注意：需要自备落地（即提前准备好搭建了代理服务的境外服务器）​购买后在产品和服务处选择流量转发服务，点击管理产品：选择添加 IPLC 转发：假设你有一个 SOCKS5 代理运行在 13.233.150.148 服务器的 2222 端口上，那么如下配置即可（除了 HTTP 代理其他全支持转发）： 协议处可选 TCP 和 UDP，如果都选择了则会分别产生一条转发规则，端口占用收费会翻倍。 创建需要一点时间：趁这个时间我们查看一下转发规则：使用方式则很简单，本来你是使用如下代理信息的： 1234567import requestsproxies = { &quot;http&quot;: &quot;socks5://username:password@13.233.150.148:2222&quot;, &quot;https&quot;: &quot;socks5://username:password@13.233.150.148:2222&quot;,}r = requests.get(&quot;https://google.com&quot;, proxies=proxies) 直接将 13.233.150.148:2222 替换为 211.xx.xxx.xx:49333（IPLC 转发规则内的地址）即可： 12345678import requests# IPLC 转发proxies = { &quot;http&quot;: &quot;socks5://username:password@211.xx.xxx.xx:49333&quot;, &quot;https&quot;: &quot;socks5://username:password@211.xx.xxx.xx:49333&quot;,}r = requests.get(&quot;https://google.com&quot;, proxies=proxies) 你的请求会直接到 211.xx.xxx.xx 这台境内服务器，然后走隧道过墙直达 Google。 3、使用体验① 价格方面设置费略贵，至少要花 150 才能使用 IPLC 线路，不过每个月赠送流量还是蛮好评的，虽然没多少，但是不看视频只查文档的话一个月 500 MB 是基本用不完的，这是我的购买日期：在 Clash 中配置了这条线路只接管 Google 和 GitHub 相关服务的流量，截至 12 月 28 日：总共 3 个月花 9 块钱。② 使用方面除了 HTTP 外的代理协议全支持，并且晚高峰也绝对稳定。Python3 100 次对 Google 的爬取：YouTube 1080p 分辨率下秒加载：准确的延迟测量等有了专业工具再补。 本章结束。","link":"/2021/12/26/bak_vps_iplc_01/"},{"title":"【归档文章】VS Code 使用 Remote 连接服务器并 Push 到 GitHub 私有仓库时报错：Missing or invalid credentials. 的解决办法","text":"关于 Remote 开发时解决 Git Push 问题的记录。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 1、错误信息123456789101112131415161718Missing or invalid credentials.Error: connect ECONNREFUSED /run/user/0/vscode-git-02xxxeed11.sock at PipeConnectWrap.afterConnect [as oncomplete] (net.js:1146:16) { errno: -111, code: 'ECONNREFUSED', syscall: 'connect', address: '/run/user/0/vscode-git-02xxxeed11.sock'}Missing or invalid credentials.Error: connect ECONNREFUSED /run/user/0/vscode-git-02xxxeed11.sock at PipeConnectWrap.afterConnect [as oncomplete] (net.js:1146:16) { errno: -111, code: 'ECONNREFUSED', syscall: 'connect', address: '/run/user/0/vscode-git-02xxxeed11.sock'}remote: Repository not found.fatal: Authentication failed for 'https://github.com/username/repo.git/' 2、解决办法参考文章：Git push: Missing or invalid credentials. fatal: Authentication failed for ‘https://github.com/username/repo.git'① 依次选择：文件 -&gt; 首选项 -&gt; 设置② 搜索 git.terminalAuthentication 并取消勾选：③ 重启 VS Code 并重新 Push： 这样操作之后有一个坏处，就是你 VS Code 对 GitHub 认证信息保存的功能会失效，你的每次 Push 都必须输入用户和密码。 结束。","link":"/2021/11/14/bak_vscode_github_push_error/"},{"title":"【归档文章】IPLC 食用（二）PittQiao（彼得巧）家苏日 IPLC 线路 NAT 主机的使用体验","text":"关于 PittQiao（彼得巧）家苏日 IPLC 线路 NAT 主机。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 主职是日本客户做开发的，公司提供了专线因此个人服务器基本也都买在日本了，再加上现在住在江苏，考虑专门上一条 IPLC 专线来连接个人服务器，就相中了这款苏州到日本的 IPLC 线路 NAT 主机。彼得巧也算老商家了，19 年就看到了他们家无锡到日本的 IPLC 线路，可惜那个时候工资少，也没这需求，这下也算了却心愿了吧。 本章商家：PittQiao（彼得巧） 1、价格信息因为是 NAT 主机因此只需要按月付费即可，流量超额可以 Telegram 联系客服免费重置。我购买的是“蘇➜日 | SUTYO-5M-NAT”这款，使用折扣码大概是打 92 折左右，差不多 180 多一点一个月：他家其他的 IPLC NAT 云基本也都是 200 多的价格 5M 到 10M 的带宽，自行挑选：购物车 2、配置购买后等个审核（发工单可加速）：审核完成后点开详细，NAT 主机的连接信息在如下位置：IPIP 查看发现用来连接服务器的 IP 是苏州的：而连接服务器后，使用如下命令测试一下出口 IP： 1curl http://ip-api.com/json/?lang=zh-CN 可以发现已经是境外出口 IP 了。之后的操作就随你了，在 iptables 上配置端口转发来中转流量到自己其他服务器上的代理，或者是直接在该 NAT 机器上安装代理软件都可以。我这边就直接装 GOST 配置 SOCKS5 代理了（白嫖出口 IP），用的是我自己写的一键脚本： 1curl -s https://gitee.com/senjianlu/one-click-scripts/raw/main/CentOS7%20下一键安装%20GOST%20并启动%20HTTP%20和%20SOCKS5%20代理服务/install.sh | bash 之后在服务器上测试启动一下 GOST，注意代理端口必须是分配给你的那 10 个中的某一个： 1gost -L username:password@:11899 在境内服务器上连接测试一下： 1curl -x http://username:password@42.xxx.xx.xxxx:11899 http://ip-api.com/json/?lang=zh-CN 正常，连接的是 IPLC 主机境内的 IP 而出口则是东京的 IP： 如果无法连接到代理且显示如下错误： 1curl: (7) Failed connect to 42.xxx.xx.xxxx:11899; Connection refused 那么你需要遵循如下步骤：① 关闭 SELinux，编辑 /etc/selinux/config 文件： 1vi /etc/selinux/config 将 SELINUX=enforce 改为 SELINUX=disabled，之后重启。② 关闭防火墙： 123systemctl stop firewalld.service# 禁止开机自启动systemctl disable firewalld.service 之后就能正常访问代理了。 3、使用体验① 价格方面个人用略贵，有产出另说。② 使用方面虽然写了禁止看视频，但实际是可以看的，YouTube 1080p 分辨率下秒加载：延迟方面，到境内那个 IP 的延迟实际上就是到东京出口的延迟了，50 ms 不错： 结束。","link":"/2021/12/29/bak_vps_iplc_02/"},{"title":"【归档文章】VS Code 使用需要认证的 SOCKS5 代理通过 Remote - SSH 连接远程服务器进行开发","text":"关于使用需要认证的 SOCKS5 代理连接 VS Code Remote 开发机器的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 本来是很简单的一件事情，追求新版本又把自己坑了一次……留个记录稍微描述详细一点，希望能帮到你。 参考的文章：「VS Code」如何通过跳板机连接服务器进行远程开发：Remote-SSH 篇 1、VS Code Remote - SSHVS Code 中 Remote - SSH 的安装和使用都很简单，就一步带过了。在插件库中搜索安装：新建连接：选择 SSH 配置存放和读取路径：接下来就是输入密码登录服务器，自行操作即可，但是如果你需要密钥登录，请跟着步骤 2 进行配置。 2、进行 SSH 密钥登录的配置和代理的配置进入刚刚所选 SSH 配置存放的目录，一般是 C:\\Users\\你的用户名\\.ssh 这个路径。选择编辑 config 文件，密钥和代理的配置参照我设置即可： 12345678910# Host 为服务器别名，可以和 HostName 一样Host $server_host # 你的服务器域名或 IP HostName $server_host # 用户 User $user # SSH 私钥地址，例如：C:\\Users\\你的用户名\\.ssh\\example IdentityFile $ssh_primary_key$path # 代理配置 ProxyCommand C:\\bin\\nmap\\ncat.exe --proxy-type socks5 --proxy $proxy_host:$proxy_port %h %p --proxy-auth $proxy_auth_username:$proxy_auth_passwod 代理的配置详细说一下，也是我踩坑的地方。下载压缩包后解压到任意目录，然后替换上面 C:\\bin\\nmap\\ncat.exe 的路径即可。虽然官方文档中明确记载了代理认证信息的配置方法，但是经过实测在当前最新版本：nmap-7.91-win32.zip 下是不支持的，VS Code 具体错误日志： 1234567891011121314151617181920[01:09:46.557] Running script with connection command: ssh -T -D 13100 &quot;example.com&quot; bash[01:09:46.559] Terminal shell path: C:\\Windows\\System32\\cmd.exe[01:09:46.742] &gt; \u001b]0;C:\\Windows\\System32\\cmd.exe\u0007[01:09:46.742] Got some output, clearing connection timeout[01:09:47.447] &gt; kex_exchange_identification: Connection closed by remote host[01:09:47.454] &gt; 过程试图写入的管道不存在。[01:09:48.732] &quot;install&quot; terminal command done[01:09:48.732] Install terminal quit with output: 过程试图写入的管道不存在。[01:09:48.732] Received install output: 过程试图写入的管道不存在。[01:09:48.733] Failed to parse remote port from server output[01:09:48.733] Resolver error: Error: at Function.Create (c:\\Users\\my_user\\.vscode\\extensions\\ms-vscode-remote.remote-ssh-0.65.7\\out\\extension.js:1:64659) at Object.t.handleInstallOutput (c:\\Users\\my_user\\.vscode\\extensions\\ms-vscode-remote.remote-ssh-0.65.7\\out\\extension.js:1:63302) at Object.t.tryInstall (c:\\Users\\my_user\\.vscode\\extensions\\ms-vscode-remote.remote-ssh-0.65.7\\out\\extension.js:1:415135) at processTicksAndRejections (internal/process/task_queues.js:93:5) at async c:\\Users\\my_user\\.vscode\\extensions\\ms-vscode-remote.remote-ssh-0.65.7\\out\\extension.js:1:294918 at async Object.t.withShowDetailsEvent (c:\\Users\\my_user\\.vscode\\extensions\\ms-vscode-remote.remote-ssh-0.65.7\\out\\extension.js:1:406463) at async Object.t.resolve (c:\\Users\\my_user\\.vscode\\extensions\\ms-vscode-remote.remote-ssh-0.65.7\\out\\extension.js:1:295994) at async c:\\Users\\my_user\\.vscode\\extensions\\ms-vscode-remote.remote-ssh-0.65.7\\out\\extension.js:127:110656[01:09:48.736] ------ 这种情况似乎只会在 VS Code 中出现，我在命令行中尝试连接时没有问题： 12C:\\Users\\my_user&gt;ssh root@example.com ProxyCommand=&quot;C:\\bin\\nmap-7.91\\ncat.exe --proxy-type socks5 --proxy example.proxy:1080 %h %p --proxy-auth 111:222&quot;root@example.com: Permission denied (publickey,gssapi-keyex,gssapi-with-mic). 而解决方法则只有一个，回退版本，和参考的教程中使用同样的版本：nmap-7.70-win32.zip这个问题的解决单纯就是试出来的，暂时也没有功夫去探究错误的原因，可能也只是个例，Stack Overflow 的个别讨论也都是纠结配置方法的问题，事实上格式官方已经给了，参考意义都不是很大。如果回退依然没有解决你的问题的话，在确保 SSH 不适用代理能访问的前提下，使用以下代码去排查下： 1lastb -n 100 在服务器运行，查看最近受阻的 100 次 SSH 登录，看客户端到服务器是否打开过连接，再做下一步的判断。 结束。","link":"/2021/07/24/bak_vscode_remote_ssh_use_proxy_with_auth/"},{"title":"【归档文章】Windows11 抢先体验 Android 虚拟机并安装第三方应用","text":"关于在 Windows11 使用 Android 虚拟机的教程。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 1、将系统地区切换至美国并开启虚拟化因为是系统层面的配置因此放在一起讲。① 设置 -&gt; 时间和语言 -&gt; 语言 &amp; 区域 -&gt; 国家或地区 -&gt; 切换到美国 不切换地区结果如下： ② 开启 Windows 虚拟化这里只需要开启 Windows 虚拟机监控程序平台 和 虚拟机平台 就够了，没有 Hyper-V 不勾选也没有关系，对实际运行不会有影响： 2、安装安卓子系统当前在微软商店安装 Amazon Appstore 会自动帮你下载安卓子系统，考虑到我已经在路由器上配置了代理，能正常访问亚马逊服务，便采用这个较为官方的方式： 如果你并不想安装 Amazon Appstore，并且后续只准备在安卓虚拟机中安装一些有 .apk 安装文件提供的国产应用，那么也可以直接前往：Windows Subsystem for Android™ with Amazon Appstore 进行下载： 3、配置安卓子系统打开其系统设置：配置需做如下修改： ① 将子系统资源改为连续以进行第三方应用安装（安装完之后可改回按需要）② 开启开发人员模式并记录下连接用的信息 4、从 .apk 文件安装应用这里就不演示从官方 Amazon Appstore 安装应用了，没有意义。我需要安装的网易 UU 加速器，用来控制同一网络环境下 OpenWrt 上的 UU 加速器路由器插件，以此为例。 ① 从官方下得安装文件 ② 下载安装 ADB 工具 官方描述：Android SDK Platform Tools 是 Android SDK 的一个组件。它包含与 Android 平台进行交互的工具，例如 adb、fastboot 和 systrace。开发 Android 应用时需要使用这些工具。如果您想要解锁设备的引导加载程序并为其刷入新的系统映像，同样需要使用这些工具。 下载地址：platform-tools-latest-windows.zip将解压后的文件夹移至任意位置： ③ 使用 ADB 连接安卓虚拟机在 ADB 工具包目录下启动 Windows 终端，并连接至安卓虚拟机（地址为你开启开发人员模式时记录的那个）： 1234# 查看当前是否有能连接的设备adb devices# 连接至安卓虚拟机adb connect 127.0.0.1:58526 ④ 安装应用找到你 .apk 存放的路径并作为参数传入： 1.\\adb install C:\\Users\\m112233\\Downloads\\uu-6.2.6.1115.apk 完成后，就能在你最近添加的项目处看见了：正常打开没有问题： 之后你可以把地区改回中国、虚拟机子系统改回按需求（这样 Android 虚拟机不会一直在后台运行着）。再安装其他软件时如果出现连不上虚拟机的问题，需要将步骤 3 的配置重新做一遍。​ 结束。","link":"/2021/11/19/bak_windows11_android/"},{"title":"【归档文章】Windows11 时钟 Clock 的使用体验","text":"关于 Windows11 中 Clock 的使用技巧及实际体验。 注：这篇文章是从旧的博客系统中迁移过来的、我觉得还存在价值的文章。但是由于时间关系，可能已经不再是最佳实践，请仅作参考。 才发现 Windows11 添加了时钟应用，自带专注时段（可以直接理解为番茄时间）的规划功能，对于一直以来只有较大任务计划而导致在碎片时间内无法集中注意力的我来说简直是神器，趁着周末体验一下。 把一些基础设置的步骤一并放上，使用的体验感受会放在结尾。 1、启用时钟开始菜单搜索 “时钟” 或者 &quot;Clock&quot; 应该都可以： 2、规划专注时段首页显示的番茄工作法的总时常，默认规划为：每工作 30 分钟左右休息 5 分钟通过点击 视图设置 来自定义：修改休息周期即可： 3、链接 Spotify 微软商店安装 Spotify 需要先将地区切换至美国： 点击 链接 Spotify 并登录、同意即可：链接完成后默认会推送一些轻音乐，右键播放后仍可以在 Spotify 应用内控制： 4、启用待办事项（Windows To Do）Windows To Do 实际为另一个应用，因此需要先登录以同步数据：可能会存在卡加载的问题，没关系看到任务栏出来了就 OK 了：你可以直接在任务栏添加任务：也可以在 Windows To Do 添加，两边会同步的： 5、使用感受可能是有新鲜感加持的原因，体验很棒！Windows11 的时钟很适合小任务的划分，以手头我正在开发的项目为例：Notion 以整个项目为大任务，其中各子模块为中任务，子模块中的每一个功能开发或是优化为小任务：通过番茄工作法，即使是 90 分钟的时间也能有规划的去推进进度，这对于自制力并不是那么强的我真的是很有帮助。题外话，从 WSL 到 WSL2 的优化、对安卓虚拟机的原生支持，再到我发掘到这个时钟应用，我开始发现微软作为开发者，其实是最懂开发者需要什么的，只是取决于他们是否愿意去做那些功能罢了，感觉 MacBook 的购买计划又可以往后延延了…… 结束。","link":"/2021/12/05/bak_windows11_clock/"},{"title":"CLF - 备考（学习）笔记","text":"AWS Certified Cloud Practitioner CLF-C02 考前（学习）笔记。由于考试较为简单，因此不再提炼知识点而是统一记录。 学习资料： AWS Skill Builder 模块 1: AMAZON WEB SERVICE 简介一、基本概念 三种部署模式：云、私有和混合云部署。 在 AWS 的考试中，云计算特指采用随用随付定价模式，通过互联网按需交付 IT 资源和应用程序。 模块 2: 云中的计算一、基本概念 垂直缩放：随时增大、减小服务器的资源。 可扩展性：仅从您需要的资源开始，并且设计架构以便自动扩展和缩减，从而响应不断变化的需求。 提供此功能的 AWS 服务是 Amazon EC2 Auto Scaling。 紧密耦合架构：单个组件发生故障/变化，会导致其他组件、甚至整个架构发生故障。 松散耦合架构：单个故障不会导致级联故障。 无服务器计算：一词是指您的代码在服务器上运行，但您无需预置或管理这些服务器。 AWS 的无服务器计算服务是 AWS Lambda。 二、Amazon EC2 实例类型 通用型：在计算、内存和联网资源上平衡。 计算优化型：适合计算密集型任务，提供了高性能处理器 (CPU)。适合充当游戏服务器、进行高性能计算 (HPC) 或科学建模。 内存优化型：适合内存密集型任务。适合部署高性能数据库。 加速计算型：使用了硬件加速器（往往是 GPU 等）。适合进行浮点数计算、图形处理或数据模式匹配。 存储优化型：适合数据存储（与其对应的高性能处理）任务。 三、Amazon EC2 定价 按需付费：只需要按使用时间付费。 EC2 实例 Savings Plans：承诺使用 1 或 3 年的 EC2 实例，并做出每小时支付承诺。最高可节省 72% 的成本。 关键词：实例系列、区域。 预留实例：承诺使用 1 或 3 年的 EC2 实例。最高可节省 75% 的成本。三种付款方式： 预付全部费用 预付部分费用 不预付 关键词：实例系列和大小、平台描述（系统）​、租赁、区域。（比 EC2 实例 Savings Plans 更为详细。） Spot 实例：不稳定的实例，Amazon 会随时停止该实例并只提前 2 分钟进行警告。最高可节省 90% 的成本。 专用主机：Amazon EC2 实例容量完全供您专用的物理服务器。往往处于合规性要求。 四、扩展 Amazon EC2 Amazon EC2 Auto Scaling：可扩展性 自动添加或删除 Amazon EC2 实例，以响应不断变化的应用程序需求。 五、利用 Elastic Load Balancing (ELB) 引导流量 Elastic Load Balancing (ELB)​：可在多个资源（例如 Amazon EC2 实例）之间自动分配应用程序的传入流量（负载均衡）。 是区域性服务（结构）。虽然 Elastic Load Balancing 和 Amazon EC2 Auto Scaling 是独立的服务，但它们可以协同工作，提供高性能和高可用性。具体表现为：流量变大，实例上线开始被分流，流量减少截断对实例的分流，实例开始下线。 六、消息收发和队列 Amazon Simple Queue Service (Amazon SQS)​：在软件/组件之间，发送、存储和接收任何容量的消息。自动扩展。 Amazon SQS 队列：消息被接受前所处的位置。 Amazon Simple Notification Service (Amazon SNS)​：是发布/订阅模式的服务，发布者使用 Amazon SNS 主题 将消息发布给订阅者，订阅者可以是 Web 服务器、电子邮件地址（终端用户）、AWS Lambda 函数或其他一些选项。 Amazon SNS 主题：分发消息的通道。 七、其他计算服务 AWS Lambda：无服务器计算 服务触发设定的事件源时运行指定代码。​代码的最长运行时长为 15 分钟。只需为使用的计算时间付费。 Amazon Elastic Container Service (Amazon ECS)​：Docker 容器编排工具 高度可扩展的高性能容器管理系统，让您可以在 AWS 上运行和扩展容器化应用程序。 注意 ECS 仅仅是编排工具，还需要搭配容器运行的平台 EC2 或 Fargate。 Amazon Elastic Kubernetes Service (Amazon EKS)​：Docker 容器编排工具 一项完全托管式服务，可用于在 AWS 上运行 Kubernetes。 注意 EKS 仅仅是编排工具，还需要搭配容器运行的平台 EC2 或 Fargate。 AWS Fargate：适用于容器的无服务器计算环境（引擎）。 它可与容器编排工具 Amazon ECS 和 Amazon EKS 一起使用。 模块 3: 全球基础设施和可靠性一、基本概念 区域：AWS 的基础设施分布在全球多个区域中，每个区域都是一个独立的地理区域，由多个可用区组成。 区域性服务 是区域层级的高度可用服务。 可用区：一个区域内有 1 个或多个可用区，而一个可用区内有 1 个或多个分离的数据中心。 可用区彼此相距数十英里，这个距离足够近，可以在可用区之间实现低延迟（请求内容与接收内容之间的时间）。但是，如果区域内的某个部分发生灾难，这个距离又足够远，可以降低多个可用区受到影响的几率。 区域数据主权：对数据的处理需要遵守所在区域的法律法规，数据和应用程序都在某个区域中驻留并运行。 内容分发网络 (CDN)​：是一种服务，可将内容缓存到位于全球各地的边缘位置，以便更快地向最终用户提供内容。 AWS 上的内容分发网络服务是 Amazon CloudFront。 AWS 最佳实践：至少在两个可用区中部署基础设置，以确保高可用性。 二、AWS 全球基础设施 合规性（遵守数据监管和法律要求）​：是区域选择的重要因素。 与客户的距离：选择靠近客户的区域可以帮助您更快地向客户分发内容。例如，您的公司总部位于华盛顿特区，但您的许多客户都居住在新加坡。您可以考虑在离公司总部较近的弗吉尼亚北部区域运行基础设施，在新加坡区域运行应用程序。 区域内的可用服务：有可能最近的 AWS 区域不支持您想要为客户提供的所有功能。 定价：服务的成本可能会因区域而有所不同。 三、边缘站点 Amazon CloudFront：内容分发网络 (CDN) 将缓存的内容副本存储在更靠近客户的位置（边缘站点），以便加快分发速度。 边缘站点：与 区域 是分开的。 AWS Outposts：AWS 服务和基础设施扩展到本地的数据中心、办公室或合作伙伴设施中。 四、如何预置（操作） AWS 资源与 AWS 服务交互的方式： AWS 管理控制台：基于 Web 的界面，用于访问和管理 AWS 服务。 AWS Command Line Interface (AWS CLI)​：通过命令行控制多项 AWS 服务。 借助使用 AWS CLI，可以通过脚本自动执行服务和应用程序执行的操作。 软件开发工具包 (SDK)​：SDK 通过为各编程语言或平台设计的 API，使用户能更轻松地使用 AWS 服务。 进阶工具： AWS Elastic Beanstalk：通过提供的应用程序代码和预期配置设置，创建和管理基于 EC2 的环境。 Elastic Beanstalk 会负责部署执行以下任务所需的资源： 调整容量 负载均衡 弹性伸缩 应用程序运行状况监控 AWS CloudFormation：基础设置即代码工具，用于定义各种 AWS 资源。通过 JSON 或 YAML 模板定义 AWS 资源，然后使用该 AWS CloudFormation 模板 创建和管理这些资源。 可以在多个 AWS 账户和区域中重复使用 AWS CloudFormation 模板。 模块 4: 联网一、基本概念 Amazon Virtual Private Cloud (Amazon VPC)​：虚拟私有云，是区域内的逻辑隔离部分。 Amazon VPC 可以进一步分为 子网。 二、与 AWS 的连接 互联网网关：互联网网关是 VPC 和互联网之间的连接。 要允许来自互联网的公共流量访问您的 VPC，可以在 VPC 中附加互联网网关。 虚拟私有网关：是允许受保护的互联网流量进入 VPC 的组件。 借助虚拟私有网关，您可以在您的 VPC 和私有网络（例如本地数据中心或企业内部网络）之间建立虚拟专用网络 (VPN) 连接。虚拟私有网关仅允许来自经批准的网络的流量流入 VPC。 AWS Direct Connect：是一项 AWS 服务，让您能够在数据中心和 VPC 之间建立专用私有连接。 企业数据中心（通过访问客户或合作伙伴路由器）将网络流量（经过 AWS 的隧道）路由到 AWS Direct Connect 站点，然后这些流量通过虚拟私有网关路由到 VPC。企业数据中心和 VPC 之间的所有网络流量都要流经这个专用私有连接。 三、子网和网络访问控制列表 网络 ACL：用于在 子网 级别控制入站和出站流量的虚拟防火墙。 账户默认的 网络 ACL 允许所有入站和出站流量。 无状态数据包筛选：网络 ACL 执行无状态数据包筛选，它们不会保留任何记忆，无论数据包是通过入站还是出站方式跨越子网边界，它们均会对其进行检查。 request 和对应的 response 会被处理 2 次。 安全组：可控制 Amazon EC2 实例的入站和出站流量的虚拟防火墙。 默认情况下，安全组会拒绝所有入站流量。 有状态数据包筛选：安全组执行有状态数据包筛选，它们会记住之前对传入数据包的处理方式。 request 和对应的 response 只会被处理 1 次。 四、全球联网 Amazon Route 53：是一项 DNS Web 服务，它不仅可以将用户请求连接到在 AWS 中运行的基础设施（如 EC2 实例和负载均衡器），还可以将用户路由到 AWS 以外的基础设施。 Amazon Route 53 还提供域名注册和转移服务。 域名系统 (DNS)​：DNS 解析是将域名转换为 IP 地址的过程。 模块 5: 存储和数据库一、基本概念 关系数据库：在关系数据库中，数据的存储方式是将其与数据的其他部分相关联。关系数据库使用结构化查询语言 (SQL) 来存储和查询数据。 提供关系数据库托管的服务是 Amazon Relational Database Service。 非关系数据库：NoSQL 数据库，数据结构简单、灵活。非关系数据库的一种结构方法是键值对，可以随时在表中添加或删除项目的属性。 提供非关系数据库托管的服务是 Amazon DynamoDB。 二、实例存储和 Amazon Elastic Block Store (Amazon EBS) 实例存储：是为 EC2 提供的临时性块级存储，与该实例相同的生命周期。 实例存储以物理方式连接到主机，当实例终止时，实例存储中的所有数据也将丢失。 Amazon Elastic Block Store (Amazon EBS)​：可用区 级别的、持久性块级存储卷的服务（外部虚拟硬盘）。 要创建 EBS 卷，需要定义卷大小、类型等配置，之后将它附加到 EC2 实例上。EC2 实例需要和 EBS 位于同一可用区。有别于后续会提到的 EFS 弹性文件系统，它不会自动扩展，磁盘的空间用完了就是用完了。 Amazon EBS 快照：对 EBS 卷的数据进行增量备份。 仅第一次备份复制所有数据，后续仅保存和上一次备份相比有更改的数据块。 三、Amazon Simple Storage Service (Amazon S3) 对象存储：每个对象都由数据、元数据和键组成。 数据：可能是图片、视频、文本文档或任何其他类型的文件。 元数据：包含有关数据是什么、如何使用数据和对象大小等的信息。 对象键：对象的唯一标识符。 Amazon Simple Storage Service (Amazon S3)​：是对象级存储的服务，Amazon S3 将数据作为对象存储在（多个）存储桶中。 对象的最大文件大小为 5TB。 支持版本控制。 支持权限控制。 Amazon S3 存储层（类）​：使用前需要确定检索数据的频率、需要的数据可用性。 ⭐ Amazon S3 Standard（S3 标准存储） 适合托管静态网站。 专为频繁访问的数据而设计 将数据存储在至少三个可用区中 ⭐ S3 Standard-Infrequent Access (S3 Standard-IA)（S3 标准 - 不频繁访问存储） 适合存储备份、灾难恢复文件。 适合存储不频繁访问的数据 存储价格较低 检索价格较高 将数据存储在至少三个可用区中 ⭐ S3 Glacier Flexible Retrieval 非常适合用于数据归档，如保存审计数据等。 低成本存储，专为数据归档而设计 能够在几分钟到几小时内完成对象检索 支持使用 S3 Glacier 文件库锁定，进行类似“一写多读 (WORM)”的策略来防止将来被编辑 S3 One Zone-Infrequent Access (S3 One Zone-IA) 足够便宜，适合存储你可以（接受丢失）轻松重现的数据。 存储价格更低，低于 Amazon S3 Standard-IA 将数据存储在单个可用区中 S3 Glacier Instant Retrieval 适用于需要立即访问的归档数据 可在数毫秒内检索对象 S3 Intelligent-Tiering Amazon S3 会监控对象的访问模式：30 天没有访问的对象转移至 S3 Standard-IA，而如果你又重新访问了不频繁访问层的数据，这些对象又会被移动到 S3 Standard。 非常适合存储访问模式未知或不断变化的数据 每个对象每月会产生少量的监控和自动化费用 S3 Glacier Deep Archive 适合保存每年只访问一两次的数据，数据检索时间为 12 小时到 48 小时。 成本最低的对象存储类，非常适合用于归档 能够在 12 小时内检索对象 将数据存储在至少三个可用区中 S3 Outposts 非常适合具有本地数据驻留要求的工作负载。 在 Amazon S3 Outposts 上创建 S3 存储桶 可让您更轻松地在 AWS Outposts 上检索、存储和访问数据 Amazon S3 生命周期管理：在存储层（类）之间自动移动数据。 四、Amazon Elastic File System (Amazon EFS) 文件存储：多个客户端（例如用户、应用程序和服务器等）可以访问存储在共享文件夹中的数据。存储服务器使用块存储和本地文件系统来组织文件；客户端通过文件路径访问数据。 Amazon Elastic File System (Amazon EFS)​：可扩展的文件系统。 区域 级别的资源。 它将数据存储在多个可用区中。 自动扩展和缩减。 支持多个实例同时读写。 真正的 Linux 文件系统。 本地服务器可以使用 AWS Direct Connect 访问 Amazon EFS。 五、Amazon Relational Database Service (Amazon RDS) Amazon Relational Database Service：支持自动修复、备份、冗余、故障转移和灾难修复的数据库托管服务。 支持的数据库引擎： Amazon Aurora PostgreSQL MySQL MariaDB Oracle Database Microsoft SQL Server Amazon Aurora：企业级关系数据库，兼容 MySQL 和 PostgreSQL 数据库引擎。多数据副本、支持添加更多的只读副本；支持备份到 S3；支持时间点恢复。 六、Amazon DynamoDB Amazon DynamoDB：键值（结构简单的数据）数据库、无服务器服务。数据结构像是 MongoDB。 拥有巨大的吞吐能力。 在任意规模实现不超过 10 毫秒的延迟。 同时会随着数据库大小进行缩减或扩展，适合用于在扩展时需要高性能的使用案例。 精细的 API 访问权限控制。 七、Amazon Redshift Amazon Redshift：数据仓库服务，可用于大数据分析。 适合从多个源收集数据，并了解数据中的关系和趋势。 八、AWS Database Migration Service AWS Database Migration Service (AWS DMS)​：在源数据库和目标数据库之间迁移关系数据库、非关系数据库和其他类型的数据存储。 在迁移期间，源数据库保持运行。支持持续复制（备份）到另一个数据库。 九、其他数据库服务和加速器其他数据库服务： Amazon DocumentDB：文档数据库服务，支持 MongoDB 工作负载。 MongoDB 是一个文档数据库程序。 Amazon Neptune：图数据库服务。 使用 Amazon Neptune 构建和运行使用高度互联数据集的应用程序，例如推荐引擎、欺诈侦测和知识图谱。 Amazon Quantum Ledger Database (Amazon QLDB)​：不可变记录系统，分类账数据库服务。 用 Amazon QLDB 查看对应用程序数据进行的所有更改的完整历史记录。 Amazon Managed Blockchain：让您可以通过开源框架创建和管理区块链网络。 区块链是一种分布式分类账系统，可让多方在没有中央授权的情况下运行交易和共享数据。 加速器（缓存解决方案）： Amazon ElastiCache：在数据库上添加缓存层，支持两种类型的数据存储：Redis 和 Memcached。 缩短常见请求的读取时间。 Amazon DynamoDB Accelerator (DAX)​：适用于 DynamoDB 的内存中的缓存。 它有助于将响应时间从个位数毫秒级缩短到微秒级。 模块 6: 安全性一、基本概念 AWS 责任共担模式： AWS 最佳实践： 不使用 根用户 来执行日常任务，而是使用根用户来创建您的首个 IAM 用户，并为其分配权限来创建其他用户。 为需要访问 AWS 的每个人创建单独的 IAM 用户​。即使的多位员工需要相同级别的访问权限，也应该为每位员工创建单独的 IAM 用户。 IAM 角色 非常适合用于需要临时授予（而不是长期授予）​对服务或资源的访问权限的情况。 关于 AWS Organizations 的作用范围：在 AWS Organizations 中，可以将服务控制策略 (SCP) 应用于组织根账户、单个成员账户或 OU。SCP 可影响账户中的所有 IAM 用户、组 和 角色，包括 AWS 账户根用户。 拒绝服务攻击 (DoS)​：蓄意让用户无法使用某个网站或应用程序。 分布式拒绝服务攻击 (DDoS)​：攻击者使用多个源发起攻击，旨在使网站或应用程序不可用。 常见的攻击方式： UDP 泛洪：攻击者向公共服务用被攻击服务器的信息请求大量 UDP 数据包。 可以使用 安全组 阻止 UDP 泛洪攻击和反射攻击等带来的非法流量。 HTTP 级别攻击：攻击者用僵尸机器向服务器发送大量 HTTP 请求。 SLOWLORIS 攻击：攻击者与服务器建立大量半开连接，使服务器无法接受新连接。 可以使用 Elastic Load Balancing 来帮助防御 SLOWLORIS 攻击，因为 ELB 需要收到整个消息后才会转发请求。提供 DDoS 防御的服务是 AWS Shield。 二、AWS 责任共担模式 客户确保云中的安全性：确保创建并放入 AWS 云中的所有内容的安全性（包括权限和授权方式等）。 您采取的安全措施取决于以下因素：您使用的服务、系统的复杂程度以及公司的特定运营和安全需求等。措施包括选择、配置和修补将在 Amazon EC2 实例上运行的操作系统、配置安全组和管理用户账户。 AWS 确保云本身的安全性 三、用户权限和访问 AWS 账户根用户：可以使用和控制账户中的所有资源。要登录 根用户，需要使用创建 AWS 账户时所用的电子邮件地址和密码登录。 AWS Identity and Access Management (IAM)​：用来管理对 AWS 服务和资源的访问。 IAM 用户：默认没有任何权限，甚至无法登录。是一个由名称和凭证组成的身份，代表与 AWS 服务和资源交互的人员或应用程序。 IAM 策略：一个用于允许或拒绝对 AWS 服务和资源的权限的 JSON 文档。 IAM 组：是 IAM 用户 的集合。当您为某个组分配 IAM 策略 时，该组内的所有用户都会获得该策略指定的权限。 IAM 角色：IAM 角色 是一种身份，可以通过担任这种身份来获得临时权限。 当某人担任某个 IAM 角色时，他们会放弃在先前角色下拥有的所有权限，并获得新角色的权限。 四、AWS Organizations AWS Organizations：可以使用它在一个中心位置整合和管理多个 AWS 账户。 默认一个企业中允许的最大账户数为 4。 集中管理所有 AWS 账户。 按层次结构对账户进行分组。 通过服务控制策略 (SCP) 集中控制组织中账户的权限。 整合账单。 有机会享受批量折扣。 组织单元 (OU)​：在 AWS Organizations 中，可以将账户分组到组织单位中，更轻松地管理具有类似业务或安全性要求的账户。 五、合规性 AWS Artifact：是一项服务，使您能够按需访问 AWS 安全性与合规性报告和选择在线协议。 AWS Artifact Agreements：用来与 AWS 签署有关在 AWS 服务中使用特定类型信息的协议。 AWS Artifact Reports：提供来自第三方审计机构的关于 AWS 的合规性报告。 经过这些审计机构的测试和验证，AWS 符合各种全球性、区域性和特定于行业的安全标准和法规。 Customer Compliance Center：包含各种有关 AWS 合规性的更多信息、资源。 可以阅读客户合规性案例，了解受管制行业中的公司如何解决各种合规性、监管和审计难题。 六、拒绝服务攻击 AWS Shield：用于保护应用程序免受 DDoS 攻击的服务。提供两种级别的保护：Standard 和 Advanced。 AWS Shield Standard：是一项免费服务，可以自动保护所有 AWS 客户。它可以保护您的 AWS 资源免受频繁发生的最常见 DDoS 攻击。 AWS Shield Advanced：是一项付费服务，不仅可以提供详细的攻击诊断，还能检测和缓解复杂的 DDoS 攻击。 它可以与其他服务（例如 Amazon CloudFront、Amazon Route 53 和 Elastic Load Balancing）集成。还可以通过编写自定义规则将 AWS Shield 与 AWS WAF 集成，从而缓解复杂的 DDoS 攻击。 七、其他安全服务 AWS Key Management Service (AWS KMS)​：支持创建、管理和使用加密密钥执行加密操作（静态加密或传输中加密）。 加密密钥是一个随机数字字符串，用于锁定（加密）和解锁（解密）数据。除了数据您还可以控制各种 AWS 服务和应用程序中密钥的使用。使用 AWS KMS，您可以为密钥选择所需的特定访问控制级，例如指定哪些 IAM 用户 和 角色 能管理密钥。 Amazon Inspector：可以运行自动化安全性评估，从而帮助提高应用程序的安全性与合规性。 AWS WAF：是一种 Web 应用程序防火墙，可让您监控进入 Web 应用程序的网络请求。 与 AWS 联网章节的 网络访问控制列表 (ACL) 类似，不过 AWS WAF 是针对 Web 请求的。 Amazon GuardDuty：是一项服务，为您的 AWS 基础设施和资源提供智能威胁检测。它通过持续监控 AWS 环境中的网络活动和账户行为来识别威胁。 模块 7: 监控和分析一、基本概念二、Amazon CloudWatch Amazon CloudWatch：是一项 Web 服务，使您能够监控和管理各项指标（包括自定义指标），以及根据来自这些指标的数据配置警报操作。 CloudWatch 使用指标来表示资源的数据点。AWS 服务将指标发送到 CloudWatch。然后，CloudWatch 使用这些指标自动创建图表，来显示一段时间内的性能变化情况。 CloudWatch 警报：使用 CloudWatch，可以通过创建警报以便在指标的值高于或低于预定义阈值时自动执行相应操作。 CloudWatch 控制面板：通过 CloudWatch 控制面板功能，可以从一个位置查看资源的所有指标。 三、AWS CloudTrail AWS CloudTrail：记录您账户的每个请求（API 调用）​，记录的信息包括 API 调用者的身份、API 调用时间和 API 调用者的源 IP 地址等。 事件通常会在 API 调用后的 15 分钟内在 CloudTrail 中更新。 CloudTrail Insights：借助这个可选功能，CloudTrail 可以自动检测您的 AWS 账户中的异常 API 活动。 四、AWS Trusted Advisor AWS Trusted Advisor：是一项 Web 服务，可以检查您的 AWS 环境并根据 AWS 最佳实践提供实时建议。 Trusted Advisor 可以检查⭐ 成本优化、性能、安全性、容错能力和服务限制五个类别，并将检查结果与 AWS 最佳实践进行比较。 对于每个类别的检查，Trusted Advisor 都会提供一系列建议的操作和其他资源，帮助您了解有关 AWS 最佳实践的更多信息。 AWS Trusted Advisor 控制面板：查看已完成的成本优化、性能、安全性、容错能力和服务限制检查。 对于每个类别： 🟩 绿色复选框表示未检测到任何问题的项目数量。 🟡 黄色三角形表示建议的调查数量。 🔴 红色圆圈表示建议的操作数量。 模块 8: 定价和支持一、基本概念二、AWS 免费套餐 AWS 免费套餐 永久免费 例如：AWS Lambda 每月提供 100 万个免费请求和长达 320 万秒的计算时间，Amazon DynamoDB 每月提供 25GB 的免费存储空间。 12 个月免费 例如：最高 5 GB 的 Amazon S3 Standard 存储，每月 Amazon EC2 计算时间的小时数阈值以及 Amazon CloudFront 数据传出量。 试用 例如：Amazon Inspector 提供 90 天免费试用，Amazon Lightsail 提供 30 天内 750 小时的免费使用。 三、AWS 定价概念四、账单控制面板五、整合账单 整合账单：AWS Organizations 提供 整合账单 选项。 查看每个账户产生的费用明细。 在企业的所有账户中共享批量折扣定价、Savings Plans 和预留实例。 六、AWS Budgets AWS Budgets：可以创建预算来规划服务使用量、服务成本和实例预留量，并且可以设置自定义提醒。 AWS Budgets 中的信息每天更新三次。 七、AWS Cost Explorer AWS Cost Explorer：直观查看、了解和管理一段时间内的 AWS 成本和使用情况，可以应用自定义筛选条件和组来分析数据。 默认报告中显示了产生成本的前五项 AWS 服务的相关成本和使用情况。 八、AWS Support 计划 AWS Support 计划 Basic Support：面向所有 AWS 客户免费提供。 包括访问白皮书、文档和支持社区。 Developer Support：成本最低，可以通过电子邮件联系客户支持。 问题 24 小时内响应，系统受损 12 小时内响应。适用于正在探索 AWS 服务阶段的公司。 Business Support：成本适中，可以直接致电云工程师，同时解锁 AWS Trusted Advisor 来提供全套最佳实践检查。 生产系统受损 4 小时内响应，生产系统故障 1 小时内响应。 AWS Enterprise On-Ramp Support（准企业支持计划）​：成本更高，可以联系多位 技术客户经理 (TAM) 进行指导和协调其他帮助。 对业务关键问题的响应时间不超过 30 分钟。 Enterprise Support（企业支持计划）​：成本最高，指派的一名 技术客户经理 (TAM) 专门进行指导和协调其他帮助。 对业务关键问题的响应时间不超过 15 分钟。 技术客户经理 (TAM)​：属于 Concierge 支持团队，被包含在 Enterprise On-Ramp（有速率限制）和 Enterprise Support 计划中。 提供以下服务： 技术设施事件管理。 Well-Architected 审核。 技术客户经理和客户一起使用 Well-Architected Framework 审核结构。Well-Architected Framework 的六大支柱：卓越运营、安全性、可靠性、性能效率、成本优化和可持续性。 运营审核。 基础设施事件管理服务：Business Support 及以上的、需要额外付费的服务，帮助规划全新发布会、全球广告计划等大型服务。 九、AWS Marketplace AWS Marketplace：一个包含独立软件供应商提供的数千款软件产品的数字目录，使用它可以查找、测试和购买在 AWS 上运行的软件。 提供多种类别的产品，例如基础设施软件、DevOps、数据产品、专业服务、业务应用程序、机器学习、工业和物联网 (IoT)。 优势： 几乎所有都支持不需要配置环境的一键式部署。 大部分提供按需付费模式。 部分提供免费试用等。 以企业为中心的功能：自定义条款和定价、私有 marketplace、集成到采购系统、成本管理工具等等。 模块 9: 迁移和创新一、基本概念二、AWS Cloud Adoption Framework (AWS CAF) AWS Cloud Adoption Framework (AWS CAF)​：AWS 云采用框架。 AWS Cloud Adoption Framework 的六大核心视角：AWS Cloud Adoption Framework 将迁移分为 6 个关注领域（视角）。 一般来说，业务、人员和监管视角侧重于业务能力，而平台、安全和运维视角侧重于技术能力。 六大视角为： 业务视角：可以确保 IT 与业务需求保持一致，并确保 IT 投资与关键业务成果挂钩。 其中的常见角色包括：业务经理、财务经理、预算责任人、预算利益攸关方。 人员视角：支持制定全组织范围的变更管理策略，从而成功地采用云。 其中的常见角色包括：人力资源专员、人事专员、人事经理。 监管视角：侧重于使 IT 策略与业务策略保持一致的技能和流程。这可以确保最大限度地提高商业价值并将风险降至最低。 其中的常见角色包括：首席信息官 (CIO)、项目经理、企业架构师、业务分析师、产品组合经理。 平台视角：包括在云中实施新解决方案以及将本地工作负载迁移到云的原则和模式。 其中的常见角色包括：首席技术官 (CTO)、IT 经理、解决方案架构师。可以帮助您根据业务目标和视角来设计、实施和优化 AWS 基础设施。 安全视角：确保企业满足可见性、可审计性、控制和敏捷性方面的安全目标。 其中的常见角色包括：首席信息安全官 (CISO)、IT 安全经理、IT 安全分析师。 运维视角：帮助您根据与业务利益攸关方事先商定的投入程度，启用、运行、使用、运营和恢复 IT 工作负载。 其中的常见角色包括：IT 运营经理、IT 支持经理。 三、迁移策略 将应用程序迁移到云的六大迁移策略 重新托管（直接迁移）​：直接迁移应用程序而无需进行更改。 在大规模旧式迁移场景中，公司希望快速实施迁移并扩展以满足其商业案例的要求，因此大部分应用程序都会进行重新托管。 更换平台（修补后迁移）​：在直接迁移的基础上做一些云优化。 完成优化时无需更改应用程序的核心架构，也不涉及新的开发工作。 停用：指删除不再需要的应用程序的过程。 保留：将对业务至关重要的应用程序保留在源环境中。 这可能包括需要在迁移前进行重大重构的应用程序，或可以推迟到以后完成的工作。 重新购买：涉及从传统许可证转向软件即服务模式。 重构/重新设计架构：涉及使用云原生功能重新考虑应用程序的架构设计和开发方式。 重构的驱动因素是强烈的业务需求，即需要增加功能、扩大规模或提高性能，但在应用程序的现有环境中难以实现这些目标。 四、AWS Snow 系列 AWS Snow 系列：是一系列物理设备，可以帮助您以物理方式将高达数 EB 的数据传入和传出 AWS。 AWS Snow 系列 包括 AWS Snowcone、AWS Snowball 和 AWS Snowmobile。 AWS Snowcone：小型耐用且安全的边缘计算和数据传输设备。 2 个 CPU、4GB 内存。高达 14TB 的可用存储容量。 AWS Snowball：分为两种类型 Snowball Edge Storage Optimized 和 Snowball Edge Compute Optimized。 Snowball Edge Storage Optimized：适合大规模数据迁移和重复传输工作流，以及具有较高容量需求的本地计算。 40 个 vCPU 和 80GiB 内存。80TB 硬盘驱动器 (HDD) 容量，用于块卷和与 Amazon S3 兼容的对象存储。1TB SATA 固态硬盘 (SSD)，用于块卷。可支持 Amazon EC2 sbe1 实例（相当于 C5）。 Snowball Edge Compute Optimized：可为机器学习、全动态视频分析、分析和本地计算堆栈等使用案例提供功能强大的计算资源。 104 个 vCPU 和 416GiB 内存。一个可选的 NVIDIA Tesla V100 GPU。80TB 可用 HDD 容量，用于与 Amazon S3 兼容的对象存储或与 Amazon EBS 兼容的块卷。28TB 可用 NVMe SSD 容量，用于与 Amazon EBS 兼容的块卷。设备运行 Amazon EC2 sbe-c 和 sbe-g 实例，这些实例相当于 C5、M5a、G3 和 P3 实例。 AWS Snowmobile：是一项 EB 级数据传输服务，用于将海量数据移动到 AWS。 AWS Snowmobile 是一个 45 英尺长的加固集装箱，由一台半挂卡车牵引，一次可以传输高达 100PB 的数据。有硬件设施与安全团队确保数据安全，同时也支持数据加密。 五、借助 AWS 推动创新 ⭐ Amazon SageMaker：快速构建、训练和部署机器学习模型。 Amazon CodeWhisperer：在编写代码的同时获取代码建议，并识别代码中的安全问题。 Amazon Lex：构建语音和文本聊天机器人。 Amazon Transcribe：将语音转换为文本。 AWS DeepRacer：让开发人员通过强化学习不断进行试验。 模块 10: 云之旅一、基本概念二、AWS Well-Architected Framework AWS Well-Architected Framework：帮助了解如何在 AWS 云中设计和运行可靠、安全、高效且具有成本效益的系统。 通过对照最佳实践和设计原则一致地衡量您的架构，并确定需要改进的方面。 AWS Well-Architected Framework 的六大支柱： 卓越运营：运行和监控系统以实现商业价值以及不断改进支持流程和程序的能力。 云中的卓越运营设计原则包括执行运营即代码，在文档中添加注释、预测故障以及频繁进行微小的可撤销更改。 安全性：指保护信息、系统和资产，同时通过风险评估和缓解策略实现商业价值的能力。 可靠性：指从基础设施或服务中断中恢复、动态获取计算资源以满足（业务和客户）需求和减少中断的能力。 可靠性包括测试恢复流程、横向扩展以提高聚合系统的可用性以及自动从故障中恢复。 性能效率：高效使用 IT 和计算资源来满足系统要求，并在需求变化和技术改进时保持此效率的能力。 评估架构的性能效率包括更频繁地进行试验、使用无服务器架构，以及设计能在数分钟内实现全球化部署的系统。 成本优化：优化全部成本，以最低成本运行系统来实现商业价值的能力。 成本优化包括采用消费模式、支出分析和归因以及使用托管服务降低拥有成本。 可持续性：降低云工作负载对环境的影响，减少能源消耗和提高工作效率。 三、云的优势 云计算的六大优势： 将前期费用转变为可变支出：只需为实际使用的计算资源付费，在尚不了解如何使用的情况下无需对数据中心和服务器投入大量资金。 实现大规模经济效益：AWS 通过其规模实现比单独运行数据中心更低的可变成本。 无需猜测容量：您可以只使用所需容量，并可以根据需要进行缩减或扩展，无需为未使用的资源付费，也不会受到容量限制。 提高速度和敏捷性：更轻松地开发和部署应用程序，同时让开发团队有更多的时间进行试验和创新。 不再花费资金来运行和维护数据中心：减少资金和时间来管理基础设施和服务器。 数分钟内实现全球化部署：快速为世界各地的客户部署应用程序，同时实现低延迟。 模块 11: AWS CERTIFIED CLOUD PRACTITIONER 基础知识一、考试详细信息 考试包含四个领域： 云概念 (26%) 安全性与合规性 (25%) 技术 (33%) 账单和定价 (16%) 考试详细信息： 包括 65 道题，需要在 90 分钟内完成。 总分为 1000 分，最低及格分数为 700 分。 除了单选题，还包含多选题（在五个或更多选项中有两个或更多正确答案）。 二、考试策略 最终评估","link":"/2024/09/04/clf_note_before_exam/"},{"title":"使用 Cloudflare R2 存储搭建图床","text":"前言选择 Cloudflare R2 作为图床的图片存储仓库，单纯是因为不再想折腾了，也不想再违规使用 GitHub 仓库。需要注意的是，白天时段从境内连接 Cloudflare CDN 服务器的速度勉强还能凑合，晚高峰就不忍直视了。 使用之前检查下 Cloudflare R2 的免费额度和计费模式（确认日是 2024/06/27）：官方文档：Pricing · Cloudflare R2 docs 🌟 Free tier | 免费额度 Feature Limit Remarks Storage 10 GB / month 一月中平均每天都存储量不超过 10 GB Class A Operations 1 million requests / month 对存储桶对操作、上传文件、删除文件等操作 Class B Operations 10 million requests / month 访问文件、下载文件等操作 Egress (data transfer to Internet) Free 假设每张图片 10MB，那么 10G 可以存储 1000 张图片，每月 1M 次操作可以保证每张图片每天被访问 33 次，10M 次操作可以保证每张图片每天被访问 330 次。已经足够使用了。 💵 R2 pricing | 价格 Feature Standard storage Price Infrequent Access storage Price Storage $0.015 / GB-month $0.01 / GB-month Class A Operations $4.50 / million requests $9.00 / million requests Class B Operations $0.36 / million requests $0.90 / million requests Data Retrieval (processing) None $0.01 / GB Egress (data transfer to Internet) Free Free 没什么好说的，相当便宜了。 操作步骤一、建立 R2 存储桶并公开1. 创建存储桶 2. 设置存储桶的访问权限 这里需要提前将域名托管到 Cloudflare，以使用 Cloudflare 的自动的 连接域 功能。 3. 上传图片测试访问上传的图片名为 头像.jpeg，访问地址为 https://ceshi.senjianlu.com/头像.jpeg，试一下：没有问题，访问成功！至此，cloudflare R2 存储桶的建立和访问权限的设置就完成了。 二、获取配置信息之后我会使用 uPic 作为图片上传工具，因此配置项的名称可能与你的不同。这里只介绍重点的、获取以下的配置信息的方法： 服务端 URL Access Key Secret Key 1. 服务端 URL 也会被标识为：S3 API、自定义节点、Endpoint 等。 注意这里不仅仅是域名，还有一个与存储桶同名的路径 /ceshi，之后配置的时候也需要带上。 2. Access Key 也会被标识为：访问密钥 ID、应用密钥 ID 等。 这里需要创建 API 令牌才可以获取到 Access Key 和 Secret Key。 3. Secret Key 也会被标识为：机密访问密钥、应用密钥等。 三、配置 uPic 关于 PicGo 的大致配置方法可以参照文章：PicGo + 白嫖Cloudflare R2 存储做图床其他工具的配置方法也大同小异，只是界面和配置项的名称不同。 1. 填入服务端 URL、Access Key 和 Secret Key，之后设置下你连接的域名即可。 2. 保存后选择对应的图床 3. 上传测试你可以直接点击 验证 按钮，也可以直接上传图片测试。默认会将图片上传至 uPic/ 目录下：上传成功后，会自动复制图片的 URL 地址，直接粘贴即可。 后记之后需要合理配置缓存，以降低超额使用的风险。","link":"/2024/06/27/cloudflare_r2_upic_image_repo/"},{"title":"在 Linux 服务器上搭建 HTTPS 正向代理并转发至小猫咪节点","text":"前言由于浏览器插件 Proxy SwitchyOmega 仅支持 HTTP、HTTPS 和 SOCKS5 协议的代理，于是在其中选择最为安全的 HTTPS 协议进行中转。该博文仅作为笔记用途。 方案概述 自签有效期 10 年的 SSL 证书。 注意：如果你和我一样之后要在 SwitchyOmega 等浏览器插件上使用代理，那么使用自签证书进行加密的话，除了再客户端上信任证书，还需要用 --ignore-certificate-errors 参数启动浏览器，这将带来潜在的安全风险！如果你的服务器有域名，可以使用 certbot 申请免费的域名证书，或是去腾讯云、阿里云等云服务厂商处购买证书。而如果你的服务器只有外部 IP，则可以去 ZeroSSL 申请免费的证书，不过有效期只有 90 天，需要定期更新，具体教程可以参考：ZeroSSL 申请免费的 IP SSL 证书。 Docker 容器内运行小猫咪并在（容器内的） 8910 端口提供需要认证的 HTTP 和 SOCKS5 代理服务。 Docker 容器内使用 stunnel 在 443 端口提供 HTTP over TLS（即 HTTPS）正向代理服务，并通过转发链将请求转发至小猫咪的 8910 端口。证书就使用自签发的。 在 Linux 宿主机上部署容器，并将宿主机的 443 端口映射容器的 443 端口。 证书的读取通过为容器映射宿主机的路径/文件，必要时重启容器实现读取新证书的功能。 使用时需要在客户端机器上安装 SSL 证书。 非自签证书可以跳过这一步。 操作步骤一、自签有效期 10 年的 SSL 证书 这一步的目的是生产一个由 CA 公钥和私钥拼接而成的 stunnel.pem 文件，用以给 stunnel 使用。​如果你有其他方式获取证书，可以跳过生成阶段，直接进行证书拼接并拷贝至 /rab/docker/https_proxy/config/ssl/stunnel.pem。​ 生成之前保险起见，更新下服务器的依赖环境： 12345sudo apt-get updatesudo apt-get install openssl# 推荐接下来的指令都在 /root/ssl_generator/ 目录执行mkdir -vp /root/ssl_generator/cd /root/ssl_generator/ 生成私钥，运行以下命令生成一个 2048 位的 RSA 私钥： 12# 目标文件 private.key openssl genpkey -algorithm RSA -out private.key -pkeyopt rsa_keygen_bits:2048 生成 CA 证书： 12# 目标文件 ca.crtopenssl req -new -x509 -key private.key -out ca.crt -days 3650 注意其他信息都可以乱填，但是 Common Name 需要与服务器的 IP 一致。​否则会出现以下错误： 123456curl: (60) SSL: unable to obtain common name from peer certificateMore details here: https://curl.se/docs/sslcerts.htmlcurl failed to verify the legitimacy of the server and therefore could notestablish a secure connection to it. To learn more about this situation andhow to fix it, please visit the web page mentioned above. 123456curl: (60) SSL: certificate subject name 'xxx.xxx.xxx.xxx' does not match target host name '(nil)'More details here: https://curl.se/docs/sslcerts.htmlcurl failed to verify the legitimacy of the server and therefore could notestablish a secure connection to it. To learn more about this situation andhow to fix it, please visit the web page mentioned above. 生成证书签发请求： 12# 目标文件 csr.csropenssl req -new -key private.key -out csr.csr 自签发证书： 12# 目标文件 certificate.crtopenssl x509 -req -days 3650 -in csr.csr -signkey private.key -out certificate.crt 将文件都转为 PEM 格式： 123openssl x509 -in ca.crt -out ca.pem -outform PEMopenssl x509 -in certificate.crt -out certificate.pem -outform PEMopenssl rsa -in private.key -out private.pem -outform PEM 生成完成之后，就能得到一个 10 年的自签发证书了： CA 证书 (CA Certificate)：ca.pem 私钥 (Private Key)：private.pem 证书 (Certificate)：certificate.pem 证书签发请求 (Certificate Signing Request)：csr.csr 重要的是证书、CA 证书和私钥，证书签发请求之后就用不到了。 之后合并下证书、CA 的公钥和私钥，注意顺序！后续给 stunnel 使用： 12# 最终的 stunnel.pem 文件自上而下依次是：证书、CA 证书和私钥cat /root/ssl_generator/certificate.pem /root/ssl_generator/ca.pem /root/ssl_generator/private.pem &gt;&gt; /root/ssl_generator/stunnel.pem 二、启动容器并设置好端口、目录映射映射关系： 宿主机端口 容器内端口 备注 443 443 由容器内 stunnel 提供的对外的 HTTPS 代理接口 宿主机目录 容器内目录 备注 /rab/docker/https_proxy/config/cat/ /root/cat/ 存放小猫咪配置文件 /rab/docker/https_proxy/config/ssl/ /root/ssl/ 存放 SSL 证书等 先在宿主机建立映射用的目录： 12mkdir -vp /rab/docker/https_proxy/config/cat/mkdir -vp /rab/docker/https_proxy/config/ssl/ 拷贝一份生成的证书到映射目录中： 1cp -r /root/ssl_generator/* /rab/docker/https_proxy/config/ssl/ 这里使用的原版的 Ubuntu 20.04 系统镜像作为基础容器： 123456docker run -it \\ --name=dev_my_https_proxy \\ -p 443:443 \\ -v /rab/docker/https_proxy/config/cat/:/root/cat/ \\ -v /rab/docker/https_proxy/config/ssl/:/root/ssl/ \\ ubuntu:20.04 因为使用了 -it 参数，所以容器启动后会直接进入容器内的交互模式。 之后更新下系统并安装必要的软件： 12345apt-get updateapt-get install wget# 以下 2 个是调试用的apt-get install curlapt-get install vim 三、下载小猫咪并迁移至容器 Ubuntu 22.04 系统下可用的小猫咪：clash来源于我对官方 Clash 容器的备份与可执行文件的提取。 下载可执行文件并赋予执行权限： 1234cd /root/# 在容器内下载小猫咪wget https://github.com/senjianlu/Clash-Docker/raw/master/backup/clashchmod +x /root/clash 默认情况下小猫咪会读取 /root/.config/clash/ 中的配置文件，因此这里还需要下载配置文件： 123456mkdir -vp /root/.config/clash/cd /root/.config/clash/# 在容器内下载配置文件wget https://github.com/senjianlu/Clash-Docker/raw/master/backup/Country.mmdbwget https://github.com/senjianlu/Clash-Docker/raw/master/backup/cache.dbwget https://github.com/senjianlu/Clash-Docker/raw/master/backup/config.yaml 四、启动小猫咪并测试 HTTP 和 SOCKS5 代理服务先启动下试试： 1./clash 配置文件的模板就不提供了，自行机场下载。注意 mixed-port 配置为 8910，并让所有请求都走代理。同时还需要添加用以认证的 authentication 配置。 配置文件参考： 12345678910111213141516port: 7890socks-port: 7891redir-port: 7892mixed-port: 8910authentication: - &quot;testUser:testPasswordForHttpsProxy&quot;allow-lan: truemode: Rulelog-level: infoexternal-controller: :9090proxies: - {name: my_node, server: aabbcc.com, port: 12345, type: vmess, uuid: xxxxx-xxxxxx-xxxxxx-xxxxx, udp: true}rules: - MATCH,my_node 这里需要注意的是需要手动指定其读取 /root/cat/ 下的配置文件： 1./clash -f /root/cat/config.yaml 启动没问题，就改为使用 nohup 让其运行在后台： 1nohup ./clash -f /root/cat/config.yaml &amp; 测试配置文件中的 mixed-port 端口上的 HTTP 或 SOCKS5 代理是否可用： 12curl -x http://testUser:testPasswordForHttpsProxy@127.0.0.1:8910 http://ip.sbcurl -x socks5://testUser:testPasswordForHttpsProxy@127.0.0.1:8910 http://ip.sb 如果不可用，只有可能是你的节点或测试命令有问题，请遵循以下步骤进行检查： 在其他设备上测试配置文件，或用其他方式测试节点是否在正常工作。 在容器内通过 curl、ping 等命令检测该主机与节点 host 的连通性，检查可能存在的 DNS 污染或网络阻断的问题。 检查配置文件中的 port、socks-port 和 mixed-port 等端口是否和测试命令中的一致。 五、安装 stunnel 并创建配置文件安装很简单： 1apt-get install stunnel 需要创建配置文件 /etc/stunnel/stunnel.conf： 1vi /etc/stunnel/stunnel.conf 配置文件内容： 12345client = no[squid]accept = 443connect = 127.0.0.1:8910cert = /root/ssl/stunnel.pem 六、使用 stunnel 启动 HTTP over TLS (HTTPS) 代理服务并测试启动 stunnel： 1stunnel 在宿主机上测试一下： 12# 注意这里的 IP 就需要使用生成 SSL 证书时填的 Common Name 了curl --proxy-cacert /root/ssl_generator/ca.pem -x https://testUser:testPasswordForHttpsProxy@$your_ip_in_ssl_common_name:443 http://ip.sb 七、为客户端安装 SSL 证书下载 CA 证书 ca.crt，或者下载 ca.pem 并在本地改为 .crt 后缀。之后的安装（信任）流程可以参考：各个系统下证书的信任流程注意：如果是在 Windows 下的话，需要将证书放入“受信任的根证书颁发机构”中。​ 九、在客户端上测试 HTTPS 代理服务我这里使用的是 SwitchyOmega 浏览器插件： 需要注意的是，如果使用自签证书会出现无法连接的错误 ERR_PROXY_CERTIFICATE_INVALID： 需要在 Edge 的快捷方式处添加 --ignore-certificate-errors 参数： 1&quot;C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe&quot; --ignore-certificate-errors 构建成易用的 Docker 镜像一、整理后的 Dockerfile 内容12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# 基础镜像系统版本为 ubuntu:20.04FROM ubuntu:20.04# 维护者信息LABEL maintainer=&quot;Rabbir admin@cs.cheap&quot;# Docker 内用户切换到 rootUSER root# 设置时区为东八区ENV TZ Asia/ShanghaiRUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime &gt; /etc/timezone# 安装依赖RUN apt-get update -yRUN apt-get install wget -yRUN apt-get install curl -y# 下载 Clash 和其配置文件RUN mkdir -vp /root/cat/WORKDIR /root/RUN wget https://github.com/senjianlu/Clash-Docker/raw/master/backup/clashRUN chmod +x /root/clash# 配置文件RUN mkdir -vp /root/.config/clash/WORKDIR /root/.config/clash/RUN wget https://github.com/senjianlu/Clash-Docker/raw/master/backup/Country.mmdbRUN wget https://github.com/senjianlu/Clash-Docker/raw/master/backup/cache.dbRUN wget https://github.com/senjianlu/Clash-Docker/raw/master/backup/config.yaml# 安装 stunnelRUN mkdir -vp /root/ssl/WORKDIR /root/RUN apt-get install stunnel -y# 编辑配置文件RUN echo &quot;client = no&quot; &gt; /etc/stunnel/stunnel.confRUN echo &quot;[squid]&quot; &gt;&gt; /etc/stunnel/stunnel.confRUN echo &quot;accept = 443&quot; &gt;&gt; /etc/stunnel/stunnel.confRUN echo &quot;connect = 127.0.0.1:8910&quot; &gt;&gt; /etc/stunnel/stunnel.confRUN echo &quot;cert = /root/ssl/stunnel.pem&quot; &gt;&gt; /etc/stunnel/stunnel.conf# 安装 httpd 以映射证书认证文件RUN apt-get install apache2 -y# 创建认证文件存放用的目录RUN mkdir -vp /root/ssl/.well-known/RUN mkdir -vp /var/www/html/# 建立软链接RUN ln -s /root/ssl/.well-known /var/www/html# 下载 Seafile 脚本到容器WORKDIR /root/RUN wget https://raw.githubusercontent.com/senjianlu/seafile-scripts/master/download.sh# 拷贝 entrypoint.sh 到容器COPY entrypoint.sh /root/entrypoint.sh# 指定启动的时候执行 entrypoint.shENTRYPOINT [&quot;/bin/sh&quot;, &quot;/root/entrypoint.sh&quot; ] entrypoint.sh 核心的启动命令： 1234567# 4. 启动# 4.1 启动 apache2（后台运行）apachectl -D FOREGROUND &amp;# 4.2 启动 stunnel（后台运行）stunnel# 4.3 启动 clashcd /root/ &amp;&amp; ./clash -f /root/cat/config.yaml 二、由 GitHub Action 自动构建GitHub 仓库：senjianlu/Https-Proxy-Docker 三、镜像拉取和运行 Docker Hub 地址：rabbir/https-proxy 按照 GitHub 文档描述启动镜像： 1234567docker run -d \\ --name=my_https_proxy \\ -p 80:80 \\ -p 443:443 \\ -v /rab/docker/https_proxy/config/cat/:/root/cat/ \\ -v /rab/docker/https_proxy/config/ssl/:/root/ssl/ \\ rabbir/https-proxy:latest 如果在境内无法拉取镜像，请手动下载镜像并上传至服务器、之后进行加载： 123456# 在境外服务器上拉取镜像并打包为 rabbir_https_proxy.tardocker pull rabbir/https-proxy:latestdocker save -o rabbir_https_proxy.tar rabbir/https-proxy:latest# 在境内服务器上加载 rabbir_https_proxy.tardocker load &lt; rabbir_https_proxy.tar 通过容器内的小猫咪日志可以检查运行状态： 1docker logs my_https_proxy 参考文章： 发现按照这个教程搭建的正常的 HTTPS 代理也挺好用的哈 可能是目前最好的 HTTPS 代理 使用 Squid 搭建 HTTPS 代理服务器 搭建基于 Gost 的 HTTPS 代理 利用 letsencrypt 和 gost 搭建 https 代理 Configuration Reference","link":"/2024/09/01/convert_node_to_https_proxy/"},{"title":"Crawl4AI 爬虫工具（一）使用 Docker Compose 部署和最小实践","text":"前言正好想学习一种 Selenium + Chrome 以外的爬虫工具，作为 AI 工作流中的一个环境，就选 LLM 友好的 Crawl4AI 吧。 方案概述 安装 Docker 环境 使用 docker-compose 部署容器 编写 Python3 脚本进行测试 操作步骤一、安装 Docker 环境参考：Ubuntu 20.04 从官方源安装最新的 Docker 二、使用 docker-dompose 部署容器 官方仓库：unclecode/crawl4ai 官方的 docker-compose.yaml 文件中涉及到很多 AI 提供商的 API Key 配置，我们本次的最小实践暂时不涉及 AI 功能因此跳过。最终我的文件配置： 1234567891011version: '3.8'services: crawl4ai: image: unclecode/crawl4ai:all-amd64 container_name: crawl4ai restart: always ports: - &quot;11235:11235&quot; environment: - CRAWL4AI_API_TOKEN=YourApiToken 我的服务部署在公网上，不希望所有人都可以使用，因此添加 CRAWL4AI_API_TOKEN 来进行认证。之后除了 /health，访问其他接口都需要提供该 Token。 启动容器： 1docker-compose up -d 如果出现下面的错误： exec /usr/local/bin/uvicorn: exec format error 说明你的 Docker 容器镜像架构和系统的不符，unclecode/crawl4ai:all 有 all-arm64 和 all-amd64 两种，需要视实际情况选择。 启动完成后，访问 http://IP:11235/health 测试一下： 三、编写 Python3 脚本进行测试因为我们没有在本地部署 crawl4ai，因此不需要安装 crawl4ai 的 Python 包。使用 requests 构造响应的请求参数，之后调用 crawl4ai 容器的远程 API 即可实现爬取。测试脚本： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import timeimport jsonimport requestsCRAWL4AI_HOST = &quot;127.0.0.1&quot;CRAWL4AI_PORT = 11235CRAWL4AI_API_TOKEN = &quot;YourApiToken&quot;def main(): # 1. 发布爬取任务 data = { &quot;urls&quot;: [&quot;https://www.baidu.com&quot;], &quot;browser_config&quot;: {}, &quot;crawler_config&quot;: {}, } url = &quot;{}://{}:{}/crawl&quot;.format(&quot;https&quot; if CRAWL4AI_PORT == 443 else &quot;http&quot;, CRAWL4AI_HOST, CRAWL4AI_PORT) headers = { &quot;Authorization&quot;: f&quot;Bearer {CRAWL4AI_API_TOKEN}&quot;, &quot;Content-Type&quot;: &quot;application/json&quot;, } try: response = requests.post(url, json=data, headers=headers) # print(response.json()) except Exception as e: print(e) # 2. 获取 Task ID task_id = response.json()[&quot;task_id&quot;] print(f&quot;任务 ID 为 {task_id}&quot;) # 3. 获取爬取结果 url = &quot;{}://{}:{}/task/{}&quot;.format(&quot;https&quot; if CRAWL4AI_PORT == 443 else &quot;http&quot;, CRAWL4AI_HOST, CRAWL4AI_PORT, task_id) for _ in range(60): try: response = requests.get(url, headers=headers) if response.json()[&quot;status&quot;] in [&quot;pending&quot;, &quot;processing&quot;]: time.sleep(1) else: print(&quot;网站标题：{}&quot;.format(response.json()[&quot;results&quot;][0][&quot;metadata&quot;][&quot;title&quot;])) with open(&quot;response.json&quot;, &quot;w&quot;) as f: f.write(json.dumps(response.json(), indent=4, ensure_ascii=False)) break except Exception as e: print(e)if __name__ == &quot;__main__&quot;: main() 执行结果：结束。","link":"/2025/08/26/crawl4ai_01/"},{"title":"使用 Docker 部署 Crawlab 网络爬虫管理平台并运行测试爬虫","text":"前言一些玩具爬虫想稍微写的简单点、好维护点，同时和生产环境的爬虫系统分开，用 Crawlab 来做统一管理吧。 方案概述 安装 Docker 环境 使用官方的 docker-compose.yaml 单机部署 Crawlab 将测试爬虫上传至 Crawlab 运行爬虫后查看状态并下载结果 操作步骤一、安装 Docker 环境参考：Ubuntu 20.04 从官方源安装最新的 Docker 二、使用官方的 docker-compose.yaml 单机部署 Crawlab 官方文档：单节点部署 docker-compose.yaml 文件内容中，MongoDB 由于将端口暴露给了宿主机，因此账号密码需要修改下： 123456789101112131415161718192021222324252627282930313233version: '3.3'services: master: image: crawlabteam/crawlab container_name: crawlab_master restart: always environment: CRAWLAB_NODE_MASTER: &quot;Y&quot; # Y: 主节点 CRAWLAB_MONGO_HOST: &quot;mongo&quot; # mongo host address. 在 Docker-Compose 网络中，直接引用 service 名称 CRAWLAB_MONGO_PORT: &quot;27017&quot; # mongo port CRAWLAB_MONGO_DB: &quot;crawlab&quot; # mongo database CRAWLAB_MONGO_USERNAME: &quot;username&quot; # mongo username CRAWLAB_MONGO_PASSWORD: &quot;password&quot; # mongo password CRAWLAB_MONGO_AUTHSOURCE: &quot;admin&quot; # mongo auth source volumes: - &quot;/opt/.crawlab/master:/root/.crawlab&quot; # 持久化 crawlab 元数据 - &quot;/opt/crawlab/master:/data&quot; # 持久化 crawlab 数据 - &quot;/var/crawlab/log:/var/log/crawlab&quot; # 持久化 crawlab 任务日志 ports: - &quot;8080:8080&quot; # 开放 api 端口 depends_on: - mongo mongo: image: mongo:4.2 restart: always environment: MONGO_INITDB_ROOT_USERNAME: &quot;username&quot; # mongo username MONGO_INITDB_ROOT_PASSWORD: &quot;password&quot; # mongo password volumes: - &quot;/opt/crawlab/mongo/data/db:/data/db&quot; # 持久化 mongo 数据 ports: - &quot;27017:27017&quot; # 开放 mongo 端口到宿主机 拉取镜像： 1docker compose pull 如果镜像拉取有问题，可以参考：自建 Docker Registry 镜像加速服务 启动容器： 1docker compose up -d 启动完成后，访问 8080 端口就能看到页面了： 用户名和密码都是 admin，登录后前往 My Settings 处修改。 三、将测试爬虫上传至 Crawlab 官方文档：创建爬虫Scrapy 爬虫样例在：senjianlu/scrapy-example 下载后解压，得到这样的目录结构： 123456789101112131415scrapy-example├── .gitignore├── README.md├── requirements.txt└── my_example_spiders ├── scrapy.cfg └── my_example_spiders ├── __init__.py ├── items.py ├── middlewares.py ├── pipelines.py ├── settings.py └── spiders ├── __init__.py └── quotes.py 需要上传的是 scrapy-example-master 下面的 my_example_spiders 目录（更上层一点的 my_example_spiders 目录）。 在页面上新建爬虫： 名称：my_example_spiders 执行命令：scrapy crawl quotes 之后进入爬虫，点击上传： 上传成功后，在左侧文件列表中可以双击打开文件： 四、运行爬虫后查看状态并下载结果 官方文档：运行爬虫 点击爬虫的运行按钮： 稍等片刻不出以外会成功： 如果出现 File not found 或是 undefined 之类的错误，大概率是你的爬虫目录上传错了。 前往任务菜单，可以找到对应执行的日志： 点击数据可以看到相关的爬取结果：视情况导出： 结束。","link":"/2024/10/15/docker_crawlab/"},{"title":"使用 Docker 部署 GOST 并开启 HTTPS 代理","text":"前言HTTP 和 SOCKS5 协议由于没有加密，所以在使用时会有一定的风险，而 HTTPS 协议则是一种加密的协议，可以有效的保护数据的安全性。本文将介绍如何使用 Docker 部署 GOST 并开启 HTTPS 代理。 方案概述 安装 Docker 环境 使用 Docker 部署 GOST 并开启 HTTP 代理 使用 acme.sh 申请证书 将证书挂载到 GOST 容器中并开启 HTTPS 代理 操作步骤一、安装 Docker 环境参考：Ubuntu 20.04 从官方源安装最新的 Docker 二、使用 Docker 部署 GOST 并开启 HTTP 代理官方仓库：gogost/gost 12345678# 拉取镜像并检查版本docker run --rm gogost/gost -V# 启动容器docker run -d \\ --name gost \\ -p 8080:8080 \\ gogost/gost \\ -L http://username:password@:8080 测试本地代理是否正常： 1curl -x http://username:password@localhost:8080 ipinfo.io 如果镜像拉取有问题，可以参考：自建 Docker Registry 镜像加速服务 三、使用 acme.sh 申请证书12345678# 申请证书acme.sh --issue -d proxy.example.com --webroot /var/acme/webroot/ --forcemkdir -vp /etc/nginx/ssl/proxy.example.com/# 安装证书acme.sh --install-cert -d proxy.example.com \\ --fullchain-file /etc/nginx/ssl/proxy.example.com/certificate.crt \\ --key-file /etc/nginx/ssl/proxy.example.com/private.key \\ --reloadcmd &quot;docker restart gost&quot; 之后你的 SSL 证书目录中会多两个文件： certificate.crt private.key 四、将证书挂载到 GOST 容器中并开启 HTTPS 代理 官方文档：TLS 由于 GOST 会自动加载当前工作目录下的 cert.pem、key.pem 和 ca.pem 文件来初始化全局证书，因此我们需要把证书挂载到相应目录中并改名： 1234567891011# 停止并删除旧容器docker stop gost &amp;&amp; docker rm gost# 启动新容器docker run -d \\ --name gost \\ --restart always \\ -p 8443:8443 \\ -v /etc/nginx/ssl/proxy.example.com/:/ssl \\ --entrypoint &quot;/bin/sh&quot; \\ gogost/gost \\ -c &quot;cp -f /ssl/certificate.crt /bin/cert.pem &amp;&amp; cp -f /ssl/private.key /bin/key.pem &amp;&amp; /bin/gost -L http+tls://username:password@:8443&quot; 如果需要调试的话： 1234567docker stop gost &amp;&amp; docker rm gostdocker run -it \\ --name gost \\ -p 8443:8443 \\ -v /etc/nginx/ssl/proxy.example.com/:/ssl \\ --entrypoint /bin/sh \\ gogost/gost 之后使用你的客户端连接即可： 当然也可以使用 curl 测试： 1curl -x https://username:password@localhost:8443 ipinfo.io","link":"/2024/11/08/docker_gost_https_proxy/"},{"title":"使用 Docker 部署 Loki + Grafana 日志聚合系统","text":"前言尝试使用 Loki + Grafana 替换掉和我业务量完全不匹配的 ELK。 方案概述 安装 Docker 环境 使用官方的 docker-compose.yaml 启动 Loki + Grafana + Promtail Grafana 配置 Loki 数据源 配置 Nginx 反代 Loki 并添加认证功能 配置 Docker 插件来测试日志推送 Loki 功能 Loki：负责存储日志和处理查询。 Promtail：代理，负责收集日志并将其发送给 Loki。 Grafana：用于日志展示等。 如果需要收集单独运行的 Docker 容器的日志的话，官方也有插件：Docker driver client 操作步骤一、安装 Docker 环境参考：Ubuntu 20.04 从官方源安装最新的 Docker 二、使用官方的 docker-compose.yaml 启动 Loki + Grafana + Promtail官方仓库：loki/production/没有什么需要修改的，docker-compose.yaml 文件内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051version: &quot;3&quot;networks: loki:services: loki: image: grafana/loki:2.9.10 ports: - &quot;3100:3100&quot; command: -config.file=/etc/loki/local-config.yaml networks: - loki promtail: image: grafana/promtail:2.9.10 volumes: - /var/log:/var/log command: -config.file=/etc/promtail/config.yml networks: - loki grafana: environment: - GF_PATHS_PROVISIONING=/etc/grafana/provisioning - GF_AUTH_ANONYMOUS_ENABLED=true - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin entrypoint: - sh - -euc - | mkdir -p /etc/grafana/provisioning/datasources cat &lt;&lt;EOF &gt; /etc/grafana/provisioning/datasources/ds.yaml apiVersion: 1 datasources: - name: Loki type: loki access: proxy orgId: 1 url: http://loki:3100 basicAuth: false isDefault: true version: 1 editable: false EOF /run.sh image: grafana/grafana:latest ports: - &quot;3000:3000&quot; networks: - loki 拉取镜像： 1docker compose pull 如果镜像拉取有问题，可以参考：自建 Docker Registry 镜像加速服务 启动容器： 1docker compose up -d 如果这里需要配置 Nginx 反代的话，可以参考： 1234567891011121314151617181920212223server { listen 443 ssl; server_name grafana.ceshiku.cn; # SSL 配置 ssl_certificate /etc/nginx/ssl/grafana.ceshiku.cn/certificate.crt; ssl_certificate_key /etc/nginx/ssl/grafana.ceshiku.cn/private.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; location / { proxy_pass http://1.2.3.4:3000; proxy_set_header Host $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-Port $server_port; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; # This allows the ability for the execute shell window to remain open for up to 15 minutes. Without this parameter, the default is 1 minute and will automatically close. proxy_read_timeout 900s; }} 同时需要在 nginx.conf 的 http 配置段中增加： 1234map $http_upgrade $connection_upgrade { default upgrade; '' close;} 三、Grafana 配置 Loki 数据源选择数据源并搜索 Loki：如果是和 Loki 在同一 Docker 网络下，使用 http://loki:3100 即可访问，其他情况需要使用公网或内网 IP：同时由于 Loki 本身没有认证功能，因此这里也不需要配置认证信息，填完名字和 URL 后就结束了： 因为将宿主机的 /var/log 目录映射给了 Promtail，因此当前 Loki 已经开始收集宿主机的日志。可以在 Grafana 面板上配置检索进行查看： 四、配置 Nginx 反代 Loki 并添加认证功能 官方对于认证功能的描述：AuthenticationNginx 认证添加可以参考：Creating a Password File 很明显把任何不需要认证的服务暴露在公网，都不会是一个很好的注意，因此这里需要添加下简单的认证。创建认证用户： 12345apt-get install apache2-utilsmkdir -vp /etc/nginx/auth/touch /etc/nginx/auth/.loki# logger 为用户名sudo htpasswd /etc/nginx/auth/.loki logger 之后输入密码，然后查看 /etc/nginx/auth/.loki 文件会看到用户名和 Hash 后的密码： 1cat /etc/nginx/auth/.loki 之后用 Nginx 反代 3100 端口的 Loki 服务，并设置使用认证： 123456789101112131415161718192021222324252627server { listen 443 ssl; server_name loki.ceshiku.cn; # 认证信息配置 auth_basic &quot;Administrator’s Area&quot;; auth_basic_user_file /etc/nginx/auth/.loki; # SSL 配置 ssl_certificate /etc/nginx/ssl/loki.ceshiku.cn/certificate.crt; ssl_certificate_key /etc/nginx/ssl/loki.ceshiku.cn/private.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; location / { proxy_pass http://1.2.3.4:3100; proxy_set_header Host $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-Port $server_port; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; # This allows the ability for the execute shell window to remain open for up to 15 minutes. Without this parameter, the default is 1 minute and will automatically close. proxy_read_timeout 900s; }} 之后访问页面确认下认证生效了： 之后记得关闭没有认证的 3100 端口的防火墙或安全组。 五、配置 Docker 插件来测试日志推送 Loki 功能1、安装 Loki driver client 插件参考：Install the Docker driver client 1docker plugin install grafana/loki-docker-driver:latest --alias loki --grant-all-permissions 之后查看下插件列表： 1docker plugin ls 2、指定容器的日志推送到 Loki参考：Change the logging driver for a container这里拿 Nginx 容器举例： 123456789docker run -d \\ --name nginx \\ --restart=unless-stopped \\ --log-driver=loki \\ --log-opt loki-url=&quot;https://logger:your_logger_password@loki.ceshiku.cn/loki/api/v1/push&quot; \\ --log-opt loki-retries=5 \\ --log-opt loki-batch-size=400 \\ -p 80:80 \\ nginx:latest 之后回到 Grafana 面板，用适当的查询条件就能看到刚刚启动的容器的日志了： 之后关闭这个 Nginx 容器： 12docker stop nginxdocker rm nginx 3、配置全局日志推送到 Loki需要修改的是 /etc/docker/daemon.json 文件： 1vi /etc/docker/daemon.json 文件内容： 12345678{ &quot;debug&quot; : true, &quot;log-driver&quot;: &quot;loki&quot;, &quot;log-opts&quot;: { &quot;loki-url&quot;: &quot;https://logger:your_logger_password@loki.ceshiku.cn/loki/api/v1/push&quot;, &quot;loki-batch-size&quot;: &quot;400&quot; }} 保存之后重启下 Docker 服务： 12sudo systemctl daemon-reloadsudo systemctl restart docker 启动个 Caddy 容器测试下： 12345docker run -d \\ --name caddy \\ --restart=unless-stopped \\ -p 80:80 \\ caddy:latest 之后去 Grafana 面板确认下，Caddy 的日志应该也会出现： 之后关闭这个 Caddy 容器： 12docker stop caddydocker rm caddy 官方还提供了在 Docker Swarm 等集群上配置的方法：Configure the logging driver for a Swarm service or Compose，不过我暂时没有这个需求，就不举例了。后期 K3s 集群上的配置应该会开一篇新的笔记。 参考资料： Grafana Loki开源日志聚合系统代替ELK或EFK Grafana Loki笔记03: 安全认证 docker日志收集docker插件+loki+grafna","link":"/2024/09/30/docker_loki/"},{"title":"使用 Docker 部署 MySQL + WordPress 并安装 OneNav 一为导航","text":"前言账单发来的时候才发现还有个 steam.cash 域名，原本以为都抛完了。恰巧看到一为导航打折，索性就把域名利用起来做个导航页吧。用的是闲置的斯巴达 2H2G 云服务器，系统为 Ubuntu 20.04，将会安装 Docker 并运行 MySQL 和 WordPress 容器，并使用 acme.sh 申请 SSL 证书，算是很完整的一次实践了。 方案概述 安装 Docker 环境 运行 MySQL 容器 运行 WordPress 容器 访问页面安装 WordPress 安装 Nginx 安装 acme.sh 申请和安装 SSL 证书 安装 OneNav 一为导航 操作步骤一、安装 Docker 环境参考：Ubuntu 20.04 从官方源安装最新的 Docker 二、运行 MySQL 容器映射关系： 宿主机端口 容器内端口 备注 3306 3306 数据库连接端口 宿主机目录 容器内目录 备注 /var/log/mysql /var/log/mysql MySQL 日志文件 /rab/docker/mysql/data /var/lib/mysql MySQL 数据文件 /rab/docker/mysql/config /etc/mysql MySQL 配置文件 1234567891011121314# 创建映射用的目录mkdir -vp /rab/docker/mysql/datamkdir -vp /rab/docker/mysql/config# 启动容器docker run -d \\ --name mysql \\ --privileged=true \\ --restart=unless-stopped \\ -p 3306:3306 \\ -v /var/log/mysql:/var/log/mysql \\ -v /rab/docker/mysql/data:/var/lib/mysql \\ -v /rab/docker/mysql/config:/etc/mysql/conf.d \\ -e MYSQL_ROOT_PASSWORD=&quot;EnM4K=b):k@U*Nr9Y&quot; \\ mysql:5.7 之后进入容器创建下 wordpress 数据库： 1docker exec -it mysql /bin/bash 在容器内登录数据库： 1mysql -u root -p 之后输入密码，然后创建数据库： 1234create database wordpress;GRANT ALL PRIVILEGES ON wordpress.* TO 'root'@'localhost' IDENTIFIED BY 'EnM4K=b):k@U*Nr9Y';flush privileges;show databases; 之后退出 MySQL 命令行，再退出容器回到宿主机。 三、运行 WordPress 容器WordPress 前端映射到了宿主机的 8080 端口。通过 --link mysql 连接到 MySQL 容器，这样 WordPress 进程默认访问 localhost:3306 的时候就能连接到数据库了。 12345678910111213# 创建映射用的目录mkdir -vp /rab/docker/wordpress/html# 启动容器docker run -d \\ --name wordpress \\ --restart=unless-stopped \\ -p 8080:80 \\ -v /rab/docker/wordpress/html:/var/www/html \\ -e WORDPRESS_DB_NAME=wordpress \\ -e WORDPRESS_DB_USER=root \\ -e WORDPRESS_DB_PASSWORD=&quot;EnM4K=b):k@U*Nr9Y&quot; \\ --link mysql \\ wordpress:latest 之后进入容器修改下 upload_max_filesize 和 post_max_size 的值： 1docker exec -it wordpress /bin/bash 1234# 设置 PHP 上传文件大小并创建配置文件echo &quot;upload_max_filesize = 20M&quot; &gt; /usr/local/etc/php/conf.d/uploads.ini# 设置 PHP POST 数据大小echo &quot;post_max_size = 20M&quot; &gt;&gt; /usr/local/etc/php/conf.d/uploads.ini 然后退出容器回到宿主机，之后再重启下 WordPress 容器： 1docker restart wordpress 这里如果不设置 upload_max_filesize 和 post_max_size 的话，WordPress 上传文件大小会受限制，同时在后续操作时可能会出现 上传的文件大小超过 php.ini 文件中定义的 upload_max_filesize 值。 错误。 四、访问页面安装 WordPress由于已经指定了数据库连接，因此这里配置下用户密码即可，站点信息之后都能修改。图片就不放了。 如果出现 Error establishing a database connection 错误的话，可能是你数据库连接信息填错了，也可能是表没有创建或是权限有问题，请参照我上面的流程进行修复。 五、安装 Nginx参考：Installing Prebuilt Ubuntu Packages之后隐藏默认证书的时候需要用到新的配置项。 12345678910sudo apt install curl gnupg2 ca-certificates lsb-release ubuntu-keyringcurl https://nginx.org/keys/nginx_signing.key | gpg --dearmor | sudo tee /usr/share/keyrings/nginx-archive-keyring.gpg &gt;/dev/nullgpg --dry-run --quiet --no-keyring --import --import-options import-show /usr/share/keyrings/nginx-archive-keyring.gpgecho &quot;deb [signed-by=/usr/share/keyrings/nginx-archive-keyring.gpg] \\ http://nginx.org/packages/ubuntu `lsb_release -cs` nginx&quot; \\ | sudo tee /etc/apt/sources.list.d/nginx.listecho -e &quot;Package: *\\nPin: origin nginx.org\\nPin: release o=nginx\\nPin-Priority: 900\\n&quot; \\ | sudo tee /etc/apt/preferences.d/99nginxsudo apt updatesudo apt install nginx 12systemctl enable nginxsystemctl start nginx 六、安装 acme.sh123456789# 安装所需软件apt-get install curlapt-get install socat# 安装 acmecurl https://get.acme.sh | sh# 添加软链接ln -s /root/.acme.sh/acme.sh /usr/local/bin/acme.sh# 切换 CA 机构acme.sh --set-default-ca --server letsencrypt 七、申请和安装证书先修改下 Nginx 的默认配置文件 /etc/nginx/conf.d/default.conf： 12mv /etc/nginx/conf.d/default.conf /etc/nginx/conf.d/default.conf.bakvi /etc/nginx/conf.d/default.conf 文件内容： 1234567891011121314151617181920212223242526272829303132# 非域名访问返回 500 错误server { listen 80; listen [::]:80; server_name _; location / { return 500; } # 特殊的证书认证用的路径 location /.well-known/acme-challenge/ { # acme.sh --webroot 模式，认证文件生成后放置的路径 root /var/acme/webroot/; }}# 非域名访问防止发送 SSL 证书server { listen 443 ssl default_server; server_name _; ssl_protocols TLSv1.2 TLSv1.3; # 启用拒绝 TLS 握手 ssl_reject_handshake on; # SSL Session 缓存，不设置的话无缓存配置不生效 ssl_session_cache shared:SSL:10m; ssl_session_timeout 10m; # log 位置自行替换 access_log /var/log/nginx/host.access.log;} 重启下 Nginx： 12nginx -s reloadservice nginx restart 然后申请下证书： 12345678# 申请证书acme.sh --issue -d steam.cash --webroot /var/acme/webroot/ --forcemkdir -vp /etc/nginx/ssl/steam.cash/# 安装证书acme.sh --install-cert -d steam.cash \\ --fullchain-file /etc/nginx/ssl/steam.cash/certificate.crt \\ --key-file /etc/nginx/ssl/steam.cash/private.key \\ --reloadcmd &quot;service nginx force-reload&quot; 然后在 /etc/nginx/conf.d/ 目录里创建个 steam.cash 域名用的配置文件： 1vi /etc/nginx/conf.d/steam.cash.conf 文件内容： 123456789101112131415161718192021222324252627282930313233343536373839server { listen 80; server_name steam.cash; # 强制跳转 HTTPS location / { return 301 https://$server_name$request_uri; } # 设置证书认证用的路径 location /.well-known/acme-challenge/ { # acme.sh --webroot 模式，认证文件生成后放置的路径 root /var/acme/webroot/; }}server { listen 443 ssl; server_name steam.cash; # SSL 配置 ssl_certificate /etc/nginx/ssl/steam.cash/certificate.crt; ssl_certificate_key /etc/nginx/ssl/steam.cash/private.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; location / { proxy_pass http://127.0.0.1:8080; # 防止出现 413 Request Entity Too Large 的问题 client_max_body_size 20m; proxy_set_header Host $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-Port $server_port; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; }} 之后再重启下 Nginx： 12nginx -s reloadservice nginx restart 如果出现 nginx: [emerg] unknown &quot;connection_upgrade&quot; variable 错误的话，需要修改下 nginx.conf： 1vi /etc/nginx/nginx.conf 在 http 代码段中添加下面内容： 1234map $http_upgrade $connection_upgrade { default upgrade; '' close;} 这步做完，访问你的网址 https://steam.cash 应该就能看到 SSL 生效的 WordPress 页面了： 八、安装 OneNav 一为导航 一为导航官网：https://www.iotheme.cn安装教程：主题如何上传至网站？ 首先当然需要进行购买和授权：然后下载主题包：就能得到一个类似 onenav.xxxxx.42xxxxxxxxxxxxxxxxxxxxxx65==.zip 的文件。回到 WordPress 后台，点击 外观 -&gt; 主题 -&gt; 安装新主题 -&gt; 上传主题，选择刚刚下载的主题包上传并安装：上传完成后，点击立即安装：等待安装完成后，启用主题：之后到主题设置处填入授权码（激活码）：授权完成后，回到主页就能看到主题生效了： 主题自定义和内容填充可以参考官方文档：One Nav 主题开始使用，新手教程 涉及生产数据，之后的操作就不掩饰了，结束。 参考资料： 一切正常，但现在mysql容器停止加载。 WordPress出现“Error establishing a database connection”数据库连接错误的解决方法","link":"/2024/10/10/docker_mysql_wordpress_onenav/"},{"title":"使用 Docker 部署 OneNav 导航站并手动切换主题","text":"前言多台设备间切换的时候，工具和各种站点总是要开开关关，部署个导航站节省下时间。 导航可选的不多，一为导航是好看但是 300+ 的价格有点贵了，dashy 太过花哨，homepage 需要挂载宿主机的 docker.sock 文件，权限要求太高了……自用没那么多要求，最后就选择 OneNav 了。 方案概述 安装 Docker 环境 启动容器 更换主题 操作步骤一、安装 Docker 环境参考：Ubuntu 20.04 从官方源安装最新的 Docker 二、启动容器 官方文档：Docker安装 参数不多，就不介绍直接启动了： 123456789# 映射下数据的目录，后续切换主题也需要用到mkdir -vp /rab/docker/onenav/data# 启动容器docker run -d \\ --name=onenav \\ --restart=unless-stopped \\ -p 9080:80 \\ -v /rab/docker/onenav/data:/data/wwwroot/default/data \\ helloz/onenav:0.9.35 三、更换主题 官方文档：更换主题作者提供的主题下载站：themes 我的链接不多，因此选个不需要打开多层菜单的也可以： 12345678910# 创建目录cd /rab/docker/onenav/datamkdir templatescd templates# 下载主题wget https://soft.xiaoz.org/onenav/themes/tushan2.tar.gz# 解压压缩包到 tushan2 目录mkdir tushan2mv tushan2.tar.gz tushan2/cd tushan2 &amp;&amp; tar -zxvf tushan2.tar.gz &amp;&amp; rm -f tushan2.tar.gz 之后选择新主题： 添加一段 CSS 将 h1 标签隐藏： 12345&lt;style&gt;h1 { display: none;}&lt;/style&gt; 结束。","link":"/2024/09/20/docker_onenav_change_theme/"},{"title":"部署 Docker Portainer 容器管理工具","text":"前言有的云服务器配置太低了，不适合充当 K3s 集群节点。我也不想一个个登陆上去管理容器，统一安装下 Portainer 以管理在上面运行着的容器。 方案概述 安装 Docker 环境 启动 Portainer 容器 使用 Cloudflare 解析并配置 Origin Rules 规则 登陆 Portainer 管理容器进行操作 操作步骤一、安装 Docker 环境参考：Ubuntu 20.04 从官方源安装最新的 Docker 二、启动 Portainer 容器 8000 端口：用于其他 Agent 连接 9000 端口：Web 管理界面 9443 端口：HTTPS 加密的 Web 管理界面 123456789101112# 建立映射目录mkdir -vp /rab/docker/portainer/data# 启动 Portainer 容器docker run -d \\ --name portainer \\ --restart=always \\ -p 8000:8000 \\ -p 9000:9000 \\ -p 9443:9443 \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v /rab/docker/portainer/data:/data \\ portainer/portainer-ce:2.21.1 三、使用 Cloudflare 解析并配置 Origin Rules 规则 我这里的 Cloudflare SSL/TLS 加密模式是 灵活，因此反代 8000 端口即可。如果你的是 完全 或 严格 模式，需要反代 9443 端口。关于更多可以参考我的另一篇文章：Cloudflare 四种 SSL/TLS 加密模式的功能解析及实践 在规则的 Origin Rules 中添加一条规则：将主机名为对应域名的请求，转发到解析的服务器的 9000 端口： 四、登陆 Portainer 管理容器进行操作之后访问域名，设置下管理员密码即可登陆管理容器。","link":"/2024/09/22/docker_potainer/"},{"title":"自建 Docker Registry 镜像加速服务","text":"前言国内的 K3s 集群拉不了镜像了……阿里云和腾讯云也陆续把镜像加速服务限制内网使用了，只能自建了。 方案概述 安装 Docker 环境 启动容器 Nginx 反代 Cloudflare 解析 测试拉取镜像 修改为 Docker 的默认镜像地址 操作步骤一、安装 Docker 环境参考：Ubuntu 20.04 从官方源安装最新的 Docker 二、启动容器官方文档：registry 12345678910# 创建数据目录mkdir -vp /rab/docker/registry/data# 启动容器docker run -d \\ --name registry \\ --restart always \\ -p 5000:5000 \\ -v /rab/docker/registry/data:/var/lib/registry \\ -e REGISTRY_PROXY_REMOTEURL=https://registry-1.docker.io \\ registry:2.8.3 三、Nginx 反代123456789101112131415161718server { listen 80; # 替换成你的域名 server_name registry.ceshiku.cn; client_max_body_size 0; chunked_transfer_encoding on; location / { proxy_pass http://127.0.0.1:5000; proxy_connect_timeout 3600; proxy_http_version 1.1; proxy_set_header Connection &quot;&quot;; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; }} 四、Cloudflare 解析解析的时候开启小云朵，以获取 HTTPS 支持和 CDN 加速。 五、测试拉取镜像1docker pull registry.ceshiku.cn/rabbir/https-proxy:latest 六、修改为 Docker 的默认镜像地址1vi /etc/docker/daemon.json 修改为： 12345{ &quot;registry-mirrors&quot;: [ &quot;https://registry.ceshiku.cn&quot; ]} 重启 Docker 服务： 12sudo systemctl daemon-reloadsudo systemctl restart docker 之后拉取镜像就会自动使用镜像加速服务了。","link":"/2024/09/21/docker_registry/"},{"title":"对已经在运行的 Docker 容器添加映射、属性等","text":"用的不多，作为笔记记录一下。 一、添加目录映射1、查看 Docker 存放数据的目录1docker info | grep &quot;Docker Root Dir&quot; 2、查看需要修改的容器 ID1docker ps 3、进入需要修改的容器的目录1cd /var/lib/docker/containers/容器ID 4、停止 Docker 服务1systemctl stop docker 不停止的话，在之后容器重启时，配置会失效。 5、修改容器配置文件 在线 JSON 编辑：jsoneditoronline 编辑 config.v2.json 文件： 1vi config.v2.json 在 MountPoints 中添加需要映射的目录： 1234567891011121314151617&quot;MountPoints&quot;: { &quot;/container_path&quot;: { &quot;Source&quot;: &quot;/my/host_path&quot;, &quot;Destination&quot;: &quot;/container_path&quot;, &quot;RW&quot;: true, &quot;Name&quot;: &quot;&quot;, &quot;Driver&quot;: &quot;&quot;, &quot;Type&quot;: &quot;bind&quot;, &quot;Propagation&quot;: &quot;rprivate&quot;, &quot;Spec&quot;: { &quot;Type&quot;: &quot;bind&quot;, &quot;Source&quot;: &quot;/my/host_path&quot;, &quot;Target&quot;: &quot;/container_path&quot; }, &quot;SkipMountpointCreation&quot;: false },} 6、启动 Docker 服务1systemctl start docker 二、添加环境变量步骤和添加目录映射类似，只是修改的是 config.v2.json 文件中的 Env 字段。 参考资料： docker对已经启动的容器添加目录映射(挂载目录)","link":"/2024/10/01/docker_running_container_add/"},{"title":"使用 Docker 部署 Seafile 文件管理系统","text":"前言在 K3s 集群中，似乎并没有很好的方法对通用的大段配置进行解耦。因此换条路走：依赖外部的 Seafile 文件系统进行通用配置文件的保存，并在容器重启时自动下载最新的配置文件，借此实现解耦。 Seafile 提供全面的网盘功能，用户可以在 Seafile 中存储、管理和共享文件。 支持全平台客户端，包括 Windows、Mac、Linux、iOS、Android 等。 ⭐ 支持多人协同在线编辑、文档编辑锁定。 ⭐ 权限管理。 版本控制。 事件通知。 ⭐ 支持通过 API 下载文件。 方案概述 安装 Docker 环境 确定容器运行参数 启动容器 证书申请、Nginx 配置等 生成带密码保护的共享链接 操作步骤一、安装 Docker 环境参考：Ubuntu 20.04 从官方源安装最新的 Docker 二、确定容器运行参数官方只提供了使用 docker-compose.yml 启动的文档：用 Docker 部署 Seafile 服务看了下最近的更新日志升级到 11.0.x，弃用了 SQLite 数据库支持，这使得外部的 MySQL 数据库成了必须，同时 Seafile 还依赖 Memcached 缓存系统。那就没有必要再折腾命令启动了，直接用官方的 docker-compose.yml 吧：11.0/docker-compose.yml MySQL 数据库和 Memcached 并未暴露到外部，仅 Seafile 容器的 80 和 443 端口需要做映射供外部访问。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152services: db: image: mariadb:10.11 container_name: seafile-mysql environment: # MySQL 数据库密码 - MYSQL_ROOT_PASSWORD=db_dev # Required, set the root's password of MySQL service. - MYSQL_LOG_CONSOLE=true - MARIADB_AUTO_UPGRADE=1 volumes: # MySQL 数据持久化 - /opt/seafile-mysql/db:/var/lib/mysql # Required, specifies the path to MySQL data persistent store. networks: - seafile-net memcached: image: memcached:1.6.18 container_name: seafile-memcached entrypoint: memcached -m 256 networks: - seafile-net seafile: image: seafileltd/seafile-mc:11.0-latest container_name: seafile ports: # 端口映射 - &quot;80:80&quot;# - &quot;443:443&quot; # If https is enabled, cancel the comment. volumes: # Seafile 数据持久化 - /opt/seafile-data:/shared # Required, specifies the path to Seafile data persistent store. environment: - DB_HOST=db # 之前设置的 MySQL 数据库密码 - DB_ROOT_PASSWD=db_dev # Required, the value should be root's password of MySQL service. - TIME_ZONE=Etc/UTC # Optional, default is UTC. Should be uncomment and set to your local time zone. # Seafile 管理员登录邮箱 - SEAFILE_ADMIN_EMAIL=me@example.com # Specifies Seafile admin user, default is 'me@example.com'. # Seafile 管理员登录密码 - SEAFILE_ADMIN_PASSWORD=asecret # Specifies Seafile admin password, default is 'asecret'. # 不配置 HTTPS，之后用 acme.sh 申请证书并用 Nginx 反代 - SEAFILE_SERVER_LETSENCRYPT=false # Whether to use https or not. - SEAFILE_SERVER_HOSTNAME=docs.seafile.com # Specifies your host name if https is enabled. depends_on: - db - memcached networks: - seafile-netnetworks: seafile-net: 三、启动容器我修改完的 docker-compose.yml： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152services: db: image: mariadb:10.11 container_name: seafile-mysql environment: # MySQL 数据库密码 - MYSQL_ROOT_PASSWORD=BZyXMJCF3EbxVt2a9czR - MYSQL_LOG_CONSOLE=true - MARIADB_AUTO_UPGRADE=1 volumes: # MySQL 数据持久化 - /rab/docker/seafile_mysql/data:/var/lib/mysql networks: - seafile-net memcached: image: memcached:1.6.18 container_name: seafile-memcached entrypoint: memcached -m 256 networks: - seafile-net seafile: image: seafileltd/seafile-mc:11.0-latest container_name: seafile ports: # 端口映射 - &quot;11080:80&quot; volumes: # Seafile 数据持久化 - /rab/docker/seafile/data:/shared environment: - DB_HOST=db # 之前设置的 MySQL 数据库密码 - DB_ROOT_PASSWD=BZyXMJCF3EbxVt2a9czR - TIME_ZONE=Asia/Shanghai # Seafile 管理员登录邮箱 - SEAFILE_ADMIN_EMAIL=admin@ceshiku.cn # Seafile 管理员登录密码 - SEAFILE_ADMIN_PASSWORD=nDD3CaMuT9Ay17K62cf4 # 不配置 HTTPS，之后用 acme.sh 申请证书并用 Nginx 反代 - SEAFILE_SERVER_LETSENCRYPT=false # Seafile 域名 - SEAFILE_SERVER_HOSTNAME=seafile.ceshiku.cn depends_on: - db - memcached networks: - seafile-netnetworks: seafile-net: 创建下数据持久化目录： 12mkdir -vp /rab/docker/seafile_mysql/datamkdir -vp /rab/docker/seafile/data 启动服务： 1docker compose up -d 之后访问映射的端口看下： 四、证书申请、Nginx 配置等参考：四、4. 安装最新的 Nginx配置完 Nginx 重启后 HTTPS 应该就生效了： 五、生成带密码保护的共享链接 各种意外情况一、Forbidden (403) CSRF verification failed. Request aborted.如果你和我一样曾出现了下面的错误： 12Forbidden (403)CSRF verification failed. Request aborted. 那么需要进入到 Docker 容器中，修改下 /opt/seafile/conf/seahub_settings.py 文件： 12# 进入容器docker exec -it seafile /bin/bash 在容器中修改配置文件： 1234# 域名修改为你的echo &quot;CSRF_TRUSTED_ORIGINS = ['https://seafile.ceshiku.cn']&quot; &gt;&gt; /opt/seafile/conf/seahub_settings.py# 退出容器exit 之后重启容器： 1docker restart seafile 即可解决问题。 二、上传或预览失败上传显示网络错误：或者语言一直处于加载状态。需要将 系统设置 中 设置 的 SERVICE_URL 和 FILE_SERVER_ROOT 带上 HTTPS：之后再上传就好了：预览：","link":"/2024/09/19/docker_seafile/"},{"title":"Trojan-Go 服务 Docker 镜像制作","text":"前言将 Trojan-Go 服务制作成 Docker 镜像，方便快速部署和迁移。 实测将 Trojan-Go 容器化不会对速度造成影响，该跑满速的还是跑满速： 方案概述 目标是将 Trojan-Go 服务和伪装用的页面封装在镜像中，而证书申请和 Nginx 外置在宿主机上。最终的启动命令类似： 1234567891011docker run -d \\ --name trojan-go \\ --restart=unless-stopped \\ # 映射到宿主机的 8443 端口，之后通过 Nginx 分流 # 客户端侧依然配置为 443 端口 -p 8443:443 \\ # Trojan-Go 的配置文件、证书和密钥存放的目录 -v /rab/docker/trojan-go/:/etc/trojan-go/ \\ -e TROJAN_GO_SERVICE_PASSWORD=&quot;yourTrojanPassword&quot; \\ -e TROJAN_GO_SERVICE_DOMAIN=&quot;trojan.example.com&quot; \\ rabbir/trojan-go:latest 实际启动命令请参考：Trojan-Go-Docker/README.md 确认下 Trojan-Go 作者提供的镜像 编辑 Dockerfile 构建镜像 实际部署 操作步骤一、确认下 Trojan-Go 作者提供的镜像Dockerfile：trojan-go/Dockerfile镜像：p4gefau1t/trojan-go 1234567891011121314151617181920212223242526FROM golang:alpine AS builderWORKDIR /ARG REFRUN apk add git make &amp;&amp;\\ git clone https://github.com/p4gefau1t/trojan-go.gitRUN if [[ -z &quot;${REF}&quot; ]]; then \\ echo &quot;No specific commit provided, use the latest one.&quot; \\ ;else \\ echo &quot;Use commit ${REF}&quot; &amp;&amp;\\ cd trojan-go &amp;&amp;\\ git checkout ${REF} \\ ;fiRUN cd trojan-go &amp;&amp;\\ make &amp;&amp;\\ wget https://github.com/v2fly/domain-list-community/raw/release/dlc.dat -O build/geosite.dat &amp;&amp;\\ wget https://github.com/v2fly/geoip/raw/release/geoip.dat -O build/geoip.dat &amp;&amp;\\ wget https://github.com/v2fly/geoip/raw/release/geoip-only-cn-private.dat -O build/geoip-only-cn-private.datFROM alpineWORKDIR /RUN apk add --no-cache tzdata ca-certificatesCOPY --from=builder /trojan-go/build /usr/local/bin/COPY --from=builder /trojan-go/example/server.json /etc/trojan-go/config.jsonENTRYPOINT [&quot;/usr/local/bin/trojan-go&quot;, &quot;-config&quot;]CMD [&quot;/etc/trojan-go/config.json&quot;] 系统镜像使用 alpine 可执行文件位于 /usr/local/bin/trojan-go 配置文件位于 /etc/trojan-go/config.json 配置文件内容： 1234567891011121314151617181920212223{ &quot;run_type&quot;: &quot;server&quot;, &quot;local_addr&quot;: &quot;0.0.0.0&quot;, &quot;local_port&quot;: 443, &quot;remote_addr&quot;: &quot;127.0.0.1&quot;, &quot;remote_port&quot;: 80, &quot;password&quot;: [ &quot;your_password&quot; ], &quot;ssl&quot;: { &quot;cert&quot;: &quot;your_cert.crt&quot;, &quot;key&quot;: &quot;your_key.key&quot;, &quot;sni&quot;: &quot;your-domain-name.com&quot; }, &quot;router&quot;: { &quot;enabled&quot;: true, &quot;block&quot;: [ &quot;geoip:private&quot; ], &quot;geoip&quot;: &quot;/usr/share/trojan-go/geoip.dat&quot;, &quot;geosite&quot;: &quot;/usr/share/trojan-go/geosite.dat&quot; }} 配置文件中的 password、cert、key 和 sni 需要替换。 后续可以将证书和配置文件放在一起，映射给容器。 二、编辑 Dockerfile 构建镜像1、Trojan-Go 服务相关这里直接使用作者构建的 Docker 镜像作为基础镜像，因此不做配置。 12# 镜像选择 p4gefau1t/trojan-goFROM p4gefau1t/trojan-go:latest 2、伪装页面相关Web 服务器使用更轻量化的 Caddy。单页项目在 GitHub 搜一下就行，有一大堆。我这里挑了 YaninaTrekhleb/restaurant-website 这个项目，上完 AWS 的课程之后对咖啡店这个主题还蛮有好感的。 1234567891011121314151617181920# 1. 安装 CaddyWORKDIR /root/RUN wget https://github.com/caddyserver/caddy/releases/download/v2.8.4/caddy_2.8.4_linux_amd64.tar.gzRUN tar zxvf caddy_2.8.4_linux_amd64.tar.gzRUN mv caddy /usr/local/bin/# 2. 下载伪装页面RUN mkdir -vp /var/www/html/WORKDIR /var/www/html/RUN wget https://github.com/YaninaTrekhleb/restaurant-website/archive/refs/heads/master.zipRUN unzip master.zipRUN mv /var/www/html/restaurant-website-master/* /var/www/html/# 3. 编辑 Caddy 的配置文件RUN mkdir -vp /etc/caddy/RUN echo &quot;:80 {&quot; &gt; /etc/caddy/CaddyfileRUN echo &quot; root * /var/www/html&quot; &gt;&gt; /etc/caddy/CaddyfileRUN echo &quot; file_server browse&quot; &gt;&gt; /etc/caddy/CaddyfileRUN echo &quot; try_files {path} /index.html&quot; &gt;&gt; /etc/caddy/CaddyfileRUN echo &quot;}&quot; &gt;&gt; /etc/caddy/Caddyfile Caddy 启动相关： 1234# 前台运行caddy run --config /etc/caddy/Caddyfile# 后台运行caddy start --config /etc/caddy/Caddyfile 3、entrypoint.sh 启动脚本entrypoint.sh 脚本核心内容： 1234567891011121314# 3. 启动 Caddycaddy start --config /etc/caddy/Caddyfile# 4. 替换 Trojan-Go 配置文件内容# 替换域名和密码sed -i &quot;s/your_password/$TROJAN_GO_SERVICE_PASSWORD/&quot; /etc/trojan-go/config.jsonsed -i &quot;s/your-domain-name.com/$TROJAN_GO_SERVICE_DOMAIN/&quot; /etc/trojan-go/config.json# 将 your_cert.crt 替换为 /etc/trojan-go/certificate.crtsed -i &quot;s/your_cert.crt/\\/etc\\/trojan-go\\/certificate.crt/&quot; /etc/trojan-go/config.json# 将 your_key.key 替换为 /etc/trojan-go/private.keysed -i &quot;s/your_key.key/\\/etc\\/trojan-go\\/private.key/&quot; /etc/trojan-go/config.json# 5. 启动 Trojan-Go/usr/local/bin/trojan-go -config /etc/trojan-go/config.json 4、托管 GitHub 并使用 GitHub Action 自动构建镜像GitHub 仓库：senjianlu/Trojan-Go-DockerDocker Hub：rabbir/trojan-go 三、实际部署只记命令，详细的过程和解析我其他博文里都有。 1、安装 Docker 环境参考：Ubuntu 20.04 从官方源安装最新的 Docker 12345678sudo apt-get updatesudo apt-get install ca-certificates curl gnupg lsb-releasesudo mkdir -p /etc/apt/keyringscurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpgecho &quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/nullsudo apt-get updatesudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugindocker -v 2、安装最新的 Nginx参考：Installing Prebuilt Ubuntu Packages 1234567891011sudo apt install curl gnupg2 ca-certificates lsb-release ubuntu-keyringcurl https://nginx.org/keys/nginx_signing.key | gpg --dearmor | sudo tee /usr/share/keyrings/nginx-archive-keyring.gpg &gt;/dev/nullgpg --dry-run --quiet --no-keyring --import --import-options import-show /usr/share/keyrings/nginx-archive-keyring.gpgecho &quot;deb [signed-by=/usr/share/keyrings/nginx-archive-keyring.gpg] \\ http://nginx.org/packages/ubuntu `lsb_release -cs` nginx&quot; \\ | sudo tee /etc/apt/sources.list.d/nginx.listecho -e &quot;Package: *\\nPin: origin nginx.org\\nPin: release o=nginx\\nPin-Priority: 900\\n&quot; \\ | sudo tee /etc/apt/preferences.d/99nginxsudo apt updatesudo apt install nginxservice nginx status 之后修改下默认的配置，使 acme.sh 能够通过 80 端口验证域名所有权： 12mv /etc/nginx/conf.d/default.conf /etc/nginx/conf.d/default.conf.bakvi /etc/nginx/conf.d/default.conf 12345678910111213141516# 非域名访问返回 500 错误server { listen 80; listen [::]:80; server_name _; location / { return 500; } # 特殊的证书认证用的路径 location /.well-known/acme-challenge/ { # acme.sh --webroot 模式，认证文件生成后放置的路径 root /var/acme/webroot/; }} 12nginx -s reloadservice nginx restart 3、创建证书申请用目录和临时容器12mkdir -vp /rab/docker/trojan-go/docker run -d --name trojan-go alpine /bin/sh 4、安装 acme.sh 并申请证书12345678910# 安装所需软件apt-get install curlapt-get install socat# 安装 acmecd /rootcurl https://get.acme.sh | sh# 添加软链接ln -s /root/.acme.sh/acme.sh /usr/local/bin/acme.sh# 切换 CA 机构acme.sh --set-default-ca --server letsencrypt 1234567# 申请证书acme.sh --issue -d trojan.example.com --webroot /var/acme/webroot/ --force# 安装证书acme.sh --install-cert -d trojan.example.com \\ --fullchain-file /rab/docker/trojan-go/certificate.crt \\ --key-file /rab/docker/trojan-go/private.key \\ --reloadcmd &quot;docker restart trojan-go&quot; 5、启动 Trojan-Go 容器1234567891011# 删除临时容器docker stop trojan-go &amp;&amp; docker rm trojan-go# 启动 Trojan-Go 容器docker run -d \\ --name trojan-go \\ --restart=unless-stopped \\ -p 8443:443 \\ -v /rab/docker/trojan-go/:/etc/trojan-go/ \\ -e TROJAN_GO_SERVICE_PASSWORD=&quot;yourTrojanPassword&quot; \\ -e TROJAN_GO_SERVICE_DOMAIN=&quot;trojan.example.com&quot; \\ rabbir/trojan-go:latest 6、配置 Nginx 根据域名分流到 Trojan-Go 容器1vi /etc/nginx/nginx.conf 添加以下内容： 1234567891011121314151617stream { # SNI 识别，将一个个域名映射成一个配置名 map $ssl_preread_server_name $stream_map { trojan.example.com trojan; } upstream trojan { server 127.0.0.1:8443; } # 端口复用 server { listen 443 reuseport; proxy_pass $stream_map; ssl_preread on; }} 12nginx -s reloadservice nginx restart 7、连接测试Surge 下可以连接：伪装页面也可以正常访问： 8、BBR 加速确保内核版本大于 4.9： 1uname -r 我这边是 5.13，直接开启 BBR 加速： 12echo &quot;net.core.default_qdisc=fq&quot; | sudo tee -a /etc/sysctl.conf echo &quot;net.ipv4.tcp_congestion_control=bbr&quot; | sudo tee -a /etc/sysctl.conf 使其生效： 1sysctl -p 确认是否开启成功： 1sysctl net.ipv4.tcp_congestion_control 保险起见可以 reboot 重启一下，顺便测试 Nginx 和 Docker 的 trojan-go 容器在开机时是否自启。结束。 参考资料： VPS 初体验（四）trojan 和 Nginx 共用 443 端口 Nginx 配置：基于 SNI 的分流 使用Nginx进行SNI分流并完美和网站共存 Ubuntu22.04开启BBR拥塞控制算法","link":"/2024/09/25/docker_trojan/"},{"title":"影视笔记 -《半泽直树》第一季第 1 集","text":"单词、文法、惯用句和和可能用的上的小 Tips。 来源：哔哩哔哩 链接：半泽直树：第 1 集 单词 追い詰める｜おいつめる④1. 逼到绝境，穷追不舍，逼到困境。 焼き付く｜やきつく③1. 烧粘在一起，烧焦；2. 留下深刻的印象，铭刻。 脳裏のうりんに焼き付く。深深铭刻在脑子里。 引き揚げ｜ひきあげ⓪1. 吊起来；提高；打捞；收回。 突っ立つ｜つったつ③1. 挺立，耸立，矗立；2. 呆立。 擦り合い｜なすりあい⓪1. 互相推委。 窮地｜きゅうち①1. 穷境，困境，窘境。 譲る｜ゆずる⓪ [名誉｜めいよ①] 栄冠｜えいかん⓪ 需要｜じゅよう⓪ 文法特にない。 惯用句特にない。 小 Tips特にない。","link":"/2024/08/24/drama_hanzawa_naoki_01_01/"},{"title":"影视笔记 -《重启人生》第 4 集","text":"单词、文法、惯用句和和可能用的上的小 Tips。 来源：哔哩哔哩 链接：重启人生：第4集 恋爱啥的就是插曲 单词 擦れ違う｜すれちがう④ タトゥー｜たとぅー①(tattoo) 纹身，刺青。 感慨｜かんがい⓪ 発信｜はっしん⓪ 続編｜ぞくへん⓪ 冤罪｜えんざい⓪ 捕まる｜つかまる⓪ 物理的｜ぶつりてき⓪ 驚異的｜きょういてき 巻く｜まく⓪ 細かい｜こまかい③ 積み重なる｜つみかさなる⑤ 潰す｜つぶす⓪ 札勘｜さつかん⓪点钱。 削減｜さくげん⓪ 省く｜はぶく② 削ぐ｜そぐ① 強盗｜ごうとう⓪ 不穏｜ふおん⓪ 続行｜ぞっこう⓪ 渋滞｜じゅうたい⓪堵车，进展不顺利，停滞不前。 ピンチ｜ぴんち①(pinch) 紧急关头；危机，困境，危急局面。 待ち伏せる｜まちぶせる④ 保湿｜ほしつ⓪ 見逃す｜みのがす③⓪1. 看漏，错过看的机会；２. 饶恕，宽恕；3. 放过，放跑，放走。 素直｜すなお①1. 坦率，直率，老实；纯朴，天真，不隐讳；2. 听话，柔顺，温顺；3. 大方，工整，地道，纯正；笔直，没有虚饰，不矫饰。 親孝行｜おやこうこう③ 題材｜だいざい⓪ 文法特にない。 惯用句 超見てた。我追了这部剧。 下手をすると…｜へたをすると…搞不好的话…… 小 Tips 「メシ押し」について： 「出しがある」について：","link":"/2024/08/18/drama_note_brush_up_life_04/"},{"title":"异常关机后 Eclipse 无法打开部分项目的解决方法","text":"大概率是关机时部分文件残留导致了冲突，实际也印证了这一点，删除 .snap 文件后就解决了。 一、错误信息错误截图：C:\\Java\\YourProject\\.metadata\\.log 中记录的错误日志： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869!SESSION 2024-09-13 16:08:24.916 -----------------------------------------------eclipse.buildId=4.26.0.20221201-1200java.version=17.0.5java.vendor=Eclipse AdoptiumBootLoader constants: OS=win32, ARCH=x86_64, WS=win32, NL=ja_JPFramework arguments: -product org.eclipse.epp.package.java.productCommand-line arguments: -os win32 -ws win32 -arch x86_64 -product org.eclipse.epp.package.java.product!ENTRY org.eclipse.core.resources 2 10035 2024-09-13 16:08:29.722!MESSAGE ワークスペースは以前のセッションで変更が保存されずに終了しました； 変更を回復するためにワークスペースをリフレッシュ中です。!ENTRY org.eclipse.osgi 4 0 2024-09-13 16:08:31.327!MESSAGE バンドル org.eclipse.core.resources (150) を自動的に有効化している間にエラーが発生しました。!STACK 0org.osgi.framework.BundleException: バンドル org.eclipse.core.resources の org.eclipse.core.resources.ResourcesPlugin.開始() での例外。 at org.eclipse.osgi.internal.framework.BundleContextImpl.startActivator(BundleContextImpl.java:839) at org.eclipse.osgi.internal.framework.BundleContextImpl.start(BundleContextImpl.java:767) at org.eclipse.osgi.internal.framework.EquinoxBundle.startWorker0(EquinoxBundle.java:1032) at org.eclipse.osgi.internal.framework.EquinoxBundle$EquinoxModule.startWorker(EquinoxBundle.java:371) at org.eclipse.osgi.container.Module.doStart(Module.java:605) at org.eclipse.osgi.container.Module.start(Module.java:468) at org.eclipse.osgi.framework.util.SecureAction.start(SecureAction.java:513) at org.eclipse.osgi.internal.hooks.EclipseLazyStarter.postFindLocalClass(EclipseLazyStarter.java:117) at org.eclipse.osgi.internal.loader.classpath.ClasspathManager.findLocalClass(ClasspathManager.java:570) at org.eclipse.osgi.internal.loader.ModuleClassLoader.findLocalClass(ModuleClassLoader.java:335) at org.eclipse.osgi.internal.loader.BundleLoader.findLocalClass(BundleLoader.java:397) at org.eclipse.osgi.internal.loader.sources.SingleSourcePackage.loadClass(SingleSourcePackage.java:41) at org.eclipse.osgi.internal.loader.BundleLoader.findClass0(BundleLoader.java:496) at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:416) at org.eclipse.osgi.internal.loader.ModuleClassLoader.loadClass(ModuleClassLoader.java:168) at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:520) at org.eclipse.ui.ide.IDE.registerAdapters(IDE.java:1751) at org.eclipse.ui.internal.ide.application.IDEWorkbenchAdvisor.initialize(IDEWorkbenchAdvisor.java:206) at org.eclipse.ui.application.WorkbenchAdvisor.internalBasicInitialize(WorkbenchAdvisor.java:171) at org.eclipse.ui.internal.Workbench$18.runWithException(Workbench.java:1615) at org.eclipse.ui.internal.StartupThreading$StartupRunnable.run(StartupThreading.java:36) at org.eclipse.swt.widgets.Synchronizer.syncExec(Synchronizer.java:183) at org.eclipse.ui.internal.UISynchronizer.syncExec(UISynchronizer.java:133) at org.eclipse.swt.widgets.Display.syncExec(Display.java:4785) at org.eclipse.ui.internal.StartupThreading.runWithoutExceptions(StartupThreading.java:94) at org.eclipse.ui.internal.Workbench.init(Workbench.java:1611) at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2748) at org.eclipse.ui.internal.Workbench.lambda$3(Workbench.java:636) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:338) at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:550) at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:171) at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:152) at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:203) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:136) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:104) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:402) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:255) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:568) at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:651) at org.eclipse.equinox.launcher.Main.basicRun(Main.java:588) at org.eclipse.equinox.launcher.Main.run(Main.java:1459)Caused by: java.lang.StackOverflowError at org.eclipse.core.internal.dtree.DeltaDataTree.reroot(DeltaDataTree.java:808) at org.eclipse.core.internal.dtree.DeltaDataTree.reroot(DeltaDataTree.java:808) at org.eclipse.core.internal.dtree.DeltaDataTree.reroot(DeltaDataTree.java:808) at org.eclipse.core.internal.dtree.DeltaDataTree.reroot(DeltaDataTree.java:808) at org.eclipse.core.internal.dtree.DeltaDataTree.reroot(DeltaDataTree.java:808) at org.eclipse.core.internal.dtree.DeltaDataTree.reroot(DeltaDataTree.java:808) at org.eclipse.core.internal.dtree.DeltaDataTree.reroot(DeltaDataTree.java:808) at org.eclipse.core.internal.dtree.DeltaDataTree.reroot(DeltaDataTree.java:808) at org.eclipse.core.internal.dtree.DeltaDataTree.reroot(DeltaDataTree.java:808) 二、解决方法删除 C:\\Java\\YourProject\\.metadata\\.plugins\\org.eclipse.core.resources\\*.snap 文件。 参考资料 Eclipse won’t start, log error says: ObjectNotFoundException: Tree element","link":"/2024/09/13/eclipse_cant_open_project/"},{"title":"指定 git commit 的日期","text":"前段时间修改的代码忘记提交了，需要指定下 git commit 的日期进行提交。 实际上，git commit 命令无法直接指定提交日期，需要修改到 Git 相关的环境变量实现。​提交时使用的代码如下： 1234# 添加文件git add .# 指定提交日期GIT_COMMITTER_DATE=&quot;Sun Aug 4 12:00:00 2024 +0800&quot; GIT_AUTHOR_DATE=&quot;Sun Aug 4 12:00:00 2024 +0800&quot; git commit -m &quot;feat: add some feature&quot; 环境变量的修改只对当前终端有效，关闭该终端后就失效了，不用担心影响其他提交。","link":"/2024/08/25/edit_git_commit_date/"},{"title":"魔改 OneNav 一为导航使其更适配 Polylang 多语言（国际化）插件","text":"前言默认情况下，一为导航只会展示按发布时间降序的数篇公告，而不会判断 Polylang 所带来的语言。通过修改原文件实现只展示该语言下的最新公告。标题中的 适配 并非将主题与插件结合，而是通过一些理念的融合、代码的修改使整站的国际化更彻底。 实现流程一、修改 templates/bulletin.phpOneNav 主题中公告对应的关键词是 bulletin。首页的公告模块是 templates/bulletin.php，核心代码在这里： 1234567891011121314151617181920&lt;div class=&quot;carousel-inner&quot; role=&quot;listbox&quot;&gt; &lt;?php $args = array( 'post_type' =&gt; 'bulletin', 'posts_per_page' =&gt; io_get_option('bulletin_n',5) ); $i = 0; $the_query = new WP_Query($args); while ( $the_query-&gt;have_posts() ) : $the_query-&gt;the_post(); ?&gt; &lt;?php if(get_post_meta(get_the_ID(),'_goto',true)){ the_title( sprintf( '&lt;div class=&quot;carousel-item %s&quot;&gt;&lt;a class=&quot;overflowClip_1&quot; href=&quot;%s&quot; target=&quot;_blank&quot; rel=&quot;bulletin noreferrer noopener%s&quot;&gt;',$i==0?'active':'', esc_url( get_permalink() ),get_post_meta(get_the_ID(),'_nofollow',true)?' external nofollow':'' ), ' ('. get_the_time('m/d').')&lt;/a&gt;&lt;/div&gt;' ); }else{ the_title( sprintf( '&lt;div class=&quot;carousel-item %s&quot;&gt;&lt;a class=&quot;overflowClip_1&quot; href=&quot;%s&quot; rel=&quot;bulletin&quot;&gt;',$i==0?'active':'', esc_url( get_permalink() ) ), ' ('. get_the_time('m/d').')&lt;/a&gt;&lt;/div&gt;' ); } ?&gt; &lt;?php $i ++; endwhile; ?&gt; &lt;?php wp_reset_postdata(); ?&gt;&lt;/div&gt; 首先明确下 WP_Query、have_posts() 和 the_post() 在 WordPress 中的作用： WP_Query：是一个类，用于自定义查询 WordPress 数据库中的帖子。 通过创建 WP_Query 对象，可以根据特定的参数（如分类、标签、作者等）获取特定的帖子集合。 12345&lt;?php$query = new WP_Query(array( 'category_name' =&gt; 'news', 'posts_per_page' =&gt; 5)); have_posts()：是一个方法，用于检查当前查询是否有更多的帖子可供循环处理，通常与 while 循环一起使用。 the_post()：也是一个方法，用于设置当前帖子数据。 每次调用 the_post() 时，WordPress 会将全局 $post 对象设置为当前循环中的帖子，并准备好模板标签（如 the_title、the_content）以显示该帖子的内容。 现在就好理解了，上述代码是通过 'post_type' =&gt; 'bulletin' 和 'posts_per_page' =&gt; io_get_option('bulletin_n',5) 这两个参数找文章，然后进行显示。那我们只需要先拿到当前的语言，然后作为查询参数一起传到后端即可。 而 Polylang 就提供获取当前语言的方法 pll_current_language： 官方文档：pll_current_language 1pll_current_language( $value ); 参数默认为 slug，参数和返回值如下： slug：返回当前语言代码，如 1。 name：返回当前语言名称，如 中文。 locale：返回当前语言的标识，如 zh_CN。 于是修改下核心部分的代码： 123456789101112131415161718192021222324252627282930313233343536373839&lt;div class=&quot;carousel-inner&quot; role=&quot;listbox&quot;&gt; &lt;?php $args = array( 'post_type' =&gt; 'bulletin', 'posts_per_page' =&gt; io_get_option('bulletin_n',5) ); # 2024/10/18 Rabbir add start # 1. 判断是否有多语言插件 if (function_exists('pll_current_language')): # 2. 通过 pll_current_language() 获取当前语言的表示 locale $language_locale_for_bulletin_search = pll_current_language(&quot;locale&quot;); # 3. 新增检索条件：meta_key = &quot;onenav_bulletin_language_locale&quot; &amp; meta_value = $language_locale_for_bulletin_search $meta_args = array( 'meta_query' =&gt; array( array( 'key' =&gt; 'onenav_bulletin_language_locale', 'value' =&gt; $language_locale_for_bulletin_search, 'compare' =&gt; '=' ) ) ); # 4. 将 meta_query 添加到 $args 中 $args = array_merge($args, $meta_args); endif; # 2024/10/18 Rabbir add end $i = 0; $the_query = new WP_Query($args); while ( $the_query-&gt;have_posts() ) : $the_query-&gt;the_post(); ?&gt; &lt;?php if(get_post_meta(get_the_ID(),'_goto',true)){ the_title( sprintf( '&lt;div class=&quot;carousel-item %s&quot;&gt;&lt;a class=&quot;overflowClip_1&quot; href=&quot;%s&quot; target=&quot;_blank&quot; rel=&quot;bulletin noreferrer noopener%s&quot;&gt;',$i==0?'active':'', esc_url( get_permalink() ),get_post_meta(get_the_ID(),'_nofollow',true)?' external nofollow':'' ), ' ('. get_the_time('m/d').')&lt;/a&gt;&lt;/div&gt;' ); }else{ the_title( sprintf( '&lt;div class=&quot;carousel-item %s&quot;&gt;&lt;a class=&quot;overflowClip_1&quot; href=&quot;%s&quot; rel=&quot;bulletin&quot;&gt;',$i==0?'active':'', esc_url( get_permalink() ) ), ' ('. get_the_time('m/d').')&lt;/a&gt;&lt;/div&gt;' ); } ?&gt; &lt;?php $i ++; endwhile; ?&gt; &lt;?php wp_reset_postdata(); ?&gt;&lt;/div&gt; 之后重新打包并更新主题。 二、确认各语言下 locale 的值 语言 slug name locale 英文 en English en_US 中文 zh 中文 (中国) zh_CN 日语 ja 日本語 ja 三、测试添加公告1、中文中文模式下暂时没有公告：为既有的公告添加一条自定义字段：回到首页就能看到公告了： 2、英文英文模式下也暂时没有公告：发布公告的同时添加下字段：回到首页就能看到公告了：在详情页面发生了 404 错误，大概率是 en/ 路径导致的： 将路径从 https://test.steam.cash/en/bulletin/45.html 修改为 https://test.steam.cash/bulletin/45.html 之后，果然页面出现了： 3、日语日语模式下就不测了，肯定会和英语出现一样的问题。 四、修复非默认语言公告详情 404 的问题由于非默认语言会在路径中携带 en/ 或 jp/ 等语言标识，因此会导致 OneNav 找不到对应的公告出现 404 错误。同样的问题也会出现了 网址 详情页中。 这里使用最简单也是最彻底的方式，正则匹配路径并将 ^/en/(.*)/(.*) 和 ^/jp/(.*)/(.*) 路径全部 302 到 /$1/$2 下。需要使用到 Wordpress 的插件 Redirection：安装并启用后，在 工具 -&gt; Redirections 中配置重定向规则： 原始 URL：^/en/(.*)/(.*)（在右侧勾上 正则表达式） 匹配：匹配 URL 302 重定向到 目标 URL：/$1/$2 其他语言的重定向，参数与英文一样，只是将 en 替换为 ja 等。 之后保存，再去首页检查就可以发现详情页和网站都正常了： 顺便介绍下 301 和 302 重定向的区别： 301 重定向：永久重定向，浏览器会缓存。 &gt; 如果是永久重定向那么浏览器客户端就会缓存此次重定向结果，下次如果有请求则直接从缓存读取，譬如我们切换域名，将所有老域名的流量转入新域名，可以使用永久重定向。 302 重定向：临时重定向，浏览器不缓存。 &gt; 如果只是临时重定向那么浏览器则不会缓存，譬如我们的服务临时升级，会使用临时重定向。 而关于 301 和 302 的区别，Google 的人员是这么说的： 1当我们识别到一个重定向并看到它是 302 时，我们首先假定它是一个临时重定向，并假定你想要为初始 URL 编制索引，而不是为了重定向。 […] 然而，当我们意识到它实际上更像是一个永久重定向，302 可能是你不小心设置的，那么我们会将其视为 301。我们不会为此 URL 编制索引， 而将为重定向目标建立索引。 这意味着如果你不怎么介意的话，全设置为 302 重定向即可，搜索引擎会自己纠正。 参考资料： WordPress 多语言插件PolyLang使用教程 搜索 WordPress 常用函数(Functions) / 钩子(Hooks) Redirect Regular Expressions SEO的301和302重定向: 应该使用哪个？","link":"/2024/10/18/edit_onenav_for_polylang/"},{"title":"通过 F12 开发者工具解决右键被禁用的问题","text":"常见的网站为了防止被爬虫爬取，会禁用右键，这样就无法通过右键菜单查看源代码，但是我们可以通过 F12 开发者工具来解决这个问题。 打开浏览器开发者工具（F12），在 Console 栏中输入 JS 语句： 1javascript:(function() { function R(a){ona = &quot;on&quot;+a; if(window.addEventListener) window.addEventListener(a, function (e) { for(var n=e.originalTarget; n; n=n.parentNode) n[ona]=null; }, true); window[ona]=null; document[ona]=null; if(document.body) document.body[ona]=null; } R(&quot;contextmenu&quot;); R(&quot;click&quot;); R(&quot;mousedown&quot;); R(&quot;mouseup&quot;); R(&quot;selectstart&quot;);})() 可能会碰到 F12 Warning: Don’t paste code into the DevTools Console that you don’t understand or haven’t reviewed yourself. This could allow attackers to steal your identity or take control of your computer. Please type ‘allow pasting’ below and hit Enter to allow pasting. 的提示，输入 allow pasting 并回车即可。中文的话按描述输入 允许粘贴 即可。 然后按回车键，在页面中右键就可以使用了。","link":"/2023/12/05/f12_enable_mouse_click/"},{"title":"极摩客 GMK G3 搭建家庭媒体服务器（一）基础环境搭建和启动 Plex","text":"前言日语的学习需要灌听力素材了，装个媒体下载和播放用的小服务器。第一篇主要涉及：物理装机、系统 (Ubuntu 24.04 Desktop) 安装、Docker 环境安装、Portainer 容器管理面板启动以及 Plex 媒体服务启动。 方案概述硬件方案 硬件 价格 备注 极摩客 GMK G3（准系统） 567 - 66（返现）= 501 光威笔记本 DDR4 内存 16GB 2666Mhz 164 京东京造固态硬盘 256GB 138 有 NAS 因此硬盘只做系统盘。 ⭐ 合计：803 元。 系统方案 不选择 NAS 系统的原因是我对这台主机的终极目标也仅仅是：Portainer + AList + Transmission + Plex，通过启动 Docker 容器和目录映射就能实现。外部有一台 Mac mini 跑着 Surge，同时也有 NAS 做持久化存储，网络环境和存储不存在问题。如果你只有这一台机器的话，那么我还是推荐安装 iStoreOS 等系统。 安装 Ubuntu 24.04 Desktop 系统 安装 Docker 环境 启动 Portainer 容器管理面板 启动 Plex 媒体服务 测试播放视频 操作步骤零、物理装机顶部快拆结构，装起来没有什么难度： 一、安装 Ubuntu 24.04 Desktop 系统官方镜像下载：Download Ubuntu Desktop选择 Server 和 Desktop 都可以，我后续有网络和蓝牙配置需求，有界面操作起来方便些，就选 Desktop 了。 由于我的家庭网络中有联通和电信两个网段，因此需要同时连接 Ethernet 和 Wi-Fi 以确保在两个网段中都能访问到它： 装完后需要安装 OpenSSH 服务，以便远程连接： 12sudo apt updatesudo apt install openssh-server 确认 OpenSSH 服务已经启动： 1sudo systemctl status ssh 开启 ufw 防火墙的 OpenSSH 服务： 1sudo ufw allow ssh 之后在其他设备上 ssh 连接即可： 二、安装 Docker 环境参考：Ubuntu 20.04 从官方源安装最新的 Docker设置镜像源：自建 Docker Registry 镜像加速服务 如果有网络问题，可以在 apt-get 的时候使用代理： 1sudo apt-get -o Acquire::http::proxy=&quot;http://username:password@1.2.3.4:8080&quot; install docker-ce docker-ce-cli containerd.io docker-compose-plugin 三、启动 Portainer 容器管理面板参考：部署 Docker Portainer 容器管理工具 12# 建立映射目录mkdir -vp /rab/docker/portainer/data 12345678910# 启动 Portainer 容器docker run -d \\ --name portainer \\ --restart=always \\ -p 8000:8000 \\ -p 9000:9000 \\ -p 9443:9443 \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v /rab/docker/portainer/data:/data \\ portainer/portainer-ce:2.21.1 前往 9000 端口查看 Portainer 管理面板： 四、启动 Plex 媒体服务一样使用 Docker 启动。 1234567# 建立映射目录mkdir -vp /rab/docker/plex/datamkdir -vp /rab/docker/plex/configmkdir -vp /rab/docker/plex/transcodemkdir -vp /rab/docker/plex/media/videomkdir -vp /rab/docker/plex/media/photomkdir -vp /rab/docker/plex/media/music 然后前往索取 | Plex 获取索引码 PLEX_CLAIM，之后就能启动容器了： 12345678910111213docker run -d \\ --name plex \\ --restart=unless-stopped \\ --network=host \\ -v /rab/docker/plex/config:/config \\ -v /rab/docker/plex/transcode:/transcode \\ -v /rab/docker/plex/data:/data \\ -v /rab/docker/plex/media/video:/video \\ -v /rab/docker/plex/media/photo:/photo \\ -v /rab/docker/plex/media/music:/music \\ -e TZ=&quot;Asia/Shanghai&quot; \\ -e PLEX_CLAIM=&quot;claim-xxxxxxxxxxxxx-1M_&quot; \\ plexinc/pms-docker 这里一定要使用 --network=host 参数，否则内网 Plex APP 将无法发现该媒体服务器。​原因是 Plex 是会读取网络接口的：使用 Docker 容器启动的 Plex 无法被 Apple TV 等设备发现，大概率就是首选网络接口定为了 Docker 的虚拟网卡，而非真实的网卡（真实的 IP 地址）。 我这里暂时没有映射设备 device，这意味着目前 Plex 将不支持硬件解码功能。当然这也是 Plex Pro 用户的付费功能，后续有需要会购入会员补充设备映射。 前往 32400 端口查看 Plex 管理面板： 五、测试播放视频下个 4K 视频测试一下：oceans.pm4然后把视频移动到 /rab/docker/plex/media/video 目录里： 12cd /rab/docker/plex/media/videowget http://vjs.zencdn.net/v/oceans.mp4 前往 Plex 扫描资料库：播放： 参考资料： 使用Plex &amp; Docker搭建自己的媒体服务器 Ubuntu 22.04: Connect to WiFi from command line Centos7 使用 Docker 安装 Plex 媒体播放器","link":"/2024/09/23/gmk_g3_media_server_01/"},{"title":"影视笔记 -《知晓天空之蓝的人啊》","text":"单词、文法、惯用句和和可能用的上的小 Tips。 来源：哔哩哔哩 链接：知晓天空之蓝的人啊 单词 憧れる｜あこがれる⓪ 語り｜かたり⓪ 余裕｜よゆう⓪ 愛でる｜めでる②1. 欣赏；2. 赞赏；3. 疼爱。 囲む｜かこむ⓪ 反発｜はんぱつ⓪ 融通｜ゆうずう⓪ 謎｜なぞ⓪ 文法特にない。 惯用句特にない。 小 Tips特にない。","link":"/2024/09/01/film_her_blue_sky/"},{"title":"极摩客 GMK G3 搭建家庭媒体服务器（二）部署 Transmission 以及 Web 界面","text":"前言安装下 Transmission 用来做 PT 下载，官方 Web 不美观也不好用，替换为 transmission-web-control。➡️ 可能是因为我使用外置硬盘作为下载目录，Transmission 频繁占满 16G 内存并卡死，因此我后续切换为了 qBittorrent，可以参照我的另一篇文章：极摩客 GMK G3 搭建家庭媒体服务器（二）（追加）部署 qBittorrent。 方案概述 启动 Transmission 容器 替换 Transmission 官方的 Web 页面 在路由器和光猫上设置端口转发（非必要，需要公网 IP） 找种子下载 操作步骤一、启动 Transmission 容器1234# 建立映射目录mkdir -vp /rab/docker/transmission/configmkdir -vp /rab/docker/transmission/downloadsmkdir -vp /rab/docker/transmission/webui 12345678910111213141516docker run -d \\ --name=transmission \\ --restart=unless-stopped \\ -p 9091:9091 \\ -p 51413:51413 \\ -p 51413:51413/udp \\ -v /rab/docker/transmission/config:/config \\ -v /rab/docker/transmission/downloads:/downloads \\ -v /rab/docker/transmission/webui:/webui \\ -e PUID=1000 \\ -e PGID=1000 \\ -e TZ=Asia/Shanghai \\ -e TRANSMISSION_WEB_HOME=/webui \\ -e USER=transmission \\ -e PASS=transmission \\ linuxserver/transmission:latest 由于制定了 TRANSMISSION_WEB_HOME 为 /webui，而现在它是空的，因此在下载主题之前，无法访问 Transmission 的 Web 页面。不过你依然可以访问 9091 端口进行登录操作，不过在之后会收到 404 错误。 二、替换 Transmission 官方的 Web 页面项目地址：transmission-web-control下载发布的压缩包： 1wget https://github.com/ronggang/transmission-web-control/archive/refs/tags/v1.6.1-update1.zip -O /tmp/transmission-web-control.zip 解压并移动到 webui 目录： 123cd /tmpunzip /tmp/transmission-web-control.zip -d /tmpcp -r /tmp/transmission-web-control-1.6.1-update1/src/* /rab/docker/transmission/webui/ 之后登录 9091 端口，即可看到新的 Web 页面： 三、在路由器和光猫上设置端口转发没有这一步实测 PT 站内的种子依旧可以下载和上传，就是不知道会不会影响速度。 1、转发前 51413 端口是不可连接的 2、路由器上设置端口转发填入 Transmission 所在服务器的 IP 地址，以及 51413 端口： 3、光猫上设置端口转发填入路由器的 IP 地址，以及 51413 端口： 4、转发后 51413 端口就是可连接的了 四、找种子下载这个就不多说了，找种子的方法有很多，比如 PT 站、磁力链接、BT 站等等。可以使用磁力天堂导航站寻找站点。 参考资料： 使用Docker安装Transmission并使用增强版UI 使用Docker安装transmission并使用Transmission-Web-Control","link":"/2024/09/25/gmk_g3_media_server_02/"},{"title":"极摩客 GMK G3 搭建家庭媒体服务器（二）（追加）部署 qBittorrent","text":"前言Transmission 用了 3 天，下载任务一多就会卡死，所以我决定换一个下载工具，这次我选择了 qBittorrent。 方案概述 启动 qBittorrent 容器 访问 qBittorrent Web 界面 测试下载 操作步骤一、启动 qBittorrent 容器 官方 Docker 镜像：linuxserver/qbittorrent 之前将 NAS 的存储空间通过 WebDAV 挂载到了 GMK G3 的 /mnt/webdav/nas 目录下，所以我将 qBittorrent 的下载目录设置为 /mnt/webdav/nas/qbittorrent。配置文件则放在 /rab/docker/qbittorrent/config 目录下。同时这里将 Web 界面端口设置为 8080，BT/PT 端口设置为 55156： 1234567891011121314docker run -d \\ --name qbittorrent \\ --restart=unless-stopped \\ -p 55156:55156 \\ -p 55156:55156/udp \\ -p 8080:8080 \\ -v /rab/docker/qbittorrent/config:/config \\ -v /mnt/webdav/nas/qbittorrent/downloads:/downloads \\ -e PUID=1000 \\ -e PGID=1000 \\ -e TZ=Asia/Shanghai \\ -e WEBUI_PORT=8080 \\ -e TORRENTING_PORT=55156 \\ linuxserver/qbittorrent:14.3.9 二、访问 qBittorrent Web 界面访问 http://localhost:8080，用户是 admin，密码不是 adminadmin 的话，需要确认容器的日志： 1docker logs qbittorrent 三、测试下载随便找了个免费的种子： 如果出现 port 6881 is blacklisted 的话，说明 PT 站屏蔽了这个端口，修改下端口并重新映射容器端口： 如果连上了 Tracker 但是报错：大概率是目录权限的问题，将 /mnt/webdav/nas/qbittorrent/downloads 目录的权限改为 777 即可： 1chmod -R 777 /mnt/webdav/nas/qbittorrent 非权限错误的话，查看详细日志获取更多信息： 1cat /rab/docker/qbittorrent/config/qBittorrent/logs/qbittorrent.log 如果和我一样是 error: No such device 错误的话，可以重新使用 linuxserver/qbittorrent:14.3.9 这个版本的镜像构建容器，实测可以解决。参考：File alert error: No such device #16148 参考文章： 【好玩的Docker项目】10分钟搭建你专属的下载神器——qbittorrent","link":"/2024/10/02/gmk_g3_media_server_02_latest/"},{"title":"解决极摩客 GMK G3 等 N100 小主机安装 Windows10 系统后无法识别网卡的问题","text":"小主机折腾了一圈 Ubuntu 24.04，发现它的 VNC 远程连接实在太过繁琐了，每次重启之后密码都会变。于是我决定换回 Windows10，但是安装完之后发现网卡无法识别，无法连接网络。很明显是缺少驱动，360 驱动大师等软件并不包含这种新型小主机的驱动，需要去各厂商官网下载。 一、问题概述包括且不限于下面的情况： 安装 Windows10 系统时，在 我们为你连接到网络 时，没有任何选项。 在不配置网络的情况下安装完 Windows10 系统后，本该有的 WiFi 选项也没有。 在设备管理器中，网卡设备前有一个黄色感叹号，提示驱动未安装。 当你希望通过 拨号连接 或者 网络共享 连接网络时，提示 未安装网卡驱动。 二、解决方法前往极摩客官网下载驱动即可（我这里拿 G3 这台机器举例）：G3 默认是 RAR 压缩包，因此还需要下载下 7-Zip 解压工具：7-Zip之后通过 U 盘等方式将驱动包传输到小主机上，解压后以管理员身份运行 install.sh 即可： 安装完成后，就可以看见网络功能正常了： 参考资料： 解决安装Windows Server系统的家用电脑网卡不识别问题","link":"/2024/11/03/gmk_g3_n100_mini_pc_windows_no_%20drive/"},{"title":"AWS 实操 - 云安全 (Cloud Security)","text":"AWS 云安全相关实际操作。 AWS Key Management Service一、创建一个客户管理的密钥 进入 AWS KMS 控制台 选择客户管理的密钥并点击创建密钥 填写密钥信息 选择密钥类型（对称、非对称） 选择密钥来源（KMS、外部、自定义密钥库） 填写别名 填写描述 设置标签 配置密钥管理员（选择 IAM 用户或角色） 定义密钥使用权限 可以指定其他 AWS 账户使用此密钥。 审核和编辑密钥策略 点击完成 等待密钥创建完成查看详情 为密钥添加 IAM 用户 之后这个 IAM 用户就可以使用这个密钥来加密或解密自己的数据 AWS Key Management Service 加密和解密一、通过 AWS CLI 使用创建的客户管理密钥进行加密和解密 在 AWS CLI 中登录拥有该密钥的用户： 1aws configure 尝试列出所有 KMS 中的所有密钥： 1aws kms list-keys 由于没有相关 IAM 权限因此失败： 在 IAM 控制台为用户添加 KMS 的列出命令 ListKeys 权限： 再次列出密钥： 1aws kms list-keys 在 KMS CLI 命令列表页找到 encrypt 和 decrypt 命令 加密： 123456789aws kms encrypt \\ --key-id xxxxxxxxxxxxxxxxxxx \\ --plaintext &quot;Hello World&quot; \\ # 只要加密后的内容，不要 KeyId 和加密方式 --query CiphertextBlob \\ # 返回结果不被引号包围 --output text \\ # Base64 解码后输出到 encrypttest文件 | base64 --decode &gt; encrypttest CiphertextBlob：加密后的信息，经过 Base64 编码后的内容 解密： 123456aws kms decrypt \\ # 刚刚生成的 encrypttest 文件，需要加上前缀 fileb:// --ciphertext-blob fileb://encrypttest --query Plaintext \\ --output text \\ | base64 --decode","link":"/2024/11/25/hands_on_cloud_security/"},{"title":"AWS 实操 - 数据库","text":"AWS 数据库相关实际操作。 RDS 只读副本一、创建 RDS 只读副本 在 RDS 控制台选择主数据库实例 点击操作，选择创建只读副本 配置只读副本数据库实例 选择实例规格（推荐与源数据库实例规格至少保持一致） 配置网络与安全 可以跨 AWS 区域 配置只读副本，这个时候只读副本也是灾难恢复的一部分。⚠ 不过跨 区域 会增加主数据库和只读副本间复制数据的延迟。 设置数据库实例标识符（数据库的唯一键） 创建只读副本 切换到只读副本数据库所在 区域，等待数据库创建成功 视数据库大小可能需要数小时。 二、连接到主数据库并插入数据开启数据库公开性，并配置相应 VPC 安全组后，测试到主数据库终端节点（端口）的连接： 12# 以 MySQL 数据库的 3306 端口为例nc -zv test.test.region.rds.amazon.com 3306 在主数据库创建数据库后，前往只读副本数据库可以看到。图就不放了。 ⭐ 连接只读副本数据库的用户名和密码与主数据库保持一致。 ⚠ 只读副本无法直接写入数据。 还需要注意的是，还需要对只读副本数据库监控中的副本滞后指标做监控，差异过大意味着主数据库数据未能及时复制到只读副本中： 三、启用主数据库的自动备份 在 RDS 控制台选择主数据库实例 点击修改 在备份处，配置备份保留期为非 0 天以启用自动备份 四、将只读副本提升为独立数据库 (Promote) 在 RDS 控制台选择只读副本数据库实例 ⭐ 点击操作，选择提升 配置提升 设置关于启用自动备份的选项 确定提升只读副本（建议停止主数据的事务，并等待只读副本滞后为 0） 等待只读副本提升完成 大约需要数分钟。","link":"/2024/11/21/hands_on_database/"},{"title":"AWS 实操 - DNS、缓存与性能优化（包括 AWS Route 53）","text":"AWS DNS、缓存与性能优化（包括 AWS Route 53）相关实际操作。 使用 Route 53 注册一个域名一、使用 Route 53 注册一个域名 在管理控制台选择联网和内容分发 选择 Route 53 进入控制面板 点击注册域 填写域名并检查是否可用 填写联系人信息 确认信息无误后注册域名 等待几分钟后就能在托管区查看到域名了","link":"/2024/11/26/hands_on_dns/"},{"title":"AWS 实操 - EC2","text":"AWS EC2 相关实际操作。 启动 EC2 实例一、在公有子网中启动一个 EC2 实例 选择 区域 点击实例，选择启动新实例 填写实例信息 填写名称和标签 选择 AMI（系统镜像） 选择实例类型（配置） 配置（创建）SSH 密钥对 设置网络 配置 安全组 配置存储 填写高级详细信息 填写实例数量 确认信息后启动实例 EC2 Instance Connect 和 SSH一、四种连接方式 二、EC2 Instance Connect 三、SSH 实例的状态检查和自动恢复一、查看实例的状态检查结果 二、创建自动恢复 只支持系统状态检查失败时自动恢复。 创建状态警报 配置警报 配置发送 SNS 通知 配置操作 恢复此实例（停止、启动实例以切换底层物理服务器） 停止此实例 中止此实例 重启此实例（不会切换底层物理服务器） 配置触发条件 配置警告名称 警报创建成功后，前往 CloudWatch 等待数据收集完成 三、手动触发警报触发警报的命令： 1234aws cloudwatch set-alarm-sate --alarm-name &quot;test&quot; \\ --state-value ALARM \\ --state-reason &quot;test&quot; \\ --region ap-northeast-1 需要注意的是，手动触发的警报虽然在历史记录中有 EC2 实例停止、启动的操作记录，但是 AWS 并不会实际执行。只有在实际发生系统状态检查失败时，才会真正执行来切换底层硬件。 EC2 置放群组 (Placement groups)一、集群 (Cluster) 置放群组 在 EC2 控制台的网络与安全菜单下，选择置放群组 创建置放群组 输入名称 选择置放策略 集群 分布 分区 等待置放群组创建成功 启动新的 EC2 实例并放入刚刚创建的置放群组中 ⚠ 有的实例不支持放入置放群组。","link":"/2024/11/19/hands_on_ec2/"},{"title":"AWS 实操 - 弹性负载均衡器和弹性伸缩","text":"AWS 弹性负载均衡器和弹性伸缩相关实际操作。 创建一个 Auto Scaling 组 (ASG)一、创建启动模板 (Launch Template) 在实例菜单选择启动模板 点击创建启动模板 配置启动模板 填写启动模板名称 选择 AMI 选择实例类型 选择密钥对 选择安全组 配置存储 添加资源标签 配置高级详细信息 其中可以配置 用户数据。 创建启动模板 启动模板创建成功 二、创建 Auto Scaling 组 在 Auto Scaling 菜单选择 Auto Scaling 组 点击创建 Auto Scaling 组 配置 Auto Scaling 组 填写 Auto Scaling 组名称 选择启动模板（上一步创建的） 确认启动模板的内容后点击下一步 配置网络（一个 VPC 和多个可用区及子网） 配置实例类型要求（会覆盖启动模板的设置） 添加负载均衡器（可以稍后再添加） 配置运行状况检查 配置监控 在 CloudWatch 中启用组指标收集并不会收费。 ⭐ 配置组大小 ⭐ 配置扩展策略 添加通知 添加标签 审核所有配置并创建 Auto Scaling 组创建成功 ⭐ 开始自动更新容量（启动实例） 在 Auto Scaling 组的活动页面可以看到启动记录 使用实例刷新 (instance refresh) 可以更新 Auto Scaling 组中的所有实例 目标组一、创建 ALB 目标组 在负载平衡菜单选择目标群组 点击创建目标组 配置目标组 选择目标类型 可选实例、IP 地址、Lambda 函数和现有的 ALB。 输入目标组名称 配置目标组协议和端口 配置协议版本（HTTP 和 80 端口） 配置健康检查 配置标签 ⭐ 注册目标 (Register targets) 创建目标组 ALB 目标组创建完成 二、创建 NLB 目标组大致流程与 ALB 目标组创建时的一致。只列举不同的流程： … … 配置目标组 … … … ⭐ 配置协议版本（TCP 和 80 端口） NLB 不支持 HTTP 协议。 … … … … … 网络负载均衡器一、创建弹性 IP 地址 (Elastic IP addresses) 供 NLB 使用 二、创建网络负载均衡器 在负载平衡菜单选择负载均衡器 点击创建负载均衡器 配置负载均衡器 选择 NLB 负载均衡器类型 输入负载均衡器名称 选择面向互联网还是内网 选择单 IPv4 还是双栈（IPv4 加 IPv6） ⭐ 配置一个 VPC 和多个 可用区 及（公有）子网 ⭐ 为每个 子网 分配弹性 IP 地址 ⭐ 配置监听器（TCP 和 80 端口）和对应的目标组 创建负载均衡器 等待负载均衡器预置完成后创建成功 通过公有 DNS 访问负载均衡器 三、为 ASG 配置 NLB 负载均衡器（目标组） 四、查看 NLB 中注册的实例 五、查看 NLB 负载均衡器关联的 IP 地址12nslookup# 之后输入 NLB 的公有 DNS 虽然之前绑定了 3 个弹性 IP，但是当前 ASG 只在两个 子网 中创建了两台实例，因此只返回了两个 子网 绑定的弹性 IP 地址： 六、使用浏览器访问 NLB 的公有 DNS ⭐ 多次访问 NLB 的公有 DNS，请求都只被发到了一个子网中实例 算法不一样导致的，ALB 会轮询。 直接访问分配的弹性 IP 地址也可以达到实例 应用程序负载均衡器一、创建应用程序负载均衡器 在负载平衡菜单选择负载均衡器 点击创建负载均衡器 配置负载均衡器 选择 ALB 负载均衡器类型 输入负载均衡器名称 选择面向互联网还是内网 选择单 IPv4 还是双栈（IPv4 加 IPv6） ⭐ 配置一个 VPC 和多个 可用区 及（公有）子网 AWS 会自动为每个 子网 分配公有 IP 地址。 ⭐ 配置安全组 NLB 不支持配置安全组，而 ALB 支持。 ⭐ 配置监听器（HTTP 和 80 端口）和对应的目标组 创建负载均衡器 等待负载均衡器预置完成后创建成功 通过公有 DNS 访问负载均衡器 二、为 ASG 配置 ALB 负载均衡器（目标组） 三、使用浏览器访问 ALB 的公有 DNS 默认每次访问都前往了不同可用区（轮询） ⭐ 使用 粘性会话 (Sticky Sessions) 可以将同一客户端的请求固定在一个可用区","link":"/2024/11/21/hands_on_elastic/"},{"title":"AWS 实操 - IAM (Identity and Access Management)","text":"AWS IAM 相关实际操作。 创建一个 IAM 用户一、创建一个 IAM 用户 从管理控制体进入 IAM 控制面板 点击用户并添加用户 填写用户信息 输入用户名 选择 AWS 访问类型 访问密钥 - 编程访问 密码 - AWS 管理控制台访问 设置权限 直接附加现有策略 从现有用户复制权限 将用户添加到组 添加标签 审核信息并创建用户 等待创建成功后，使用新的 IAM 用户即可登陆控制台 AWS Security Token Service (STS)一、在已经附加了角色的 EC2 实例上查看 STS 生成的临时凭证 S3ReadOnly 角色 配置了 AmazonS3ReadOnlyAccess 策略 EC2 实例已经附加了 S3ReadOnly 的 角色 在 EC2 实例上列出 S3 存储桶 1aws s3 ls 通过 EC2 实例元数据 (metadata) 条目检索角色提供的安全证书 1curl http://169.254.169.254/latest/meta-data/iam/security-credentials/S3ReadOnly/","link":"/2024/11/23/hands_on_iam/"},{"title":"AWS 实操 - 身份与联合身份验证（针对 SAP-C02 认证）","text":"AWS 身份与联合身份验证相关实际操作。 创建跨账户 IAM 角色访问（Creating Cross-Account IAM Roles）一、最终目标 二、在生产环境中创建 IAM 角色 全程通过生产环境账户进行操作。 进入 IAM 控制台 选择角色 创建角色 ⭐ 选择受信任的实体类型为其他 AWS 账户 输入身份账户的账户 ID ⭐ 给予这个角色 S3 存储桶的完全访问权限 填写角色名称并创建 角色创建成功后确认信息 角色 ARN ⭐ 用以切换角色的链接 信任关系（策略） 三、在身份账户中创建 IAM 用户 全程通过身份账户进行操作。 进入 IAM 控制台 选择用户 创建 IAM 用户 选择密码 - AWS 管理控制台访问 不选择任何权限 不添加标签 确认用户信息并创建 创建成功后为 IAM 用户 添加内联策略 选择策略编辑的 JSON 选项卡 填入如下策略 123456789{ &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: { &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: &quot;sts:AssumeRole&quot;, // 这里的 Resource 就是生产环境中的角色 ARN &quot;Resource&quot;: &quot;arn:aws:iam::PRODUCTION-ACCOUNT-ID:role/UpdateApp&quot; }} 填写名称并创建策略 四、使用 IAM 用户登录 AWS 控制台并切换角色 全程通过身份账户的 IAM 用户进行操作。 使用 IAM 用户 登录身份账户 账户：身份账户的账户 ID 用户名：IAM 用户 用户名 密码：IAM 用户 密码 访问生产账户的角色的切换链接 确认账户和角色 填写显示名称 切换角色 角色切换成功后访问 S3 存储桶确认权限生效 可以在右上角的角色历史记录中轻松切换其他角色 创建 AWS Organizations 和 SCP一、最终目标 二、创建 AWS Organizations 并邀请其他 AWS 用户 全程通过组织的管理账户（主账户）进行操作。 进入 AWS Organizations 控制台 创建组织 添加账户 选择邀请现有 AWS 账户 输入想要邀请的账户 ID 点击邀请 等待成员账户接受邀请 三、接受邀请并加入组织 全程通过组织的成员账户进行操作。 进入 AWS Organizations 控制台 查看邀请并接受 确认 SCP 策略被附加到该账户（S3 操作拒绝） 四、为 IAM 用户添加策略 全程通过组织的管理账户（主账户）进行操作。 进入 AWS Organizations 控制台 选择策略 选择服务控制策略并启用 默认的策略 FullAWSAccess 附加到每个根、OU 和用户并允许所有服务的所有操作 创建策略 输入策略名称 编辑策略 添加操作 - 选择 S3 的所有操作 添加资源 - 选额 S3 的所有资源 确认策略内容并创建 等待策略创建成功 切换到 AWS 账户 将策略附加到成员账户上 进入成员账户详情 选择策略选项卡 点击附加 选择刚刚创建的策略并附加 之后前往相应成员账户确认策略生效（S3 操作拒绝） 集中式日志架构 (Centralized Logging Architecture)一、最终目标 二、在中央账户建立日志收集用的 S3 存储桶 进入 S3 控制台 创建存储 CloudTrail 日志的存储桶 配置存储桶策略 选择存储桶 编辑存储桶策略 添加策略 允许日志收集账户的 CloudTrail 进行 s3:GetBucketAcl 和 s3:PutObject 操作。 123456789101112131415161718192021222324252627282930{ &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Sid&quot;: &quot;AWSCloudTrailAclCheck20150319&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Principal&quot;: { &quot;Service&quot;: &quot;cloudtrail.amazonaws.com&quot; }, &quot;Action&quot;: &quot;s3:GetBucketAcl&quot;, // 修改为对应存储桶的 ARN &quot;Resource&quot;: &quot;arn:aws:s3:::iloveawscn-central-config&quot; }, { &quot;Sid&quot;: &quot;AWSCloudTrailWrite20150319&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Principal&quot;: { &quot;Service&quot;: &quot;cloudtrail.amazonaws.com&quot; }, &quot;Action&quot;: &quot;s3:PutObject&quot;, // 修改为对应存储桶的 ARN &quot;Resource&quot;: &quot;arn:aws:s3:::iloveawscn-central-config/*&quot;, &quot;Condition&quot;: { &quot;StringEquals&quot;: { &quot;s3:x-amz-acl&quot;: &quot;bucket-owner-full-control&quot; } } } ]} 保存策略 创建存储 AWS Config 日志的存储桶 选择存储桶 编辑存储桶策略 添加策略 保存策略 日志收集账户配置完成后确认日志收集状态 三、在日志收集账户将日志转发到存储桶 打开 CloudTrail 控制台 创建跟踪 (Trail) 输入跟踪名称 存储位置选择现有的 S3 存储桶 输入中央账户的 S3 存储桶的名称 创建跟踪 打开 AWS Config 控制台 选择设置 编辑设置 选择从另一个账户选择存储桶 输入中央账户的 S3 存储桶的名称 保存设置","link":"/2024/12/24/hands_on_identity/"},{"title":"AWS 实操 - 监控、日志和审计","text":"AWS 监控、日志和审计相关实际操作。知识点请参考：AWS 知识点 - 监控、日志和审计、AWS 知识点 - 监控、日志和审计 - 拓展（针对 SAP-C02 认证） 将 Linux 系统日志内容推送至 CloudWatch一、将系统日志推送至 CloudWatch 日志组 为 EC2 分配 IAM 角色以允许其创建日志组并将日志发送至日志组 访问 IAM 控制台 在左侧的访问管理菜单选择角色 创建角色 选择 EC2 将使用此角色 附加 CloudWatchAgentServerPolicy 策略 修改角色名称 点击创建角色 等待 IAM 角色创建成功 为 EC2 实例附加角色 附加成功后检查策略内容 在 EC2 上安装 CloudWatch 代理 1yum install -y awslogs 配置 CloudWatch 代理 1cd /etc/awslogs/ 修改 awscli.conf 文件，将区域改为 CloudWatch 所在区域 修改 awslogs.conf 文件，配置将哪些日志推送到什么 CloudWatch 日志组 运行 CloudWatch 代理 123systemctl start awslogsd# 查看运行情况systemctl status awslogsd 切换到 CloudWatch 控制台查看发送过来的日志","link":"/2024/12/07/hands_on_monitor/"},{"title":"AWS 实操 - 部署和管理","text":"AWS 部署和管理相关实际操作。知识点请参考：AWS 知识点 - 部署和管理、AWS 知识点 - 部署和管理 - 拓展（针对 SAP-C02 认证） AWS Elastic Beanstalk一、使用 AWS Elastic Beanstalk 部署一个 Web 应用 在 Elastic Beanstalk 控制台点击创建应用按钮 配置应用程序信息 填写应用程序名称 选择应用程序标签 选择运行的平台（PHP、Python 和 Go 等）、平台分支和平台版本 指定代码来源 从本地计算机上传代码 从 S3 复制源代码 点击创建应用程序 Elastic Beanstalk 后台会创建 EC2、安全组、EIP 并上传代码到 EC2 实例等，在这过程中控制台将跟踪进度并显示事件 通过应用程序页面上方的 URL 访问应用 Elastic Beanstalk 进阶一、通过日志查看应用实际部署在的 EC2 实例 二、应用程序日志排查 在 EB 控制台选择日志 请求完整日志 下载对应日志（压缩包） 三、弹性伸缩 在 EB 控制台选择配置 编辑容量 将环境类型从单一实例变更为负载均衡 配置最小和最大实例数 配置实例类型 配置 AMI 配置实例放置的可用区 配置触发扩展的指标 或配置基于事件的扩展 应用容量 编辑其他类似环境内存限制等配置 配置日志流式传输到 CloudWatch 等功能 EC2 实例部分配置也能在 EB 进行配置","link":"/2024/11/20/hands_on_ops/"},{"title":"AWS 实操 - S3 (Simple Storage Service)","text":"AWS S3 相关实际操作。 创建 S3 存储桶一、创建一个 S3 存储桶 打开服务控制台，选择存储 选择 S3 进入 S3 控制台 点击创建存储桶按钮 填写存储桶信息 填写存储桶名称（全球唯一） 选择 AWS 区域 配置对象所有权 ACL 默认为禁用，即该存储桶只能由我这个账号使用。如果需要跨 AWS 账户使用存储桶，需要启用 ACL。 配置公有访问 默认阻止所有公有访问。 配置存储桶版本控制 配置标签 配置加密 高级设置 创建存储桶 等待存储桶创建成功，查看详情 上传文件 选择文件 选择文件的存储类别 设置文件的加密 添加标签 添加元数据 点击上传 等待文件上传成功，查看文件的详细信息 如果配置了存储桶可以公开访问，就能通过文件的对象 URL 访问文件了 存储桶的 ACL 和文件对象的 ACL 是分开的 访问控制列表 (ACL)一、为存储桶中的对象开启公有访问 进入到存储桶中 存储桶当前还处于不公开状态。 选择任意对象并拷贝其对象 URL，测试访问发现访问被拒绝 回到存储桶并选择权限 修改存储桶级别的访问控制列表 (ACL) 点击编辑阻止公有访问（存储桶设置） 取消组织所有公开访问的勾选框 确认公开访问 点击查看访问控制列表 (ACL)，不需要更改保持默认即可 ⭐ 启用对象的公共访问是不需要开启存储桶的列出权限的。 选择存储桶内的对象并选择权限 编辑存储桶对象级别的访问控制列表 (ACL) 勾选所有人（公有访问权限） 确认了解变更对对象的影响 保存更改 再次尝试通过对象 URL 访问对象，成功了 更简单的方式是选择对象并点击操作，选择使用 ACL 设为公开 二、为存储桶开启跨 AWS 账户的访问 进入到存储桶中 选择权限 编辑访问控制列表 (ACL) 在底部添加被授权者的规范 ID 并设置权限 保存更改 S3 生命周期配置一、为 S3 存储桶配置生命周期规则（转换） 进入到存储桶中 选择管理 创建生命周期规则 填写生命周期规则信息 填写生命周期规则名称 选择规则范围 设置筛选条件（来筛选影响的对象） 或确定应用到存储桶中的所有对象 选择生命周期规范操作 在存储桶之间转移对象的当前版本 设定 30 天后转换为标准 - IA 设置 90 天后转换为 Glacier 归档类型 审核规则 点击创建 转换规则创建成功 二、为 S3 存储桶配置生命周期规则（过期） 进入到存储桶中 选择管理 创建生命周期规则 填写生命周期规则信息 填写生命周期规则名称 选择规则范围 设置筛选条件（来筛选影响的对象） 或确定应用到存储桶中的所有对象 选择生命周期规范操作 永久删除对象的非当前版本 删除 30 天后对象的非当前版本 保留较新版本的数量 审核规则 点击创建 转换规则创建成功 三、禁用存储桶的生命周期规则 使用 S3 预签名 URL 共享对象一、使用 AWS CLI 为 S3 对象创建预签名 URL 进入到存储桶中 选择任意对象并拷贝其对象 URL，测试访问发现访问被拒绝 通过 AWS CLI 生成这个对象的预签名 URL 12# 60 秒过期aws s3 presign s3://iloveawscn-saa/presignurl.jpeg --expires-in 60 通过返回的链接成功访问对象（在有效期内） 过了有效期后访问被拒绝（提示访问过期，同时有详细的过期时间显示） 通过 S3 控制台也能生成预签名 URL","link":"/2024/11/24/hands_on_s3/"},{"title":"AWS 实操 - 块和文件存储","text":"AWS 块和文件存储相关实际操作。 使用亚马逊 AMIs一、手动创建 AMI ⚠ 手动创建快照时，如果实例没有关闭，可能会遇到操作系统锁定并保护某些文件导致失败的问题。 点击 Elastic Block Store 子菜单选择卷 选择卷 点击操作选择创建快照 之后通过快照创建 AMI 没有详细演示。 二、自动创建 AMI 并使用它创建新的 EC2 实例 使用这种方式创建 AMI 会自动关闭这台实例，然后拍摄快照，最后从快照创建 AMI。 点击实例子菜单选择实例 选择需要创建 AMI 的实例 点击操作选择映像和模板 创建映像 填写映像信息 填写映像名称 ⭐ 将为每个卷都创建一个快照 点击创建映像 前往映像子菜单选择 AMI AMI 控制台显示刚刚的映像状态为待处理 编辑该 AMI 的权限 修改 AMI 共享设置 ⭐ 等待映像创建完成后，相应的快照也创建完成了 在实例控制台点击启动新实例 ⭐ 在应用程序和操作系统镜像处选择刚刚创建的 AMI ⭐ 可以选择不同的可用区 确认信息并启动实例 使用相同的密码即可登陆新的实例","link":"/2024/11/27/hands_on_storage/"},{"title":"K3s 学习（一）境内 K3s 集群的特殊设置","text":"前言Docker Hub 被 Ban 掉之后境内的 K3s 集群就几乎瘫痪了 🤦，找补一下。 问题与解决一、Docker Hub 镜像拉取问题1、问题描述我是在 Rancher 导入新的集群时发现的。新的集群一直处于 Pending 状态，查看日志发现是因为镜像拉取失败导致的： 12kubectl get pods -n cattle-systemkubectl logs cattle-cluster-agent-xxxxxxxxx-aabbc -n cattle-syste 错误信息为： 12Error from server (BadRequest): container &quot;cluster-register&quot; in pod &quot;cattle-cluster-agent-xxxxxxxxx-aabbc&quot; is waiting to start: image can't be pulledError from server (BadRequest): container &quot;cluster-register&quot; in pod &quot;cattle-cluster-agent-xxxxxxxxx-aabbc&quot; is waiting to start: trying and failing to pull image 2、解决方法首先需要找一个 Docker Hub 的镜像站：Docker Hub 镜像加速器或者申请一个阿里云的镜像加速器：阿里云容器镜像服务当然你也可以和我一样自建：部署 Docker 镜像加速服务然后修改下对应集群节点的配置文件：/etc/rancher/k3s/registries.yaml 1vi /etc/rancher/k3s/registries.yaml 文件内容： 12345mirrors: &quot;docker.io&quot;: endpoint: - &quot;https://registrie.ceshiku.cn&quot; - &quot;https://xxxxxxxx.mirror.aliyuncs.com&quot; 重启 K3s 服务： 1systemctl restart k3s 3、确认解决再次查看集群状态： 12kubectl get pods -n cattle-systemkubectl logs cattle-cluster-agent-xxxxxxxxx-aabbc -n cattle-syste 二、K3s 集群节点安装12345curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ sh -s - \\ # 使用自定义的镜像加速器作为默认镜像源 --system-default-registry=registrie.ceshiku.cn 三、无法解析 Rancher 面板的域名1、问题描述1ERROR: https://rancher.ceshiku.cn/ping is not accessible (Could not resolve host: rancher.ceshiku.cn) 2、解决方法官方文档：Agent 无法连接 Rancher server自建下域名和 IP 的映射关系： 123456789101112131415161718192021222324252627282930313233343536kubectl -n cattle-system patch deployments cattle-cluster-agent --patch '{ &quot;spec&quot;: { &quot;template&quot;: { &quot;spec&quot;: { &quot;hostAliases&quot;: [ { &quot;hostnames&quot;: [ &quot;rancher.ceshiku.cn&quot; ], &quot;ip&quot;: &quot;1.2.3.4&quot; } ] } } }}'# 这一步可能会报错，因为没有 daemonsets，可以忽略kubectl -n cattle-system patch daemonsets cattle-node-agent --patch '{ &quot;spec&quot;: { &quot;template&quot;: { &quot;spec&quot;: { &quot;hostAliases&quot;: [ { &quot;hostnames&quot;: [ &quot;rancher.ceshiku.cn&quot; ], &quot;ip&quot;: &quot;1.2.3.4&quot; } ] } } }}' 四、CoreDNS 一直处于 CrashLoopBackOff 状态1、问题描述1kubectl get pods -A 1kube-system coredns-5fc867466c-rrkqq 0/1 CrashLoopBackOff 36 (3m21s ago) 44m 2、解决方法在导入集群前，修改 Server 宿主机的 DNS 配置： 1vi /etc/systemd/resolved.conf 12[Resolve]DNS=8.8.8.8,223.5.5.5 123systemctl restart systemd-resolvedsudo mv /etc/resolv.conf /etc/resolv.conf.baksudo ln -s /run/systemd/resolve/resolv.conf /etc/ 之后需要重装集群。 五、CPU 飙升服务器卡死大概率内存不够，尝试增加虚拟内存解决：KVM 虚拟化的服务器建立 SWaP 分区以增加虚拟内存","link":"/2024/09/21/k3s_note_01_china/"},{"title":"K3s 学习（二）使用 Docker 部署 Rancher","text":"前言优化了下之前的流程。现在仍然是将 Rancher 部署在集群外的机器上，但是新增了通过 acme.sh 自动申请证书的功能。 方案概述 安装最新的 Docker（环境） 启动 Rancher 域名解析到服务器 安装最新的 Nginx 安装 acme.sh 申请和安装证书（包含证书更新时的 hook） 修改 Nginx 配置并重启 修改证书自动更新相关配置并测试 操作步骤一、安装最新的 Docker（环境）参考：Ubuntu 20.04 从官方源安装最新的 Docker 12345678sudo apt-get updatesudo apt-get install ca-certificates curl gnupg lsb-releasesudo mkdir -p /etc/apt/keyringscurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpgecho &quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/nullsudo apt-get updatesudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugindocker -v 二、启动 Rancher 容器内的 80 端口映射到宿主机 8080 端口（之后会通过 Nginx 反代） 容器内的 443 端口映射到宿主机 8443 端口 使用 ectd 作为数据存储，并通过映射到 /rab/docker/rancher 目录实现持久化 123456789docker run -d \\ --name rancher \\ --privileged \\ --restart=unless-stopped \\ -p 8080:80 \\ -p 8443:443 \\ -v /rab/docker/rancher:/var/lib/rancher \\ rancher/rancher:v2.8.6-rc3 \\ --no-cacerts 三、域名解析到服务器在域名托管处进行操作，如果是 Cloudflare 的话记得关掉小云朵。直到 ping 域名得到正确 IP 后再进行下一步。 四、安装最新的 Nginx参考：Installing Prebuilt Ubuntu Packages之后隐藏默认证书的时候需要用到新的配置项。 12345678910sudo apt install curl gnupg2 ca-certificates lsb-release ubuntu-keyringcurl https://nginx.org/keys/nginx_signing.key | gpg --dearmor | sudo tee /usr/share/keyrings/nginx-archive-keyring.gpg &gt;/dev/nullgpg --dry-run --quiet --no-keyring --import --import-options import-show /usr/share/keyrings/nginx-archive-keyring.gpgecho &quot;deb [signed-by=/usr/share/keyrings/nginx-archive-keyring.gpg] \\ http://nginx.org/packages/ubuntu `lsb_release -cs` nginx&quot; \\ | sudo tee /etc/apt/sources.list.d/nginx.listecho -e &quot;Package: *\\nPin: origin nginx.org\\nPin: release o=nginx\\nPin-Priority: 900\\n&quot; \\ | sudo tee /etc/apt/preferences.d/99nginxsudo apt updatesudo apt install nginx 12systemctl enable nginxsystemctl start nginx 五、安装 acme.sh123456789# 安装所需软件apt-get install curlapt-get install socat# 安装 acmecurl https://get.acme.sh | sh# 添加软链接ln -s /root/.acme.sh/acme.sh /usr/local/bin/acme.sh# 切换 CA 机构acme.sh --set-default-ca --server letsencrypt 六、申请和安装证书（包含证书更新时的 hook）我这里的域名是 rancher.ceshiku.cn。先申请证书： 这里先用 --standalone 模式申请证书，之后 Nginx 后启动后会占用 80 端口，需要改为使用 --webroot 模式更新证书。 1acme.sh --issue -d rancher.ceshiku.cn --standalone -k ec-256 再安装证书： 指定证书的目录 在更新时执行 Nginx 的重新加载 1234567# 建立证书的目录mkdir -vp /etc/nginx/ssl/rancher.ceshiku.cn# 安装acme.sh --install-cert -d rancher.ceshiku.cn \\ --fullchain-file /etc/nginx/ssl/rancher.ceshiku.cn/certificate.crt \\ --key-file /etc/nginx/ssl/rancher.ceshiku.cn/private.key \\ --reloadcmd &quot;service nginx force-reload&quot; 七、修改 Nginx 配置并重启在 /etc/nginx/conf.d/ 目录下新建配置 rancher.ceshiku.cn.conf： 1vi /etc/nginx/conf.d/rancher.ceshiku.cn.conf 文件内容： 12345678910111213141516171819202122232425262728293031323334353637server { listen 80; server_name rancher.ceshiku.cn; # 强制跳转 HTTPS location / { return 301 https://$server_name$request_uri; } # 设置证书认证用的路径 location /.well-known/acme-challenge/ { # acme.sh --webroot 模式，认证文件生成后放置的路径 root /var/acme/webroot/; }}server { listen 443 ssl; server_name rancher.ceshiku.cn; # SSL 配置 ssl_certificate /etc/nginx/ssl/rancher.ceshiku.cn/certificate.crt; ssl_certificate_key /etc/nginx/ssl/rancher.ceshiku.cn/private.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; location / { proxy_pass http://127.0.0.1:8080; proxy_set_header Host $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-Port $server_port; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; }} 然后为 /etc/nginx/nginx.conf 添加配置来防止出现 nginx: [emerg] unknown &quot;connection_upgrade&quot; variable 错误： 1vi /etc/nginx/nginx.conf 1234map $http_upgrade $connection_upgrade { default upgrade; '' close;} 备份并重新建立 default.conf 来保证基础的安全，包括对 IP 的直接访问返回 500 错误，以及不返回默认的 SSL 证书： 12mv /etc/nginx/conf.d/default.conf /etc/nginx/conf.d/default.conf.bakvi /etc/nginx/conf.d/default.conf 1234567891011121314151617181920212223242526272829303132# 非域名访问返回 500 错误server { listen 80; listen [::]:80; server_name _; location / { return 500; } # 特殊的证书认证用的路径 location /.well-known/acme-challenge/ { # acme.sh --webroot 模式，认证文件生成后放置的路径 root /var/acme/webroot/; }}# 非域名访问防止发送 SSL 证书server { listen 443 ssl default_server; server_name _; ssl_protocols TLSv1.2 TLSv1.3; # 启用拒绝 TLS 握手 ssl_reject_handshake on; # SSL Session 缓存，不设置的话无缓存配置不生效 ssl_session_cache shared:SSL:10m; ssl_session_timeout 10m; # log 位置自行替换 access_log /var/log/nginx/host.access.log;} 之后重启： 12nginx -s reloadservice nginx restart 最后访问域名即可： 八、修改证书自动更新相关配置并测试看下当前申请的证书列表： 1acme.sh --list 重新使用 --webroot 模式认证域名所有权，认证文件放在 /var/acme/webroot/ 中： 1acme.sh --issue -d rancher.ceshiku.cn --webroot /var/acme/webroot/ -k ec-256 --force 1234acme.sh --install-cert -d rancher.ceshiku.cn \\ --fullchain-file /etc/nginx/ssl/rancher.ceshiku.cn/certificate.crt \\ --key-file /etc/nginx/ssl/rancher.ceshiku.cn/private.key \\ --reloadcmd &quot;service nginx force-reload&quot; 然后执行 renew 确认一下可以正常更新： 1acme.sh --renew -d rancher.ceshiku.cn --force 之后在证书即将过期时，就会自动更新了。 参考资料： 零依赖!使用acme.sh设置nginx多个https证书自动更新，无限续期https证书","link":"/2024/09/15/k3s_note_02_02_update/"},{"title":"K3s 学习（六）在 Kubernetes 集群上安装 cert-manager","text":"前言起因是随着业务扩展，又在日本、新加坡以及英国等国家地区增设了不少边缘节点，一个一个维护消耗的精力太多了，因此需要将这些内容分发服务器也做统一管理了，这样后续扩容也更加方便。这其中的一个痛点是 SSL 证书，主业务 40 刀每年的泛域名证书已经让我很肉疼了。想着能不能让集群中的 pod 都用 Let’s Encrypt 的免费证书，于是便发现了 cert-manager 这个云原生证书管理开源项目，似乎可以做到。因此便有了这次尝试：先构建一台 K3s Server + 一台 K3s Agent 的最小化 K3s 集群，之后安装 cert-manager，然后启动一个纯前端的项目验证安装成功。 方案概述 构建一台 K3s Server + 一台 K3s Agent 的最小化 K3s 集群 检查集群满足 cert-manager 的安装要求 安装 Helm 并添加 Helm Chart 仓库 安装 cert-manager 测试 cert-manager 建立集群证书颁发者 ClusterIssuer 部署纯前端项目 配置 Service 和 Ingress 暴露应用 访问应用检查 SSL 证书 操作步骤一、构建最小化集群 参考 K3s 官方文档：快速入门指南 最大 100 台的集群需要 K3s Server 至少拥有 4 核心和 8GB 内存。这里使用了一台 2H8G（可动态扩容）的云服务器作为 K3s Server，另一台 4H16G 的云服务器作为 Agent，均已重装为 Ubuntu 22.04 系统。 可能需要更新下源并安装必要的依赖： 12apt-get updateapt-get install curl 安装并标记为 K3s Server： 123curl -sfL https://get.k3s.io | sh -s - # 查看以下 node-tokencat /var/lib/rancher/k3s/server/node-token 安装并标记为 K3s Agent： 1curl -sfL https://get.k3s.io | K3S_URL=https://$your_node_ip:6443 K3S_TOKEN=$your_node_token sh - 在 Server 上检查 Agent 来确定集群构建成功： 1kubectl get nodes 二、检查集群满足 cert-manager 的安装要求需要满足以下这些基本要求： 打 ✅ 的项目是 K3s 集群自带或者非常基础的条件，无需关注。打 ⬜ 的项目需要注意。 ✅ 集群必须包含一个 Ingress Controller 文档描述：“对于 RKE、RKE2 和 K3s，你不需要手动安装 Ingress Controller，因为它是默认安装的。”。这里的默认负载方案是 traefik 和 servicelb。 ✅ 集群需要有 kubectl（Kubernetes 命令行工具） K3s 集群同样默认安装，我们之前就是通过 kubectl get nodes 这个命令检查节点的。 ⬜ 集群需要有 Helm （Kubernetes 包管理器） ✅ 集群需要能够访问互联网 如果无法联网请参考：离线环境：Kubernetes 安装，我并没有做过实践。 三、安装 Helm 并添加 Helm Chart 仓库 官方文档：安装 Helm - 使用 Apt (Debian/Ubuntu) 在 K3s Server 上安装一下： 12345678# 必要的依赖sudo apt install gnupg2# 安装 Helmcurl https://baltocdn.com/helm/signing.asc | gpg --dearmor | sudo tee /usr/share/keyrings/helm.gpg &gt; /dev/nullsudo apt-get install apt-transport-https --yesecho &quot;deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/helm.gpg] https://baltocdn.com/helm/stable/debian/ all main&quot; | sudo tee /etc/apt/sources.list.d/helm-stable-debian.listsudo apt-get updatesudo apt-get install helm 安装完成后确认下： 1helm version 仓库这里选用 Stable 版本，官方推荐它适用于生产环境： 1helm repo add rancher-stable https://releases.rancher.com/server-charts/stable 之后在使用 Helm 安装的时候，很有可能会出现 “Kubernetes cluster unreachable” 错误，需要在安装前运行下面命令来防止： 12echo 'export KUBECONFIG=/etc/rancher/k3s/k3s.yaml' &gt;&gt; ~/.bashrcsource ~/.bashrc 四、安装 cert-manager 这一步请参照比 Rancher 官方更新的文档：Installing the Chart 所有命令依然是都在 K3s Server 上运行。去官方 GitHub 仓库确认下版本编号，之后下载最新的 cert-manager.crds.yaml，我当前是 v1.15.3： 12cd /root/kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.15.3/cert-manager.crds.yaml 添加仓库并更新本地缓存： 12helm repo add jetstack https://charts.jetstack.iohelm repo update 安装： 这一步出错的可能性非常高！如果下一步安装失败了，会有非常多的冲突项要清理，之后才能进行重新安装。我比较建议失败了就记录下解决方法，然后重装系统并在执行安装前完成所有必要项目。 123456# 建立下命名空间kubectl create namespace cert-manager# 安装helm install cert-manager jetstack/cert-manager \\ --namespace cert-manager \\ --version v1.15.3 检查下各 pod 的情况： 1kubectl get pods --namespace cert-manager 五、测试 cert-manager1、建立集群证书颁发者 ClusterIssuer新建配置文件 letsencrypt.yml： 1vi letsencrypt.yml 注意将 admin@ceshiku.cn 修改为你的邮箱。 123456789101112131415apiVersion: cert-manager.io/v1kind: ClusterIssuermetadata: name: letsencrypt-prodspec: acme: email: admin@ceshiku.cn privateKeySecretRef: name: prod-issuer-account-key server: https://acme-v02.api.letsencrypt.org/directory solvers: - http01: ingress: class: traefik selector: {} 部署并查看： 12kubectl apply -f letsencrypt.ymlkubectl describe clusterissuer letsencrypt 2、部署纯前端项目1kubectl create namespace logos 新建配置文件 deployment.yml： 1vi deployment.yml 12345678910111213141516171819apiVersion: apps/v1kind: Deploymentmetadata: name: rancher-logo-app namespace: logosspec: selector: matchLabels: name: rancher-logo-backend template: metadata: labels: name: rancher-logo-backend spec: containers: - name: backend image: ruanbekker/logos:rancher ports: - containerPort: 80 部署并查看： 12kubectl apply -f deployment.ymlkubectl get deployment -n logos 3、配置 Service 和 Ingress 暴露应用新建配置文件 service.yml： 1vi service.yml 12345678910111213apiVersion: v1kind: Servicemetadata: name: rancher-logo-service namespace: logosspec: ports: - name: http port: 80 protocol: TCP targetPort: 80 selector: name: rancher-logo-backend 部署并查看： 12kubectl apply -f service.ymlkubectl get service -n logos 新建配置文件 ingress.yml： 1vi ingress.yml 注意将 logos.ceshiku.cn 修改为你的域名。 1234567891011121314151617181920212223apiVersion: networking.k8s.io/v1kind: Ingressmetadata: annotations: cert-manager.io/cluster-issuer: letsencrypt-prod name: rancher-logo-ingress namespace: logosspec: tls: - secretName: rancher-logo-k3s-ruan-dev-tls hosts: - logos.ceshiku.cn rules: - host: logos.ceshiku.cn http: paths: - pathType: Prefix path: / backend: service: name: rancher-logo-service port: number: 80 部署并查看： 12kubectl apply -f ingress.ymlkubectl get ingress -n logos 外部流量先到 Ingress，然后通过 Service 到 Deployment： 4、访问应用检查 SSL 证书证书可信： 各种意外情况一、Kubernetes cluster unreachable常在 Helm 安装 cert-manager 时出现，错误内容： 1Error: INSTALLATION FAILED: Kubernetes cluster unreachable: Get &quot;http://localhost:8080/version&quot;: dial tcp [::1]:8080: connect: connection refused 解决方法： 12echo 'export KUBECONFIG=/etc/rancher/k3s/k3s.yaml' &gt;&gt; ~/.bashrcsource ~/.bashrc 之后往往需要删除 cert-manager 命名空间方便重新安装： 1kubectl delete namespace cert-manager 二、cert-manager 的安装有误如果你需要重新安装 cert-manager，那么需要删除命名空间： 1kubectl delete namespace cert-manager 大概率它会卡住然后命名空间处于 Terminating 状态，那么请参照 Kubernetes 删除 namespace 时一直处于 Terminating 状态的解决方法这篇文章进行强制删除。之后再通过 kubectl delete 删除冲突的 Cluster 和 ClusterRole 等： 官方清理文档：Helm 1234567kubectl delete crd \\ issuers.cert-manager.io \\ clusterissuers.cert-manager.io \\ certificates.cert-manager.io \\ certificaterequests.cert-manager.io \\ orders.acme.cert-manager.io \\ challenges.acme.cert-manager.io 1kubectl delete apiservice v1beta1.webhook.cert-manager.io 最后重新安装，重新安装的时候大概率会有其他冲突项需要手动一点点删除。 参考资料： 在 Kubernetes 集群上安装/升级 Rancher [BUG] Failed to update cluster [local]: Internal error occurred: failed calling webhook “rancher.cattle.io.clusters.management.cattle.io” 卸载helm安装的Rancher 라즈베리파이 4에 K8S 클러스터 올리기 — cert-manager 배포하기 安装 k3s + ingress nginx + cert-manager 将 K3s 中 Ingress 组件从 Traefik 替换为 Nginx K8s &amp; K3s 集群中应用自动签发 Https 证书 k3s+traefik+cert-manager+letsencrypt实现web服务全https 📺 K3S + Nginx + Cert-Manager + LetsEncrypt | HTTPS for your Kubernetes (K8s) Cluster | Tutorial Cert Manager 申请 SSL 证书流程及相关概念 - 一 ⭐ k3s 使用 Letsencrypt 和 Traefik 完成 https 入口部署 使用 Cert Manager 自动管理 Kubernetes Gateway 证书","link":"/2024/09/18/k3s_note_06/"},{"title":"日语知识点 - 日语声调","text":"日语声调及标注 ⓪①②③④ 的案例单词的读法。 日语声调一、基本概念 日语的声调类型属于高低型，不是强弱型。 没有在同一个高度的声调类型。 例如：いち② 这个单词的 い 和 ち 是不同的声调。 第一个音节与第二个音节的高度一定不一样。 高音部只有一处，且下降后不会再上升。 ⓪ 型音较为特殊，除了第一个音节是低音，其他音节都是高音。 二、标记方法 数字标记：⓪①②③④，告诉你第几个音节需要读成高音。 例如：はし① はし② はし⓪ 用线做标记，线在上的音节读成高音，线在下的音节读成低音。 例如： 三、发音 高音约等于汉语的第一声。 低音约等于汉语的第三声的前半部分（只有降的那一半）。 声调 高音 低音 发音 备注 はし① は し は 略微上扬，し 略微下降。 はし② し は は 略微下降，し 略微上扬。 はし⓪ し は は 略微下降，し 略微下降。在这里由于和 はし② 一样高音都在第二个音节，因此读音也完全一样。 四、拓展 单词的声调会延续到下一个助词，这可以用来区分 ⓪ 型音和其他音调。 ⓪ 型音会把助词也带成高音，而其他音调则会将助词带成低音。 参考资料： 📺 【日语语音】21 日语声调详解 数字式&amp;线式标记法","link":"/2024/09/03/knowledge_akusento/"},{"title":"AWS 知识点 - 云安全 (Cloud Security)","text":"AWS 云安全相关知识点。 AWS Directory Service（AWS 目录服务）一、微软 AD (Active Directory) 基本概念 负责处理以及存储在组织中的网络对象，包括用户、群组、电脑、邮件、配置文件和打印机等 ⭐ Windows 环境中的集中管理方式，用于安全管理、创建账户和分配权限等 AD 中域、域树和域森林的概念： 域 (domain)：最基本的管理单元，同时也是最基层的容器。它可以对员工、计算机等基本数据进行存储。 域树 (tree)：在一个活动目录中可以根据需要建立多个域，比方说“甲公司”的财务科、人事科、销售科就可以各建一个域，因为这几个域同属甲公司，所以就可以将这几个域构成一棵域树并交给域树管理，这棵域树就是甲公司。 森林 (forest)：又因为，甲公司、乙公司、丙公司都归属 A 集团，那么为了让A集团可以更好地管理这三家子公司，就可以将这三家公司的域树集中起来组成域森林（即A集团）。 二、AWS Directory Service 基本概念 三、AWS Managed Microsoft AD AWS Managed Microsoft AD 是部署到 VPC 级别的，但是可以在不同的 可用区 创建域控制器实现高可用 四、AWS Managed Microsoft AD 集成 五、AWS Managed Microsoft AD 连接到本地 AD ⭐ 信任关系 (Trust relationship) 不等于数据复制，只是如果在 AWS 托管 AD 上没有找到用户，会再去本地 AD 查找 六、AD Connector 七、Simple AD 联合身份验证 (Identity federation)一、AWS 联合身份验证基本概念 二、SAML 2.0 联合身份验证 必须配置组织的 IdP (Identity Provider) 和 AWS 账户的相互信任 ⭐ 在用户侧与 STS 进行通信 三、自定义身份代理 (Custom Identity Broker) ⭐（公司）认证程序直接和 STS 通信获取临时安全凭证 四、Web 联合身份验证 (Web Federated Identity) ⭐ AWS 推荐使用 AWS Cognito 实现 Web 联合身份验证 也可以通过编写代码并调用 AssumeRoleWithWebIdentity API 实现 Web 联合身份验证 AWS Key Management Service (KMS)一、AWS Key Management Service 基本概念 ⭐ 无论是客户创建的 CMK 还是 AWS 创建的 CMK，都无法从 KMS 中导出！ ⭐ AWS KMS 服务创建的密钥永远不会在创建密钥的 区域 以外传输，且只能在该区域内使用！ AWS 托管密钥 (AWS managed keys)：AWS 创建、管理和使用的 CMK 例如加密 EBS 卷的密钥。 客户管理的密钥 (Customer managed keys)：客户自己创建、管理和使用的 CMK，客户可以对其进行完全控制 二、AWS Key Management Service 使用流程 ⭐ 用户使用密钥 ID 加密和解密数据，而非使用密钥本身 AWS Certificate Manager (ACM)一、AWS Certificate Manager (ACM) 基本概念 网络安全、DDoS 攻击防护、Shield 和 WAF一、网络安全基本组成 ⭐ 网络 ACL (NACL) 位于子网级别 二、网络攻击类型 三、AWS 的 DDoS 防护 四、AWS 针对 DDoS 防护的架构示例 五、AWS Shield ➕ 使用第三方 DNS 需要购买 AWS Shield Advanced 六、AWS WAF（Web 应用程序防火墙） 七、AWS WAF 的 Web ACL 日志 八、AWS Firewall Manager","link":"/2024/11/25/knowledge_cloud_security/"},{"title":"AWS 知识点 - 云安全 (Cloud Security) - 拓展（针对 SAP-C02 认证）","text":"AWS 云安全相关知识点。 信封加密 (Envelope Encryption)一、信封加密基本概念和优势 ⭐ 不使用主密钥直接加密数据 二、加密流程 最后存储的是加密后的文件和密文数据密钥 三、解密流程 网络 ACL (Network ACLs)一、网络 ACL 基本概念 二、安全组和网络 ACL 的差异 网络 ACL 会按数字顺序（数字越小优先级越高）处理所有规则来决定是否允许数据流 网络 ACL 自动运用于相应 子网 中的所有实例 一个 网络 ACL 可以与多个 子网 关联 ⚠ 一个 子网 只能与一个 网络 ACL 关联","link":"/2024/12/26/knowledge_cloud_security_extend/"},{"title":"AWS 知识点 - 成本","text":"AWS 成本相关知识点。 成本分配标签 (Cost Allocation Tags)一、成本分配标签基本概念 用以整理资源和精细化跟踪 AWS 成本 AWS 成本管理工具一、AWS Cost Explorer 免费工具 查过过去 13 个月的成本数据，并预测未来 3 个月的支出情况 二、AWS Cost &amp; Usage Report 三、AWS Price List API","link":"/2024/11/17/knowledge_cost/"},{"title":"AWS 知识点 - 数据库","text":"AWS 数据库相关的知识点。 亚马逊关系型数据库服务 RDS (Relational Database Service)一、Amazon RDS 基本概念 RDS 是托管的关系型数据库 ⭐ RDS 运行在 EC2 实例上，需要选择实例类型 RDS 支持的数据库引擎： Amazon Aurora MySQL MariaDB Oracle Microsoft SQL Server PostgreSQL 二、Amazon RDS 垂直扩展 (Vertical Scaling) (Scale Up) 三、Amazon RDS 水平扩展 (Horizontal Scailng) (Scale Out) 和灾难恢复 (DR, Disaster Recovery) 亚马逊 RDS 的备份和恢复一、Amazon RDS 自动备份 (Auto Backup) RDS 自动备份时，实际上是创建了一个快照 ⚠ 快照保留 0 ~ 35 天 二、Amazon RDS 手动备份 (Manual Backup) 手动备份将备份整个数据库的 EC2 实例，而非单个数据库 快照没有过去时间 三、Amazon RDS 维护窗口 (Maintenance windows) RDS 只读副本 (Read Replicas)一、RDS 只读副本基本概念 二、RDS 只读副本重要知识点 ⭐ 创建只读副本，必须启用源数据库的自动备份 只读副本能提升 (Promote) 为独立数据库 亚马逊 RDS 安全相关一、亚马逊 RDS 安全相关基本概念 ⭐ 不能更改现有数据库的加密状态 二、⭐ 亚马逊 RDS 安全相关考点 ⭐ 只读副本的加密状态始终与主实例相同 只读副本与主数据库位于同一 区域 将使用同一 KMS 密钥，位于不同 区域 的话使用不同 KMS 密钥 三、将未加密的数据库实例调整为加密的 给未加密的数据库实例创建一个未加密的 DB 快照 将未加密的快照复制为加密的快照 从加密的快照恢复一个加密的 RDS 实例 更新应用程序指向新的加密的数据库实例的终端节点 亚马逊 Aurora一、Amazon Aurora 基本概念 与现有的 MySQL 和 PostgreSQL 数据库兼容 ⭐ Aurora 副本始终位于同一 区域 内 ⭐ 允许在一个 区域 内进行写入扩展 多主数据库仅适用于 MySQL。 二、Amazon Aurora 架构带来的容错性优势 三、Aurora 副本和 MySQL 副本的比较 四、Aurora MySQL 跨区域副本 五、Aurora 全局数据库 六、Aurora 多主数据库 七、Aurora Serverless ⭐ Aurora Serverless 是一种基于性能进行扩展的方式，无需始终运行数据库 亚马逊 ElastiCache（内存缓存服务）一、Amazon ElastiCache 基本概念 ElastiCache 是用来托管 Redis 或 Memcached 的服务 ⚠ 使用 ElastiCache 需要对当前使用 Redis 或 Memcached 的应用程序进行修改（重构） 二、Amazon ElastiCache 作为 DB 缓存 三、Amazon ElastiCache 作为用户会话存储 四、ElastiCache Redis 和 Memcached 的区别 ⚠ Memcached 的多节点并不是复制数据的，只是数据分片 亚马逊 DynamoDB一、Amazon DynamoDB 基本概念 二、Amazon DynamoDB 重要特性 三、Amazon DynamoDB 主键 (Primary Key) 例子中的 People 表中，PersonID 就是分区键（主键）。 例子中的 Music 表中，分区键 Artist 和排序键 SongTitle 共同构成了主键。 四、Amazon DynamoDB 二级索引 ⭐ 只能通过分区键以及排序键，或者通过索引对表进行查询 这与 RDS 中可以对任一列进行查询很不一样。 五、Amazon DynamoDB Accelerator (DAX) ⭐ DAX 是 DynamoDB 的缓存服务 解决 HOT KEY 问题，通过缓存热点项目，使访问不达到 DynamoDB 以减轻压力 六、选择 DynamoDB Accelerator (DAX) 还是 ElastiCache DAX 适合不需要繁重计算的场景（对 DynamoDB 表中的单个项目做缓存，以及对查询和扫描结果做缓存） ElastiCache 适合需要对 DynamoDB 表中数据的繁重计算结果进行缓存的场景 亚马逊 RedShift一、Amazon RedShift 基本概念 ⭐ RedShift 是基于 SQL 的用于分析的数据仓库 ⭐ RedShift 运行在 EC2 实例上，需要选择实例类型 二、在线事务处理 (OLTP) 和在线分析处理 (OLAP) 的区别 OLTP 使用数据库：RDS、DynamoDB OLAP 使用数据库：RedShift、EMR (Elastic MapReduce) 三、报告和分析的使用场景 数据先集中到 RedShift，再由使用 SQL 引擎的 BI 工具连接并进行分析 四、RedShift 数据源 ⭐ 可以使用 RedShift Spectrum 对 S3 的数据进行 SQL 查询 五、RedShift 使用场景 亚马逊 Kinesis一、Amazon Kinesis Services 家族 二、Kinesis Data Streams 三、Kinesis Client Library (KCL) 四、Kinesis Data Firehose ⭐ 在 Kinesis Data Firehose 将数据输出到目标之前，可以选择性地调用 Lambda 函数对数据进行额外的处理或转换来实现自定的逻辑，类似过滤、修改、聚合和格式化等。 五、Kinesis Data Analytics 提供对流式数据进行实时 SQL 处理的能力","link":"/2024/11/21/knowledge_database/"},{"title":"AWS 知识点 - DNS、缓存与性能优化（包括 AWS Route 53）","text":"AWS DNS、缓存与性能优化（包括 AWS Route 53）相关知识点。 DNS (Domain Name System) 解析流程一、DNS (Domain Name System) 解析流程 亚马逊 Route 53一、亚马逊 Route 53 基本原理 托管区域 (Hosted zones) 存储对应域（及其子域）的所有 DNS 记录 二、亚马逊 Route 53 路由策略 (Routing Policy) 三、亚马逊 Route 53 功能 域名注册 托管区域（DNS 解析） 健康检查 Traffic Flow 使用 Traffic Flow 来路由 DNS 流量，简化在大型复杂配置中创建和维护记录的过程。 Route 53 托管区域一、Route 53 托管区域基本概念 ⭐ 创建 私有托管区域 需要指定关联的 VPC，同时开启 VPC 的启用 DNS 解析和启动 DNS 主机名 私有托管区域 可以使用任何域名 二、迁移到 Route 53 或从 Route 53 迁移到其他提供商 可以将一个 AWS 账户下的 VPC 与另一个账户中创建的 Route 53 托管区域相关联 使用创建托管区域的账户，授权另一个账户的 VPC 与托管区域关联。 使用创建 VPC 的账户，将 VPC 与托管区域关联。 Route 53 记录 (Record) 和生存时间 (TTL)一、Route 53 记录 (Record) 基本概念 ⭐ 大部分权威 DNS 解析的服务商都不提供域名裸域又叫根域 (Root Record) 的 CNAME 解析 ⭐ ALIAS 记录支持将流量路由到 AWS 服务，并支持在根域上创建别名记录 二、Route 53 生存时间 (TTL) 基本概念 在 TTL 内 DNS 记录会缓存在客户本地 缓存过期后客户端会再次请求 Route 53 获取 IP 地址 Route 53 路由策略一、简单路由策略 (Simple routing policy) ⚠ 简单路由策略 (Simple routing policy) 无法附加健康状况检查 二、加权路由策略 (Weighted routing policy) 加权路由策略 (Weighted routing policy) 适合软件新版本测试 将少部分流量路由到新版本。 可以关联健康状态检查 可以跨 AWS 区域 分配流量 三、故障转移路由策略 (Failover routing policy) 可以关联健康状态检查 四、基于延迟的路由策略 (Latency routing policy) 基于用户到 AWS 区域 的延迟 可以关联健康状态检查 五、地理位置路由策略 (Geolocation routing policy) 适用于内容本地化，或是网站或业务只服务于某些国家的需求 六、多值应答路由策略 (Multivalue answer routing policy) 亚马逊 CloudFront、源站和地理限制一、Amazon CloudFront 基本概念 提供 DDoS 攻击防护，集成了 AWS Shiedl 和 WAF 二、Amazon CloudFront 源站 (Origins) 支持源站类型： S3 存储桶 静态文件的上传读取场景 ⭐ 通过配置源访问身份 (OAI, Origin Access Identity) 只允许通过 CloudFront 访问存储桶内文件，防止用户对 S3 存储桶的直接访问 S3 网站 需要开启 S3 存储桶的静态网站托管 (static website hosting) 配置 自定义源站 可以通过指定一个主源和一个备用源实现高可用 ⭐ 边缘节点没有内容的情况下 CloudFront 才会访问源站获取内容并缓存 三、Amazon CloudFront 使用 S3 作为源站样例 使用 S3 作为源站才能使用 AWS 私有专线回源 四、Amazon CloudFront 使用 EC2 或 ALB 作为源站样例 ⭐ EC2 必须能从公网被访问（可以限制来源 IP 仅为 CloudFront 边缘节点的公网 IP） ⚠ 使用 EC2 或 ALB 作为源站时是使用互联网回源的，而非 AWS 私有专线 五、CloudFront 和 S3 跨区域复制的区别 六、CloudFront 地理限制功能 (GEO Restriction) 根据第三方 GeoIP 数据库确定用户位置，并限制其访问 CloudFront 签名 URL (signed URLs) 和签名 Cookie (signed cookies)一、CloudFront 签名 URL (signed URLs) 和签名 Cookie (signed cookies) 基本概念 ⭐ 基本功能都是限制部分用户能否访问 CloudFront 内容 ⭐ 签名 URL (signed URLs) 适合限制对单个文件的访问 ⭐ 签名 Cookie (signed cookies) 适合限制对多个文件的频繁访问 二、CloudFront 签名 URL (signed URLs) 工作流 签名 Cookie (signed cookies) 的工作流基本一样。 三、CloudFront 签名 URL 与 S3 预签名 URL (Presigned URLs) 的区别 CloudFront Lambda@Edge一、CloudFront Lambda@Edge 基本概念 将 Lambda 函数部署在 CloudFront 分配的边缘节点上 发生四种 CloudFront 事件时，可以执行 Lambda 函数： 查看器请求 (Viewer request) 源请求 (Origin request) 源响应 (Origin response) 查看器响应 (Viewer response) ⭐ Lambda@Edge 没有缓存 二、CloudFront Lambda@Edge 认证和授权案例 检查认证和授权工作运行在世界各地的边缘节点上 三、CloudFront Lambda@Edge 其他使用案例 AWS Global Accelerator一、AWS Global Accelerator 基本概念 大致流程： ⭐ Route 53 的 ALIAS 记录指向 Global Accelerator 用户请求域名的 DNS 记录时，Route 53 就会返回两个静态的、任播 IP 地址 用户访问这两个 IP 中的其中一个，先到最近的边缘节点 之后再前往 Global Accelerator 最后通过 AWS 全球网络被路由到最佳的应用程序节点 ⭐ 只有用户到边缘节点的网络经过互联网，因此整体网络质量会高很多 架构模式之 DNS、缓存与性能优化 请求和响应行为 (Behaviour) Amazon S3 源的请求和响应行为","link":"/2024/11/26/knowledge_dns/"},{"title":"AWS 知识点 - Docker 容器和 ECS","text":"AWS Docker 容器和 ECS 相关知识点。 亚马逊弹性容器服务 (ECS, Elastic Container Service)一、ECS 的基本概念 在 ECS 上可以以秒级别地快速扩展或缩减（编排）容器数量 ⭐ 两种容器的启动类型： EC2 启动类型：将 ECS 任务运行在用户自主管理的 EC2 实例上 Fargate 启动类型：将容器运行在 ECS 管理的无服务器基础架构上 EKS (Elastic Kubernetes Service)：AWS 提供的 Kubernetes 托管服务 ECR (Elastic Container Registry)：AWS 的 Docker 镜像仓库的托管服务 二、Docker 基本概念 三、ECS 常见的使用场景 微服务架构 批处理作业 迁移应用程序到云端（将本地应用程序容器化后迁移至 ECS） 四、ECS 的核心概念 ⭐ ECS 集群：ECS 任务 或 ECS 服务 的逻辑分组 ECS 任务：定义要运行的容器、容器个数（最多 10 个）、参数等的一次性任务 ⭐ ECS 服务：指定在集群中要保存多少个 ECS 任务 定义副本 任何 ECS 任务 失败或中止，调度程序都会启动另一个副本来替代它，以维持数量。 五、Fargate 为 vCPU、操作系统、存储和内存资源量付费 ECS 的 IAM 角色一、ECS 安全相关 EC2 启动类型：需要 EC2 实例的 IAM 角色 和任务 IAM 角色 Fargate 启动类型：只需要任务 IAM 角色 ECS 的弹性扩展 (Service Auto Sacling)一、ECS 服务的弹性伸缩基本概念 ⭐ EC2 启动类型的场景下，除了需要扩展/收缩任务数量，还需要控制运行容器的 EC2 实例数量 弹性伸缩支持的类型和 EC2 的一样： 目标跟踪扩展策略 分布扩展策略 计划策略 Fargate 由于是无服务器架构，更适合配置弹性伸缩 ECS 与 ALB一、ECS 与 ALB 基础架构和优势 亚马逊 EKS (Elastic Kubernetes Service)一、亚马逊 EKS 基本概念 ⭐ EKS 是 区域 级别的服务 通过 EKS 可以构建跨多个可用区的高度可用的应用程序 ⭐ 可以跨 AWS 和本地数据中心管理 Kubernetes 集群和应用程序 EKS 支持 ALB、NLB 和 CLB 负载均衡器 ALB：Application Load BalancerNLB：Network Load Balancer，NLB 能够在极低的延迟下，支持每秒数千万的请求，在 API 上兼容现有的 ALB 应用负载均衡器。CLB：Classic Load Balancer ⭐ Pods 是 Kubernetes 中的一个或多个容器的集合，是集群中最小的部署和管理的基本单元 二、EKS 与 ELB (Elastic Load Balancing) AWS 负载均衡器控制器 (AWS Load Balancer Controller) 负载管理 Kubernetes 集群的负载均衡器 三、EKS Auto Scaling 集群 Auto Scaling Vertical Pod Autoscaler：垂直扩展，为 Pod 自动调整 CPU 和内存预留 Horizontal Pod Autoscaler：水平扩展，根据资源使用情况，通过自动缩放 Deployment、Replication Controller 以及 ReplicaSet 中 Pod 的数量 Deployment：用于管理运行一个应用负载的一组 Pod。Replication Controller：是 Kubernetes 中最早引入的副本控制器，其主要作用是确保指定数量的Pod副本始终在集群中运行。ReplicaSet：也是一种副本控制器，目的是维护一组在任何时候都处于运行状态的 Pod 副本的稳定集合。 工作负载 Auto Scaling Kubernetes Cluster Autoscaler：与 AWS Sacling 组一起使用 Karpenter open-source AutoScaling project：与 EC2 fleet 一起使用 四、EKS Distro EKS Distro 缓解了跟踪更新、确定兼容性以及在分布各处的团队中统一使用 Kubernetes 版本的需求 五、ECS Anywhere 和 EKS Anywhere 在 AWS Outposts 以外的基础设施（如裸金属服务器）上运行 ECS 和 EKS 当然 AWS Outposts 上也肯定是可以运行的。 亚马逊 ECR (Elastic Container Registry)一、亚马逊 ECR 基本概念 二、ECR 的组件 三、ECR 的拓展功能 四、ECR 使用流程 五、ECR 涉及的 IAM 权限 六、将镜像推送到 ECR 私有仓库的流程 在 Docker 客户端进行身份认证： 1aws ecr get-login-password --region region | docker login --username AWS --password-stdin aws_account_id.dkr.ecr.region.amazonaws.com 将镜像推送到 ECR： 1234# 本地镜像打标签docker tag image_name:tag aws_account_id.dkr.ecr.region.amazonaws.com/repository_name:tag# 推送镜像docker push aws_account_id.dkr.ecr.region.amazonaws.com/repository_name:tag 架构模式之 Docker 容器和 ECS","link":"/2024/11/18/knowledge_docker_ecs/"},{"title":"AWS 知识点 - EC2","text":"AWS EC2 相关知识点。 Amazon EC2 (Elastic Computer Cloud)一、Amazon EC2 基本概念 二、Amazon EC2 启动流程 AWS EBS (Elastic Block Store)：挂载到 EC2 实例的持久性数据块级存储服务。 三、EC2 的优点 启动 EC2 实例一、EC2 实例的创建和使用 EC2 用户数据和元数据一、EC2 用户数据 (User Data) ⭐ EC2 用户数据 会在实例第一次启动的时候运行 可以用来做一些初始化的配置或软件安装。 用户数据内容限制在 16 KB 以内 二、EC2 元数据 (Metadata) 访问实例元数据的地址：http://169.254.169.254/latest/meta-data 在 EC2 上访问其他 AWS 服务的两种方式 - 通过访问密钥和 IAM 角色一、访问密钥 (Access Keys) 相当于将 IAM 用户的访问密钥存储在 EC2 实例上供使用 ⚠ 并非最佳实践 二、EC2 实例 Profiles（为 EC2 附加 IAM 角色） ⭐ EC2 承担 IAM 角色并获取其权限 使 AWS 推荐的最佳实践 实例的状态检查 (Status checks) 和自动恢复 (automatic recovery)一、状态检查 (Status checks) 基本概念 ⭐ 状态检查分为三种类型 系统状态检查 (System status checks) 实例状态检查 (Instance status checks) 附加的 EBS 状态检查 (Attached EBS status checks) 二、系统状态检查 ⭐ 会检测出需要 AWS 参与修复的深层实例问题 出现问题时： 等待 AWS 修复问题 手动停止、启动实例（并非重启）以使其自动迁移到没有问题的底层硬件上 三、实例状态检查 ⭐ 会检测出需要用户参与修复的软件、网络配置等问题 出现问题时，需要用户自己解决问题： 重启实例 更改实例相关配置 四、附加的 EBS 状态检查 附加的 EBS 状态检查可监控附加到实例的 Amazon EBS 卷是否可以访问并能够完成 I/O 操作。 出现问题时： 等待 AWS 解决问题 自行采取措施，例如更换受影响的卷或停止并重启实例。 可以使用 StatusCheckFailed_AttachedEBS 指标进行监控，它表示受损的二进制值。 例如：当检测到长时间影响时，可以故障转移到辅助实例或可用区。或者，可以使用 EBS CloudWatch 指标监控每个附加的卷的 I/O 性能，以检测和替换受损的卷。 五、自动恢复 (automatic recovery) 基本概念 ⭐ 只支持在系统状态检查失败时自动恢复，并不支持实例状态检查 EC2 置放群组 (Placement groups)一、EC2 置放群组基本概念 将 EC2 靠近以获取更低的延迟和更高的吞吐量 将 EC2 分散在不同的机柜以获得高可用 创建置放群组的三种策略： 集群 (Cluster) 分区 (Partition) 分布 (Spread) 二、集群 (Cluster) 置放群组 ⚠ 一个集群置放群组不能跨多个 可用区 在集群置放群组中启动实例时，对实例的类型是有要求的 常使用的免费套餐中的 t2 类型就是不支持的。 ⭐ 在后续往集群放置群组中添加实例、或是重启停止的实例时，可能会碰到容量不足的问题而导致启动失败，如果发生这类问题，需要停止该放置群组中的所有实例，然后尝试再次启动来更改整体使用的底层硬件设备。 三、分区 (Partition) 置放群组 一个分区不与另一分区共享机柜，以尽量隔绝底层设备故障带来的影响 四、分布 (Spread) 置放群组 公有 IP、私有 IP 和弹性 IP 地址 (Elastic IP addresses)一、公有 IP、私有 IP 和弹性 IP 地址基本概念 ⭐ 公有 IP 地址是动态的 IP（停止、启动实例后会改变） ⭐ 弹性 IP 地址是静态的 IP ⭐ 网络接口（带着弹性 IP）支持在同一可用区的不同实例间关联 ⭐ 弹性 IP 支持跨不同可用区映射 二、同一可用区的灾难响应 将网络接口（带着弹性 IP）关联到新的实例 三、不同可用区的灾难响应 将弹性 IP 映射到其他可用区的网络接口上 EC2 实例上为何看不到公有 IP 地址？(NAT, Network Address Translation)一、公网 IP 是映射到 EC2 实例的主私有 IP 上的 NAT 映射发生在 EC2 外部的互联网网关 请求发出经由互联网网关时，源地址会从私有 IP 地址替换为公有 IP 地址 请求回到 EC2 的时候，经由互联网网关时，目的地址会从公有 IP 地址替换为私有 IP 地址 私有子网和堡垒机 (Bastion host)一、私有子网和堡垒机基本概念 公有子网中启动的所有 EC2 实例都会有一个公有 IP 地址 ⭐ 公有子网的路由表中会多一条 0.0.0.0/0 指向互联网网关的路由 由于公有子网和私有子网的路由表中都有 VPC 本地路由，因此两个子网中的实例之间可以相互访问 通过公有子网的 EC2 实例访问私有子网中的 EC2 实例时，公有子网的设备就被称作堡垒机（跳板机） NAT 网关和 NAT 实例一、NAT 网关和 NAT 实例基本概念 ⭐ NAT 网关 和 NAT 实例 的作用是使私有子网的实例能够访问互联网，而非满足（从）互联网访问私有子网实例的需求（单向出站） 如果想要实例和互联网能够双向访问的话，应该将实例部署在公有子网中 NAT 网关 在单个可用区内就自动提供了高可用性 二、NAT 网关 NAT 网关 是 AWS 提供的服务 NAT 网关 被部署在公有子网中 私有子网路由表中配置指向 NAT 网关 的 ID 的路由 三、NAT 实例 ⚠️ NAT 实例 不是 AWS 提供的服务，实际上就是做过特殊设置的 EC2 实例 需要使用特殊的 AMI 必须配置禁用源和目标检查 (Disable source/destination checking for the network interface)，使 NAT 实例允许进行网络地址转换 (NAT) 私有子网路由表中配置指向 NAT 实例 的 ID 的路由 EC2 实例系列和启动类型一、EC2 实例系列 二、EC2 实例启动类型（购买选项） 三、EC2 可用的指标 AWS Savings Plans一、AWS Savings Plans 基本概念 EC2 不同的购买选项对应的业务场景","link":"/2024/11/19/knowledge_ec2/"},{"title":"日语知识点 - 英语 26 个字母的读法","text":"日语中 26 个英语字母的读法。 英语字母 读法 英语字母 读法 A エー N エヌ B ビー O オー C シー P ピー D ディー Q キュー E イー R アール F エフ S エス G ジー T ティー H エイチ U ユー I アイ V ブイ J ジェー W ダブリュー K ケー X エックス L エル Y ワイ M エム Z ゼット","link":"/2024/10/05/knowledge_eiigo/"},{"title":"AWS 知识点 - 弹性负载均衡器和弹性伸缩","text":"AWS 弹性负载均衡器和弹性伸缩相关知识点。 垂直扩展、水平扩展和弹性伸缩一、垂直扩展 (Vertical Scaling) (Scale Up) 和水平扩展 (Horizontal Scailng) (Scale Out) 二、弹性伸缩 (Auto Sacling) Amazon EC2 Auto Scaling一、Amazon EC2 Auto Scaling 基本概念 ⭐ Auto Scaling 组始终在单一 VPC 内，不能跨 VPC（同样不能跨 区域） Auto Scaling 组会在多个可用区平均地分配资源 二、配置 EC2 Auto Sacling 组 (ASG) 配置流程： 启动模板 (launch template) 或 启动配置 (launch configuration)。 启动配置 (launch configuration) 可以指定的属性较少，逐渐被取代。 配置购买选项。 例如 Spot 还是按需实例。 配置 VPC 和 子网。 附加 负载均衡器。 配置运行状况检查。 EC2 状况检查 和 ELB 状况检查。 定义组的大小和扩展策略。 三、Auto Sacling 状况检查 四、Auto Sacling 监控 五、其他缩放相关的配置 负载均衡器与高可用一、负载均衡器与高可用的样例 实例可以位于多个 可用区 中 二、容错性 (Fault tolerance) 三、高可用和容错性 同时使用 Auto Sacling 和 负载均衡器 来确保容量 弹性负载均衡器 (ELB) 类型一、弹性负载均衡器 (ELB) 类型基本概念 ⭐ ALB (Application Load Balancer) 工作在 OSI 的第 7 层（应用层），通过请求内容（路径、HOST 和查询字符串等）做出路由决策；HTTP、HTTPS 协议。 ⭐ NLB (Network Load Balancer) 工作在 OSI 的第 4 层（传输层），主要通过 IP 协议数据做出路由决策；适用于超高性能、极低延迟和大规模 TLS 卸载的使用场景；TCP、UDP、TLS 和 TCP_UDP 协议。 CLB (Classic Load Balancer) 是上一代的负载均衡器，基本不会是正确答案。 ⭐ GLB (GWLB, Gateway Load Balancer) 工作在 OSI 的第 3 层（网络层），将进入流量转发到监听规则中指定的目标组；适用于虚拟设备前端，如防火墙、入侵检测、防御系统和深度数据包检测系统等；监听所有端口的所有数据包；与虚拟设备使用 Geneve 协议，6081 端口交换流量。 OSI 模型： 二、ALB 和 NLB 的区别 三、ELB 使用场景 使用 ALB 和 NLB 进行路由一、应用程序负载均衡器 (ALB) 二、网络负载均衡器 (NLB) 侦听器 (Listener) 和目标组 (Target groups)一、侦听器基本概念 二、目标组基本概念 ⭐ 目标组与 ASG 绑定，负载均衡器通过将请求路由到目标组来使其真正到达 ASG 中的实例 EC2 Auto Scaling 扩展策略一、目标跟踪扩展策略 (Target tracking scaling policies) 是动态扩展策略 二、简单扩展策略 (Simple scaling policies) 是动态扩展策略 三、步进扩展策略 (Step scaling policies) 是动态扩展策略 四、计划扩展策略 (Scheduled scaling policies) ⚠ 不是动态扩展策略 五、预测性扩展策略 (Predictive scaling policies) 预测性扩展的工作原理是分析历史负载数据，以检测流量中的每日或每周模式。它使用这些信息来预测未来的容量需求。 跨区域（可用区）负载均衡 (cross-zone load balancing)一、跨区域负载均衡基本概念 ⭐ 应用程序负载均衡器 (ALB) 会始终启用跨区域负载均衡 网络负载均衡器 (NLB) 和 网关负载均衡器 (GLB) 的跨区域负载均衡默认是关闭的，但是支持手动开启 二、禁用跨区域负载均衡 ⚠ 流量分配不均匀 三、启用跨区域负载均衡 流量分配均匀 会话状态和粘性会话 (Sticky Sessions)一、存储会话状态 将用户认证信息存储在 DynamoDB 或 ElastiCache 中而非可能会被停止的 EC2 实例中 二、粘性会话 (Sticky Sessions) 客户端在 Cookie 的整个生命周期内绑定到特定的实例 ELB 的安全侦听器一、SSL/TLS 终止 (SSL/TLS Termination) ALB 转发的是请求，不仅需要在 ALB 上配置 SSL 证书加密和客户端的通信，还需要在 EC2 实例上配置 SSL 证书来加密 ALB 到 EC2 的通信 NLB 转发的是流量，在 EC2 上配置 SSL 证书后不用在 NLB 上再次配置 SSL 终止是在服务器或特定设备上进行的，该设备接收传入的 SSL/TLS 连接并对流量进行解密。 Auto Scaling 和负载均衡器架构场景","link":"/2024/11/21/knowledge_elastic/"},{"title":"项目管理知识点 - 挣值分析 (EVA)","text":"包括挣值分析的概念、公式和计算方法等。 🌟 基本概念 完工预算 (BAC, Budget at Completion)不包括管理储备的项目总预算。 计划价值 (PV, Planned Value)按照计划时间分配的预算，只和时间有关。​也可以被称为 BCWS (Budgeted Cost of Work Scheduled)。 挣值 (EV, Earned Value)按照实际完成的工作量（理应被）分配的预算，只和工作完成百分比 PC (Percentage of Completion) 有关。​也可以被称为 BCWP (Budgeted Cost of Work Performed)。 实际成本 (AC, Actual Cost)实际花费的成本。​也可以被称为 ACWP (Actual Cost of Work Performed)。 进度偏差 (SV, Schedule Variance)计算公式：$$SV = EV - PV$$✅ 正值 &gt; 0 表示进度超前。​❌ 负值 &lt; 0 表示进度滞后。​ 💡 注意：默认讲的是关键路径 CPM (Critical Path Method) 的进度。​ 进度绩效指数 (SPI, Schedule Performance Index)计算公式：$$SPI = \\frac{EV}{PV}$$✅ SPI &gt; 1 表示进度超前。​❌ SPI &lt; 1 表示进度滞后。​ 💡 注意：默认讲的是关键路径 CPM (Critical Path Method) 的进度。​ 成本偏差 (CV, Cost Variance)计算公式：$$CV = EV - AC$$✅ 正值 &gt; 0 表示成本节约。​❌ 负值 &lt; 0 表示成本超支。​ 成本绩效指数 (CPI, Cost Performance Index)计算公式：$$CPI = \\frac{EV}{AC}$$✅ CPI &gt; 1 表示成本节约。​❌ CPI &lt; 1 表示成本超支。​ 完工尚需绩效指数 (TCPI, To-Complete Performance Index)计算公式：$$TCPI = \\frac{BAC - EV}{BAC - AC}$$❌ TCPI &gt; 1 表示需要更高的绩效才能按照 BAC 完工。​✅ TCPI &lt; 1 表示可以按照 BAC 完工。​ 完工总估算 (EAC, Estimate at Completion)计算公式：$$EAC = AC + (BAC - EV)$$ 📕 稍加练习 一、SPI = 1.2 且 CPI = 0.8，当前处于什么状态？ 答：✅ SPI &gt; 1 表示进度超前。❌ CPI &lt; 1 表示成本超支。 二、SPI = 0.8 且 CPI = 1.2，当前处于什么状态？ 答：❌ SPI &lt; 1 表示进度滞后。✅ CPI &gt; 1 表示成本节约。解决方法：赶工，向关键路径添加资源。 三、SPI = 0.8 且 CPI = 0.8，当前处于什么状态？ 答：❌ SPI &lt; 1 表示进度滞后。❌ CPI &lt; 1 表示成本超支。解决方法：快速跟进，关键路径串行改并行。 四、SPI = 1.2 且 CPI = 0.8，刚刚错失一个里程碑，当前处于什么状态？ 答：❌ SPI &gt; 1 虽然表示进度超前，但是错失里程碑说明并非关键路径上的进度。​❌ CPI &lt; 1 表示成本超支。 五、项目的成本偏差 (CV) 为 500 美元，该项目已完成 40%，其实际成本 (AC) 为 1200 美元。该项目的成本效率 (CPI) 是多少？ 答：$$PV = 1200 + 500 = 1700$$$$CPI = \\frac{EV}{AC} = \\frac{1700}{1200} = 1.42$$✅ CPI &gt; 1 表示成本节约，也和题目描述的 CV &gt; 0 一致。","link":"/2024/06/03/knowledge_eva/"},{"title":"AWS 知识点 - IAM (Identity and Access Management)","text":"AWS IAM 相关知识点。 AWS IAM (Identity and Access Management)一、AWS IAM (Identity and Access Management) 概述 基于身份的策略 (Identity-based Policies)：附加到 IAM 用户、组或角色。这些策略可让您指定该身份可执行哪些操作（其权限）。 例如，您可以将策略附加到名为 John 的 IAM 用户，以声明允许他执行 Amazon EC2 RunInstances 操作。 基于资源的策略 (Resource-based Policies)：附加到某个资源。 例如，您可以将基于资源的策略附加到 Amazon S3 存储桶、Amazon SQS 队列、VPC 端点、AWS Key Management Service 加密密钥以及 Amazon DynamoDB 表和流。 IAM 用户、组、角色和策略一、IAM 用户、组、角色和策略基本概念 角色 是一种 IAM 身份，可以让需要的用户代入进来从而拥有相应的权限 二、IAM 用户 个人用户在创建后默认没有任何权限 三、IAM 组 四、IAM 角色 (Roles) ⭐ 角色可以让 IAM 用户、应用程序和服务代入 ⭐ IAM 角色的信任策略 (Trust policies) 定义了谁可以承担这个角色 IAM 的资源策略定义了这个角色可以访问、操作哪些 AWS 资源 五、IAM 策略 (Policies) ⭐ 默认情况下策略是隐式拒绝的，即：不分配允许策略那就是拒绝的 IAM 验证和 MFA一、IAM 身份认证方式 二、多因素身份验证 (MFA, Multi Factor Authentication) ⚠️ AWS 并不提供官方的硬件 MFA 设备，如果有需要的话得前往第三方自行购买 AWS Security Token Service (STS)一、AWS Security Token Service 基本概念 使用 AWS Security Token Service (AWS STS) 创建可控制对您的 AWS 资源的访问的临时安全凭证，并将这些凭证提供给受信任用户 二、AWS Security Token Service 使用案例 三、IAM 角色与 AWS Security Token Service 的运作原理 ⭐ AccessKeyId、SecretAccessKey 等临时凭证并不是 IAM 角色生成的，而是 STS 服务生成的 IAM 角色与 STS 服务建立信任关系 ⭐ IAM 角色允许指定的 IAM 用户、应用程序和服务代入该角色，并通过 sts:AssumeRole 获取临时安全凭证 基于身份的策略和基于资源的策略一、基于身份的策略 (Identity-based policies) 基本概念 ⭐ 内联策略 (Inline policies) 是直接添加到单个用户、组和角色的策略，并与其保持严格的一对一关系 删除绑定的身份，内联策略也将被删除。 ⭐ 托管策略 (Managed policies) 是基于身份的独立策略，支持附加到 AWS 账户中的多个用户、组和角色 AWS 托管策略 是由 AWS 创建和管理的策略 客户托管策略 (Customer managed policies) 是由客户创建和管理的策略 二、基于资源的策略 (Resource-based Policies) 基本概念 ⭐ IAM 角色的信任策略就是基于资源的策略，定义了谁可以承担这个角色 理解最小权限原则 (PoLP, Principle of Least Privilege)一、最小权限原则 (PoLP) 基本概念 二、最小权限原则 (PoLP) 案例 IAM 策略评估逻辑 (Policy evaluation logic)一、IAM 策略评估逻辑基本概念 默认情况下所有请求都被拒绝（隐式拒绝） 评估所有附加的策略 如果有显式拒绝则拒绝请求 ❌ 如果有显式允许则允许请求 ✅ 否则默认隐式拒绝请求 ❌ 二、显式拒绝案例 IAM 最佳实践一、⭐ IAM 最佳实践清单 定期轮换凭证 (rotation)","link":"/2024/11/22/knowledge_iam/"},{"title":"AWS 知识点 - IAM 策略（重点解析）","text":"AWS IAM 策略的重点解析。 IAM 策略的重点解析一、策略中的各键及其解释 JSON 策略文档结构 123456789101112131415161718192021222324252627282930{ &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Sid&quot;: &quot;FirstStatement&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: [&quot;iam:ChangePassword&quot;], &quot;Resource&quot;: &quot;*&quot; }, { &quot;Sid&quot;: &quot;SecondStatement&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: &quot;s3:ListAllMyBuckets&quot;, &quot;Resource&quot;: &quot;*&quot; }, { &quot;Sid&quot;: &quot;ThirdStatement&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: [ &quot;s3:List*&quot;, &quot;s3:Get*&quot; ], &quot;Resource&quot;: [ &quot;arn:aws:s3:::amzn-s3-demo-bucket-confidential-data&quot;, &quot;arn:aws:s3:::amzn-s3-demo-bucket-confidential-data/*&quot; ], &quot;Condition&quot;: {&quot;Bool&quot;: {&quot;aws:MultiFactorAuthPresent&quot;: &quot;true&quot;}} } ]} Version - 指定要使用的策略语言版本。建议您使用最新的 2012-10-17 版本。 Statement - 将该主要策略元素作为以下元素的容器。可以在一个策略中包含多个语句。 Sid（可选） - 包括可选的语句 ID 以区分不同的语句。 Effect - 使用 Allow 或 Deny 指示策略是允许还是拒绝访问。 Principal（仅在某些情况下需要） - 如果创建基于资源的策略，您必须指示要允许或拒绝访问的账户、用户、角色或联合身份用户。如果要创建 IAM 权限策略以附加到用户或角色，则不能包含该元素。主体暗示为该用户或角色。 Action - 包括策略允许或拒绝的操作列表。 Resource（仅在某些情况下需要）- 如果创建 IAM 权限策略，您必须指定操作适用的资源列表。如果创建基于资源的策略，则该元素是可选的。如果不包含该元素，则该操作适用的资源是策略附加到的资源。 Condition（可选） - 指定策略在哪些情况下授予权限。 上述的例子是基于身份的策略，因此没有指定 Principal。 Sid（语句 ID）为 FirstStatement 的第一个语句让具有附加策略的用户更改自己的密码。 该语句中的 Resource 元素是“*”（这表示“所有资源”）。但实际上，ChangePassword API 操作（或等效的 change-password CLI 命令）仅影响发出请求的用户的密码。 第二个语句使用户可以列出其 AWS 账户 中的所有 Amazon S3 存储桶。 该语句中的 Resource 元素是 “*”（这表示“所有资源”）。但由于策略没有为其他账户中的资源授予访问权限，因此，用户只能列出自己的 AWS 账户 中的存储桶。 第三个语句允许用户列出和检索名为 amzn-s3-demo-bucket-confidential-data 的存储桶中的任何对象，但是仅当使用 Multi-Factor Authentication (MFA) 对用户进行了身份验证时才能如此。策略中的 Condition 元素将强制实施 MFA 身份验证。 如果策略语句包含 Condition 元素，则仅当 Condition 元素计算为 true 时，语句才有效。在此示例中，Condition 在用户进行了 MFA 身份验证时计算为 true。如果用户没有进行 MFA 身份验证，则此 Condition 计算为 false。在这种情况下，此策略中的第三个语句不会应用，因此用户将无法访问 amzn-s3-demo-bucket-confidential-data 存储桶。 二、基于身份的策略12345678{ &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: { &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: &quot;s3:ListBucket&quot;, &quot;Resource&quot;: &quot;arn:aws:s3:::amzn-s3-demo-bucket&quot; }} 由于基于身份的策略之后会分配给用户、组和角色，因此不需要指定 Principal 主体。 三、基于资源的策略12345678910111213{ &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [{ &quot;Sid&quot;: &quot;1&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Principal&quot;: {&quot;AWS&quot;: [&quot;arn:aws:iam::account-id:root&quot;]}, &quot;Action&quot;: &quot;s3:*&quot;, &quot;Resource&quot;: [ &quot;arn:aws:s3:::amzn-s3-demo-bucket&quot;, &quot;arn:aws:s3:::amzn-s3-demo-bucket/*&quot; ] }]} 而基于资源的策略需要指定 Principal 主体，来限制特定的用户、组和角色可以操作该资源。 四、策略示例 IAM 基于身份的策略示例","link":"/2024/12/08/knowledge_iam_policy/"},{"title":"AWS 知识点 - 身份与联合身份验证（针对 SAP-C02 认证）","text":"AWS 身份与联合身份验证相关知识点。只有针对 AWS Certified Solutions Architect - Professional (SAP-C02) 认证的内容。 企业的多账户策略 (Multi-Account Strategy for Enterprises)一、多账户体系结构 二、身份账户体系结构 (Identity Account architecture) 在组织中设置一个独立的、专用的AWS账户，作为身份账户 (Identity Account)。在这个身份账户中，集中为组织建立用户、密码以及访问密钥、管理用户。 三、日志账户体系结构 (Logging Account architecture) 四、发布账户体系结构 (Publishing Account Structure) 有利于（开发环境等的）标准化 五、账单结构 (Billing Structure) 身份账户体系结构 (Identity Account Architecture)一、单一 AWS 账户发展成多个而带来的管理问题 二、身份账户体系结构基本概念 三、身份账户下的 IAM 用户代理其他账户下的 IAM 角色以获取相应权限 AWS Organizations 补充一、AWS Organizations 补充 ⭐ 组织在创建时默认启用包括整合账单在内的所有功能 二、服务控制策略 (SCP) 补充 附加到根 (root) 上的策略会应用于组织中的所有账户 集中式日志架构 (Centralized Logging Architecture)一、集中式日志存储架构 二、集中日志管理注意事项 三、AWS 提供的相关服务 AWS ElasticSearch Service AWS CloudWatch Logs Kinesis Firehose AWS S3","link":"/2024/12/16/knowledge_identity/"},{"title":"日语知识点 - 时间的读法","text":"涉及到秒、分、时、日、周、月、年的读法。 秒的读法全部都是音读数字，数字后面加秒（びょう）。注意 4 秒「よんびょう」和 7 秒「ななびょう」和 9 秒「きゅうびょう」只能使用特定的音读。 数字 読み方 0 秒 れいびょう 1 秒 いちびょう 2 秒 にびょう 3 秒 さんびょう 4 秒 よんびょう 5 秒 ごびょう 6 秒 ろくびょう 7 秒 ななびょう 8 秒 はちびょう 9 秒 きゅうびょう 10 秒 じゅうびょう 20 秒 にじゅうびょう 30 秒 さんじゅうびょう 40 秒 よんじゅうびょう 50 秒 ごじゅうびょう 60 秒 ろくじゅうびょう 分的读法3、4 为「ぷん」，1、6、8、10 为「っぷん」，2、5、7、8、9 为「ふん」。 数字 読み方 0 分 れいふん 1 分 いっぷん 2 分 にふん 3 分 さんぷん 4 分 よんぷん 5 分 ごふん 6 分 ろっぷん 7 分 ななふん 8 分 はっぷん 9 分 きゅうふん 10 分 じゅっぷん 11 分 じゅういっぷん 12 分 じゅうにふん 13 分 じゅうさんぷん 14 分 じゅうよんぷん 15 分 じゅうごふん 30 分 さんじゅっぷん（半はん） 时的读法只要在数字后面加上「じ」即可。 数字 読み方 1 時 いちじ 2 時 にじ 3 時 さんじ 4 時 よじ 5 時 ごじ 6 時 ろくじ 7 時 しちじ 8 時 はちじ 9 時 くじ 10 時 じゅうじ 11 時 じゅういちじ 12 時 じゅうにじ 日的读法时间点1 到 31 日的读法分成量部分：1 到 10 日用训读；11 到 31 日中除特殊（14 日、20 日、24 日）外，均读音读。 数字 読み方 1 日 ついたち 2 日 ふつか 3 日 みっか 4 日 よっか 5 日 いつか 6 日 むいか 7 日 なのか 8 日 ようか 9 日 ここのか 10 日 とおか 11 日 じゅういちにち 12 日 じゅうににち 13 日 じゅうさんにち 14 日 じゅうよっか 15 日 じゅうごにち 16 日 じゅうろくにち 17 日 じゅうしちにち 18 日 じゅうはちにち 19 日 じゅうくにち 20 日 はつか 21 日 にじゅういちにち 22 日 にじゅうににち 23 日 にじゅうさんにち 24 日 にじゅうよっか 25 日 にじゅうごにち 26 日 にじゅうろくにち 27 日 にじゅうしちにち 28 日 にじゅうはちにち 29 日 にじゅうくにち 30 日 さんじゅうにち 31 日 さんじゅういちにち 时间段除一天外，经过的天数和日期可以一样，也可以在日期后面加「間（かん）」 数字 読み方 一日 いちにち（間） 二日 ふつか（間） 三日 みっか（間） 四日 よっか（間） 五日 いつか（間） 六日 むいか（間） 七日 なのか（間） 周的读法时间点 数字 読み方 星期一 月曜日げつようび 星期二 火曜日かようび 星期三 水曜日すいようび 星期四 木曜日もくようび 星期五 金曜日きんようび 星期六 土曜日どようび 星期日 日曜日にちようび 时间段几周的读法，“周”在日语中说「週間（しゅうかん）」，由于 4 周就是一个月，所以除有特殊含义的数目以外，很少说很大数目的周数。 数字 読み方 一週間 いっしゅうかん 二週間 にしゅうかん 三週間 さんしゅうかん 四週間 よんしゅうかん 五週間 ごしゅうかん 六週間 ろくしゅうかん 七週間 ななしゅうかん 八週間 はちしゅうかん 九週間 くしゅうかん 十週間 じゅっしゅうかん 月的读法时间点 数字 読み方 1 月 いちがつ 2 月 にがつ 3 月 さんがつ 4 月 しがつ 5 月 ごがつ 6 月 ろくがつ 7 月 しちがつ 8 月 はちがつ 9 月 くがつ 10 月 じゅうがつ 11 月 じゅういちがつ 12 月 じゅうにがつ 时间段需要表示月份经过的时候，月数“个月”的日语读法是「かげつ」一般写「ヶ月」或「ヵ月」。1 个月和 2 个月可以用训读，分别说成「一月（ひとつき）​」和「二月（ふたつき）​」。 数字 読み方 一ヶ月 いっかげつ 二ヶ月 にかげつ 三ヶ月 さんかげつ 四ヶ月 よんかげつ 五ヶ月 ごかげつ 六ヶ月 ろっかげつ 七ヶ月 ななかげつ 八ヶ月 はっかげつ 九ヶ月 きゅうかげつ 十ヶ月 じゅっかげつ 十一ヶ月 じゅういっかげつ 年的读法时间点在日语中表示年份是按全部数字的位数来读。 1986 年的 1 直接读成「せん」 而不是「いちせん」，另外 2006 年中间的零也不用读出来。 数字 読み方 1800 年 せんはっぴゃくねん 1900 年 せんきゅうひゃくねん 1986 年 せんきゅうひゃくはちじゅうろくねん 2000 年 にせんねん 2006 年 にせんろくねん 2010 年 にせんじゅうねん 2020 年 にせんにじゅうねん 2024 年 にせんにじゅうよんねん 2035 年 にせんさんじゅうごねん 时间段当需要表示年数的经过读法可与年相同，也可以在后面加「間（かん）」： 例如「三年間が経過した。」（三年已经过去了。） 数字 読み方 一年 いちねん（間） 二年 にねん（間） 三年 さんねん（間） 四年 よねん（間） 五年 ごねん（間） 十年 じゅうねん（間） 二十年 にじゅうねん（間） 百年 ひゃくねん（間）","link":"/2024/08/10/knowledge_jikann_yomikata/"},{"title":"日语知识点 - 助动词的详细划分","text":"关于助动词的详细划分，包括按照助动词的词尾变化、动词连接法和语法意义分类。 按照助动词的词尾变化分类 动词型：れる（られる）、せる（させる）、たがる ｲ形容词型：たい、ない、らしい ナ形容词型：そうだ、ようだ、みたいだ、だ 特殊变化型：ます、です、た、ぬ（ん） 无变化型：う（よう）、まい 按照动词连接法分类 接用动词末然形后：せる（させる）、れる（られる）、ない、ぬ（ん）、う（よう） 接于动词连用形后：た、ます、たい、たがる、そうだ（样态） 接于用言终止形后：そうだ（传闻）、らしい、みたいだ、まい 接于用言连体形后：ようだ 接用于体言后：だ、です 按照动词的语法意义分类 断定助动词：だ、です 过去助动词：た 敬体助动词：ます、です 否定助动词：ない、ぬ（ん） 愿望助动词：たい、たがる 使役助动词：せる（させる） 被动助动词：れる（られる） 可能和自发助动词：れる（られる） 敬语助动词：れる（られる） 推测助动词：う（よう）、まい、らしい 比况助动词：ようだ、みたいだ 样态助动词：そうだ 传闻助动词：そうだ","link":"/2024/09/07/knowledge_jodoushi/"},{"title":"AWS 知识点 - 机器学习 (ML, Machine Learning)","text":"AWS 机器学习相关知识点。 机器学习服务一、AWS Rekognition ⭐ 分析图像和视频 可以处理存储在 S3 存储桶中的视频 识别图像和视频中的对象、人物、场景和活动 将完成状态发布到 Amazon SNS 主题中 事件驱动架构中的 AWS Rekognition 的一种使用案例： 二、Amazon Transcribe ⭐ 语言转文本 使用自动语音识别 (ASR) 的深度学习过程快速准确地将语音转为文本 三、Amazon Translate ⭐ 神经机器翻译服务 使用深度学习模型提供更准确、更自然的翻译 为不同的用户本地化网站和应用程序能内容 四、Amazon Textract ⭐ 从文档中提取打印文本、手写体和数据 能够理解上下文 五、Amazon SageMaker ⭐ 帮助准备、构建、培训和部署高质量的机器学习 (ML) 模型 六、Amazon Comprehend ⭐ 自然语言处理 (NLP) 服务 使用机器学习挖掘非结构化数据中的信息 七、Amazon Lex ⭐ 聊天对话机器人 八、Amazon Polly ⭐ 将文本转为语音 九、Amazon Forecast ⭐ 时间序列预测服务 基于历史业务数据进行预测，用于业务指标分析 十、Amazon DevOps Guru ⭐ 分析运营数据以及应用程序指标和事件，以识别偏离正常操作模式的行为（在问题影响客户之前识别）","link":"/2024/11/17/knowledge_machine_learning/"},{"title":"AWS 知识点 - 监控、日志和审计","text":"AWS 监控、日志和审计相关知识点。只涉及到 AWS Certified Solutions Architect – Associate (SAA-C03) 考试为止的内容，更多请参考针对 SAP-C02 认证的拓展：AWS 知识点 - 监控、日志和审计 - 拓展（针对 SAP-C02 认证）实操请参考：AWS 实操 - 监控、日志和审计 CloudWatch 警报、指标和 Events一、CloudWatch 基本概念 ⚠️ CloudWatch Metrics（指标） 是不包括内容相关的 ⭐ CloudWatch Alarms（警报） 可以触发 EC2 实例的动作，或是 Auto Sacling 和 SNS CloudWatch Alarms（警报） 的事件都会被 CloudWatch Events 捕获 CloudWatch Dashboard（仪表盘） 用来展示 CloudWatch 指标和警报 ⭐ CloudWatch Dashboard（仪表盘） 支持显示多区域的 CloudWatch 指标 二、CloudWatch Alarms 集成相关 三、CloudWatch Events 基本概念 ⭐ CloudWatch Events 提供近乎实时的系统事件流，可捕获 AWS 资源的更改或变化 CloudWatch Events 提供了一个描述亚马逊云科技资源变更情况的事件流。 您可以轻松构建这样的工作流，即当发生关注的事件时，自动采取您定义的操作，例如停止 EC2 实例、发送 SNS 消息或向 SQS 队列添加消息。 CloudWatch Logs 和 The unified CloudWatch agent一、CloudWatch Logs 基本概念 二、CloudWatch Logs 来源 三、CloudWatch Logs 指标过滤器 (Metrics filters) 和 Insights（洞察） ⭐ 分析 CloudWatch Logs 中的日志，可以通过 CloudWatch Logs Insights 进行查询 四、CloudWatch Logs 导出到 S3 ⚠️ CloudWatch Logs 导出到 S3 不是实时或近乎实时的 ⚠️ CloudWatch Logs 导出到 S3 也不是自动的，需要调用 CreateExportTask 这个 API 五、CloudWatch Logs 订阅 六、CloudWatch Logs 多账户/多区域日志聚合 七、CloudWatch Logs agent 和 The unified CloudWatch agent CloudWatch Logs agent 是旧版本的代理程序，只能将日志发送到 CloudWatch Logs ⭐ The unified CloudWatch agent 除了日志，还支持收集内存、进程等其他系统级别的信息并发送到 CloudWatch Logs AWS CloudTrail一、AWS CloudTrail 基本概念 ⭐ 通过创建 CloudTrail 跟踪 (Trail)，可以将 API 活动事件记录到 S3 以实现无限保留 可以使用 CloudWatch Events 基于在 CloudTrail 中记录到 API 调用来触发操作 ⭐ 通过启用日志完整性检查 (CloudTrail log file integrity validation) 以确认日志文件在 CloudTrail 传送后是被修改、删除还是未更改 二、AWS CloudTrail 事件类型 管理事件 (management events)：提供有关在资源上执行的管理操作的信息 数据事件 (data events)：提供有关在资源上执行的资源操作的详细信息 洞察事件 (Insights events)：识别和响应与写入 API 调用相关的任何异常活动 ➕ 网络活动事件 (network activity events)：使 VPC 终端节点 的所有者记录其私有 VPC 到相应 AWS 服务的访问 API 调用","link":"/2024/11/27/knowledge_monitor/"},{"title":"AWS 知识点 - 监控、日志和审计 - 拓展（针对 SAP-C02 认证）","text":"AWS 监控、日志和审计相关知识点。只有针对 AWS Certified Solutions Architect - Professional (SAP-C02) 认证补充的内容，基础请参考针对 SAA-03 的考点汇总：AWS 知识点 - 监控、日志和审计实操请参考：AWS 实操 - 监控、日志和审计 理解 CloudWatch Logs一、集中式日志存储架构","link":"/2024/12/07/knowledge_monitor_extend/"},{"title":"AWS 知识点 - 部署和管理","text":"AWS 部署和管理相关知识点。只涉及到 AWS Certified Solutions Architect – Associate (SAA-C03) 考试为止的内容，更多请参考针对 SAP-C02 认证的拓展：AWS 知识点 - 部署和管理 - 拓展（针对 SAP-C02 认证）实操请参考：AWS 实操 - 部署和管理 AWS CloudFormation一、AWS CloudFormation 基本概念 二、AWS CloudFormation 的组成 AWS Elastic Beanstalk一、AWS Elastic Beanstalk 基本概念 二、一个案例理解 Elastic Beanstalk 的优势 三、Elastic Beanstalk 帮我们做了什么 AWS Systems Manager Parameter Store (SSM Parameter Store)一、SSM Parameter Store 基本概念 ⭐ 将代码和密钥等重要数据分离 ⭐ 存储的参数的管理使用路径的方式，可以使用 IAM 策略来定义安全访问这些路径 与 CloudFormation 集成，可以在 CloudFormation 模板中拉取存储在 SSM Parameter Store 中的密钥 ⚠ SSM Parameter Store 不支持密钥的自动轮转 ( automatic rotation) 要实现自动轮转，需要将密钥存储在 Secrets Manager 中，然后使用 Parameter Store 参数形式引用该密钥，具体参考：通过 Parameter Store 参数引用 AWS Secrets Manager 密钥 AWS OpsWorks一、AWS OpsWorks 基本概念 二、Chef 和 Puppet 基本概念 RTO (Recovery time objective) 和 RPO (Recovery point objective)一、灾备 (DR) 的重要性 二、恢复时间目标 (RTO, Recovery time objective) ⭐ RTO (Recovery time objective)：恢复时间目标，是指所能容忍的业务系统停止服务的最长时间，也就是灾难发生到业务系统恢复服务功能所需要的最短时间 三、恢复点目标 (RTO, Recovery point objective) ⭐ RPO (Recovery point objective)：恢复点目标，是指业务系统所能容忍的数据丢失量 四、RTO 和 RPO ⭐ RPO 指标来自故障发生前，RTO 指标来自故障发生后 组织通过根据当业务不可用时对业务的财务影响来定义可接受的 RTO 和 RPO","link":"/2024/11/20/knowledge_ops/"},{"title":"AWS 知识点 - 部署和管理 - 拓展（针对 SAP-C02 认证）","text":"AWS 部署和管理相关知识点。只有针对 AWS Certified Solutions Architect - Professional (SAP-C02) 认证补充的内容，基础请参考针对 SAA-03 的考点汇总：AWS 知识点 - 部署和管理实操请参考：AWS 实操 - 部署和管理 Elastic Beanstalk 部署策略一、Elastic Beanstalk 部署策略基本概念 二、一次部署全部 (All at once) 策略 ⚠ 执行部署时，环境中的所有实例将短时间禁用（有停机时间） ⚠ 应用程序更新失败时，只能通过手动部署之前的旧版本进行回滚 三、滚动部署 (Rolling) 策略 四、附加批次滚动部署 (Rolling with additional batch) 策略 ⭐ 新启动额外的新实例进行部署保证服务容量，并在部署完成后删除 五、不可变部署 (Immutable) 策略 ⭐ 由于需要通过健康状况检查，新的实例才会替换旧的实例，因此这是生产环境的核心业务的首选之一 ⚠ 仍然使用旧的弹性扩展组，这与使用新的扩展组替换旧扩展组的 蓝/绿部署 (Blue/green deployments) 不同。 AWS CodeDeploy一、AWS CodeDeploy 基本概念 二、使用 CodeDeploy 部署 EC2 三、使用 CodeDeploy 部署 Auto-Sacling Group (ASG) 中的实例 就地部署 (In-place deployments)：更新当前 ASG 中所有的 EC2 实例 蓝/绿部署 (Blue/green deployments) 根据之前的配置创建一个新的 ASG ⭐ 必须使用 ELB（负载均衡器） 可以进行配置如何处理旧的实例 四、使用 CodeDeploy 部署 Lambda 可以设置 CloudWAtch Alarms 实现自动回滚 ⭐ SAM (Serverless Application Model) 原生使用 CodeDeploy 进行部署 流量转移 (Traffic Shifting) 前通过 Pre-Traffic Hook 进行验证，转移后通过 Post-Traffic Hook 进行验证 五、使用 CodeDeploy 部署 ECS AWS Service Catalog一、AWS Service Catalog 基本概念 ⭐ 可以通过 Service Catalog 预先定义资源的模板，供其他用户快速启动 AWS 资源，来实现组织的一致性以及满足合规性要求 二、AWS Service Catalog 管理员及用户流程 Serverless Application Model (SAM)一、Serverless Application Model (SAM) 基本概念 ⭐ SAM 可以帮助在本地运行 Lambda 函数、DynamoDB 表和 API 网关等无服务器应用 SAM 通过 YAML 配置，是 CloudFormation 的扩展 二、SAM 的 CI/CD 架构 AWS CodePipeline 是一项持续交付服务，可用于对发布软件所需的步骤进行建模、可视化和自动化 AWS 部署方式对比及总结一、部署方式总结 EC2 的 User Data AMI Auto Scaling 组的启动模板和启动配置（可以基于 AMI） CodeDeploy（部署应用程序） Elastic Beanstalk（适合刚开始使用 AWS 的公司） OpsWorks SAM 是基于 CloudFormation 的扩展，同时使用 CodeDeploy 进行部署，是集成度更高的针对无服务器应用的部署方式","link":"/2024/12/05/knowledge_ops_extend/"},{"title":"AWS 知识点 - AWS Organizations 和 Control Tower","text":"AWS Organizations 和 Control Tower 相关知识点。 AWS Organizations一、AWS Organizations 基本概念 二、AWS Organizations 架构 服务控制策略 (SCPs, Service control policies)一、服务控制策略 (SCPs, Service control policies) 基本概念 ⭐ SCP 是用来控制（限制）最大可用权限的 授予权限是 IAM 来完成的。 ⭐ SCP 不会影响管理账户 (root, management, master) 中的 IAM 用户和角色 ⭐ 对 OU（组织单元） 的策略限制会传递到其子 OU AWS Control Tower一、AWS Control Tower 基本概念 护栏 (controls, guardrails) 用于治理和合规性 管理账户内的根用户可以执行护栏中禁止的操作 架构模式之 AWS Organizations","link":"/2024/11/17/knowledge_organizations/"},{"title":"项目管理知识点 - 资源平衡和资源平滑","text":"在项目进行时，可以根据资源的实际使用情况对资源做相应的调整以满足项目的需要。优化技术：资源平滑和资源平滑。 资源平衡 (Resource Level)对资源冲突的两项或多项活动的开始日期和结束日期进行调整以消除或缓解资源冲突的一种技术。资源平衡往往导致关键路劲改变，通常是延迟。​ 这儿的资源制约因素可以是关键资源只在特定时间可用，或者数量有限，或者被过度分配等等情况。资源平衡往往会改变关键路径（通常是延长）。 注：Sue 由于被过度分配，因此需要延后 Activity B，这导致了关键路径延长。 资源平滑 (Resource Smooth)利用关键路径上活动的浮动时间，调整非关键路径上的活动使项目资源数量减少波动的一种技术。资源平滑不会改变关键路径。​ 注：图中的 Design 阶段有 5 天的浮动，利用这 5 天浮动处理非关键路劲上的活动也不会影响关键路径。","link":"/2024/06/01/knowledge_resource_level_and_resource_smooth/"},{"title":"AWS 知识点 - S3 (Simple Storage Service)","text":"AWS S3 相关知识点。 Amazon S3 概述一、Amazon S3 基本概念 ⭐ S3 存储桶的名称必须是全球唯一的 存储桶的数据存储在单个 区域 中 ⭐ 存储桶中的对象是没有层次结构的（目录是对象键的一部分） S3 提供了强读写一致性 强读写一致性：任何一次读都能读到某个数据的最近一次写的数据。弱读写一致性：数据更新后，如果能容忍后续的访问只能访问到部分或者全部访问不到，则是弱一致性。 二、存储桶、文件夹和对象 三、访问 Amazon S3 EC2 实例可以通过 互联网网关 使用公有终端节点与 S3 进行通信 ⭐ EC2 实例也可以通过 网关终端节点 使用私有连接访问 S3 S3 存储类别及成本优化一、S3 的存储类别 S3 标准 (S3 Standard)：常用用途 S3 标准 - 不频繁访问存储 (S3 Standard-IA, S3 Standard-Infrequent Access) 适合存储不频繁访问的数据 存储价格较低 检索价格较高 将数据存储在至少三个可用区中 S3 单区 - 不频繁访问存储 (S3 One Zone-IA, S3 One Zone-Infrequent Access) 例如可以用来存储图片缩略图。 可以接受丢失数据 存储价格更低，低于 Amazon S3 Standard-IA 将数据存储在单个可用区中 S3 智能分层 (S3 Intelligent-Tiering) 30 天没有访问的对象转移至 S3 Standard-IA，而如果你又重新访问了不频繁访问层的数据，这些对象又会被移动到 S3 Standard 非常适合存储访问模式未知或不断变化的数据 每个对象每月会产生少量的监控和自动化费用 S3 Glacier Flexible Retrieval 低成本存储，专为数据归档而设计 能够在几分钟到几小时内完成对象检索 S3 Glacier Deep Archive 可以作为磁带的替代方案。 适合保存每年只访问一两次的数据 数据检索时间为 12 小时到 48 小时 成本最低的对象存储类 二、S3 存储类型使用场景 三、S3 成本优化 ⭐ 使用 S3 Select 和 Glacier Select 节省 CPU 和网络成本 S3 Select：使用结构化查询语言 (SQL) 语句筛选 Amazon S3 对象的内容，并仅检索所需的部分数据。Glacier Select：允许直接对存储在 Amazon Glacier 中的数据运行查询，从而只从您的存档中检索所需数据来用于分析。 使用 S3 生命周期策略 (Lifecycle rules) 在存储层（类）之间自动移动数据 请求方付费 (S3 Requester Pays) IAM 策略、存储桶策略和 ACL一、IAM 策略 ⭐ 在 IAM 策略中，Principal 元素是不需要的 在基于资源的 JSON 策略中使用 Principal 元素指定允许或拒绝访问资源的主体（谁）。基于身份的策略是附加到 IAM 身份（用户、群体或角色）的权限策略。在这些策略中，附加了策略的身份即是主体的身份。 二、存储桶策略 (Bucket Policy) ⭐ 存储桶策略 (Bucket Policy) 可以跨 AWS 账号 三、S3 访问控制列表 (ACL) ⚠ 它是早于 IAM 的访问控制机制 ⭐ S3 访问控制列表 (ACL) 不仅可以应用到存储桶，还可以直接应用到存储桶中的对象上 四、各访问控制机制与其适合的场景 五、⭐ 授权过程 ⭐ 除了显示允许的策略，其他策略都拒绝 S3 版本控制、复制和生命周期配置一、S3 版本控制 (Versioning) 二、S3 复制 (Replication) ⭐ S3 复制 (Replication) 前提是开启了 S3 版本控制 三、S3 生命周期配置 S3 加密一、S3 加密类型 二、S3 默认加密配置 ⚠ 启用默认加密之前就已经上传到存储桶的对象，其加密状态不会更改 三、阻止上传未加密的对象 使用 S3 预签名 URL 共享对象一、使用 S3 预签名 URL 共享对象基本概念 S3 分段上传 (Multipart Upload) 和传输加速 (Transfer Acceleration)一、S3 分段上传 (Multipart Upload) 基本概念 二、S3 传输加速 (Transfer Acceleration) ⭐ 在存储桶级别启用传输加速功能 S3 Select 和 Glacier Select一、S3 Select 和 Glacier Select 基本概念 ⭐ 截至 2024 年末，S3 Select 已经不再向新的 AWS 用户提供，推荐使用功能更强大的 Amazon Athena 什么是 Amazon Athena？ Amazon Athena 是一种交互式查询服务，让您能够轻松使用标准 SQL 直接分析 Amazon Simple Storage Service (Amazon S3) 中的数据。只需在 AWS Management Console 中执行几项操作，即可将 Athena 指向 Amazon S3 中存储的数据，并开始使用标准 SQL 运行临时查询，然后在几秒钟内获得结果。 S3 服务器访问日志记录一、S3 服务器访问日志记录基本概念 S3 跨账户访问一、S3 跨账户访问基本概念 二、S3 跨账户访问场景 架构模式之亚马逊 S3","link":"/2024/11/24/knowledge_s3/"},{"title":"AWS 知识点 - S3 (Simple Storage Service) - 拓展（针对 SAP-C02 认证）","text":"AWS S3 相关知识点。 S3 存储桶跨区域复制 (CRR)一、S3 存储桶跨区域复制基本概念","link":"/2024/12/27/knowledge_s3_extend/"},{"title":"日语知识点 - 使役、被动和使役被动","text":"关于动词使役、被动和使役被动的变形。 一、使役（主动）一言以蔽之，使役动词即为中文可翻译为“使”、“让”的动词，例如：（老爸）​让小孩子去买酱油。其中的“让……买”在日语中的“买”这个动作就应该是使役形的。 动词的变形规律 几类动词 原型 变形规律 使役 一类动词 書く 末尾变「あ」段 + 「せる」 書かせる 二类动词 食べる 末尾 -「る」+「させる」 食べさせる 三类动词 する 固定 させる 三类动词 来る 固定 こさせる 固定句式 名词（人）+「を」+ 使役动词（自动词）​**（让某人做……）​** 名词（人）+「に」+（名词）+「を」+ 使役动词（他动词）​**（让某人做……）​** （使役动词「て」形）+「いただけませんか」（能让我做……吗？）​ 使役形需要注意的两点 所有的使役形动词都是他动词，前面的助词是「を」 父親は子供に醬油を買わせる。車を走らせる。 使役的使用会改变动作行使人的方法 假设当前 A 在对 B 说话： A 说的话 实际动作行使人 备注 食べます。 A A 自己吃。 食べてください。 B 劝诱 B 吃。 食べていただきます。 B “您吃吧。” 食べさせていただきます。 A “您让我吃吧。” 二、被动什么是被动，或者也可以说是受身，最简单的例子“大鱼被小鱼吃”，这个“吃”的动作即为被动。 动词的变形规律 几类动词 原型 变形规律 使役 一类动词 書く 末尾变「あ」段 + 「れる」 書かれる 二类动词 食べる 末尾 -「る」+「られる」 食べられる 三类动词 する 固定 される 三类动词 来る 固定 こられる 固定句式 A +「は」＋ B +「に」＋「受身动词」（A 被 B ~）​ A +「は」＋ B +「に」+ 名词（物品）＋「を」＋「受身动词」（A 的某物被 B ~）​ 被动形的 6 种用法及出现 大きな魚は小さな魚に食べられます。​【最简单的被动】 なにを食べられましたか。【下级对上级说话，被动表尊敬】 お祖母ちゃんに亡くなられました。【作为受害者】 小鳥に逃げられました。 地球は丸いだと考えられます。【被所有人都这么认知】 【N1 后期会出现的情感情不自禁流露】 女性に花を送って、喜ばれました。【讨人（喜欢）这种感觉，很抽象，在 J-TEST E-F 等级考试中出现过】 三、使役被动使役：使某人做某事被动：某人被动作行使人做了某事，例如：我被科长训斥了使役被动：动作行使人被某人要求做某事，例如：我被科长要求去买酱油 动词的变形规律 几类动词 原型 变形规律 使役 一类动词 書く 末尾变「あ」段 + 「せられる」 書かせられる 二类动词 食べる 末尾 -「る」+「させられる」 食べさせられる 三类动词 する 固定 させられる 三类动词 来る 固定 こさせられる 句式参照被动的句式即可。​例：子供は父に歯医者に行かされた。","link":"/2024/09/08/knowledge_sareru_rareru/"},{"title":"AWS 知识点 - 无服务器应用程序","text":"AWS Serverless 相关知识点。 无服务器服务和事件驱动架构 事件驱动型架构 (EDA, Event-driven architecture)​：事件驱动架构是一种松耦合、分布式的驱动架构，收集到某应用产生的事件后实时对事件采取必要的处理后路由至下游系统，无需等待系统响应。 一、无服务器服务和事件驱动架构的例子 二、无服务器服务基本概念 AWS Lambda一、AWS Lambda 基本概念 Lambda 最长的代码运行时间为 15 分钟 二、AWS Lambda 使用场景 三、AWS Lambda 函数调用 同步调用 从 CLI、SDK 或者 API Gateway 触发 异步调用 S3、SNS 和 CloudWAtch 事件等来源 Lambda 函数最多重试 3 次 处理必须是幂等的：不能因为重试导致结果不同 事件源映射 ⭐ Lambda 将进行轮询 SQS、Kinesis 等数据流和 DynamoDB 流 记录按顺序处理（除了 SQS） SQS 消息无序。 四、AWS Lambda 函数并发 ⭐ 默认单 区域 所有函数总并发上限为 1000 ⭐ 达到并发上限后，将无法再扩展，会碰到 Rate Exceeded 或 429 TooManyRequestsException 错误 应用程序集成服务 (Application Integration) 概述一、应用程序集成服务 (Application Integration) 种类 二、AWS Step Functions 创建工作流（也称为状态机）来构建分布式应用程序、自动化流程、协调微服务以及创建数据和机器学习管道 可视化、编辑和调试应用程序的工作流程 检查工作流程中每个步骤的状态，以确保应用程序按预期顺序运行 三、AWS SWF (Simple Workflow Service) 可以理解为 Step Functions 的简单版本 ⭐ 适用于需要人工处理一部分工作的工作流 四、Amazon MQ ⭐ 适用于本身就适用 Apache Active MQ 或 RabbitMQ 的客户迁移到 AWS 考题中涉及到“行业协议”、“API”和“将队列迁移到 AWS”的术语，则需要注意 Amazon MQ。 五、⭐ Kinesis vs SQS vs SNS 扇出（Fanout）：消息先经过 SNS 队列分发给订阅者，再由订阅者放入各自 SQS 队列。 AWS SQS一、使用 SQS 队列解耦 二、SQS 队列类型 标准队列：无法保证消息顺序 FIFO 队列：消息先进先出 Message group ID：属于同一消息组的消息会严格按照顺序先进先出。 Message deduplication ID：特定时间内用以进行消息去重的令牌，确保消息只得到一次处理。 三、SQS 死信队列 (DLQ, dead-letter queues) 四、SQS 延迟队列 (SQS delay queues) 在延迟秒数内，消息不可见 五、SQS 短轮询和长轮询 (SQS short and long polling) AWS SNS一、AWS SNS 基本概念 二、AWS SNS + AWS SQS Fan-Out（扇出） 亚马逊 API 网关一、亚马逊 API 网关所处位置 二、亚马逊 API 网关类型 三、REST API 架构 HTTP API 没有上图中的方法请求，而是使用路由，通过路由将请求发送到 AWS Lambda 函数或其他可路由的 HTTP 终端节点。 四、API 网关集成 (API Gateway API integration) ⭐ AWS 服务操作只有非代理类型 五、API 网关缓存 六、API 网关限流 限制为每秒 10,000 个请求或 5000 个并发 超过限制后将返回 429 TooManyRequestsException 错误 七、API 网关使用计划 (Usage plans) 和 API 密钥 (API keys) 区分普通用户和高级用户时可以采取 使用计划 对访问阈值进行分开限制，和配置到不同的阶段或终端节点 使用 API 密钥 区分普通用户和高级用户","link":"/2024/11/18/knowledge_serverless/"},{"title":"AWS 知识点 - 块和文件存储","text":"AWS 块和文件存储相关知识点。 Amazon Machine Images (AMI)一、Amazon Machine Images (AMI) 基本概念 亚马逊 EBS 部署与卷类型一、Amazon EBS (Elastic Block Store) ⚠ 多个实例在之前是无法挂载同一个 EBS 卷的，但是现在可以通过多重挂载 (Multi-Attach) 在一些使用限制的情况下挂载同一个 EBS 卷 ⭐ EC2 实例必须和 EBS 卷位于同一可用区 默认情况下根卷会在实例终止时删除，而非引导卷则不会删除 EBS 卷在硬件层面是通过网络挂载到 EC2 所在的物理服务器上的 这和直接物理连接到物理服务器的 实例存储卷 (Instance Store Volume) 不一样。 二、EBS 多重挂载 (Multi-Attach) 仅适用于 Nitro 系统的 EC2 实例 卷的类型必须是预配置 IOPS SSD 的 IO1 和 IO2 卷 三、Amazon EBS 固态硬盘 (SSD) 卷 ⭐ 只有 SSD 卷能够充当引导卷 (Boot Volume) 四、Amazon EBS 硬盘驱动器 (HDD) 卷 亚马逊 EBS 复制、共享与加密一、跨可用区复制 EBS 上的数据 通过在 区域 级别的 S3 存储桶中创建 EBS 快照，并在另一个可用区重建快照来完成跨可用区的 EBS 数据复制 二、跨可用区通过快照创建 EC2 实例 ⭐ 通过快照创建 AMI 并在新的可用区使用这个 AMI 创建 EC2 实例 三、复制、共享 AMI 和快照 亚马逊 EBS 快照与 DLM (Data Lifecycle Manager)一、Amazon EBS、快照和 AMI 基础知识 二、Amazon Data Lifecycle Manager (DLM) EC2 实例存储卷 (Instance Store Volume)一、EC2 实例存储卷 (Instance Store Volume) 基本概念 ⭐ 实例存储卷 (Instance Store Volume) 直接物理连接到 EC2 所在物理服务器的 ⭐ 实例存储卷 (Instance Store Volume) 是临时的，EC2 关闭后数据就丢失了 ⭐ 实例存储卷 提供了更高的性能 Amazon Elastic File System (EFS)一、Amazon Elastic File System (EFS) 基本概念 ⭐ 建立了跨区域的 VPC 对等连接，其他区域的 EC2 实例也能通过 IP 地址挂载当前区域内的 EFS ⭐ EFS 当前仅支持 Linux 系统的实例进行挂载 如果是 Windows 操作系统则可以使用 Amazon FSx。 Amazon FSx 允许你在四个广泛使用的文件系统之间进行选择：NetApp ONTAP、OpenZFS、Windows File Server 和 Lustre。 AWS 存储网关 (Storage Gateway)一、AWS 存储网关 (Storage Gateway) 基本概念 二、AWS 存储网关 - 文件网关 (File Gateway) ⭐ 文件网关提供了虚拟的本地文件服务器（文件实际存放在 S3 中） ⭐ 本地缓存提供对最近使用的文件的低延迟访问 三、AWS 存储网关 - 卷网关 (Volume Gateway) 卷网关使用 iSCSI（基于块的存储协议）协议 缓存卷模式 (Cache mode)：最新或频繁使用的数据缓存在本地，所有的数据都存储在 S3 存储桶中 存储卷模式 (Stored mode)：所有数据都是存在本地的，但是会异步备份到 S3 存储桶中并创建时间点快照 四、AWS 存储网关 - 磁带网关 (Tape Gateway) 架构模式之块和文件存储","link":"/2024/11/27/knowledge_storage/"},{"title":"日语知识点 - 数字的读法","text":"涉及到个位、十位、百位、千位、万位及以上，还有小数、百分数和分数的读法。 个位数字的音读和训读 数字 音读 训读 0 ぜろ れい 1 いち ひと 2 に ふた 3 さん み 4 し/よん よ 5 ご いつ 6 ろく む 7 しち なな 8 はち や 9 きゅう/く ここの 十位数字的音读和训读 数字 音读 训读 10 じゅう とお 20 にじゅう はたち 30 さんじゅう みそ 40 よんじゅう よそ 50 ごじゅう いそ 60 ろくじゅう むそ 70 ななじゅう ななそ 80 はちじゅう やそ 90 きゅうじゅう ここのそ 百位数字的音读和训读需要注意除了 300「さんびゃく」、600「ろっぴゃく」和 800「はっぴゃく」之外都是用「ひゃく」即可。 数字 音读 训读 100 ひゃく もも 200 にひゃく ふたもも 300 さんびゃく みもも 400 よんひゃく よもも 500 ごひゃく いもも 600 ろっぴゃく むもも 700 ななひゃく ななもも 800 はっぴゃく やもも 900 きゅうひゃく ここのもも 千位数字的音读和训读只有 3,000「さんぜん」和 8,000「はっせん」需要注意。 数字 音读 训读 1,000 せん ち 2,000 にせん ふたち 3,000 さんぜん みち 4,000 よんせん よち 5,000 ごせん いちち 6,000 ろくせん むち 7,000 ななせん ななち 8,000 はっせん やち 9,000 きゅうせん ここのち 万位数字的音读和训读 数字 読み方 10,000 いちまん 20,000 にまん 30,000 さんまん 40,000 よんまん 50,000 ごまん 60,000 ろくまん 70,000 ななまん 80,000 はちまん 90,000 きゅうまん 万以上数字的音读和训读 数字 読み方 100,000 じゅうまん 1,000,000 ひゃくまん 10,000,000 いっせんまん 100,000,000 いち億おく 小数的读法小数点「.」的读法是「てん」，小数点后的数字的读法和整数部分一样。 例如 3.14 是「さんてんいちよん」。 数字 読み方 0.1 れいてんいち 0.5 れいてんご 1.5 いってんご 3.14 さんてんいちよん 10.5 じゅうてんご 100.5 ひゃくてんご 1,000.5 せんてんご 10,000.5 いちまんてんご 100,000.5 じゅうまんてんご 百分数的读法百分数的读法是「パーセント」。 例如 50% 是「ごじゅうパーセント」。 数字 読み方 0% れいパーセント 1% いちパーセント 50% ごじゅうパーセント 66.6% ろくじゅうろくてんろくパーセント 100% ひゃくパーセント 1000% せんパーセント 10000% いちまんパーセント 分数的读法分数的读法是「ぶんの」。 例如 1/2 是「いちぶんのに」。 数字 読み方 1/2 にぶんのいち 1/3 さんぶんのいち 1/4 よんぶんのいち 1/5 ごぶんのいち 32/100 ひゃくぶんのさんじゅうに 100/1000 せんぶんのひゃく","link":"/2024/08/10/knowledge_suuji_yomikata/"},{"title":"AWS 知识点 - 迁移","text":"本地环境迁移到 AWS 相关的知识点。 AWS 迁移工具一、AWS 迁移工具（服务）概览 使用 AWS 应用程序发现服务 (AWS Application Discovery Service, ADS) 收集本地数据中心的服务器和资源的使用情况或配置数据。 使用 AWS 应用迁移服务 (AWS Application Migration Service, MGN) 将本地服务器迁移到 EC2 实例中。 使用 AWS 数据库迁移服务 (AWS Database Migration Service, DMS ) 将本地数据库迁移到 RDS 等数据库。 使用 AWS DataSync 将本地的数据迁移到 S3、EFS 和 FSx 等文件服务中。 使用 AWS Migration Hub 监控迁移过程并进行相关配置。 二、AWS 应用程序发现服务 (AWS Application Discovery Service, ADS) 支持收集本地的 VMware 虚拟机、物理服务器和 Hyper-V 虚拟机的信息并进行存储（到 S3 存储桶中）和分析。 支持收集的信息包括：主机名、IP 地址、MAC 地址、资源分配和利用情况等。 Application Discovery Service 数据收集工具主要有两种： 发现连接器 (Discovery Connector)：部署在虚拟机平台上，只支持 VMWare 平台。 发现代理 (Discovery Agent)：部署在各个（虚拟）服务器上。 AWS 数据库迁移服务 (DMS)一、AWS 数据库迁移服务 (DMS) 基本概念 不同模式、不同数据库类型间的迁移（异构迁移）需要使用 模式转换工具。 两种模式转换解决方案： 使用 AWS Database Migration Service 控制台并启动 AWS DMS Schema Conversion (DMS SC)工作流程，从而获得完全托管的体验。 下载 AWS Schema Conversion Tool (AWS SCT) 软件到本地驱动器。 迁移目标包括 Aurora、Redshift、DynamoDB 和文档数据库 (Amazon Document DB)。 Aurora：兼容 MySQL 和 PostgreSQL 的数据库。 Redshift：完全托管的 PB 级数据仓库服务。 DynamoDB：完全托管的无服务器 NoSQL 数据库，数据结构像是 MongoDB。 Amazon Document DB：文档数据库服务，支持 MongoDB 工作负载。 二、DMS 使用场景 AWS 应用迁移服务 (MGN)一、AWS 应用迁移服务 (MGN) 基本概念 迁移流程： 安装数据收集工具 ⭐ AWS 推进使用基于代理 (Discovery Agent) 的复制以支持持续数据保护。 使用 AWS 应用迁移服务 (MGN) AWS 应用迁移服务 (MGN) 会创建启动模板 根据启动模板在 AWS 中启动 EC2 实例 可以整合 CloudWatch Events 和 Lambda 以在工作流程中自动执行某些操作 二、服务存在依赖关系时的分组迁移 三、MGN 使用场景和优势 AWS DataSync（数据同步服务）一、AWS DataSync（数据同步服务）基本概念 支持对 SnowCone 设备和 S3 on Outposts 进行数据同步 二、AWS DataSync 使用场景和优势 AWS Snow Family一、AWS Snow Family 基本概念 二、AWS Snow Family 各设备存储容量 AWS Snowcone：2 个 CPU、4GB 内存；14TB 的可用存储容量。 AWS Snowball： Snowball Edge Storage Optimized：40 个 vCPU 和 80GiB 内存；80TB 硬盘驱动器 (HDD) 容量，1TB SATA 固态硬盘。 适合大规模数据迁移和重复传输工作流，以及具有较高容量需求的本地计算。 Snowball Edge Compute Optimized：104 个 vCPU 和 416GiB 内存；80TB 可用 HDD 容量，28TB 可用 NVMe SSD 容量；一个可选的 NVIDIA Tesla V100 GPU。 可为机器学习、全动态视频分析、分析和本地计算堆栈等使用案例提供功能强大的计算资源。 AWS Snowmobile：是一个 45 英尺长的加固集装箱，由一台半挂卡车牵引，一次可以传输高达 100PB 的数据。 三、优化传输到 AWS Snow Family 设备的性能 四、AWS Snowball 使用场景和优势 注意这里只针对 AWS Snowball。","link":"/2024/11/14/knowledge_sync/"},{"title":"日语知识点 -「ところが」と「ところで」","text":"「ところが」与「ところで」的意思、区别与使用例。 「ところが」表示逆接，可以翻译成“然而”。后句发生了与前一句所描述的，相反的事情。 使用例： 子供が熱を出したので今日は休むと彼からは電話で連絡がありました。ところがその後ろから楽しそうにはしゃぐ子供の声が聞こえてくるんですよね。 他打电话来说孩子发烧了，所以今天要休息。但是后面却传来孩子们欢快的声音。 新聞はかるく扱っていたようだ。ところが、これは大事件なんだ。 报纸似乎没有作为重要问题登载。不过，这是一件大事。 「ところで」进行话题转换，可以翻译成“话说回来”。后句是和前一句关系不大的事情。 使用例： 子供が熱を出したので今日は休むと彼からは電話で連絡がありました。ところでお弁当の注文はどうしますか？ 他打电话来说孩子发烧了，所以今天要休息。对了，便当的订单怎么样了？ ところで、家に来て私の母に会いますか。 话说回来，要来我家看看我妈妈吗？","link":"/2024/08/18/knowledge_tokoroga_tokorode/"},{"title":"项目管理知识点 - 常用工具、方法及图表","text":"包括蒙特卡洛分析、德尔菲法和帕累托图等。 蒙特卡洛分析 (Monte Carlo Analysis) ✨ 关键词：定量风险分析 蒙特卡洛分析是一种通过模拟大量可能的结果来预测结果的技术。它是一种统计模拟技术，用于分析风险和不确定性。蒙特卡洛分析通常用于项目管理中的风险管理，以确定项目完成日期和成本的概率分布。依赖数据库。 📖 PMP 复习资料：11.4 实施定量风险分析……模拟：在定量风险分析中，使用模型来模拟单个项目风险和其他不确定性的综合影响，以评估它们对项目目标的潜在影响，模拟通常采用蒙特卡洛模拟。…… S 曲线 (S-Curve) ✨ 关键词：定量风险分析 S 曲线是一种用于显示项目进度或成本随时间变化的图表。 📖 PMP 复习资料：影响图/Influence diagrams：…..借助模拟技术（如蒙特卡洛分析）来分析哪些要素对重要结果具有最大的影响。影响图分析，可以得出类似于其他定量风险分析的结果，如 S 曲线图和龙卷风图。 敏感性分析（龙卷风图） (Sensitivity Analysis) ✨ 关键词：定量风险分析 敏感性分析是一种确定风险和活动关联、以及风险大小的技术。 📖 PMP 复习资料：影响图/Influence diagrams：…..借助模拟技术（如蒙特卡洛分析）来分析哪些要素对重要结果具有最大的影响。影响图分析，可以得出类似于其他定量风险分析的结果，如 S 曲线图和龙卷风图。 敏感性分析/Sensitivity analysis：一种定量风险分析技术，将项目成果的变化与定量风险分析模型中输入的的变化建立关联，从而确定对项目成果产生最大潜在影响的单个项目风险或其他不确定性来源。 德尔菲法 (Delphi Method) ✨ 关键词：整合意见、专家调查 德尔菲法是一种专家调查技巧，用于收集和整合专家的意见。它通常用于不确定性较高或缺乏明确数据的问题情境下。德尔菲法的核心是通过多轮匿名问卷调查，反复收集专家的观点，并在每一轮中向专家们反馈上一轮的汇总结果。​最终，逐步达成共识或接近共识。​ 德尔菲法的关键特征包括： 匿名性：参与的专家保持匿名，以避免群体压力或权威影响个人的观点，从而使得结果更加客观。 多轮调查：通过多轮问卷调查，逐步修正和整合专家们的意见。每一轮的结果都作为下一轮的参考，促使专家们重新考虑他们的观点。 反馈机制：每轮调查后，会向所有专家反馈汇总后的结果，这种反馈帮助专家们更好地理解其他人的观点，并可能修正自己的意见。 统计分析：最终的结果通常通过统计分析得出，例如计算中位数、四分位数或其他统计量，以呈现专家们的共识程度。 德尔菲法广泛应用于未来趋势预测、政策制定、技术评估、风险管理等领域，尤其适用于复杂、多变且数据有限的环境。 帕累托图 (Pareto Chart) ✨ 关键词：重要性排序、少数原因导致大部分结果 帕累托图是一种直方图，用于显示按重要性排序的数据。它基于帕累托原则，即少数原因导致大部分结果。 📖 PMP 复习资料：8.2 管理质量……帕累托图：即按缺陷发生次数从高往低排序后的直方图，当有大量缺陷需要修复时，帕累托图可以用来指导修复缺陷的顺序。…… 亲和图 (Affinity Diagram) ✨ 关键词：分组 亲和图是一种用来对大量创意进行分组，以便进一步审查和分析的技术。亲和图还可以对潜在缺陷成因进行分类，展示最应关注的领域。 📖 PMP 复习资料：5.2 收集需求……亲和图：对（头脑风暴产生的）大量创意进行分组（分类）的技术，以便进一步审查和分析。…… SWOT 分析 (SWOT Analysis) ✨ 关键词：风险识别、优势劣势机会威胁 SWOT 分析是一种用于风险识别的技术。 📖 PMP 复习资料：11.2 识别风险……SWOT 分析：根据组织自身的强弱 (S、W) 和外部环境的机会和威胁 (O、T)，识别来自组内部、外部的机会和威胁，也称态势分析。…… 甘特图 (Gantt Chart) ✨ 关键词：进度计划 甘特图是一种用于显示项目进度的图表。它显示了项目的任务、开始时间、结束时间和持续时间。 凸显模型 (Highlight Report) ✨ 关键词：管理干系人 凸显模型根据相关方的权力、紧急程度和合法性分为三大部分，以此来确定已识别的相关方的相对重要性。一般适用于复杂的相关方大型社区中。","link":"/2024/06/02/knowledge_tools/"},{"title":"AWS 知识点 - 亚马逊虚拟私有云 (Amazon Virtual Private Cloud, VPC)","text":"借助 Amazon Virtual Private Cloud (Amazon VPC)，您可以在自己定义的逻辑隔离的虚拟网络中启动 AWS 资源。这个虚拟网络与您在数据中心中运行的传统网络极其相似，并会为您提供使用 AWS 的可扩展基础设施的优势。 AWS 组件中英文对照表 VPC 组件（中文） 英文 用途 VPC VPC 子网 Subnets IP 寻址 IP addressing 路由 Routing 网关和断点 Gateways and endpoints 对等连接 Peering connections 流量镜像 Traffic Mirroring 中转网关 Transit gateways Amazon VPC 流日志 VPC Flow Logs VPN 连接 VPN connections 参考资料： Amazon VPC 是什么？ What is Amazon VPC? AWS 全球基础设施一、AWS 全球基础设施基本概念 区域 (Region) 是分散在世界各地数据中心的物理位置，是相互独立的 可用区 (AZ, Availability Zone) 是指一个 AWS 区域 中的一个或多个数据中心 二、区域及其扩展 AWS Outposts：允许在本地扩展和运行原生 AWS 服务。 AWS Wavelength Zone：在 5G 网络的通信服务提供商 (CSP) 中嵌入 AWS 计算和存储服务。 AWS Local Zone：将计算、存储、数据库和其他某些初级服务放置在更靠近大量人口聚居的位置，或者靠近行业和 IT 中心的位置，使您能够提供最终用户要求延迟不超过 10 毫秒的应用程序。 三、Amazon CloudFront 四、截止 2024 年末 AWS 基础设施数量 Amazon VPC 概述一、Amazon VPC 基本概念 二、Amazon VPC 的 CIDR 块配置 不同 VPC 的 CIDR 块需要不同 （VPC 内）子网 的 CIDR 块是 VPC CIDR 块的子集 三、Amazon VPC 组件 ⭐ 仅出口 Internet 网关 (Egress Only Internet Gateways) 仅适用于 IPv6 流量，且只适用于出站通信，会阻止互联网到实例的入站通信。 互联网网关 适用于 IPv4（和 IPv6）流量，允许出站流量和入站流量。 网络 ACL 是 子网 级别的防火墙。 四、⭐ Amazon VPC 关键知识点 子网 不能跨可用区。 VPC 基础知识VPC 基础 私有 IP 网段（RFC 1918 规范） 在互联网的地址架构中，专用网络是指遵守 RFC 1918 和 RFC 4193 规范，使用专用IP地址空间的网络。 10.0.0.0 - 10.255.255.255 (10.0.0.0/8)：大型网络 172.16.0.0. - 172.31.255.255 (172.16.0.0/12)：AWS 默认的 CIDR 块 192.168.0.0 - 192.168.255.255 (192.168.0.0/16)：家庭网络 ⭐ 子网 的 CIDR 块中前四个 IP 地址和最后一个 IP 地址无法使用，是 AWS 用于联网目的保留的 公有子网 通过 Internet 网关 联网 私有子网 通过 NAT 实例 或 NAT 网关 联网 NAT 实例 是部署在 公有子网 的、供 私有子网 内实例经由它、连接 互联网网关 的、需要自行维护的实例（相对便宜） NAT 网关 是 AWS 提供的、可用区 (AZ) 级别高度可用的、需要绑定弹性 IP 地址的服务 VPC 流日志 (VPC Flow Logs) 可以为 VPC、子网 或 网络接口 (ENI) 创建流日志 安全组和网络 ACL一、安全组和网络 ACL 概览 网络 ACL 是应用于 子网 级别的。 一个 子网 只能关联一个 网络 ACL，但一个 网络 ACL 可以关联多个 子网。 安全组 是应用于 (EC2) 实例 级别的。 同一 安全组 可以应用于不同 子网 中的不同 实例。 安全组 是有状态的，网络 ACL 是无状态的。 二、有状态和无状态防火墙 有状态防火墙 将自动允许入站请求的返回流量。 在 安全组 上只需要配置 入站规则，不需要配置 出站规则。 无状态防火墙 无法区分进站和出站请求是否是同一个请求，因此会检查进和出两个方向的允许规则。 在 网络 ACL 上需要配置 入站规则 和 出站规则。 三、安全组规则样例 安全组 仅支持配置 允许 规则，不支持配置 拒绝 规则。 源可以是单个 IP、IP 范围或另一个安全组（的 ID）。 四、安全组配置最佳实践 自上而下只允许必要的流量，拒绝所有其他流量。 安全组 通过 安全组 ID 进行引用。 五、网络 ACL 规则样例 网络 ACL 支持配置 允许 和 拒绝 规则。 规则是按顺序从上到下（编号从小到大）依次匹配的，一旦匹配到一条规则，后续规则不再生效。 ⭐ 默认的 网络 ACL 规则是 允许所有入站和出站流量。 ⭐ 自己创建的自定义 网络 ACL 规则默认是 拒绝所有入站和出站流量。 VPC 对等连接 (VPC peering)一、VPC 对等连接基本概念 内网连接两个 VPC。 用以连接的两个 VPC 不能有重叠的 CIDR 块。 不支持传递。 例：A 与 B 相连，B 与 C 相连，此时 A 无法访问到 C。 ⭐ 需要手动更新每个 VPC 子网的路由表。 支持跨 AWS 区域和 AWS 账户。 二、最长前缀匹配 (longest prefix matches) 三、不受支持的 VPC 对等配置 两个 VPC 中任意 IPv4/IPv6 CIDR 块重叠都无法建立对等连接。 不支持边界到边界的路由。 VPC 终端节点 (VPC endpoints)一、VPC 终端节点基本概念 VPC 终端节点 使得能将 VPC 通过 AWS 的私有网络连接到支持的 AWS 服务，而不用经过 Internet。 VPC 终端节点 有两种类型： 网关终端节点：⭐ 只支持 S3 和 DynamoDB​。 接口终端节点 排查终端节点问题主要是 2 个方向：DNS 解析配置 和 路由表。 二、网关终端节点 (Gateway VPC endpoints) 网关终端节点 新建过程： 选择 网关终端节点 类型 选择连接到 S3/DynamoDB 服务 选择 VPC 选择 路由表（需要连接服务的EC2 所在 子网 的 路由表） 支持配置 策略 三、接口终端节点 (Interface VPC endpoints) 创建 接口终端节点 将新建一个 弹性网络接口 (Elastic network interfaces, ENI) 弹性网络接口 是 VPC 中表示虚拟网卡的逻辑网络组件。您可以创建并配置网络接口，并将其连接到同一可用区中启动的实例。 接口终端节点 新建过程： 选择 接口终端节点 类型 选择连接到相应的 AWS 服务 选择 VPC 选择 子网（需要连接服务的EC2 所在 子网） 这里与 网关终端节点 选择 路由表 不同： 启用私有 DNS 名称 启用后，调用相应服务的共有 DNS 会解析成私有地址。 如果有的话，配置相应服务的 安全组 支持配置 策略 VPC 终端节点策略 (VPC endpoint policy) VPC 终端节点策略 的考点通常以“涉及访问 S3 的终端节点的内容，然后让你设计控制 S3 存储桶的访问”这种形式出现。 一、VPC 终端节点策略基本概念 ⚠ 并非所有的 AWS 服务都支持 终端节点策略 终端节点策略 是在服务原有 IAM 用户策略 或 服务特定策略 以外的多一层保障 二、⭐ S3 存储桶策略在 VPC 终端节点场景下的应用 aws:SourceIp 条件只能用来限制 共有 IP​ 对 S3 存储桶 的访问 要限制 VPC 终端节点 对 S3 存储桶 的访问需要使用 aws:sourceVpce 或 aws:sourceVpc 示例： 三、通过网关终端节点访问 S3 存储桶失败时的排障 依次确认以下 6 点： EC2 的安全组出口规则 VPC 终端节点策略 子网的路由表 VPC 要启用 DNS 解析 S3 存储桶 策略 IAM 用户 策略 AWS Site-to-Site VPN一、AWS Site-to-Site VPN 基本概念 虚拟专用网关 (Virtual Private Gateway, VGW) 是 VPC 级别的 会创建两条 VPN 隧道进行冗余 二、AWS Site-to-Site VPN 的路由配置 公司数据中心和 VPC 的 CIDR 块需要不同 三、AWS Site-to-Site VPN 与 Internet 访问 四、AWS VPN CloudHub AWS Client VPN 与软件 VPN一、AWS Client VPN 基本概念 二、软件 VPN（⚠️ 非 AWS 托管） 相当于自行搭建节点。 AWS Direct Connect(DX) 与 Direct Connect Gateway一、AWS Direct Connect 基本概念 建立的是专用私有连接 本地数据中心 &lt;–&gt; AWS Direct Connect 位置 &lt;–&gt; 某区域内的某 VPC 二、AWS Direct Connect 虚拟接口 访问 S3 等具有公有域名的 AWS 服务使用的是 公共虚拟接口 (Public virtual interface) 访问 VPC 内资源使用的是 私有虚拟接口 (Private virtual interface) VPC 终端节点 是无法使用 私有虚拟接口 (Private virtual interface) 访问的 VPC 终端节点 不支持边界到边界的路由。需要访问 S3 等公共服务时，直接使用 公共虚拟接口 (Public virtual interface) 即可。 三、AWS Direct Connect 连接的类型 ⭐ 无论那种方案都需要 1 个月以上的时间。 涉及到传输大容量数据的考题，需要注意时间限制。 四、AWS Direct Connect 加密 五、AWS Direct Connect 网关 本地数据中心连接到多 区域 多 VPC 时使用 六、AWS Direct Connect 网关 + Transit Gateway Transit VPC &amp; Transit Gateway一、Transit VPC 基本概念 非 AWS 托管，只是 AWS 建议的异地数据中心建立连接的方式。 通过 VPN 实现的网络中转中心 二、网络复杂性随着规模增加 三、Transit Gateway 可以跨 区域 可以跨 AWS 账户 ⭐ 支持边界到边界的路由 架构模式之 Amazon VPC","link":"/2024/11/13/knowledge_vpc/"},{"title":"AWS 知识点 - 亚马逊虚拟私有云 (Amazon Virtual Private Cloud, VPC) - 拓展（针对 SAP-C02 认证）","text":"借助 Amazon Virtual Private Cloud (Amazon VPC)，您可以在自己定义的逻辑隔离的虚拟网络中启动 AWS 资源。这个虚拟网络与您在数据中心中运行的传统网络极其相似，并会为您提供使用 AWS 的可扩展基础设施的优势。 AWS PrivateLink一、AWS PrivateLink 基本概念 ⭐ 通过为自己的应用程序配置终端节点，使其他用户可以通过 AWS 的私有访问访问它 ⭐ 其他用户需要通过创建 VPC 接口终端节点 (Interface VPC Endpoint) 来访问应用程序 二、使用 PrivateLink 的集中化进行 Web 访问过滤的解决方案 AWS 与本地网络间的高可用连接方案一、连接高可用的基本概念 避免单点故障 (Single Point of Failure) 双设备 双线路 多服务提供商 尽量使用动态路由协议（自动切换） 二、冗余 Active/Active VPN 连接 两个数据中心的内部连接故障后，仍然可以通过 AWS 的 CloudHub 实现互相访问 三、冗余的 Active/Active AWS Direct Connect (DX) 线路 四、Active AWS Direct Connect (DX) 为主 VPN 为辅","link":"/2024/12/26/knowledge_vpc_extend/"},{"title":"日语知识点 - 格助词「を」在自动词前的使用","text":"关于格助词「を」在自动词前被使用的 6 种情况。 格助词「を」大多数情况下用在他动词前，提示动作的对象，构成宾语。例如：「ドアを開けます。」「ご飯を食べます。」等。但是也存在明明是自动词，但是前面却使用「を」的情况，比如常见的：「空を飛ぶ。」「公園を散歩する。」等。其实在日语中，除了他动词以外，「を」也大量被用于自动词之前，一般以「Ｎ名词+を+Ｖ动词」形式出现。 下面将自动词前用「を」的情况进行分类，同时感受「を」格助词所传递的微妙的语感。 一、V为移动动词，用来表达事情发生的起点、通过点比如「川を渡る」「空を飛ぶ」等，但是还有其他移动动词。 注意：方向性较强的移动动词不适用，比如：「向かう」「近づく」等，这类动词不适用于「Ｎ名词+を+Ｖ动词」的结构，使用格助词「に」「へ」，这里不赘述。 适用于前加「を」的方向性较弱的词，如： 「出る」「離れる」「去る」「卒業する」「出発する」等。 主要表示动作的出发。 「歩く」「登る」「通る」「横切る」「渡る」「泳ぐ」「飛ぶ」「徘徊する」「往来する」「散歩する」等。 主要表示动作的通过。 例句： 私が小学校を出たとき、父が死んだ。 私が小学校から出たとき、父が死んだ。 这里的「を」是“毕业”的意思。而对比句给人的印象是从学校的建筑物里出来。 故郷を離れる前の夜に、父といろいろ話しました。 故郷を去る。 交差点を渡りながら、道沿いの店を除きながら、道半坂を登り、中途の喫茶店へ入った。 今朝公園を散歩していたときに… 道を横切る。 通用門を通って中へ入る。 ジープで山を登った。 ケーブルカーで山に登った。 采用「ヲ格」，根据以上分类，此时句子的重点在于强调通过点。而对比句采用「ニ格」，这时句子强调的是到达点。 二、「N+を+V (自动词)」表示自动词的作用持续、动作进行的时间的长度例句： 池の水際は杜若が今を盛りと咲いている。 会社員は夏を働いた。 9 和 10 中的「咲く」「働く」所持续的时间都是用「ヲ格」来表示，提示各个动作的进行贯穿了前面所揭示的时间的整个过程。这个语感换成是别的格助词则语感不同。以下面的句子为例： 留学生たちは夏に働いた。 「ニ格」接在表示时间的名词后面，表示具体动作发生的时间，因此语法正确。这两个例句在含义上的区别在于：对比巨的「ニ格」单纯地将「働く」这个动作发生的时间表达出来。而 10 的「ヲ格」则表达出一天未休地工作了整个夏天,明确表达出「働く」这个动作贯穿了夏天的由始至终。 三、「N+を+V (自动词)」表示状态这个用法可与前述 2 之表示自动词的作用持续、动作进行的时间的长度的用法联系起来。例句： 娘が見合いを逃げたくらいで大騒ぎして、と真弓はまた腹が立ってきた。 11 中的这个用法可以表达出由始至终地缺席、不参与状态，而不是半途开溜或者中途不参与。 雨の中を傘をさずに立ち続けた。 在表达含义上，「ヲ格」助词在表达时间状态的句子当中，一般后面都接有违常识的动作的持续或者发生。如例 12，按照常识，下雨应该打伞，但是却不打伞而站立在雨中，因此带有轻微的逆接，说话人通过这个轻微的逆接来表达诸如感谢、埋怨、不安等心情，这也是通过「ヲ格」助词的使用才能传达的情绪，如果换成其他格助词，在语义上虽然能将事情说清楚，但是说话人的情绪却被淹没其中，不能得到很好的表达。由于表示逆接的「ヲ格」助词的用法经常以「ところを」「中を」的形式出现,因此很多语法书也将这种表达轻微逆接的「ヲ格」助词当作接续助词来看待。 四、表示时间、期间、数量的经过点例句： 長い歳月を経てこの作品を書き上げた。 9 時を過ぎると、さすがにつかれを覚える。 年間百を上回る美術団体はここで展覧会を行っている。 13 和 14 表示时间的经过，15 表示数量的经过。 五、「N+を+V (自动词)」表示引发某种情绪的缘由以及事物例句： S はやはり S 自身は死なずに僕の死んだことを喜んでいる。 27日開館の予定で昼夜工事を急いでいる。 以上「N+を+V (自动词)」结构都表达出主语的愤怒、高兴、着急等的心情，「ヲ格」助词前面的名词表示引发这些情绪的缘由。如果用表示原因的「デ格」助词来替换的话，就像下面的句子一样： SはやはりS自身は死なずに僕の死んだことで喜んでいる。 使用「デ格」助词的话则只是单纯的客观描述。因此，两者在心情的传递方面是有着很大区别的。 ほとんどの人は、セルフケアや身体症状を困ることだ。 女の子が男の子を怒る。 なにを慌てているの。 18、19 和 20 中的「を」主要强调精神作用和愿望的对象。 では今日の報告を終わります。 目をあいて見る。 3 分の 2 以上の賛成を必要になる。 点滴を終わった倫子に直江が命じた。 サイレンの音は角を曲がった。 21、22、23、24 和 25 均为自动词代替与其对应的他动词，以减弱主观性，或暗示这一动作并非单纯出自主观愿望，还有不得已或意料以外的原因。 学校を遅れたら大変よ。 私の気持ちを分かってもらいたい。 26 和 27 则相反，为了加强主观态度，用「を」代替了本应用「に」或「が」的格助词。 六、没有相应的他动词，用自动词来做他动词 返事を急がなくてもいい。 大郎は今日も学校を休んだ。 总结以上是对助词「を」用于自动词前的总结和情感分析，每一种的划分并非绝对，其中有许多交叉或者重合之处。但是可以发现助词「を」很大程度上都表达着说话者的某种感情色彩，是一个“情绪化”的格助词，更多时候需要结合语境做判断和理解。​","link":"/2024/09/06/knowledge_wo_jidoushi/"},{"title":"日语知识点 - 日语词类划分整理","text":"关于日语中独立词和附属词的划分，以及各自的分类和特点。 日语词类（日本語の品詞）​日语的词类在学校语法中总体上可以分为两大类：独立词和附属词（自立語と付属語）​ 独立词（自立語）​：自身可做文节（具有语法功能的最小单位）的词语 附属词（付属語）​：无法单独做文节的，必须依附于独立词使用的词语 一、独立词（自立語）独立词可分为有活用和无活用（活用与否取绝于是否根据后面所接续的助词修改语尾） 在有活用的独立词中：有命令形的是动词；没有命令形、连体形以“い”结尾的是形容词（有的书籍称作“イ形容詞”、“第1类形容词”）；没有命令形、连体形以“な”结尾的是形容动词（有的书籍称作“ナ形容詞”、“第2类形容词”）。 在无活用的独立词中：能做主语的是名词；不能做主语、能单独做连用修饰语的是副词；能做连体修饰语的是连体词；能做接续语的是连词；只能做独立语的是感叹词。 此外，在日语中，“名词”和“体言”这两个词往往混用。虽然“体言”和“名词”可以说指的是同一事物，但在强调它是没有活用的时候称其为“体言”；强调它在句子成分中能充当主语时称其为“名词”。 现在的学校文法中，“用言”指有活用的独立语（动词，形容词，形容动词）；“体言”指无活用独立语中的名词（以及代名词、数词），副词、连体词等是不能算作”体言“的！ 详尽解释和举例： 用言 动词、形容词和形容动词总称用言。用言可以独立作谓语，也可以独立作定语（连体修饰语）或状语（连用修饰语），不过根据后面所接续的助词，必须改变语尾，即活用。 动词（動詞）​：表示事物的存在、动作或临时状态。例：洗う、受ける。 形容词（形容詞）：说明体言的性质或固定状态。例：広い、固い。 形容动词（形容動詞）​：功用与形容词相近、功能介于动词和形容词之间，但是语尾变化与形容词和动词不同，是后来从名词（尤其是汉语名词）和日语固有的词根派生而来。例：静か。 体言 名词、代词和数词总称体言，可以做句子的主语、补语、宾语、也可以和断定助动词结合起来作谓语，没有语尾变化。 名词（名詞）​：表示事物名称的单词。例：部屋、人間、日本。 代词（代名詞）​：代指人或者事物的单词。例：私、ここ。 数词（数詞）​：数目的称呼叫做数词。例：一つ、第二。 其他词类 连体词（連体詞）​：只能加在体言前作修饰。例：この、あの、その。 副词（副詞）​：修饰用言的状态、程度、形容词与形容动词经由语尾变化可以变成副词。例：少し、とても。 连词（接続詞）​：用于连接词和词、成分和成分、句子和句子的词。在句与句之中作为承先启后的作用。用于表达前后两者关系。本身没有活用。例：そして、更に。 感叹词（感動詞）​：表示发话者的感叹、互换或应答。叹词本身无实在的词汇意义，也无词尾变化，可以独立构成句子。例：あら、へえ。 二、附属词（付属語）附属语同样分为有活用的和无活用。 有活用的附属词是助动词。例：「気を引かれる、私は泣かない、花が笑った、さあ、出かけよう、今日は来ないそうだ、もうすぐ春です」中的粗体部分皆为助动词。助动词同时具有助词和动词的性质、接续在动词后面，给动词增添特殊意义或是派生成被动、使役动词，接续时前面的动词语尾必须变化，而有些助动词本身也会有语尾变化。例：られる（代表被动）、ない（代表否定） 详细可参考：日语知识点 - 助动词的详细划分 无活用的附属词是助词。例：「香菜ちゃんが微笑んだ、買ってくる、やるしかない、分かったか」中的粗体部分皆为助词。根据职能、接续法、后续性和重叠的规律，助词还可细分为：格助词：表示名词和谓语之间格关系。例：が、を。接续助词：表示活用语和其后接续部分的关系。例：ながら、て。副助词：在词语后添加程度、限定等意义并修饰后续用言。例：のみ、さえ。终助词：在句末表达疑问、咏叹、感动、禁止等语气和意图。例：かな、かも。助词是日语中最重要的词类，决定在句中的地位、和其他单词的关系、句子的时态，或是表示特殊的意义。现代日语有三十几个助词，大多是由一两个音节组成，但是在最重要的格助词中也存在复合格助词，日语的一个句子就是由单词后面附上助词，依照大概的顺序组合而成。例：は・が（提示主题、或分开主语和谓语）、を（表动词的受语） 总结最后附上一张日网扒来的图，看起来还是比较一目了然的：","link":"/2024/09/07/knowledge_word_class/"},{"title":"Kubernetes 删除 namespace 时一直处于 Terminating 状态的解决方法","text":"似乎是大部分人都会遇到的问题，删除 namespace 时，namespace 一直处于 Terminating 状态，无法删除。需要通过 API 强制删除 namespace，以下是解决方法。 1、查看处于 Terminating 状态的 namespace1kubectl get namespace 我这里是 cert-manager 这个 namespace 一直处于 Terminating 状态。 2、拿到 namespace 的描述输出到 tmp.json 文件中： 12cd /root/kubectl get namespace cert-manager -o json &gt; tmp.json 文件内容： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162{ &quot;apiVersion&quot;: &quot;v1&quot;, &quot;kind&quot;: &quot;Namespace&quot;, &quot;metadata&quot;: { &quot;annotations&quot;: { &quot;kubectl.kubernetes.io/last-applied-configuration&quot;: &quot;{\\&quot;apiVersion\\&quot;:\\&quot;v1\\&quot;,\\&quot;kind\\&quot;:\\&quot;Namespace\\&quot;,\\&quot;metadata\\&quot;:{\\&quot;annotations\\&quot;:{},\\&quot;name\\&quot;:\\&quot;cert-manager\\&quot;}}\\n&quot; }, &quot;creationTimestamp&quot;: &quot;2024-09-13T09:17:19Z&quot;, &quot;deletionTimestamp&quot;: &quot;2024-09-13T11:51:03Z&quot;, &quot;labels&quot;: { &quot;kubernetes.io/metadata.name&quot;: &quot;cert-manager&quot; }, &quot;name&quot;: &quot;cert-manager&quot;, &quot;resourceVersion&quot;: &quot;8322&quot;, &quot;uid&quot;: &quot;b15a240c-xxxx-xxxx-xxxx-xxxxxxxxxxxx&quot; }, &quot;spec&quot;: { &quot;finalizers&quot;: [ &quot;kubernetes&quot; ] }, &quot;status&quot;: { &quot;conditions&quot;: [ { &quot;lastTransitionTime&quot;: &quot;2024-09-13T12:24:08Z&quot;, &quot;message&quot;: &quot;All resources successfully discovered&quot;, &quot;reason&quot;: &quot;ResourcesDiscovered&quot;, &quot;status&quot;: &quot;False&quot;, &quot;type&quot;: &quot;NamespaceDeletionDiscoveryFailure&quot; }, { &quot;lastTransitionTime&quot;: &quot;2024-09-13T12:24:08Z&quot;, &quot;message&quot;: &quot;All legacy kube types successfully parsed&quot;, &quot;reason&quot;: &quot;ParsedGroupVersions&quot;, &quot;status&quot;: &quot;False&quot;, &quot;type&quot;: &quot;NamespaceDeletionGroupVersionParsingFailure&quot; }, { &quot;lastTransitionTime&quot;: &quot;2024-09-13T12:24:08Z&quot;, &quot;message&quot;: &quot;Failed to delete all resource types, 6 remaining: the server has received too many requests and has asked us to try again later, the server was unable to return a response in the time allotted, but may still be processing the request, the server was unable to return a response in the time allotted, but may still be processing the request, the server was unable to return a response in the time allotted, but may still be processing the request, the server was unable to return a response in the time allotted, but may still be processing the request, the server was unable to return a response in the time allotted, but may still be processing the request&quot;, &quot;reason&quot;: &quot;ContentDeletionFailed&quot;, &quot;status&quot;: &quot;True&quot;, &quot;type&quot;: &quot;NamespaceDeletionContentFailure&quot; }, { &quot;lastTransitionTime&quot;: &quot;2024-09-13T12:24:08Z&quot;, &quot;message&quot;: &quot;All content successfully removed&quot;, &quot;reason&quot;: &quot;ContentRemoved&quot;, &quot;status&quot;: &quot;False&quot;, &quot;type&quot;: &quot;NamespaceContentRemaining&quot; }, { &quot;lastTransitionTime&quot;: &quot;2024-09-13T12:24:08Z&quot;, &quot;message&quot;: &quot;All content-preserving finalizers finished&quot;, &quot;reason&quot;: &quot;ContentHasNoFinalizers&quot;, &quot;status&quot;: &quot;False&quot;, &quot;type&quot;: &quot;NamespaceFinalizersRemaining&quot; } ], &quot;phase&quot;: &quot;Terminating&quot; }} 3、将文件中的 finalizers 值设置为空列表这里就不演示了，编辑删除即可。 4、通过 API 强制删除 namespace1curl -k -H &quot;Content-Type:application/json&quot; -X PUT --data-binary @tmp.json http://localhost:8001/api/v1/namespaces/cert-manager/finalize 如果你的请求返回了： 123456789{ &quot;kind&quot;: &quot;Status&quot;, &quot;apiVersion&quot;: &quot;v1&quot;, &quot;metadata&quot;: {}, &quot;status&quot;: &quot;Failure&quot;, &quot;message&quot;: &quot;the object provided is unrecognized (must be of type Namespace): couldn't get version/kind; json parse error: unexpected end of JSON input (\\u003cempty\\u003e)&quot;, &quot;reason&quot;: &quot;BadRequest&quot;, &quot;code&quot;: 400} 那么就是你的请求命令出错了，出现了类似 --data-binary 前的 -- 变成了 — 的情况，需要手动进行修正。 5、查看 namespace 是否已删除1kubectl get namespace 大功告成。","link":"/2024/09/13/kubernetes_delete_namespace_terminating/"},{"title":"Linux 下使用 Rclone 将本地文件复制到 Cludflare R2 存储桶中","text":"前言项目 S3 存储桶要从国内迁移到国外，首次的文件量有点大，用 Rclone 传输下。 方案概述 安装 Rclone 获取 Cloudflare R2 存储桶的 Access Key 和 Secret Key 将本地文件传输至 Cloudflare R2 存储桶 操作步骤一、安装 Rclone 官方文档：Install 我这里是 Ubuntu 系统，采用官方推荐的下载最新版本可执行文件的方式： 123456789101112# 下载curl -O https://downloads.rclone.org/rclone-current-linux-amd64.zipunzip rclone-current-linux-amd64.zipcd rclone-*-linux-amd64# 拷贝可执行文件到 /usr/bin 目录并设置权限sudo cp rclone /usr/bin/sudo chown root:root /usr/bin/rclonesudo chmod 755 /usr/bin/rclone# 安装手册页sudo mkdir -p /usr/local/share/man/man1sudo cp rclone.1 /usr/local/share/man/man1/sudo mandb 然后通过 rclone version 命令查看是否安装成功： 1rclone version 二、获取 Cloudflare R2 存储桶的 Access Key 和 Secret Key 我这里就稍作演示，详细可以参照我的另一片文章：二、获取配置信息 我们可以看下 Rclone 需要的配置信息： 1234567[r2demo]type = s3provider = Cloudflareaccess_key_id = abc123secret_access_key = xyz456endpoint = https://&lt;accountid&gt;.r2.cloudflarestorage.comacl = private 因此我们需要从 Cloudflare R2 控制台获取： access_key_id secret_access_key endpoint 选择 R2 存储桶，然后在右侧选择管理 R2 API 令牌： 创建 API 令牌，然后复制 Access Key 和 Secret Key： 这里权限按需求填写，我拿来举例子因此选了只读权限，后续挂载到本地的话可能需要写入权限。 三、将本地文件传输至 Cloudflare R2 存储桶 官方文档：rclone | Cloudflare R2 docs详细的 Rclone 配置说明：Cloudflare R2 找到配置文件路径，然后编辑配置文件： 1234# 找到配置文件路径rclone config file# 编辑配置文件vim /root/.config/rclone/rclone.conf 然后编辑配置文件，添加 Cloudflare R2 的配置信息（这里不需要设置存储桶）： 1234567891011# 这个是配置文件的名称，可以自定义[r2demo]type = s3provider = Cloudflare# 访问密钥 IDaccess_key_id = abc123# 机密访问密钥secret_access_key = xyz456# 管辖权的终结点endpoint = https://&lt;accountid&gt;.r2.cloudflarestorage.comacl = private 保存配置文件，然后列出指定存储桶内项目确认下是否配置成功： 1rclone tree r2demo:your_bucket_name 注意这里一定要填写你的存储桶名称，不然会出现以下错误： 1NOTICE: Failed to tree: operation error S3: ListBuckets, https response error StatusCode: 403, RequestID: , HostID: , api error AccessDenied: Access Denied 没有问题的话就可以开始传输文件了： 12# 将 /root/test 目录下的所有文件传输到 Cloudflare R2 存储桶中rclone copy /root/test r2demo:your_bucket_name/ -P --s3-no-check-bucket 注意：使用 Rclone 操作 Cloudflare R2 存储桶时，总是会进行一次 CreateBucket 操作，如果没有权限会报错： 12345672024/10/20 16:01:54 ERROR : rclone-current-linux-amd64.zip: Failed to copy: failed to prepare upload: operation error S3: CreateBucket, https response error StatusCode: 403, RequestID: , HostID: , api error AccessDenied: Access Denied2024/10/20 16:01:54 ERROR : Attempt 1/3 failed with 1 errors and: failed to prepare upload: operation error S3: CreateBucket, https response error StatusCode: 403, RequestID: , HostID: , api error AccessDenied: Access Denied2024/10/20 16:01:54 ERROR : rclone-current-linux-amd64.zip: Failed to copy: failed to prepare upload: operation error S3: CreateBucket, https response error StatusCode: 403, RequestID: , HostID: , api error AccessDenied: Access Denied2024/10/20 16:01:54 ERROR : Attempt 2/3 failed with 1 errors and: failed to prepare upload: operation error S3: CreateBucket, https response error StatusCode: 403, RequestID: , HostID: , api error AccessDenied: Access Denied2024/10/20 16:01:55 ERROR : rclone-current-linux-amd64.zip: Failed to copy: failed to prepare upload: operation error S3: CreateBucket, https response error StatusCode: 403, RequestID: , HostID: , api error AccessDenied: Access Denied2024/10/20 16:01:55 ERROR : Attempt 3/3 failed with 1 errors and: failed to prepare upload: operation error S3: CreateBucket, https response error StatusCode: 403, RequestID: , HostID: , api error AccessDenied: Access Denied2024/10/20 16:01:55 NOTICE: Failed to copy: failed to prepare upload: operation error S3: CreateBucket, https response error StatusCode: 403, RequestID: , HostID: , api error AccessDenied: Access Denied 你可以将 --s3-no-check-bucket 参数添加到命令中，这样就不会检查存储桶是否存在，直接上传文件。 回到 Cloudflare R2 控制台查看存储桶内的文件： 参考资料： 家庭数据中心系列 使用rclone和cloudflare R2打造chevereto的异地容灾图床 折腾图床的经历和最终方案（Cloudflare R2 + Rclone + Picgo）","link":"/2024/10/20/linux_rclone_cloudflare_r2/"},{"title":"在 Linux 下开启 WebDAV 服务使局域网内设备都可以访问挂载后的 S3 存储桶","text":"前言在上一篇文章通过 S3fs 挂载 Cloudflare R2 存储桶到 Linux 服务器本地目录中将存储桶挂载到了本地，在这之后已经可以在本机上进行操作了。但是如果想要在局域网内的其他设备上访问这个挂载后的存储桶，还需要开启 WebDAV 服务。 方案概述 安装 Apache2 并启用 WebDAV 模块 生成 WebDAV 密码认证文件 配置 Apache2 的 WebDAV 服务 加载配置启动 WebDAV 服务 局域网内设备访问 操作步骤一、安装 Apache2 并启用 WebDAV 模块安装 Apache2： 12sudo apt updatesudo apt install apache2 启用 WebDAV 模块： 12sudo a2enmod davsudo a2enmod dav_fs 重启 Apache2 服务： 1sudo systemctl restart apache2 二、生成 WebDAV 密码认证文件生成密码认证文件： 1sudo htpasswd -c /etc/apache2/.htpasswd username -c 参数表示创建一个新的密码认证文件，username 是你要设置的用户名，执行命令后会提示输入密码。 如果不是第一次创建密码认证文件，不要使用 -c 参数，否则会覆盖原有的密码认证文件。 三、配置 Apache2 的 WebDAV 服务我这里需要挂载的本地目录是 /mnt/cloudflare-r2，URL 后面的路径则是 /webdav。在 /etc/apache2/sites-available 目录下新建一个配置文件： 1sudo vim /etc/apache2/sites-available/webdav.conf 新增以下配置： 123456789101112131415161718192021222324Listen 5005&lt;VirtualHost *:5005&gt; ServerAdmin webmaster@localhost DocumentRoot /var/www/html ErrorLog ${APACHE_LOG_DIR}/error.log CustomLog ${APACHE_LOG_DIR}/access.log combined DavLockDB /var/www/DavLock &lt;Directory /mnt/cloudflare-r2&gt; Options Indexes MultiViews AllowOverride None Order allow,deny allow from all &lt;/Directory&gt; Alias /webdav /mnt/cloudflare-r2 &lt;Location /webdav&gt; DAV On AuthType Basic AuthName &quot;Restricted Content&quot; AuthUserFile /etc/apache2/.htpasswd Require valid-user &lt;/Location&gt;&lt;/VirtualHost&gt; 关于配置的说明： Listen 5005：开启对 5005 端口的监听。 &lt;VirtualHost *:5005&gt;：监听的端口。 ServerAdmin webmaster@localhost：管理员邮箱地址。 DocumentRoot /var/www/html：文档根目录。 ErrorLog ${APACHE_LOG_DIR}/error.log：错误日志文件位置。 CustomLog ${APACHE_LOG_DIR}/access.log combined：访问日志文件位置和格式。 DavLockDB /var/www/DavLock：WebDAV 的锁定数据库文件位置。 &lt;Directory /mnt/cloudflare-r2&gt;：配置 /mnt/cloudflare-r2 目录的访问权限。 Options Indexes MultiViews：开启目录列表和多视图。 AllowOverride None：禁止使用 .htaccess 文件覆盖配置。 Order allow,deny：允许访问。 allow from all：允许所有人访问。 Alias /webdav /mnt/cloudflare-r2：创建别名 /webdav，指向 /mnt/cloudflare-r2 目录。 &lt;Location /webdav&gt;：配置 /webdav 路径的访问权限。 DAV On：启用 WebDAV 功能。 AuthType Basic：启用基本身份验证。 AuthName &quot;Restricted Content&quot;：认证提示信息。 AuthUserFile /etc/apache2/.htpasswd：用户名和密码文件。 Require valid-user：要求用户验证后才能访问。 之后保存配置文件并退出编辑器。 四、加载配置启动 WebDAV 服务启用配置文件： 12sudo a2ensite webdav.confsudo systemctl reload apache2 重启 Apache2 服务： 1sudo systemctl restart apache2 如果有防火墙和安全组的话，记得开放 5005 端口，然后就能访问 WebDAV 服务了，访问 http://IP:5005/webdav： 如果出现以下错误： 123ForbiddenYou don't have permission to access this resource.Apache/2.4.58 (Ubuntu) Server at xxx.xxx.xxx.xxx Port 5005 可能是两种情况：1️⃣ 你没有对根目录 /mnt/cloudflare-r2 的访问权限；2️⃣ 挂载目录的权限不正确。验证 1️⃣ 你可以通过加上指定文件名的方式访问，例如 http://ip:5005/webdav/test.txt，如果这种情况下可以访问的话，大概率是你的配置文件写错了，请参照我上面的配置进行检查（AI 可能会帮你瞎补全）。而验证 2️⃣ 的话，可以通过修改挂载目录的权限来解决。那么就需要确认下挂载的 S3 存储桶的权限是否正确： 1234# 查看挂载目录的权限ls -l /mnt/cloudflare-r2# 修改挂载目录的权限sudo chown www-data:www-data /mnt/cloudflare-r2 没问题的话将 Apache2 服务设置为开机自启： 1sudo systemctl enable apache2 五、局域网内设备访问我这里拿 MacOS 的访达举例，打开 Finder，然后按 Command + K，输入 http://IP:5005/webdav 进行连接：之后输入用户名和密码，就可以访问到挂载的存储桶了： 虽然有点慢，但是文件的拖拽上传也正常： 结束。 参考资料： Linux Ubuntu 手动搭建webDav Ubuntu Apache 搭建WebDav网盘","link":"/2024/10/20/linux_run_webdav_server/"},{"title":"通过 S3fs 挂载 Cloudflare R2 存储桶到 Linux 服务器本地目录","text":"前言部分存储桶的数据需要在本地进行操作，但是又不想直接下载到本地，这时候可以通过 s3fs 挂载到本地目录，实现本地操作云端数据的目的。 S3fs 是基于 FUSE 的文件系统，允许 Linux 和 MacOS 挂载 S3 的存储桶在本地文件系统，S3fs 能够保持对象原来的格式。 方案概述 安装 S3fs 获取 Cloudflare R2 存储桶的 Access Key 和 Secret Key 挂载 Cloudflare R2 存储桶到本地目录 设置开机自动挂载 操作步骤一、安装 S3fs 官方仓库：https://github.com/s3fs-fuse/s3fs-fuse Ubuntu 下可以直接通过 apt 安装： 12sudo apt updatesudo apt install s3fs fuse 查看版本： 1s3fs --version 二、获取 Cloudflare R2 存储桶的 Access Key 和 Secret Key参考我的另一篇文章：二、获取-Cloudflare-R2-存储桶的-Access-Key-和-Secret-Key 三、挂载 Cloudflare R2 存储桶到本地目录1、创建认证用的密码文件这里需要用到存储桶的 Access Key 和 Secret Key，将其写入到 ~/.passwd-s3fs 文件中： 12echo ACCESS_KEY_ID:SECRET_ACCESS_KEY &gt; ~/.passwd-s3fschmod 600 ~/.passwd-s3fs 2、挂载存储桶123456789# 创建本地目录mkdir /mnt/cloudflare-r2# 挂载s3fs your_bucket_name \\ /mnt/cloudflare-r2 \\ -o passwd_file=~/.passwd-s3fs \\ # 使用 Cloudflare R2 的 Endpoint -o url=https://xxxxxxxxxxxxxxxxxxxxxx.r2.cloudflarestorage.com \\ -o use_path_request_style 之后进入 /mnt/cloudflare-r2 目录，即可看到存储桶的文件： 12cd /mnt/cloudflare-r2ls 创建一个新文件，然后查看 Cloudflare R2 存储桶内是否有该文件： 1echo &quot;Hello, Cloudflare R2&quot; &gt; test.txt 四、设置开机自动挂载编辑 /etc/fstab 文件，添加一行： 1sudo vi /etc/fstab 在文件末尾添加一行，格式如下： 1s3fs#your_bucket_name /mnt/cloudflare-r2 fuse _netdev,allow_other,passwd_file=/root/.passwd-s3fs,url=https://xxxxxxxxxxxxxxxxxxxxxx.r2.cloudflarestorage.com,use_path_request_style 0 0 注意这个 # 号是必须的，不加会报错。 保存退出之后测试是否能够自动挂载： 12systemctl daemon-reload sudo mount -a 没有问题的话，重启服务器，查看是否自动挂载： 1reboot 再次创建文件验证重启后的挂载正常： 12cd /mnt/cloudflare-r2echo &quot;Hello, Cloudflare R2 after reboot&quot; &gt; test2.txt 结束。 参考资料： 挂载 S3 到 Mac 和 Windows 上作为本地目录使用 服务器开机自动挂载S3储存","link":"/2024/10/20/linux_s3fs_cloudflare_r2_disk/"},{"title":"Linux 下将 WebDAV 挂载为本地目录","text":"前言本地绿联的 NAS 重装了下，准备给媒体服务器做存储用，因此需要开启 WebDAV 服务并挂载到 Linux 服务器上。 方案概述 绿联 NAS 开启 WebDAV 服务 Linux 服务器挂载 WebDAV 为本地目录 Linux 服务器上设置开机自动挂载 重启系统验证挂载是否成功 操作步骤一、绿联 NAS 开启 WebDAV 服务在网络服务处开启： 二、Linux 服务器挂载 WebDAV 为本地目录安装 davfs2： 1sudo apt install davfs2 然后创建下要挂载的目录： 1mkdir -vp /mnt/webdav/green_dh2100_4t 挂载： 1sudo mount -t davfs http://192.168.1.1:5081/dav/rabbir/ /mnt/webdav/green_dh2100_4t 之后输入用户名和密码即可，进入挂载目录查看： 1ls /mnt/webdav/green_dh2100_4t 挂载成功： 三、Linux 服务器上设置开机自动挂载1、编辑 davfs2 配置文件文件在 /etc/davfs2/davfs2.conf： 1vi /etc/davfs2/davfs2.conf 取消 use_lock 的注释，并将其值改为 0： 1234# 可选# dav_group usersuse_locks 0 2、保存 WebDAV 认证信息在 /etc/davfs2/secrets 文件中新增认证信息： 1vi /etc/davfs2/secrets 在末尾添加： 1http://192.168.1.1:5081/dav/rabbir/ admin 123456 3、修改 fstab 文件1vi /etc/fstab 在末尾添加： 1http://192.168.1.1:5081/dav/rabbir/ /mnt/webdav/green_dh2100_4t davfs rw,user,_netdev 0 0 _netdev：确保在网络可用时才挂载，因为 WebDAV 是基于网络的文件系统。 rw：读写权限。 user：允许普通用户挂载。 四、重启系统验证挂载是否成功1reboot 重启完成后查看挂载情况： 12cd /mnt/webdav/green_dh2100_4tls -l 挂载成功： 如果之后碰到其他用户操作该目录时出现 Permission denied 等权限问题时，可以通过 chown 命令修改目录的所有者和所属组。 1chown -R 777 /mnt/webdav/green_dh2100_4t 参考资料： Linux将WebDAV为本地磁盘 Linux通过davfs2挂载WebDav网盘","link":"/2024/10/01/linux_webdav/"},{"title":"解决 Markdown 加粗符号 (**) 在其他符号后无法生效的问题","text":"Markdown 格式的博客文章里，经常出现 ** 加粗符号在其他符号后无法生效的问题，看看如何用相对优雅的方式解决这个问题。 问题描述 第一个主要组件是其核心库 (Core)​：它负责接收并处理输入源，以执行相应的操作。 这些输入源主要是用户编写的 Terraform 配置文件，其中定义了需要创建配置或管理的资源。 类似上图中的问题，）​** 并未被加粗。 解决方法在符号和 ** 之间加上空格或是 ZWSP（零宽空格）都可以解决这个问题。 而我倾向于后者，它不会破坏原有的排版，也不会影响阅读体验，只是在编写博文的时候会有一点点难受。 原本写法： 1）​** 添加 ZWSP 后的写法： 在 ） 和 ** 之间添加 ZWSP 字符。 1）​** 你可能会好奇，为什么看上去是一样的？这也是为什么它被叫做零宽空格的原因。我们来看下 ZWSP 字符： 1​ 你无法看到也无法选中它，那你该如何添加呢？两种方法：第一种是前往 Zero Width Space 网站复制；第二种则是点击这个按钮：复制 ZWSP 字符 关于 ZWSP 的更多介绍：一般情况下，ZWSP 被用来指定长文字的换行位置，当屏幕宽度不足以单行显示时 ZWSP 就会起作用了。 没有使用时： 1LongLongLongLongLongLongLongLongBreakBeforeHereLongLongLongLongLongLongLongLongLongLongLongLongLongLongText 使用 ZWSP 后： 12LongLongLongLongLongLongLongLongBreakBeforeHereLongLongLongLongLongLongLongLongLongLongLongLongLongLongText 参考资料： 为什么掘金的 Markdown 加粗语法（……）有时候不生效","link":"/2024/10/06/markdown_cant_blod/"},{"title":"解决 MySQL 数据库数据出现乱码的问题","text":"针对 MySQL 检索出现类似 {'name': 'æµ‹è¯•åˆ†ç±»', 'description': 'æµ‹è¯•åˆ†ç±»çš„æ\\x8f\\x8fè¿°', 'order': '99', 'seo_title': 'SEO æ\\xa0‡é¢˜', 'seo_metakey': 'SEO å…³é”®è¯\\x8dä¸€ã€\\x81å…³é”®è¯\\x8d2', 'seo_desc': 'SEO æ\\x8f\\x8fè¿°'} 的乱码进行修复。 1、错误现象在 GitHub Action 的环境中启动了 MySQL 容器，插入了数据： 1234INSERT INTO `wp_terms` (`term_id`, `name`, `slug`, `term_group`) VALUES ('2', '测试分类', 'test_favorite', '0');INSERT INTO `wp_termmeta` (`meta_id`, `term_id`, `meta_key`, `meta_value`) VALUES ('2', '2', 'seo_title', 'SEO 标题');INSERT INTO `wp_termmeta` (`meta_id`, `term_id`, `meta_key`, `meta_value`) VALUES ('3', '2', 'seo_metakey', 'SEO 关键词一、关键词2');INSERT INTO `wp_termmeta` (`meta_id`, `term_id`, `meta_key`, `meta_value`) VALUES ('4', '2', 'seo_desc', 'SEO 描述'); 之后通过 Python 检索的时候，就成了： 1{'name': 'æµ‹è¯•åˆ†ç±»', 'slug': 'test_favorite', 'parent': 0, 'description': 'æµ‹è¯•åˆ†ç±»çš„æ\\x8f\\x8fè¿°', 'order': '99', 'seo_title': 'SEO æ\\xa0‡é¢˜', 'seo_metakey': 'SEO å…³é”®è¯\\x8dä¸€ã€\\x81å…³é”®è¯\\x8d2', 'seo_desc': 'SEO æ\\x8f\\x8fè¿°', 'card_mode': 'null', 'columns_type': 'global', 'columns': 'a:5:{s:2:&quot;sm&quot;;s:1:&quot;2&quot;;s:2:&quot;md&quot;;s:1:&quot;2&quot;;s:2:&quot;lg&quot;;s:1:&quot;3&quot;;s:2:&quot;xl&quot;;s:1:&quot;5&quot;;s:3:&quot;xxl&quot;;s:1:&quot;6&quot;;}', '_term_id': 2, '_term_taxonomy_id': 2} 这在本地并未发生过，因此猜测是数据库默认编码不支持中文导致的。 2、解决办法先确认下是否是由数据库编码引起的，进入数据库： 12docker exec -it mysql /bin/bashmysql -u root -p 检索下编码相关的变量 character%： 1show variables like 'character%'; 12345678910111213+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | latin1 || character_set_connection | latin1 || character_set_database | latin1 || character_set_filesystem | binary || character_set_results | latin1 || character_set_server | latin1 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+8 rows in set (0.00 sec) 果然都是不支持中文 latin1 编码格式，退出 MySQL 命令行接着去修改下配置文件： 12# 退出 MySQL 命令行quit 在 /etc/my.cnf 文件下面加上两行： 12echo &quot;[mysql]&quot; &gt;&gt; /etc/my.cnfecho &quot;default-character-set=utf8mb4&quot; &gt;&gt; /etc/my.cnf 之后退出并重启容器即可。重新插入数据，再检索就正常了： 1{'name': '测试分类', 'slug': 'test_favorite', 'parent': 0, 'description': '测试分类的描述', 'order': '99', 'seo_title': 'SEO 标题', 'seo_metakey': 'SEO 关键词一、关键词2', 'seo_desc': 'SEO 描述', 'card_mode': 'null', 'columns_type': 'global', 'columns': 'a:5:{s:2:&quot;sm&quot;;s:1:&quot;2&quot;;s:2:&quot;md&quot;;s:1:&quot;2&quot;;s:2:&quot;lg&quot;;s:1:&quot;3&quot;;s:2:&quot;xl&quot;;s:1:&quot;5&quot;;s:3:&quot;xxl&quot;;s:1:&quot;6&quot;;}', '_term_id': 2, '_term_taxonomy_id': 2} 参考资料： Docker中Mysql容器的中文乱码问题","link":"/2024/10/16/mysql_chinese_mojibake/"},{"title":"n8n AI 工作流（一）使用 Docker Compose 部署和测试","text":"前言Steam.Cash 导航站将使用 n8n 配置信息收集工作流。 n8n 是一个图形化的低代码自动化流程平台，在 AI 出现之前它最初的用途是自动化你的一些日常工作流。 方案概述 安装 Docker 环境 从官方仓库获取 docker-compose.yaml 文件 配置环境变量 启动容器并配置认证信息 测试工作流运行正常 操作步骤一、安装 Docker 环境参考：Ubuntu 20.04 从官方源安装最新的 Docker 二、从官方仓库获取 docker-compose.yaml 文件 官方仓库：n8n-io/n8n-hosting 在服务器上下载： 1git clone https://github.com/n8n-io/n8n-hosting.git 我这里选择了 withPostgres 模式进行安装： 12# 拷贝到当前的 n8n 目录中cp ./n8n-hosting/docker-compose/withPostgres/* ./n8n/ 三、编辑环境变量12cd n8nvi .env 只要编辑数据库连接信息即可： 123456POSTGRES_USER=postgresPOSTGRES_PASSWORD=changeYourPasswordPOSTGRES_DB=n8nPOSTGRES_NON_ROOT_USER=n8nPOSTGRES_NON_ROOT_PASSWORD=changeYourPassword 四、启动容器并配置认证信息在 n8n/ 目录中执行： 1docker-compose up -d 端口是 5678，不过访问页面 http://IP:5678 的话会报错，因为还没有启用 SSL： 错误信息： Your n8n server is configured to use a secure cookie,however you are either visiting this via an insecure URL, or using Safari. To fix this, please consider the following options:Setup TLS/HTTPS (recommended), orIf you are running this locally, and not using Safari, try using localhost insteadIf you prefer to disable this security feature (not recommended), set the environment variable N8N_SECURE_COOKIE to false 我这里简单用 Cloudflare 做下反代来开启 SSL：选择 更改端口：将（指向服务器的）目标端口改为 5678： 注意此时 SSL/TLS 模式需要为灵活： 保存后稍等片刻再访问 https://your.domain.com 即可：填写完成后即可进入控制面板： 如果你使用了 Nginx 配置 SSL 证书，请注意需要添加这两项： 12proxy_set_header Upgrade $http_upgrade;proxy_set_header Connection 'Upgrade'; 否则在运行流程的时候会出现下面的错误： ❌ Problem running workflowLost connection to the server 五、测试工作流运行正常选择首页的 Test a simple AI Agent example：按照提示输入 hi 之后报错了： 错误信息： Error in sub-node ‘OpenAI Model’ 错误日志： NodeOperationError: Error in sub-node OpenAI Model at ExecuteContext.getInputConnectionData (/usr/local/lib/node_modules/n8n/node_modules/.pnpm/n8n-core@file+packages+core_@opentelemetry+api@1.9.0_@opentelemetry+sdk-trace-base@1.30_0c275070fd0434c00ffd62213b2bcae4/node_modules/n8n-core/src/execution-engine/node-execution-context/utils/get-input-connection-data.ts:302:11) at processTicksAndRejections (node:internal/process/task_queues:105:5) at ExecuteContext.getInputConnectionData (/usr/local/lib/node_modules/n8n/node_modules/.pnpm/n8n-core@file+packages+core_@opentelemetry+api@1.9.0_@opentelemetry+sdk-trace-base@1.30_0c275070fd0434c00ffd62213b2bcae4/node_modules/n8n-core/src/execution-engine/node-execution-context/execute-context.ts:203:10) at getChatModel (/usr/local/lib/node_modules/n8n/node_modules/.pnpm/@n8n+n8n-nodes-langchain@file+packages+@n8n+nodes-langchain_944c224e2f203516e58b6afc03783333/node_modules/@n8n/n8n-nodes-langchain/nodes/agents/Agent/agents/ToolsAgent/common.ts:269:26) at ExecuteContext.toolsAgentExecute (/usr/local/lib/node_modules/n8n/node_modules/.pnpm/@n8n+n8n-nodes-langchain@file+packages+@n8n+nodes-langchain_944c224e2f203516e58b6afc03783333/node_modules/@n8n/n8n-nodes-langchain/nodes/agents/Agent/agents/ToolsAgent/V1/execute.ts:44:19) at ExecuteContext.execute (/usr/local/lib/node_modules/n8n/node_modules/.pnpm/@n8n+n8n-nodes-langchain@file+packages+@n8n+nodes-langchain_944c224e2f203516e58b6afc03783333/node_modules/@n8n/n8n-nodes-langchain/nodes/agents/Agent/V1/AgentV1.node.ts:461:11) at WorkflowExecute.runNode (/usr/local/lib/node_modules/n8n/node_modules/.pnpm/n8n-core@file+packages+core_@opentelemetry+api@1.9.0_@opentelemetry+sdk-trace-base@1.30_0c275070fd0434c00ffd62213b2bcae4/node_modules/n8n-core/src/execution-engine/workflow-execute.ts:1212:9) at /usr/local/lib/node_modules/n8n/node_modules/.pnpm/n8n-core@file+packages+core_@opentelemetry+api@1.9.0_@opentelemetry+sdk-trace-base@1.30_0c275070fd0434c00ffd62213b2bcae4/node_modules/n8n-core/src/execution-engine/workflow-execute.ts:1582:27 at /usr/local/lib/node_modules/n8n/node_modules/.pnpm/n8n-core@file+packages+core_@opentelemetry+api@1.9.0_@opentelemetry+sdk-trace-base@1.30_0c275070fd0434c00ffd62213b2bcae4/node_modules/n8n-core/src/execution-engine/workflow-execute.ts:2158:11 这里其实是由于认证没过，需要新增认证信息，双击出错的 OpenAI Model 节点，然后点击 Create new credential：由于 DeepSeek 兼容 OpenAI，因此这里新增使用 DeepSeek API 的认证信息即可： DeepSeek 的 API 可以去官网申请，起充为 10 元，还是很便宜的：deepseek 开放平台 之后选择 deepseek-chat 模型后保存： 再次测试输入 hi：获得输出： 1Welcome to n8n. Let's start with the first step to give me memory: &quot;Click the + button on the agent that says 'memory' and choose 'Simple memory.' Just tell me once you've done that.&quot; 运行成功，至此 n8n 的部署和测试完成。","link":"/2025/08/25/n8n_01/"},{"title":"Hexo 下将旧博客的 URL 重定向到新博客","text":"前言旧博客博文链接中的日期路径为 /yyyy/MM/，而新博客则为 /yyyy/MM/dd/，这导致了大量的 404 错误，严重影响 Goolge 搜索引擎的排名和用户的实际访问体验。因此，配置旧博文 URL 重定向到新博文 URL 的任务迫在眉睫。 方案概述由于新的博客系统为 Hexo，因此可以通过 Hexo 的插件 hexo-generator-alias 来实现旧博文 URL 重定向到新博文 URL 的功能。官方仓库：hexojs/hexo-generator-alias 安装 hexo-generator-alias 插件 在新的文章中配置 alias 别名字段指向旧博文的 URL 重新生成博客静态文件并部署 验证重定向是否生效 操作步骤一、安装 hexo-generator-alias 插件1npm install hexo-generator-alias --save 二、在新的文章中配置 alias 别名字段指向旧博文的 URL我以失效的 https://senjianlu.com/2021/09/k3s-note-02-02/ 为例，当然它已经 404 了： 在迁移后的博文的 Front-matter 中添加 alias 字段，指向旧博文的 URL： 123alias:- 2021/09/k3s-note-02-02/--- 三、重新生成博客静态文件并部署重新生成博客静态文件： 1hexo generate 部署博客： 1hexo deploy 四、验证重定向是否生效再次访问旧博文的 URL：https://senjianlu.com/2021/09/k3s-note-02-02/，可以看到已经重定向到了新的博文链接： 结束。","link":"/2024/10/07/old_blog_url_redirect/"},{"title":"OneNav 一为导航通过 Python3 脚本实现网址的增删改查","text":"前言通过伪代码的方式记录思路和实现流程。请总以仓库最新代码为准：senjianlu/sync-onenav-from-excelOneNav 一为导航主题版本为 V4.1810。 方案概述 仓库地址：senjianlu/sync-onenav-from-excel网址的增删改查对应的实现：app/models/OneNavSite.py 注意点 Excel 表中的 网址自定义 ID 是 网址 的主键，它在代码中一般是 site_id 和 sync_site_id；而 WordPress 的数据结构中，以 wp_posts 表的 ID 作为 网址 的主键，它在代码中一般是 post_id。 通过在 wp_postmeta 表中新增一条 meta_key 为 _sync_site_id 的数据，来标识哪些是由 Excel 同步来的数据。 Python3 脚本中将以 site 表示 OneNav 中的 网址 这一概念。 models/OneNavSite.py 将作为 网址 的对象存在，其拥有 增、删、改 和 查 方法。 但是非 models 内部的模块，尽量不要直接调用对象的方法。 对 网址 进行增删改查操作前，需要视情况做事前判断，例如：是否存在指定的 网址分类 或 网址标签。 onenav/site.py 中包含了增删改查前中后的所有操作，它作为 OneNavSite 对象的接口存在，任何对 OneNavSite 的操作请走 site.py。 唯一区分 网址分类 的 favorite_id 可以与 WordPress 中的 term_id 划等号。 要查询 wp_term_relationships 表中的关系时，使用的是 term_taxonomy_id，因此需要先通过 term_id 在 wp_term_taxonomy 中找到对应的 term_taxonomy_id。 涉及的表 wp_posts：保存 网址 的基础数据。 wp_postmeta：保存 网址 的其他数据，例如查看数等。 wp_term_relationships：保存 网址 和 网址分类 的所属关系。 wp_term_taxonomy：保存 网址分类 下 网址 的总数。 新增和删除的时候需要修改该表数据。 伪代码编写OneNavSite 类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class OneNavSite(): &quot;&quot;&quot; 类说明: OneNav 网址类 &quot;&quot;&quot; def __init__(self, favorite_ids: list, tag_ids: list, title: str, content: str, link: str, spare_links: list, sescribe: str, language: str, country: str, order: int, thumbnail_pic_url: str, preview_pic_url: str, wechat_qr_pic_url: str, _sync_site_id: str, _post_id: int = None): &quot;&quot;&quot; 函数说明: 初始化 :param favorite_ids: 网址分类 ID 列表 :param tag_ids: 网址标签 ID 列表 :param title: 标题 :param content: 内容 :param link: 链接 :param spare_links: 备用链接地址（其他站点） :param sescribe: 一句话描述（简介） :param language: 站点语言 :param country: 站点所在国家或地区 :param order: 排序 :param thumbnail_pic_url: LOGO，标志的图片链接 :param preview_pic_url: 网站预览截图的图片链接 :param wechat_qr_pic_url: 公众号二维码的图片链接 :param _sync_site_id: 用来将 Excel 中属于与表中数据建立关系的字段 &quot;&quot;&quot; self.favorite_ids = favorite_ids self.tag_ids = tag_ids self.title = title self.content = content self.link = link self.spare_links = spare_links self.sescribe = sescribe self.language = language self.country = country self.order = order self.thumbnail_pic_url = thumbnail_pic_url self.preview_pic_url = preview_pic_url self.wechat_qr_pic_url = wechat_qr_pic_url # 用来将 Excel 中属于与表中数据建立关系的字段 self._sync_site_id = _sync_site_id # 插入表后的 post_id self._post_id = _post_id 备用链接地址（其他站点）类 1234567891011121314151617class OneNavSpareSite(): &quot;&quot;&quot; 类说明: OneNav 备用网址类 &quot;&quot;&quot; def __init__(self, name: str, url: str, note: str): &quot;&quot;&quot; 函数说明: 初始化 :param name: 站点名称 :param url: 站点链接 :param note: 备注 &quot;&quot;&quot; self.name = name self.url = url self.note = note 查 (select) 通过 Excel 表中的 _sync_site_id 查询 wp_postmeta 表，获取 post_id 通过 post_id 查询 wp_posts 表中的数据 通过 post_id 查询 wp_postmeta 表中的数据 通过 post_id 查询 wp_term_relationships 表中的网址数据 通过 wp_term_relationships 表中的 term_taxonomy_id 查询 wp_term_taxonomy 表中的数据 123456789101112131415161718192021222324252627282930313233343536373839404142@staticmethoddef select(sync_site_id: str, session): &quot;&quot;&quot; 函数说明: 查询网址 :param sync_site_id: 用来将 Excel 中属于与表中数据建立关系的字段 :param session: 数据库会话 &quot;&quot;&quot; # 1. 通过 _sync_site_id 查询网址在 wp_postmeta 表中对应的 post_id wp_postmeta_row = session.query(WpPostmeta).filter( WpPostmeta.meta_key == &quot;_sync_site_id&quot;, WpPostmeta.meta_value == sync_site_id ).first() if not wp_postmeta_row: return None post_id = wp_postmeta_row.post_id # 2. 通过 post_id 查询 wp_posts 表中的网址数据 wp_post_row = session.query(WpPosts).filter( WpPosts.ID == post_id ).first() if not wp_post_row: return None # 3. 通过 post_id 查询 wp_postmeta 表中的网址数据 wp_postmeta_rows = session.query(WpPostmeta).filter( WpPostmeta.post_id == post_id ).all() # 4. 通过 post_id 查询 wp_term_relationships 表中的网址数据 wp_term_relationships_rows = session.query(WpTermRelationships).filter( WpTermRelationships.object_id == post_id ).all() # 5. 通过 wp_term_relationships_rows 的 term_taxonomy_id 查询网址分类 wp_term_taxonomy_rows = session.query(WpTermTaxonomy).filter( WpTermTaxonomy.term_taxonomy_id.in_([wp_term_relationships_row.term_taxonomy_id for wp_term_relationships_row in wp_term_relationships_rows]) ).all() # 6. 生成网址对象 site = _generate_class_from_rows( sync_site_id=sync_site_id, wp_post_row=wp_post_row, wp_postmeta_rows=wp_postmeta_rows, wp_term_taxonomy_rows=wp_term_taxonomy_rows ) # 7. 返回 return site 增 (insert) 新增 wp_posts 的数据 新增 wp_postmeta 的数据 通过 favorite_ids 和 tag_ids 获取 wp_term_taxonomy 中 term_id 符合的数据，获取 term_taxonomy_id 新增 wp_term_relationships 的数据 更新 wp_term_taxonomy 中对应行的 count + 1 12345678910111213141516171819202122232425262728293031323334353637383940414243def insert(self, domain, session): &quot;&quot;&quot; 函数说明: 添加网址 :param domain: 导航站点域名 :param session: 数据库会话 &quot;&quot;&quot; # 1. 生成 wp_posts 表数据 new_wp_posts_row = _generate_new_wp_posts_row(self) # 2. 提交 wp_posts 表数据并获取 post_id session.add(new_wp_posts_row) session.commit() post_id = new_wp_posts_row.ID # print(&quot;post_id: &quot;, post_id) # 3. 更新 wp_posts 表数据中的 guid new_wp_posts_row.guid = &quot;{}/sites/{}.html&quot;.format(domain, post_id) session.commit() # 4. 生成 wp_postmeta 表数据 new_wp_postmeta_rows = _generate_new_wp_postmeta_rows(post_id, self) # 5. 获取 wp_term_taxonomy 表数据 wp_term_taxonomy_rows = session.query(WpTermTaxonomy).filter( or_( WpTermTaxonomy.term_id.in_(self.favorite_ids), WpTermTaxonomy.term_id.in_(self.tag_ids) ) ).all() # 6. 生成 wp_term_relationships 表数据 new_wp_term_relationships_rows = _generate_new_wp_term_relationships_rows(post_id, wp_term_taxonomy_rows) # 7. 添加数据 for new_wp_postmeta_row in new_wp_postmeta_rows: session.add(new_wp_postmeta_row) for new_wp_term_relationships_row in new_wp_term_relationships_rows: session.add(new_wp_term_relationships_row) # 8. 提交 session.commit() # 9. 更新 wp_term_taxonomy 表数据 for new_wp_term_relationships_row in new_wp_term_relationships_rows: session.query(WpTermTaxonomy).filter( WpTermTaxonomy.term_taxonomy_id == new_wp_term_relationships_row.term_taxonomy_id ).update({ &quot;count&quot;: WpTermTaxonomy.count + 1 }) # 10. 提交 session.commit() 改 (update) 更新 wp_posts 中的数据 更新 wp_postmeta 中的数据 判断网址分类和网址标签是否发生了变更 没有变更的话，接下来不做任何事 发生了变更的话 筛选出新增或删除的 term_id 通过 term_id 获取 wp_term_taxonomy 中 term_id 符合的数据，获取 term_taxonomy_id 新增或删除 wp_term_relationships 表中的网址数据 更新 wp_term_taxonomy 中对应行的 count + 1 或 count - 1 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970def update(self, session): &quot;&quot;&quot; 函数说明: 更新网址 :param session: 数据库会话 &quot;&quot;&quot; post_id = self._post_id # 1. 生成 wp_posts 表数据 new_wp_posts_row = _generate_new_wp_posts_row(self) # 2. 生成 wp_postmeta 表数据 new_wp_postmeta_rows = _generate_new_wp_postmeta_rows(post_id, self) # 3. 获取 wp_term_taxonomy 表数据 wp_term_taxonomy_rows = session.query(WpTermTaxonomy).filter( or_( WpTermTaxonomy.term_id.in_(self.favorite_ids), WpTermTaxonomy.term_id.in_(self.tag_ids) ) ).all() # 4. 生成 wp_term_relationships 表数据 new_wp_term_relationships_rows = _generate_new_wp_term_relationships_rows(post_id, wp_term_taxonomy_rows) # 5. 更新数据 # 5.1 更新 wp_posts 表数据 session.query(WpPosts).filter(WpPosts.ID == post_id).update({ &quot;post_title&quot;: new_wp_posts_row.post_title, &quot;post_content&quot;: new_wp_posts_row.post_content, &quot;post_name&quot;: new_wp_posts_row.post_name, &quot;post_modified&quot;: new_wp_posts_row.post_modified, &quot;post_modified_gmt&quot;: new_wp_posts_row.post_modified_gmt }) # 5.2 更新 wp_postmeta 表数据 for new_wp_postmeta_row in new_wp_postmeta_rows: session.query(WpPostmeta).filter( WpPostmeta.post_id == post_id, WpPostmeta.meta_key == new_wp_postmeta_row.meta_key ).update({ &quot;meta_value&quot;: new_wp_postmeta_row.meta_value }) # 5.3 判断需要新增或删除的网址分类 wp_term_relationships_rows = session.query(WpTermRelationships).filter( WpTermRelationships.object_id == post_id ).all() old_term_taxonomy_ids = [wp_term_relationships_row.term_taxonomy_id for wp_term_relationships_row in wp_term_relationships_rows] new_term_taxonomy_ids = [wp_term_taxonomy_row.term_taxonomy_id for wp_term_taxonomy_row in wp_term_taxonomy_rows] term_taxonomy_ids_2_add = list(set(new_term_taxonomy_ids) - set(old_term_taxonomy_ids)) term_taxonomy_ids_2_delete = list(set(old_term_taxonomy_ids) - set(new_term_taxonomy_ids)) # 5.4 添加新的网址分类 for add_term_taxonomy_id in term_taxonomy_ids_2_add: new_wp_term_relationships_row = WpTermRelationships( object_id=post_id, term_taxonomy_id=add_term_taxonomy_id, term_order=0 ) session.add(new_wp_term_relationships_row) session.query(WpTermTaxonomy).filter( WpTermTaxonomy.term_taxonomy_id == add_term_taxonomy_id ).update({ &quot;count&quot;: WpTermTaxonomy.count + 1 }) # 5.5 删除不需要的网址分类 for delete_term_taxonomy_id in term_taxonomy_ids_2_delete: session.query(WpTermRelationships).filter( WpTermRelationships.object_id == post_id, WpTermRelationships.term_taxonomy_id == delete_term_taxonomy_id ).delete() session.query(WpTermTaxonomy).filter( WpTermTaxonomy.term_taxonomy_id == delete_term_taxonomy_id ).update({ &quot;count&quot;: WpTermTaxonomy.count - 1 }) # 6. 提交 session.commit() 删 (delete) 删除 wp_posts 中的数据 删除 wp_postmeat 中的数据 删除 wp_term_relationships 中的数据 通过 wp_term_relationships 中关联的 term_taxonomy_id，将 wp_term_taxonomy 中对应行的 count - 1 12345678910111213141516171819202122232425def delete(self, session): &quot;&quot;&quot; 函数说明: 删除网址 :param session: 数据库会话 &quot;&quot;&quot; post_id = self._post_id # 1. 删除 wp_posts 表数据 session.query(WpPosts).filter(WpPosts.ID == post_id).delete() # 2. 删除 wp_postmeta 表数据 session.query(WpPostmeta).filter(WpPostmeta.post_id == post_id).delete() # 3. 删除和更新网址分类的关联数据 wp_term_relationships_rows = session.query(WpTermRelationships).filter( WpTermRelationships.object_id == post_id ).all() for wp_term_relationships_row in wp_term_relationships_rows: session.query(WpTermTaxonomy).filter( WpTermTaxonomy.term_taxonomy_id == wp_term_relationships_row.term_taxonomy_id ).update({ &quot;count&quot;: WpTermTaxonomy.count - 1 }) session.query(WpTermRelationships).filter( WpTermRelationships.object_id == post_id ).delete() # 4. 提交 session.commit()","link":"/2024/10/12/onenav_python3_site_crud/"},{"title":"Caddy 的优势和 CentOS7 下的部署","text":"前言Caddy 是一款基于 Go 语言编写的强大且可扩展的平台。与 Nginx 相比它的配置更加简单，自动支持 HTTPS 等功能也使它整体更加易用。 Caddy 的优势 全自动支持 HTTP/2 协议，无需任何配置。 无需配置，自动使用 Let’s Encrypt 让站点支持 HTTPS。 对 WebSockets 友好。 可以自动把 Markdown 格式的文件转成 HTML。 基于 Go 编写，安装时只有一个二进制文件，没有多余依赖，简单部署。 基于 Go 编写，发挥多核优势。 基于 Go 编写，跨平台优秀。 Caddy 安装（在 CentOS7 系统）一、安装一键安装： 123yum install -y yum-plugin-copryum copr enable @caddy/caddyyum install -y caddy 二、检查目录找一下： 1whereis caddy 返回： 1# caddy: /usr/bin/caddy /etc/caddy /usr/share/caddy /usr/bin/caddy：为可执行文件 /etc/caddy：为配置文件目录 /usr/share/caddy：为静态文件目录 三、启动顺便设置为开机启动： 12systemctl enable caddysystemctl start caddy 四、配置1、简单的 HTML + JS 网站123456ceshiku.cn:80 { gzip log /var/log/caddy/access.log root /var/www tls /etc/ssl/cert.pem /etc/ssl/key.pem} 2、反向代理1234567http://ceshiku.cn { proxy / 127.0.0.1:8080/ proxy /websocket 127.0.0.1:8080 { websocket }} 3、负载均衡12345http://ceshiku.cn { proxy / 127.0.0.1:8080 127.0.0.1:8090 127.0.0.1:8100 { policy round_robin }} 五、其他常用命令1234567891011caddy startcaddy stopcaddy reloadcaddy restartcaddy status# 编辑配置文件caddy edit# 使 Caddy Web Server 成为一项服务caddy service# 升级 Caddy Web Servercaddy update","link":"/2023/07/01/p_caddy/"},{"title":"PMP 考试 - 考前笔记","text":"基本概念、考试小坑和从未碰到但重要的知识点，考前翻看巩固用。 基本概念 【敏捷、团队基本原则】➡️ 敏捷团队一起定义《团队基本规则》。 【项目管理流程、PMO】➡️ 公司的项目管理流程（其中就有质量流程）、框架正常由 PMO 提供，如果项目经理发现这些流程、框架不符合项目特点、要求，可以要求 PMO 修改、变更。 【绩效、能力、信任】➡️ 团队绩效不好，有可能是能力问题（通过培训改进），也有可能是配合、信任问题（通过团队建设改进）。 【需求功能遗漏、干系人参与】➡️ 关键需求或功能被遗漏，多与未让干系人尽早参与有关，并可以通过让干系人参与项目来解决。而非单纯的沟通问题。 【获得干系人认可、范围管理、干系人参与定义范围】让干系人参与定义范围来获得干系人对项目结果的认可和批准。 【管理团队、资源管理计划】➡️ 管理团队的核心计划是资源管理计划。它也是能提高多元文化团队绩效的计划。 【团队章程】➡️ 团队章程中包括： 团队价值观 沟通指南 决策标准和过程 冲突处理过程 会议指南 团队共识 需要注意的是，不包含项目目标和团队职业与角色定义。 🌟【敏捷、回顾会议、解决障碍/问题】➡️ 敏捷中的回顾会议，可以用来讨论、解决问题、障碍。 【敏捷、团队章程、就绪的定义 (DOR)、完成的定义 (DOD)】➡️ 敏捷团队章程中出了团队共识、价值观和基本规则之外，还应包含就绪的定义 (DOR)​ 和完成的定义 (DOD)​。 【敏捷、就绪的定义 (DOD)】➡️ 可以确保质量、确保达到了商业价值。 【项目目标、与干系人确保目标一致】➡️ 项目目标应包含一系列的成功标准，如时间、成本、范围、质量等，主要干系人和项目经理应就这些问题达成共识并予以记录。 【绩效、KPIs】➡️ 能帮助干系人、高管全面地了解项目执行情况，绩效好坏；KPIs 可以针对项目、组织、团队（成员），不针对可交付成果。 【绩效、绩效管理制度】➡️ 是考核标准，有助于帮助团队提高绩效，项目经理应该向团队成员公开并提供反馈。 【项目经理没有经验】➡️ 先查看组织过程资产，再获取主题专家 (SEMs) 的帮助。 【新人项目经理】➡️ 先查看项目管理计划，再查看绩效信息 (SPI 和 CPI 等)，再找团队成员了解。 如果题干强调“项目具有不稳定性”时，需要检查风险登记册。 【敏捷、看板、在制品 (WIP)】➡️ 维持较小的在制品 (WIP) 限制，有利于团队集中力量办大事，推动进展，加快交付。 【敏捷、累积流量图】➡️ 包含三类：正在开发的工作、已经完成的工作、计划开展的工作。可以用来评估项目状态。 【按需的进度计划及其扩展】➡️ 先执行确定的工作，不确定的工作可以先放在待办项列表中。 旧的按需的进度计划：敏捷下特殊情况可以调整进度（资源不可用时，优先开展资源可用的活动）。例如：① 政府将出台法规影响项目的工作，法规没出台活动没法开展，先做别的。② 开发方法有争议，先做别的。 【风险管理、事业环境因素】➡️ 严重影响项目的内外部事业环境因素：政府新法规、公司新政策、竞争对手新产品、市场或项目商业价值新变化、其他未知 - 未知风险发生等。 应对：① 当成已知 - 未知风险进行识别（记录、更新风险登记册）、或当前未知 - 未知风险发生（更新问题日志），之后（和干系人一起）一起分析影响，制定应对策略。② 重新进行商业论证或成本效益分析，并上报干系人。 避免：事先识别风险，识别事业环境因素、假设条件。 思路：记录 -&gt; 分析 -&gt; 上报 -&gt; 制定或实施措施 -&gt; 提出变更请求。 【工件更新、工件管理】➡️ 定期更新项目计划，确保工件都是最新版本，并且与所有干系人共享。 工件包括项目管理过程、输入、工具、技术、输出、事业环境因素和组织过程资产。 【合规要求】➡️ 将合规要求纳入项目管理计划（质量管理计划）​，或纳入产品待办项，或融入开发工具。 【跟踪验证项目的收益】➡️ 预测方法使用效益管理计划；敏捷方法使用冲刺评审会议（演示证明收益实现）​。 【依赖关系、项目之间】➡️ 参考整体进度计划，或与其他项目经理了解情况，或查看其他项目的项目管理计划。 【依赖关系、活动之间】➡️ 记录在进度计划中，或当成制约因素。 🌟🌟🌟【依赖关系、团队之间】➡️ 预测方式使用 RAM/RACI 和项目状态评审会（项目状态审查会议）​；敏捷方法使用每日站会和 Scrum on Scrum (SOS)。 【项目目标、效益管理计划】➡️ 项目目标是根据效益管理计划制定的。 【敏捷、产品待办列表优先级】➡️ 敏捷项目，三种情况下需要重排产品待办项列表的优先级：预算减少、时间提前和资源减少。因为这三种情况下，能完成的工作范围会减少，因此要重排优先级。 【敏捷、好工具、好技术】➡️ 好方法、好建议或好工具，要积极支持、尝试。 【敏捷、范围】➡️ 敏捷没有范围基准，这与敏捷拥抱变更的概念一致。 考试小坑 压缩项目进度计划 (Crash the project schedule) 等于赶工，即增加资源缩短工期。 冲突解决类培训有助于在管理干系人的期望时，提高项目经理的人际关系能力。 延长进度属于风险的规避策略。 开发原型（原型法）​主要目的是收集需求，而非展示“解决方案的可行性”。 原型法是指在实际制造预期产品之前，先造出该产品的模型，并据此征求对需求的早期反馈。原型法能使相关（干系人）可以体验最终产品的模型（完整的用户体验）​，而不是仅限于讨论抽象的需求描述。 虽然要考虑到干系人情绪，要进行解释、说服工作，但是具体行为任然应该按照规章办事。 例如：服务部门因未能参与供应商评估过程感到沮丧，这时应*进行会面、审核过程，而非直接将他们纳入过程。* 有固定交付时间的项目，更适合使用敏捷方法执行。 配置管理问题包括：术语不一致、使用了错误版本的文件等，就事论事解决即可。 例如：术语不一致就规范术语；使用了错误版本的文件就为所有项目文档保留一个唯一的存储库。 社区反对需要干系人参与；实际对社区造成了污染等影响，需要实际面对。 已知 - 未知风险发生，优先实施应对措施，之后再更新风险登记册。 项目收尾后，运营过程出现问题由运营支持部门解决，项目经理只记录经验教训即可。 收集需求的会议，要尽量和所有干系人一起开（因为需求可能存在冲突）。有人无法参会应向他会前了解需求；与会人员过少考虑重新召开。 采购中的风险管理参考采购管理计划。因为风险管理计划中不涉及采购工作，而采购管理计划中包含了风险管理事项。 获得干系人对项目结果的认可和批准属于范围管理问题。 里程碑信息最早出现在项目章程中。干系人问什么时候可以提供里程碑信息，那么就是在项目启动过程中。 资源冲突导致的进度延迟，应该找资源的职能经理解决。 最差的情况需要将干系人认识为职能经理，总之优先于查看资源管理计划。 工作重叠（工作撞车），是责任分配的问题，预测型项目的责任分配通过 RAM、RACI 来实现，包含在资源管理计划中。 敏捷最后一次迭代有交付物无法按时完成，要么忽略该可交付成果，要么延长迭代时间。无论哪一项，都要征求关键干系人的意见。 工作包确定后，在现实项目中，资源是核心的制约因素，因此大多是先确定可用资源，再根据资源估算成本。 冲刺未达到产品负责人的期望，说明该冲刺的目标有误，应在迭代开始时明确目标。 项目经理对团队的整合重点应在早期形成阶段，而非震荡阶段。 团队文化、风格、规则的形成和建立，越早越能起到事半功倍的作用。 全面考虑干系人的需求是原则问题，比查看组织过程资产优先。 资源没有时间也优先找资源的职能经理谈，而不是之间找资源本人谈。 自组织团队的能力问题也属于仆人式领导需要参与解决的障碍。 数量级（估算）​等于类比估算，适用于之前有成功交付项目、且本次预算需要紧急提交的情况。 产品规格可以引申为质量要求。 干系人（相关方）对最终产品提出了担忧可以引申为可交付成果有问题，即验收问题。 需求跟踪矩阵提供了一个全面的需求清单，并为每个需求设定了验收标准。 从未碰到 【干系人、无法参与会议】➡️ 重要干系人没时间出席重要会议时，可以让其排代表参加。 【角色、职责】➡️ RACI、RAM 中包含角色和职责。 【权力、职责】➡️ 资源管理计划中包含权力和职责。 【用户故事】➡️ 三要素：角色、活动、价值。 【自组织团队】➡️ 不需要过于强势的团队成员，也不需要团队成员有领导力、影响力。 【进度风险管理】➡️ 进度风险管理问题，可以选假设情景分析，以及蒙特卡罗模拟（也是假设情景分析中的一种）。 【预测方法、削减预算】➡️ 需要参考成本效益分析先削减范围（消减价值低、成本高的工作）。","link":"/2024/08/27/pmp_note_before_test/"},{"title":"PMP 考试 - 每日练习 2024&#x2F;08&#x2F;12","text":"仅供自己复习使用。如果侵权请联系删除。 一、项目经理领导一个在整个组织中实施新过程的项目。项目实施是分阶段进行的,项目经理为试点业务部门计划了一个演示 在稍后的日期,一个业务部门的经理被邀请参加冲刺评审。项目经理应该怎么做? 将冲刺审查请求提交给项目发起人。 要求经理获得产品负责人的批准。 ✅ 邀请经理参加计划的冲刺评审。 仅为经理组织一次特别演示。 ✨ 关键词：干系人管理 3️⃣ ✅ 💡 解析：冲刺评审会议,强调让干系人参加,以便获得对交付物的认可、反馈,3️⃣ 正确;1️⃣ 没有必要麻烦发起人;2️⃣ 与产品负责人无关,不需要他的批准;4️⃣ 冲刺评审是敏捷项目中的正常活动,欢迎干系人参与,没有必要单独演示。 二、一个项目正在进行六次迭代中的第五次,团队中有一个成员意外离开了公司。项目经理下一步该怎么做? 在状态报告中详细说明项目延迟的原因。 ✅ 邀请干系人讨论缓解计划。 承担一些必要的工作,以尽量减少影响。 登记一个问题,并将其升级到项目发起人。 ✨ 关键词：资源离职作为风险 2️⃣ ✅ 💡 解析：团队成员辞职、请假,一般当成风险识别,接下来应该分析影响、制定并实施风险应对计划。四个选项中,2️⃣ 可以理解为制定风险应对计划,正确。注意,PMP考试中的“缓解计划”、“减轻计划”,可以直接理解为“风险应对计划”。其他选项都没有当成风险识别来处理,或者不专业。 三、一位项目经理刚刚收到一位运营职能经理的通知,要求他完成一个几周前正式关闭的项目的额外范围项目。这个范围看起来相对较小,作为日常运营活动的一部分很容易处理。项目经理应该如何处理这个要求呢? 提交变更请求并分配执行所需的预算和资源。 确认预算和资源可用于执行工作请求。 检查有关申请的组织内可用的其他资源。 ✅ 评估请求的性质,并相应地计划沟通。 ✨ 关键词：项目结束后、变更 4️⃣ ✅ 💡 解析：项目几周前已正式关闭,此时干系人向项目经理提出变更请求是不合适的。一旦项目正式关闭(移交给运营部门),再出现问题应由运营支持部门来处理、解决,不再是项目经理的责任,D正确,意思是告诉对方找运营支持部门。1️⃣ 2️⃣ 3️⃣ 都是想直接接手解决该问题,判断错误。 四、项目经理最近完成了一个项目,并开始与其他主管管理新项目。作为早期项目活动的一部分,来自原始项目的主管作为非主管资源被分配到团队,并立即开始挑战当前主管所做的所有决定。项目经理应如何解决此冲突? ❌ 给项目团队与新主管解决问题的时间。 确保新主管在面临挑战时发挥带头作用。 立即从项目团队中移除该资源。 ✅ 与资源部门就项目的角色和职责进行沟通。 ✨ 关键词：冲突 1️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：本题属于典型的问题成员题目,该问题成员没有摆正自己的位置,应直面该问题成员,或强调基本规则。但本题的选项不经典,使用排除法。1️⃣ 不介入,指望被挑战的主管来解决,这只会让问题更严重;2️⃣ 这个带头作用在本题情景中无法理解,大概是让被挑战的主管忍让,不符合 PMI(西方)的冲突管理理念;3️⃣ 撵人,在PMP考试中几乎永远不选;4️⃣ 应该直面该问题成员,4️⃣ 的意思是和该成员的职能领导沟通,间接地提醒该成员摆正位置,其他选项都排除的情况下,4️⃣ 选项可以理解和接受。本题答案不经典,仅供参考。 五、一个项目团队正在计划下一次冲刺评审。项目负责人从高级经理那单独收到一封电子邮件询问项目状态,使用的样板比发送给项目管理办公室(PMO)的每月报告使用的模板更详细,团队使用电子产品待办事项列表清单和看板来跟踪进度,项目经理下一步应该做什么? 修改PMO模板,使其包含这些信息。 ✅ 与高级经理联系,讨论他们的需求。 允许高级经理访问产品待办事项列表。 与经理组织对看板的评审。 ✨ 关键词：沟通问题 2️⃣ ✅ 💡 解析：典型的沟通问题,但不是敏捷沟通,因为敏捷沟通不使用“每月报告”,可以理解为混合型的目的沟通问题。沟通的信息内容和沟通方式,应根据干系人的需求来确定,2️⃣ 正确。1️⃣ 沟通内容、方式因人而异,没有必要修改PMO的模板;3️⃣ 跑题了,高级经理想了解的是项目状态,而非范围;4️⃣ 看板目前是团队在使用,4️⃣ 的意思是让高级经理也使用看板,没有 2️⃣ 好。 六、一个敏捷的团队正在头脑风暴,并根据严重程度对所有风险进行优先级排序,团队应如何处理已识别的风险? ❌ 减轻适用于当前和后续选代的风险。 关注项目可交付物,而不是记录在案的风险。 同意任何问题在成为问题时都是可以处理的。 ✅ 确认风险将在相应的选代中处理。 ✨ 关键词：敏捷、风险排序 1️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：本题考敏捷风险管理。敏捷风险管理强调全员参与和全生命周期管理,以确保风险都在控制之中,4️⃣ 的描述相对最好。1️⃣ “减轻”一词,在PMP考试中往往可以理解为“应对”,如果将 1️⃣ 理解为应对所有迭代中的风险,则和 4️⃣ 说法一样,但 1️⃣ 还可以理解为只处理同时影响当前和后续迭代的风险,意思就狭隘了;2️⃣ 错误说法,排除;3️⃣ 说法错误,大多数风险应对是在识别风险后就实施的,而非等到风险发生才实施。本题考点不明确,答案和解释仅供参考。 七、业务转型项目有四个阶段的交付计划,项目团队成功完成了项目的一个阶段。为了进一步提高团队绩效并授权团队成员,项目经理应该采取哪两项行动?(选择两项) 鼓励团队成员与项目经理交叉检查决策。 在执行前审查所有决定。 ❌ 允许团队成员做出有限的决定。 ✅ 组织并分配团队成员做他们擅长的任务。 ✅ 支持团以成员在他们擅长的领域做出决定。 ✨ 关键词：提高绩效、敏捷、授权团队、支持团队 3️⃣ 5️⃣ ❌ -&gt; 4️⃣ 5️⃣ ✅ 💡 解析：如何为团队授权?开放式问题,用排除法。1️⃣ 虽然在培训方法中有交叉培训,但在决策方法中没有交叉检查决策这一说法;2️⃣ 没有真正授权;3️⃣ 有授权,但是没有 4️⃣ 5️⃣ 科学、具体;4️⃣ 让团队成员做擅长的工作,是授权的基础;5️⃣ 科学、正确。本题在 3️⃣ 4️⃣ 5️⃣ 之间选择,根据常识,3️⃣ 明显不如 4️⃣ 5️⃣ 正确。 八、在项目执行阶段,两个团队成员在技术和人际关系层面与团队内的其他团队成员发生冲突。项目经理应该首先采取哪两项行动来解决这个冲突?(选择两项) 要求人力资源(HR)在其升级并影响团队绩效之前进行干预。 ✅ 安排与无法有效合作的团队成员单独会面。 在团队会议上解决冲突,让整个团队参与并找到解决方案。 ✅ 在受影响的团队成员之间使用直接协作的方法尽早讨论冲突。 计划在冲刺后解决团队成员的冲突,专注于实现目标。 ✨ 关键词：冲突 2️⃣ 4️⃣ ✅ 💡 解析：团队成员之间的冲突问题。有冲突,要面对;团队内部冲突解决还要依据冲突解决原则。1️⃣ 不是人力资源部门或经理的责任;2️⃣ 属于面对、开会,是解决冲突的正解;3️⃣ 冲突解决应先私下,不要一开始就公开解决;4️⃣ 符合冲突解决原则,先私下、合作的方式解决;5️⃣ 拖延策略,错误。 九、一个项目团队正在进行一个敏捷软件开发项目。项目经理担心虚拟团队可能不像总部的同城团队那样有效。项目经理应该采取哪两种行动来确保团队达到绩效预期?(选择两项) ✅ 每天举行虚拟会议,审查进展情况。 ❌ 为团队成员实施即时软件。 责令职能经理推动问责制。 ✅ 利用基于网络的看板。 要求每月提交个人状态报告。 ✨ 关键词：敏捷、虚拟团队 2️⃣ 4️⃣ ❌ -&gt; 1️⃣ 4️⃣ ✅ 💡 解析：敏捷项目中虚拟团队管理问题。虚拟团队的重点问题是沟通问题,包括制定沟通管理计划,和使用远程沟通工具。而本题又是敏捷项目,敏捷项目的沟通强调信息发生源、看板。1️⃣ 适用于敏捷团队的内部沟通,可以选;2️⃣ 4️⃣ 都是远程沟通工具,但题目强调了敏捷项目,因此 4️⃣ 比 2️⃣ 更好(B说的应该是即时沟通软件);3️⃣ 与敏捷项目、虚拟团队无关,且属于甩锅行为;5️⃣ 既不符合敏捷项目,也不符合虚拟团队,二者均不提倡书面报告。 十、在每日站会中,一名团队成员告知团队,称用户发送的一条消息提到他们在生产过程中发现了缺陷。项目负责人该做什么? 调查是哪名团队成员实施了待办事项列表中的相应事项。 确定是谁执行了回归测试。 ✅ 联系用户并在待办事项列表中创建缺陷。 咨询质量保证 (QA) 团队并请他们进行调查。 ✨ 关键词：敏捷、缺陷 3️⃣ ✅ 💡 解析：敏捷项目发现缺陷,可以当成技术负债来处理,也可以将修复缺陷工作当成待办项列入待办项列表处理,3️⃣ 正确。1️⃣ 2️⃣ 都是在抓凶手,出现质量缺陷,解决质量缺陷问题是第一要务,抓凶手于事无补,不是当务之急;4️⃣ 或者理解为不承认有错误,或者理解为还是在抓凶手,都不妥。本题也可以按照“敏捷项目,验收不通过,下一步怎么办”的经典套路(见秘笈内容)来选,正确答案就一个:将干系人的新需求列入待办项列表,本题也可以套用。","link":"/2024/08/12/pmp_test_daily_20240812/"},{"title":"PMP 考试 - 每日练习 2024&#x2F;08&#x2F;13","text":"仅供自己复习使用。如果侵权请联系删除。 一、某大型建筑项目由于重要材料突然短缺而面临进度延误和成本超支的问题。为了避免将来出现这种情况,项目经理应该做什么? ✅ 审视外部业务环境对项目范围的影响。 请求增加应急储备,以抵消进度延误和成本超支的影响。 对关键材料采取保值措施,以规避价格上涨的风险,避免动用应急储备。 ❌ 和项目发起人讨论此问题,并将商定内容记录在问题日志中。 ✨ 关键词：风险、问题、避免将来 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：如何避免事业环境因素对项目产生的意外影响?——事先要识别风险(包括制约因素、假设条件),这也是 PMP 考试中的一个套路。1️⃣ 正确,事先识别制约因素、假设条件,可以避免问题发生;2️⃣ 属于事后措施,不能避免;3️⃣ 属于转移措施,同样不能避免;4️⃣ 麻烦发起人,错误。 二、项目经理正在从事一个行业首创的项目。在制定风险管理计划时,项目经理应该如何让项目更具弹性? ✅ 除了针对已知风险制定具体的风险预算外,还要为突发性风险确定合适的预算水平并制定应急计划。 为项目投保,确保在出现不可预见的风险并引发问题时有第三方可以承担责任。 制定可靠的质量管理计划,以便能够在需求交付期间识别任何可能会引发问题的风险。 提交增加应急预算的变更请求,以应对项目的已知风险和未知风险。 ✨ 关键词：规划风险管理、弹性 1️⃣ ✅ 💡 解析：项目的弹性即缓冲,包括时间缓冲和成本缓冲。1️⃣ 说的是成本缓冲(应急储备以及管理储备),可以增加项目弹性(从风险角度也可以叫韧性);2️⃣ 是转移风险,是刚性不是弹性;3️⃣ 通过质量管理计划来识别风险,是胡说八道;4️⃣ 这些预算都应该是事先预留的,如果还需要临时申请,就说明事先没有预留,即没有弹性。本题有出处,见 PMBOK 第六版 399 页项目韧性下第一个方形小黑点,1️⃣ 几乎是原话照抄。 三、项目团队进入设计审查阶段,技术负责人因急事请假而无法参加会议。但是,项目经理一直鼓励团队成员积极参与产品的设计。这样的做法帮助了项目团队,其中一名技术团队成员得以将设计提交给技术委员会。项目经理展示了哪种领导素质? 魅力型。 ✅ 服务型领导。 互动型。 交易型。 ✨ 关键词：鼓励 2️⃣ ✅ 💡 解析：项目经理一直向团队成员提供鼓励、支持,属于服务型领导风格。其他几个选项的关键词(见 PMBOK 第六版65页)都没有出现。另外,目前 PMP 考试中,但凡考领导力风格的,答案几乎都是服务型。 四、项目经理观察到,有两名项目团队成员每次在项目活动中一起工作都会不断发生争执。项目经理接下来应该采取什么措施? 检查分配给这两名团队成员的任务,并将这些任务重新分配给其他团队成员。 ✅ 与这两名团队成员谈话,了解他们发生冲突的根本原因。 要求这两名团队成员一起工作时专注于项目目标。 要求这两名团队成员解决他们的矛盾,确保在工作中不再发生争执。 ✨ 关键词：冲突 2️⃣ ✅ 💡 解析：典型的团队成员之间的冲突问题。由于“不断发生争执”,说明两人无法自行解决冲突,所以 4️⃣ 排除。有冲突,要面对,2️⃣ 正确。典型套路题目,不多解释了。 五、在一次经验教训会议中,为了促进虚拟团队的协作,项目经理找到了一些虚拟协作的良好实践。为了支持虚拟团队的信息交流,以利于规划和协调工作,项目经理应该做什么? 根据需要随时筹划和召开会议。 ✅ 设置团队群聊,在会议之外进行交流。 缩短虚拟会议时间,增加面对面会议次数。 让团队成员使用在线表格自由阐述问题。 ✨ 关键词：经验教训会议、虚拟协作、信息交流 2️⃣ ✅ 💡 解析：本题考虚拟团队的沟通问题。虚拟团队强调使用远程沟通工具、在线(即时)沟通工具。1️⃣ 与虚拟团队特点无关,且说法不专业;2️⃣ 属于远程、在线沟通工具,能够增进团队成员之间的信息交流;3️⃣ 前半句很不正确,排除;4️⃣ 是一种自说自话,缺少互动的拉式沟通,不适合虚拟团队信息交流。 六、项目经理发现大部分团队成员没有填写必要的项目状态报告,但项目经理急需这些状态报告来为项目发起人编制一份全面的状态报告。项目经理应该做什么来应对这种情况? 指责没有填写状态报告的团队成员。 向项目发起人解释团队成员的行为。 ✅ 与出差错的团队成员讨论此问题。 快速整理出一份令项目发起人满意的报告。 ✨ 关键词：大部分没有填写必要的项目状态报告、需要这些信息 3️⃣ ✅ 💡 解析：本题属于团队不遵守基本规则的问题,应向团队强调基本规则,但选项中没有。团队成员不遵守规则也可以当成冲突,有冲突要面对,3️⃣ 正确。本题还可以当成问题成员(团队成员单方面造成的冲突),问题成员,或者向其强调规则,或者面对、开会解决冲突,还是选 3️⃣。1️⃣ 人民内部矛盾,方式要尽量温和;2️⃣ 麻烦发起人,错误;4️⃣ 不但逃避问题,而且是在造假。 七、某电力公司的项目经理正在开展一个改善配电网络的战略项目。其中一个关键可交付成果需要项目技术总监的批准。由于该技术总监请假一个月,该项目现在已经延迟了两周。项目经理本应采取什么措施来避免发生这种问题? 执行风险减轻应对措施,防止进一步的延迟。 ✅ 制定所有干系人 (相关方)的名单,包括该技术总监。 ❌ 管理干系人(相关方)参与并安排决策会议。 推进项目的执行并及时通知干系人(相关方)。 ✨ 关键词：干系人请假导致延迟、关键路径、本应采取什么 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：项目执行中途,一个事业环境因素严重影响项目,如何避免?此类问题一般都是在项目早期的风险识别(包括制约因素、假设条件)问题。1️⃣ 4️⃣ 都是事后措施,排除;2️⃣ 3️⃣ 之间,2️⃣ 更符合识别制约因素、假设条件,可以避免题目描述的问题;而 3️⃣ 严格来说更像事后措施且不解决题目问题。 八、某个软件迁移项目中发生了冲突。项目团队的大多数人希望实施一种可以快速取得成果,但会产生高运营成本的策略。一些项目团队成员已获得高级管理层中关键干系人(相关方)的支持。但是,项目经理将更多精力放在迁移阶段,以求降低运营成本。时间在流逝,而项目没有进展。为了解决这个冲突,项日经理应该使用哪种冲突解决方法? ✅ 强迫/命令。 妥协/调解。 撤退/回避。 ❌ 安排/讨论(Arrange/discuss)。 ✨ 关键词：项目经理与团队的冲突 4️⃣ ❌ 💡 解析：典型的冲突解决问题。关键词是“时间在流逝,而项目没有进展”,提示情况紧急,需要采取果断措施,因此选 1️⃣。2️⃣ 3️⃣ 选项都不对应上述关键词,4️⃣ 是陌生词汇,不能选。 九、某团队每次选代都能交付价值,其中一名团队成员十分积极主动,主导了每一次讨论。这造成了其他人没有机会说话。由于这名团队成员的存在,大多数其他团队成员都不能表达自己的观点,并且觉得自己不受重视。项目经理该做什么来应对这种情况? ❌ 安排与每名团队成员进行一对一会面,了解他们的观点并鼓励他们畅所欲言。 ✅ 制定基本规则,让每名团队成员都有机会发言和贡献意见。 向那名积极主动的团队成员提供有效沟通和协作的培训。 使用循环法展开讨论,认可每名团队成员的意见。 ✨ 关键词：沟通问题、不能打压员工积极性 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：典型的问题成员问题。正确答案或者是强调规则,或者是解决冲突(开会、面对)。2️⃣ 正确。1️⃣ 4️⃣ 都没有针对问题成员;3️⃣ 对问题成员进行培训,是错误判断。 十、在项目进行到一半的内部审查期间,一个承担了 30% 工作量的子团队请求例外处理,这将花费数百万美元的支持费用。项目经理首先应该做什么? ✅ 启动变更控制流程。 更新风险登记册。 ❌ 召开团队会议。 告知项目发起人。 ✨ 关键词：变更 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：项目子项目团队提出一个重大变更,内部变更从具体操作来说,应先分析影响,再通知客户。但归根结底也还是变更问题,1️⃣ 选项包括对内部变更的处理,属于变更问题的通吃选项。3️⃣ 相对比较含糊,即使 3️⃣ 的意思是“和团队一起分析变更影响”,也包含在 1️⃣ 的范围之内了。","link":"/2024/08/13/pmp_test_daily_20240813/"},{"title":"PMP 考试 - 每日练习 2024&#x2F;08&#x2F;14","text":"仅供自己复习使用。如果侵权请联系删除。 一、某新项目的项目经理第一次与发起人会面,了解其在项目周期中的期望。发起人要求参加每周例会,并希望能够直接联系团队成员了解情况。项目经理接下来该做什么? 在与发起人会面之前更新沟通管理计划,以反映其未来的参与意愿。 向团队成员解释,将严格按照沟通管理计划进行沟通。 ✅ 通过商议,让发起人在项目的关键里程碑期间参与会议,并就沟通管理计划达成一致。 在开工会议上与发起人讨论沟通管理计划,但强调项目经理单独做出最终决定。 ✨ 关键词：管理相关方发起人参与 3️⃣ ✅ 💡 解析：发起人要求参加每周例会,目的是了解项目的信息,不算出格的要求。而发起人希望直接联系团队成员了解情况,则属于不合理要求,因为可能会影响一个原则——“项目经理对项目沟通的控制”。表面上看,是干系人问题,但本质上还是发起人担心不能全面了解项目情况,是沟通问题,应通过充分满足发起人的信息需求来解决。1️⃣ 是避免造车。2️⃣ 没有考虑发起人的沟通需求,与 1️⃣ 类似。3️⃣ 前半句在管理干系人,不需要每周参会,参加里程碑会议即可;后半句的意思是根据发起人的需求制定沟通管理计划;正确。4️⃣ 沟通管理计划不应在开工会议上公开讨论,且后半句很负面。 二、在查看经验教训数据库后,项目经理意识到当前的团队对于组织流程的了解可能无法满足新项目的需求。项目经理该怎么做? ✅ 培养团队成员,让他们作为跨职能团队开展工作。 请职能部门经理提供合适的团队成员。 查看项目章程,看是否可以修改项目范围。 请项目组合经理将项目重新分配给另一个团队。 ✨ 关键词：团队对项目方法的能力不足 1️⃣ ✅ 💡 解析：三种情况下,需要对团队成员进行培训:1、能力不够;2、不懂规矩,认知不够;3、有错误观念。本题属于第2种情况,应进行培训,选 1️⃣。 三、某项目经理在负责一个项目,需要交付一种复杂产品。治理委员会要求制定全面的质量管理计划。质量管理计划应该包含哪两项评估成本?(选择两项) ✅ 记录产品待办事项列表中事项的验收标准。 ❌ 更新商业论证,以便与待办事项列表保持一致。 上线后保留整个团队至四周的保修期限结束。 ✅ 聘请专业测试人员进行性能和安全性测试。 咨询敏捷教练以确保提高交付速度。 ✨ 关键词：质量管理的成本 1️⃣ 2️⃣ ❌ -&gt; 1️⃣ 4️⃣ ✅ 💡 解析：选项中哪两项与质量评估(检查)成本有关?2️⃣ 3️⃣ 5️⃣ 都与质量检查无关;4️⃣ 是质量检查工作,属于质量评估成本;1️⃣ 制定验收标准,是为质量评估工作的基础,也可以当成质量评估成本。本题用排除法,只有 1️⃣ 4️⃣ 与评估成本有关联。 四、项目经理针对风险登记册中列明的一项风险执行了减轻计划,但该风险仍成为现实。项目经理接下来该做什么? 将此事记录在风险登记册中,修订风险减轻计划,指定风险减轻任务负责人,并更新项目管理计划。 ✅ 将此事记录在问题日志中,指派一名团队成员处理此问题,让他/她检查风险登记册是否有相应的应急计划,并拟定行动计划。 评估成本和时间影响,将数据记录在风险登记册中,并向发起人申请额外的资金和时间。 将此事记录在问题日志中,召开紧急团队会议,准备变更请求,并更新项目管理计划和进度计划。 ✨ 关键词：风险发生、问题管理 2️⃣ ✅ 💡 解析：实施的风险应对计划无效(应对计划无效本身属于问题而非风险),应考虑实施应急计划(备用计划)。四个选项中,只有 2️⃣ 强调了实施应急计划,其他选项中“更新风险登记册”、“更新项目管理计划”、“找发起人”等都是错误做法,可以排除。 五、某高级理人员向项目经理报告了一个软件错误。而项目团队报告说该错误是一个已知问题,只是未告知这名高级管理人员。为了防止这种沟通不畅的问题再次发生,项目经理该怎么做? ❌ 查看干系人(相关方)参与计划,确定是否应将这名高级管理人员加入到该计划。 ✅ 更新干系人(相关方)登记册,将这名高级管理人员纳入所有沟通范围。 邀请这名高级管理人员参加项目会议,让他/她了解最新的项目状态。 与这名高级管理人员会面,简单介绍相关的报告和上报流程。 ✨ 关键词：沟通问题、干系人登记册 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：重要信息没有主动通知干系人,本质上还是沟通问题。1️⃣ 质疑是否该管理这个干系人,是明显错误的想法;2️⃣ 前半句是管理干系人,后半句是管理沟通,正确;3️⃣ 从沟通角度来说,是在刁难该干系人,不是正确的沟通问题解决方式;4️⃣ 是在指责该干系人没有遵守报告和上报流程,错误。 六、某项目经理受命负责一个将采用敏捷法进行交付的项目。项目章程己获批准,资源情况已作介绍。项自团队有意为该项目制定团队章程。项目经理该怎么做? 让团队开始进行第一次迭代,因为敏捷项目章程已获批准。 允许团队进行自我管理,同时确保团队专注于交付里程碑。 ✅ 让团队制定团队章程,这样他们才能够优化协作并促进合作。 向团队成员解释敏捷项目不需制定团队章程。 ✨ 关键词：敏捷、团队章程 3️⃣ ✅ 💡 解析：敏捷项目的团队章程如何制定?敏捷项目强调自组织团队,应支持团队自行讨论制定章程,即使是预测型项目,制定团队章程也要强调团队参与;3️⃣ 正确。1️⃣ 项目章程和团队章程是两码事;2️⃣ 因为题目中问的是章程的事情,2️⃣ 选项没有提到章程,不妥。4️⃣ 错误概念。 七、项目经理在一个混合组织中工作,该组织寻求以创新方法为员工提供反馈。项目经理应该考虑使用什么方法来支持团队的绩效? 优势为本的方法。 ❌ 行为奖励制度。 奖金制度。 ✅ 看板方法。 ✨ 关键词：支持团队的绩效 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：题目关键词有“混合组织”、“以创新方法为员工提供反馈”,因此题目最后的问题可以理解为如何向团队成员提供绩效反馈,而不是如何激励员工。敏捷方法中,团队成员的绩效可以用看板来显示(反馈),符合题目中强调的“创新方法”。1️⃣ 不知所云,陌生词汇排除;2️⃣ 3️⃣ 都是奖励方法,不是绩效反馈方法;且项目管理强调基于本职工作绩效进行奖励,且相对比较排斥物质(金钱)奖励,因此从奖励角度来说,2️⃣ 3️⃣ 也不是好选项。 八、一名关键干系人(相关方) 在项目中拥有很大权力,并且高度关注项目,他/她在对产品功能施加影响,这可能会改变产品的成本目标。但是,如果这种影响没有发生,项目团队可能会动摇客户购买最终产品的决心。项目经理接下来该做什么? 与这名干系人(相关方)一起审查项目范围。 为项目制定风险减轻策略。 ✅ 就新功能的影响向这名干系人 (相关方) 提出建议。 确定此风险的严重程度并采取相应的措施。 ✨ 关键词：干系人提出变更请求 3️⃣ ✅ 💡 解析：题目有话没有好好说,要结合选项再去理解题目:说的是关键干系人提出了一个影响成本目标的范围变更,如果项目经理不同意则影响客户的购买意愿,但项目经理认为最好不变,因为会影响成本目标,项目经理应该怎么办?本题应该当成变更问题来选,但选项中没有标准的变更选项,只有 3️⃣ 比较接近,可以理解为“影响引起变更的因素”。本题可以当成干系人问题(干系人提出了有负面影响的要求),应管理干系人,3️⃣ 即用负面影响来说服干系人,从这个角度更容易找到正确答案。 九、项目经理负责管理某全球电信提供商的网络建设项目。由于一名项目主题专家 (SMEs)在技术研讨会期间向管理层抱怨了技术限制,管理层要求更改一项技术要求。项目经理应该先采取哪项措施? 检查沟通管理计划和上报指南,确定是否需要更新。 将SME的不当报告告知技术经理。 与管理层会面,请他们不要接受团队成员的非正式报告。 ✅ 与SME会面,指导其了解适当的沟通和上报计划。 ✨ 关键词：沟通问题、跳过项目经理上报、项目主题专家 (SMEs) 识别为干系人 4️⃣ ✅ 💡 解析：本题是典型的“干系人问题+变更问题”,按秘笈套路,先考虑干系人问题,即管理干系人期望。选项中只有 4️⃣ 是直面干系人并对其施加影响,正确。另外,干系人问题也都可以当成冲突问题,要面对、开会,也是选 4️⃣。本题也可以按“问题成员”套路,强调规则或与其面对,也选 4️⃣。 十、Scrum 团队交付的项目必须符合法规要求。在设计研讨会上,开发人员推荐了几个方案,但无法就具体实施哪个方案达成一致。为了解决这个问题,项目经理应该采取哪两项措施? (选择两项) ✅ 让每个人表明自己对各个方案的同意程度。 让产品负责人选择最佳方案。 ❌ 将团队分成小组,以汇总调查结果。 ✅ 审查所有方案并确定其中最优的一项。 使用石川图选择最佳方案。 ✨ 关键词：敏捷、团队决策 1️⃣ 3️⃣ ❌ -&gt; 1️⃣ 4️⃣ ✅ 💡 解析：本题考决策技术。1️⃣ 公平、民主,类似于名义组技术,是常用的群体决策技术,可以选;2️⃣ 不符合自组织团队的决策原则,也不是好的决策技术;3️⃣ 没有这种决策技术;4️⃣ 多中选优,属于决策树技术,可以使用;5️⃣ 石川图是用于找根本原因的,不是决策技术。","link":"/2024/08/14/pmp_test_daily_20240814/"},{"title":"PMP 考试 - 每日练习 2024&#x2F;08&#x2F;15","text":"仅供自己复习使用。如果侵权请联系删除。 一、项目团队正在执行一个涉及跨职能整合的复杂项目。在选代执行的过程中,相关部门出台了合规审计要求,这需要项目团队掌握额外的技能。项目经理该怎么做? ✅ 评估团队的能力,并规划必要的培训。 在待办事项列表中创一个刺探 (Spike),以满足审计需求。 在当前的选代中安排对用户故事进行审计。 在开始审计之前,咨询产品负责人的意见。 ✨ 关键词：能力不足 1️⃣ ✅ 💡 解析：题目关键词“这需要团队掌握额外的技能”。团队缺乏技能,应进行培训。1️⃣ 是正确答案;其他选项都没有提及培训,不合适。 二、项目结束后,卖方将发票发送给组织。会计部门拒绝支付发票,因为只有一封来自项目发起人的电子邮件,而没有正式的项目完工书面通知。项目经理应采用哪两种措施? (选择两项) ✅ 将已批准的合同发送给会计部门。 将已批准的项目管理计划递交给会计部门。 ❌ 向会计部门提供已批准的范围管理计划和已完成工作清单。 ✅ 提供已批准的成本管理计划和卖方完成的工作清单。 口头指示会计部门支付卖方的发票。 ✨ 关键词：合同完成、付款 1️⃣ 3️⃣ ❌ -&gt; 1️⃣ 4️⃣ ✅ 💡 解析：如何向会计部门证明合同已正式完成,以促使会计部门支付合同款项?1️⃣ 能证明合同的存在和签定,且合同中包括支付条款;2️⃣ 项目管理计划不能作为付款依据;3️⃣ 范围管理计划与合同支付没有直接关系;4️⃣ 卖方完工清单可以作为支付依据,另外成本管理计划也支持采购相关事项;5️⃣ 项目经理没有权力对会计部门发号施令。 三、某项目需要高级管理团队频繁提供支持。过去的一些项目得到了高层团队的大力支持,然而,近期的许多项目都以失败告终,原因是高级管理层的回应十分迟缓而且经常不参加会议。为了确保干系人(相关方) 有效参与,项目经理应该做什么? ❌ 提前预定与管理层干系人(相关方) 的会议,方便他们做好日程安排。 在固定的时间和方便的地点定期举行简短的跟进会议。 ✅ 查看其他项目中涉及管理层干系人 (相关方) 的经验教训。 请求一名高级管理层代表出席会议,否则将停止项目。 ✨ 关键词：管理干系人参与 1️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：回应迟缓、不参加会议,属于典型的干系人问题,应管理干系人参与。1️⃣ 干系人问题是态度问题,不是提前预定就能解决问题的;2️⃣ 还是会议技术层面的手段,不解决干系人的态度问题;3️⃣ 借鉴之前项目管理干系人的经验教训,是管理当前项目干系人的很好的方法,可以选;4️⃣ 项目经理没有这个权力。 四、项目经理负责一个内部项目,该项目的干系人(相关方) 来自不同的背景和职位。为了帮助干系人(相关方)增进理解,项目经理应该做什么? 定期征集所有干系人 (相关方) 的书面反馈,保持他们的参与度。 ✅ 让所有干系人(相关方) 参与所有决策过程,以解决此问题。 预测可能存在的误解,并在月度会议上分享给干系人(相关方)。 采用参与式方法,让所有干系人(相关方) 用相同的方式看待问题。 ✨ 关键词：管理干系人参与、如何增强干系人对项目的理解和支持（让干系人尽早参与决策）​ 2️⃣ ✅ 💡 解析：典型的干系人管理问题,答案也很经典。如何增强干系人对项目的理解和支持?让干系人尽早参与(决策),是增强干系人对项目理解和支持的最佳选择,也是本类题目最好的答案,2️⃣ 正确。1️⃣ 和参与决策相比,收集干系人书面反馈作用非常有限;3️⃣ 典型的闭门造车;4️⃣ 后半句是不可能实现的目标。 五、某项目经理正带领一个虚拟团队管理项目,团队成员分布在两个不同时区。功能分析师和编码团队不在同一个时区,所以他们使用共享文档存储库来保存工作内容。在冲刺发布前的最后一次会议中,他们发现结果与最新版本的功能规范不一致。项目经理接下来该做什么? ❌ 在双方都能接受的时间安排与团队召开每日站会。 ✅ 在两个团队都能接受的时间举行可以共享屏幕的视频会议。 利用数字快照工具突出显示版本之间的变更。 要求团队在有变更时通过电子邮件往来分享更新后的文档。 ✨ 关键词：团队沟通问题 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：虚拟团队内部之间的沟通出现了偏差、误解。表面上是版本问题,实际上是虚拟团队的沟通问题。1️⃣ 与 2️⃣ 相比没有强调视频会议,从防止沟通误解,尤其是版本问题时,没有 2️⃣ 好;2️⃣ 面对面的远程沟通工具,特别适合虚拟团队使用,正确;3️⃣ 4️⃣ 都比不上面对面的沟通方式,且虚拟团队不提倡书面沟通。 六、项目团队开始定义一项产品,其功能仅够早期客户使用。他们决定先创建原型。项目经理应该如何说服干系人 (相关方) 采用这种方法? ✅ 描述该产品如何让最终用户了解到完整的用户体验。 解释称该产品提供足够的证据来指明未来的方向。 ❌ 描述该产品将如何帮助加快产品构建活动。 解释称该产品的开发不需要大量时间和精力。 ✨ 关键词：MVP、原型法 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：题目考原型法的好处。题目出处和依据见 PMBOK 第 6 版 147 页第一段第三行“它使得相关方(干系人)可以体验最终产品的模型,而不是仅限于讨论抽象的需求描述”。四个选项中,1️⃣ 最好。2️⃣ 3️⃣ 4️⃣ 在书上都没有依据,且 2️⃣ 4️⃣ 明显示错误说法。 七、某项目经理负责组建一个虚拟团队,团队成员是在世界各地工作的主题专家 (SMES)。在组建团队时应该考虑哪三个因责?(选择三项) 可能会出现道德和伦理问题并影响团队的生产力。 ✅ 文化障碍可能会影响团队沟通。 ✅ 较大的时区差距可能会是团队协作的难点。 ✅ 团队的进展和状态将更难跟踪。 ❌ 每个团队成员可用的技术基础设施可能不同。 ✨ 关键词：虚拟团队、世界各地、管理痛点 2️⃣ 3️⃣ 5️⃣ ❌ -&gt; 2️⃣ 3️⃣ 4️⃣ ✅ 💡 解析：跨国虚拟团队有哪些需要关注的管理痛点?1️⃣ 和虚拟团队无关;2️⃣ 跨国团队存在文化差异,容易引起沟通误解;3️⃣ 跨国时差问题会影响协同、配合;4️⃣ 因为不在现场,工作状态和绩效难以及时跟踪;5️⃣ 此问题存在,但不是团队管理问题,不影响团队管理。 八、在没有商业论证的情况下,高级管理层要求项目团队构建一个必须在短时间内上市的产品。项目经理应该指示团队做什么? ✅ 等到商业论证完成后再继续。 制定项目管理计划并提交给董事会。 收集学习要求,用于准备提案。 收集客户反馈并设计项目管理计划。 ✨ 关键词：管理层的不合理要求不能听、坚持原则 1️⃣ ✅ 💡 解析：新项目,题目强调“没有商业论证”,则首先应该进行商业论证,确定项目是否值得投资,1️⃣ 正确。本题考项目管理的基本原则,且是一道欲擒故纵的陷阱题目,应坚持原则。2️⃣ 是按高级管理层的要求直接开始项目了,错误;3️⃣ 不知所云,当成陌生词汇吧;4️⃣ 比 2️⃣ 好一些,但一样忽略了商业论证。 九、项目经理负责执行一次即将开始的维护任务,此任务会使公司网络下线至少四小时。项目经理正在仔细规划对所有受影响用户的沟通事宜。有多种沟通模型可供使用,包括在内部网站上发布详细的维护信息、发送电子邮件,以及自动电话呼叫和短信通知。项目经理应该如何决定使用哪种沟通模型? ✅ 使用一种或多种沟通模型,根据影响计划沟通通知对干系人(相关方)进行分组。 ❌ 咨询负责过以往维护任务的项目经理,了解他们如何分发通知。 通过已确定的每种沟通模型向所有干系人 (相关方) 发送通知,确保广泛分发。 计划在周末执行维护任务,这样就不需要将信息分发给用户。 ✨ 关键词：干系人沟通、沟通模型 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：应该如何与不同的干系人进行沟通?应根据不同干系人的沟通需求、喜好定制化沟通内容和形式,1️⃣ 正确。2️⃣ 和 1️⃣ 相比,2️⃣ 是刻舟求剑、郑人买履;3️⃣ 千人一面地统一沟通,错误;4️⃣ 隐瞒、不沟通,错误。 十、客户要求产品负责人优先处理一项功能,并在下一个冲刺中开发此功能。在冲刺计划会议中,产品负责人要求团队在下一个冲刺中增加这项功能。开发团队回复称下一个冲刺工作量已满,他们会将这项功能延至后面的冲刺。项目经理应该如何解决这个问题? ✅ 鼓励产品负责人和开发团队研究替代方案,一起决定可以采取的做法。 ❌ 让产品负责人决定下一个冲刺的工作内容,因为待办项列表属于其责任范围。 告诉产品负责人接受团队的意见,将这项功能的开发延至下一个冲刺。 让另一个开发团队负责这项功能,并在冲刺结束时进行整合。 ✨ 关键词：冲突问题 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：就某项功能是否在下个冲刺中开发,产品负责人和开发团队出现了意见分歧。技术意见不一致,最佳选择是让双方达成一致意见,其次的选择是根据商业价值决定开发顺序。1️⃣ 是让双方达成一致意见的意思,正确;2️⃣ 3️⃣ 都是一边倒的选择,冲突会继续存在;4️⃣ 敏捷项目中,团队是相对固定的,不存在这样条件。","link":"/2024/08/15/pmp_test_daily_20240815/"},{"title":"PMP 考试 - 每日练习 2024&#x2F;08&#x2F;16","text":"仅供自己复习使用。如果侵权请联系删除。 一、项目经理的团队成员分布在不同时区和国家/地区。一名团队成员提醒项目经理,他/她不可以在正常工作时间以外工作。这名团队成员提到这一点是为了避免和其他团队成员发生冲突。项目经理该怎么做? 制定团队基本规则,以便在正常工作时间进行沟通。 与职能部门经理协商,换掉这名团队成员。 只更新项目通信矩阵中的视频通信规则。 ✅ 为项目团队的沟通建立一致同意的时间范围。 ✨ 关键词：沟通问题 4️⃣ ✅ 💡 解析：虚拟团队(沟通)问题。团队一起协商虚拟团队的会议时间和采用的协同沟通工具,是此类问题的正确答案,4️⃣ 正确。1️⃣ 因为有时差,强制规定会议时间,势必导致其他某些人必须在工作时间之外参加会议,因为违法劳动法,因此只能协商,不能强迫。 二、某项目属于业务转型计划的一部分,该计划还包含其他项目,意在完成不同的组织变革。项目简介表明这些项目之间存在显著的依赖关系。应该使用什么策略来确保妥善管理这种依赖关系? 对所有项目使用一个风险登记册,来管理风险、问题和依赖关系。 对所有项目使用一个产品待办事项列表,来管理风险、问题和依赖关系。 ✅ 使用通用模板制定主进度计划,并整合所有里程碑和依赖关系。 为每个项目制定独立的项目进度计划,只比较里程碑。 ✨ 关键词：多项目间依赖关系 3️⃣ ✅ 💡 解析：如何管理(本)项目与组织中其他项目的依赖关系?项目与其他项目的依赖关系,一般都属于外部依赖关系,依赖关系的管理主要发生在制定进度计划过程中,3️⃣ 正确。1️⃣ (外部)依赖关系属于强制性的制约因素,不应当成风险管理;2️⃣ 题目中没有提示用敏捷方法,且所有项目使用一个待办项列表也是不存在的说法;4️⃣ 忽略了依赖关系管理。本题有超纲,因为考的是项目集管理,且问题不是针对项目经理提出的,而是针对项目集经理提出的,答案和解释仅供参考。 三、某项目经理正在领导一个成员分散在不同地理位置的虚拟团队。他/她应该怎样做来避免项目中不同文化带来的不确定性? ✅ 收集相关的文化资料,并让团队成员参与讨论不同文化背景下的职业道德。 启动项目并将出现的任何不确定性添加到风险登记册中。 解散虚拟团队并建立一个集中办公团队。 建立一个文化中立的团队,避免受文化差异影响。 ✨ 关键词：虚拟团队、不同文化带来的风险 1️⃣ ✅ 💡 解析：如何避免文化差异给团队带来的风险(冲突)?面对文化差异,项目经理应对团队开展学习、团队建设,以便团队成员了解、遵守、适应彼此的文化差异,防止发生因文化差异导致的冲突,1️⃣ 正确;2️⃣ 文化差异问题是项目经理的责任问题,一般不当成风险管理;3️⃣ 否定了虚拟团队的可行性,错误;4️⃣ 应面对而非逃避文化差异,4️⃣ 的目标不现实,无法实现。 四、项目经理接到 CEO 指示,要求确保项目有利可图并为公司带来足够的价值。CEO 还告诉项目经理不必制定项目章程。为了确保项目实现预期的优势并提供所需的价值,项目经理需要哪两个工件?(选择两项) 项目成本管理计划。 ✅ 项目效益管理计划。 项目概案分析。 ✅ 项目商业论证。 工作分解结构(WBS)。 ✨ 关键词：项目的商业价值（目标效益） 2️⃣ 4️⃣ ✅ 💡 解析：创建什么文件,能确保项目给公司创造价值?项目的商业价值也可以称作目标效益,首先记录在效益管理计划中,见PMBOK第6版33页内容。其次,商业论证文件为了验证项目是否值得投资,包含成本-效益分析,因此也含了商业价值(效益)。因此,本题 2️⃣ 4️⃣ 正确。1️⃣ 显示如何管理项目成本,不强调项目要创造的价值、效益;3️⃣ 陌生词汇,排除。5️⃣ 是对可交付成果的细分,与商业价值无关。 五、某敏捷项目经理刚接手一个大型软件开发实施项目。在启动阶段的早期,项目发起人请求说明初始版本的交付时间表。敏捷项目经理应该使用什么工具来做这些评估? ✅ 产品待办事项列表、预算、资源管理计划。 ❌ 待办事项列表整理、产品待办事项列表、最小可行性产品(MVP)。 预算、最小可行性产品(MVP)、回顾笔记。 资源管理计划、回顾笔记、待办事项列表整理。 ✨ 关键词： 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：本题答案在 1️⃣ 2️⃣ 3️⃣ 4️⃣ 之间争议较大,答案和解释仅供参考。题目问初始版本的交付时间?敏捷项目的版本周期、迭代周期正常是固定好的,如果问初始版何时交付,说明正在确定版本周期。而版本交付周期和工作量以及资源投入量有关,两者都确定了才能推算出交付时间,因此要同时考虑初始版本的工作量(范围)和可以使用的资源数量,而且两者都受制于预算,从这个角度判断,1️⃣ 相对最好。2️⃣ 强调了给待办项排序和最小可行性产品,都是确定初始版本范围的工作,但没有资源数量,就很难预测时间,有人说资源是固定的,如果这样说,2️⃣ 可以选,但很牵强;3️⃣ 只有 MVP,回顾笔记还是陌生词汇,个人认为 3️⃣ 还不如 2️⃣;4️⃣ 和 1️⃣ 比较接近,但回顾笔记是个bug,题目强调是在启动阶段早期,即使把回顾笔记理解为回顾会议结果,也不符合本题的时间点。 六、在一个混合项目的待办事项列表细化会议中,团队发现由于架构师的工作量问题,有些事项尚未完成。项目经理该怎么做? ❌ 等待架构师完成未完成的事项。 请求产品负责人的许可,以完成这些事项。 ✅ 将未完成的事项重新分配到下一个冲刺。 利用额外的资源来完成这些事项。 ✨ 关键词：外部依赖、待办事项未完成 1️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：当前迭代部分工作未能完成,可以放入下一次迭代执行,在《敏捷实践指南》中可以找到直接的依据,3️⃣ 正确。1️⃣ 势必要延长本次迭代周期,这是敏捷所不允许的;2️⃣ 与 1️⃣ 一样,不管 PO 是否同意,都是错误做法;4️⃣ 不要说敏捷项目,即使在预测型项目中,额外资源也很难获得,4️⃣ 的期望不现实。 七、某项目处于执行阶段,包括团队成员在内的干系人(相关方)抱怨进展报告缺乏透明度和信任,此后前任项目经理离开了组织。为了解决这个问题,现任项目经理应该做什么? 让项目团队确定在项目执行中使用的报告要求。 准备一次团队建设活动,在活动中将干系人(相关方)和项目团队合并在一起。 与项目管理办公室(PMO)合作,了解干系人(相关方)的需求。 ✅ 与干系人(相关方)会面,收集并了解他们对报告的要求和期望。 ✨ 关键词：相关方期望 4️⃣ ✅ 💡 解析：典型的沟通问题。干系人对沟通不满,应查看沟通管理计划或找干系人了解沟通需求。4️⃣ 是找干系人了解沟通需求,正确。1️⃣ 闭门造车,无法满足干系人沟通需求;2️⃣ 与沟通问题无关;3️⃣ 与 PMO 无关。 八、多个敏捷团队正在处理产品可交付成果。在最后几次迭代中,有一个团队接收其他团队发来的几条计划外非生产支持请求,这影响了团队的速度和计划内可交付成果。在这种情况下,项目经理该怎么做? 让团队在每次迭代中满足大部分请求。 ✅ 让团队专注于计划内可交付成果,不要开展任何计划外活动。 告诉团队尽可能完成计划内可交付成果和收到的请求。 ❌ 告知其他团队的成员,将这些请求直接添加到迭代待办事项列表中。 ✨ 关键词：团队接收其他团队发来的几条计划外非生产支持请求、计划外非生产要求 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：题目关键词“计划外非生产要求”,即与项目无关的工作,这是不应该执行的工作,也不应列入待办项列表,B正确。AC都是满足计划外非生产请求,错误;D,让列入待办项列表,错误。 九、某个敏捷项目在经历几次发布和十几次迭代之后迎来尾声。然而,在演示会议期间,一名关键干系人(相关方)要求项目经理提供添加一组新功能的成本估算。项目经理该怎么做? ❌ 在下一次规划会议中估算新功能的规模(在迭代中),再乘以团队的运转率(每次迭代)。 ✅ 召集团队中最有经验的成员,让他们用计划扑克估算方法计算成本。 依靠公司内部以往项目的历史数据来提供类比成本估算。 分析项目的CPI(成本绩效指数),并据此预测新功能的成本。 ✨ 关键词：敏捷、项目后期、新功能、成本估算 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：敏捷项目某一待办项的成本估算就是工作量估算(故事点或人.天),可以使用计划扑克方法,2️⃣ 正确。1️⃣ 估算的不是成本,是持续时间或迭代周期;3️⃣ 题目强调了“新功能”,3️⃣ 没有可行性;4️⃣ 本末倒置,先有成本估算,才会有成本绩效(CPI等),而不是相反。 十、项目经理负责一个价值数百万美元的会议中心项目,在施工期间一场大火烧毁了建筑。项目经理本应采取什么措施来确保这种类型的风险不会显著影响项目成本? 接受风险。 ❌ 减轻风险。 ✅ 转移风险。 消除风险。 ✨ 关键词：数百万美元损失、风险 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：本题考风险应对策略。可以按照常识,灾害类风险一般都采用买保险的方式来应对,属于转移 3️⃣。按PMBOK风险管理策略的分类,严重风险(威胁)一般采取回避和转移,本题没有回避策略,所以选转移。另外之前版本的PMBOK签订,转移策略适用于财务后果严重的风险,价值数百万美元的建筑被毁,属于财务后果严重,适用于转移策略。","link":"/2024/08/16/pmp_test_daily_20240816/"},{"title":"PMP 考试 - 每日练习 2024&#x2F;08&#x2F;20","text":"仅供自己复习使用。如果侵权请联系删除。 一、项目经理刚刚受聘负责带领一个混合环境中的项目团队,该团队正在处理一组关键项目。为了确保拥有适当的环境和职权,以便有效交付项目,项目经理应该做什么? ✅ 任命一个不受组织因素影响的自组织项目团队。 制定一份详细的项目管理计划,并分享给项目团队。 制定一份详细的风险日志,并分享给项目的所有干系人(相关方)。 创建一个符合现有组织结构的项目指导委员会。 ✨ 关键词：敏捷、授权 1️⃣ ✅ 💡 解析：题目关键词“确保(团队)拥有适当的环境和职权”,暗示需要给团队授权。四个选项中,只有 1️⃣ 有给团队授权的意思,“任命”一词英文为“authorize”,此处应译为“授权”更合适。 二、某项目意在改善团队的运作,现正处于发现阶段,在与关键干系人(相关方)会面后,项目范围明显扩大,将项目持续时间延长了很多年,运营主管对此存有疑虑,他不希望等待多年才能完成最初的要求。项目经理如何消除这个顾虑? 将项目限制在初始请求范围内,避免范围蔓延,并提交商业论证。 ✅ 商定最小可行性产品(MVP),并以增量方式交付解决方案。 为了明确起见,请发起人批准修改后的项目章程。 让运营经理提交变更请求,以提高优先级。 ✨ 关键词：发现阶段、范围扩大、干系人不满、交付初级产品 2️⃣ ✅ 💡 解析：题目关键词“不希望等待多年才能完成最初的要求”,即希望尽快交付初级产品。敏捷方法中的最小可行性产品(MVP)和增量交付可以解决这个顾虑,2️⃣ 正确。本题就是考MVP的概念题目,其他选项都不解决问题。 三、在冲刺回顾中,两名团队成员讨论了在生产中发现的缺陷,负责开发的成员抱怨称缺陷本应在测试过程中就已发现,讨论变得非常激烈。项目负责人该做什么? ✅ 确保所有团队成员都理解完成的定义(DoD)。 告知测试人员其职责是确保所有缺陷都被检测到。 记录这次讨论并上报给职能部门经理。 转到下一个话题,稍后在调查此问题的原因。 ✨ 关键词：敏捷、质量问题、验收不通过 1️⃣ ✅ 💡 解析：本题属于典型套路题目,敏捷验收不通过,如何避免?1️⃣ 是符合套路的正确答案,可以理解为,测试过程中之所以没有发现缺陷,是因为对验收标准(DOD)理解错误导致。2️⃣ 在 1️⃣ 之后考虑,1️⃣ 是 2️⃣ 选项的前提;3️⃣ 与职能经理无关;4️⃣ 回避问题,错误。 四、某复杂项目进入到了一个需要很多质量保证(QA)资源的阶段。公司聘请了应届毕业生来担任这些职位,他们参加了为期两周的培训,然后就被分配到该项目中,当下一个版本发布给用户时,公司接到投诉称在生产中发现了更多缺陷。项目经理本应采取什么措施来避免发生这种问题? ✅ 评估培训结果,确保新员工掌握了必要的知识。 确认培训师具有复杂项目的培训经验。 要求项目团队查看培训材料,确保符合项目要求。 只聘请经验丰富的人力资源,而不是培训应届毕业生。 ✨ 关键词：团队成员能力问题 1️⃣ ✅ 💡 解析：新员工培训后,依然绩效不好,如何避免?四个选项说的都是培训的事,暗示是培训效果不好导致。1️⃣ 培训应以结果为导向,应该验证一下效果,确保员工符合岗位要求;2️⃣ 质量培训师,只需要有足够质量管理经验即可,“复杂项目培训经验”要求过高;3️⃣ 团队成员没有这个判断能力;4️⃣ 能力都是可以通过学习、实践来提高的,4️⃣ 的说法不妥。 五、项目经理负责监管一个复杂的应用程序开发项目,并带领五名直属的团队成员,该项目的客户指定了应用程序的性能参数,项目经理应该如何衡量和提升团队绩效? 根据客户指定的参数来衡量和提升团队绩效。 ✅ 根据关键绩效指标(KPIs),来衡量和提升团队绩效。 根据可交付成果的及时完成情况来衡量和提升团队绩效。 根据标准组织目标来衡量和提升团队绩效。 ✨ 关键词：衡量和提升团队绩效 2️⃣ ✅ 💡 解析：题目问的是如何“衡量”和“提示”团队绩效,但是看选项,说的都是如何衡量绩效。四个选项中,2️⃣ 强调了关键绩效指标,很专业、很全面,包括了 1️⃣ 3️⃣ 的内容;1️⃣ 3️⃣ 相比与 2️⃣,都比较片面;4️⃣ 组织目标太宏观,无法衡量具体团队人员的绩效。 六、项目团队每周要通过演示材料向高级领导汇报项目的最新状态。项目团队负责人必须确保这些材料有意义、高质量且无错误。在查看材料的过程中,团队负责人注意到有两位项目经理提交的演示材料总是存在细节和准确性方面的问题。团队负责人如何才能给团队最好的帮助? 创建提交演示材料的质量和对单,并将核对单分享给团队。 ✅ 面见材料存在细节问题的这两名项目经理,并给予他们辅导。 提醒项目经理注意准备高质量的演示材料。 要求项目经理提前提交演示材料以供审查。 ✨ 关键词：团队成员能力问题 2️⃣ ✅ 💡 解析：题目表达有问题,“两名项目经理”应该说的是两名团队成员,因为题目一开始说,团队成员需要向团队负责人提交演示材料。(团队成员)能力不够,应予以辅导、培训,2️⃣ 正确。 七、项目经理得知项目所需的某些物品的成本将在未来几个月内大幅增长,这将对项目产生负面影响,目前项目的成本绩效指数(CPI)为1.5。项目经理接下来该做什么? 不对项目做任何变更,并购买所需的物品,因为CPI是1.5。 向发起人汇报并请求提供额外的预算,以便尽早购买所需物品。 使用赶工方法提早完成项目,避免成本增加。 ✅ 进行风险评估,以确定成本增加的影响和恰当的后续措施。 ✨ 关键词：风险管理、风险识别 4️⃣ ✅ 💡 解析：项目经理得知某些材料成本未来将涨价,属于风险识别。风险识别后,应分析影响,制定并实施风险应对计划。1️⃣ 没有应对风险;2️⃣ 属于风险应对措施,可以选,但不如 4️⃣ 全面、专业;3️⃣ 与 2️⃣ 一样,是风险应对措施,也是不如 4️⃣ 全面、专业;4️⃣ 先分析影响,再确定应对措施,在四个选项中最好、最正确。 八、在一个硬件升级项目的审查会议上,项目经理了解到,由于硬件平台最近发生了变更,因此潜在不可用的影响将比预期要大,项目经理应对以下哪项作出更新? 问题日志。 ✅ 风险登记册。 经验教训登记册。 应急储备金。 ✨ 关键词：风险扩大、风险管理 2️⃣ ✅ 💡 解析：已识别风险的量化信息发生改变(影响比预期大),应将新的量化信息更新到风险登记册,B正确。题目关键词“潜在”、“预期”,可以判断是已知-未知风险,且尚未发生。 九、某敏捷团队接到一个项目任务,要求对政府重点产品实施变更。团队需要在六个月内完成这项任务。该团队领导接下来该做什么? 创建项目章程和工作说明书(SOW),评估变更和变更范围。 ✅ 为该需求创建高层级的故事集(Eple),并开始安排需求讨论会。 创建完成此变更所需的全部故事,将故事记录在待办事项列表中,其根据商业验收进行优先级排序。 只为下一个冲刺创建全部故事,跳过故事集,直至下一个冲刺。 ✨ 关键词：敏捷、高层级需求 2️⃣ ✅ 💡 解析：敏捷项目,团队首先要做什么?开放式问题,用排除法。1️⃣ 项目经理可以创建项目章程,但不能创建SOW(由客户、发起人提供),而本题问题的不是项目经理做什么,而是团队做什么;另外,1️⃣ 的后半句明显不符合敏捷方法,排除。2️⃣ 重点在后半句,找干系人收集需求,敏捷的需求可以用故事来反映,故事可以像 WBS 一样分解为高层级的故事(史诗级故事)和最底层故事,2️⃣ 的说法没有问题。3️⃣ 敏捷方法不主张也不可能一开始就将所有故事创建出来,另外 3️⃣ 的后半句排序依据也是严重错误。4️⃣ 否定了用户故事(待办项)的细分、细化过程,不妥。 十、在项目实施过程中,项目经理注意到有些团队成员需要接受额外的培训才能继续进行开发任务,项目经理确定了适合他们的培训,现在需要调整项目活动以便安排培训进程。项目经理接下来该做什么? ✅ 降低团队在该冲刺中的产能,不必改变冲刺长度。 保持团队在该冲刺中的产能,不必改变冲刺长度。 团队在该冲刺中的产能,将冲刺长度调整为最多15天。 降低团队在该冲刺中的产能,将冲刺长度调整为最多15天。 ✨ 关键词：敏捷、冲刺周期、时间盒 1️⃣ ✅ 💡 解析：额外的培训必将影响当前的冲刺工作。敏捷项目的每一个冲刺时间是固定的,一般宁可调整冲刺的任务量,也不延长冲刺时间,3️⃣ 4️⃣ 的后半句说法错误;1️⃣ 2️⃣ 之间,3️⃣ 不可能实现;1️⃣ 可以理解为,当有优先级更高的工作必须完成是,可以将本次冲刺中的部分工作调整到下一次迭代或重新放入待办项列表,1️⃣ 正确。","link":"/2024/08/20/pmp_test_daily_20240820/"},{"title":"PMP 考试 - 每日练习 2024&#x2F;08&#x2F;19","text":"仅供自己复习使用。如果侵权请联系删除。 一、项目经理受命负责一个大型复杂项目,团队成员因为一项技术决策的事宜而找到项目经理。项目经理应该采用什么样的决策方法? 项目经理必须对每一项决策进行审批,因为他/她是项目的最终负责人。 ✅ 项目团队成员应在各自的职责和专业领域内做出决策。 应根据情况使用临时决策权,以确保敏捷性和灵活性。 项目经理应咨询发起人的意见,从技术角度审查决策。 ✨ 关键词：团队决策 2️⃣ ✅ 💡 解析：本题考项目中的决策都应该由谁来做。如果团队成员本身很有经验、很专业,可以授权他们在自己熟悉的专业领域进行决策,以提高效率。1️⃣ 说法太绝对,错误;2️⃣ 翻译稍有问题,应该是“可以被授权”而非“应”,由于其他选项错的更多,2️⃣ 可以选;3️⃣ “根据情况”不是一个可以把握原则,工作中无法执行;4️⃣ 与发起人无关。 二、在一次辅导会议中，项目经理向一名初级项目经理简单介绍了使用挣值管理 (EVM) 方法来管理项目的益处，初级项目经理应该参考什么？ ✅ S 曲线。 累积流图。 ❌ 看板面板。 水晶图。 ✨ 关键词：挣值管理、图标参考 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：题目问的是挣值方法的好处，但选项中只有 S 曲线与挣值有关，是挣值技术的基础 BAC 的表现方方式，其他与挣值方法都无关。因此本题应理解为，要使用挣值方法，首先要创建什么？选 1️⃣ 正确。 三、某项目正处于执行阶段,企业提出与批准的范围不符的变更,其中一项请求导致项目超出预算并且进度落后,项目发起人询问如何解决此问题。项目经理首先应该做什么? 修改商业论证。 重新确定项目进度计划的基准。 更新完工估算 (EAC)。 ✅ 查看变更管理计划。 ✨ 关键词：非法变更、范围蔓延 4️⃣ ✅ 💡 解析：典型的变更问题。即使当前项目绩效很差,也要通过变更流程来处理范围变更。4️⃣ 选项最符合变更流程,是变更问题通吃选项。其他都与范围变更无关或不解决范围变更问题。 四、项目经理被告知项目团队的绩效非常低,而且他们必须在下一个任务中改进。为了提高团队在下一个项目中的绩效,项目经理应该采取什么措施? 与项目团队成员讨论沟通和决策等话题。 ✅ 建立绩效管理制度,确保团队绩效得到改善。 ❌ 奖励制度,促进团队成员提升个人绩效。 寻找机会让项目团队参加项目管理研讨会。 ✨ 关键词：提升团队绩效 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：如何提高团队绩效?团队绩效差,无外乎能力不够(应培训),协同配合有问题(应团队建设),士气低落(要激励)。3️⃣ 选项针对的是士气低落,但 3️⃣ 的目的“提升个人绩效”与题目要求不符;1️⃣ 不是解决绩效问题的方法;2️⃣ 建立绩效考核制度,是管理团队绩效的基础,可以考虑;4️⃣ 与题干绩效没有关系。 五、敏捷团队的项目负责人发现一名团队成员在工作中遇到了障碍,影响了团队的工作进展,项目现在面临可能会延期完工的风险。项目负责人应该怎么做? ✅ 在每日站会中识别障碍和相关风险。 在回顾会议中识别障碍。 将障碍报告给职能部门经理。 将障碍和相关风险上报给业务发起人。 ✨ 关键词：敏捷、识别障碍 1️⃣ ✅ 💡 解析：本题要结合选项来判断题目考的是什么。题目考的是,敏捷项目什么场合什么方式识别或提出障碍和风险。基本概念题目,敏捷项目的问题和障碍大多在每日站会上提出,风险也可以在每日站会上提出,1️⃣ 正确。2️⃣ 回顾会议主要是总结经验教训、解决问题,不是提出问题的时机;3️⃣ 障碍与职能经理无关;4️⃣ 更不需要麻烦发起人。 六、项目经理接到任命,负责为公司以前的一个客户管理项目。有人告知项目经理,可能会试图增加项目范围,而不考虑此变更对于时间、成本、质量和风险的影响。为帮助规划和管理预算及资源,项目经理应该采取什么措施? 制定严谨的范围声明并查看历史信息。 拒绝让客户更改范围,并仔细查看经验教训登记册。 将可交付成果分解为工作包,并查看项目章程。 ✅ 引入范围变更流程,并查看项目章程。 ✨ 关键词：变更管理 4️⃣ ✅ 💡 解析：项目范围存在变更的可能性,应事先建立范围变更流程来管理未来可能的范围变更,这是本题的底层逻辑,4️⃣ 正确。1️⃣ 不解决(应对)范围变更问题;2️⃣ 错误概念;3️⃣ 也不能解决范围变更问题。注意,本题问题与项目章程没有直接关系,但选项中说“查看项目章程”没有大的问题。另外,规范的范围变更流程,会全面考虑范围变更都对时间、成本、质量、风险的影响,4️⃣ 可以覆盖题目提及的问题。 七、项目团队在开会讨论团队成员之间最近存在的误解,在讨论期间项目经理注意到有的团队成员没有发声。项目经理应该使用哪种工具来应对这种情况? 强迫。 ❌ 共识。 ✅ 激励。 头脑风暴。 ✨ 关键词：团队信任问题 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：团员开会不主动发言,是信任和融入问题,不能通过规则或强制命令来解决,1️⃣ 排除;可以通过团建以及激励来解决,3️⃣ 正确。2️⃣ 针对意见分歧;4️⃣ 是获得更多创意,与题目问题没有直接关系;都排除。 八、在一个平衡矩阵型组织中,项目经理经常收到一名高级工程师的抱怨,称其他项目团队成员的配合度不够,没有按要求提供必要的报告信息,项目经理首先应该做什么? 请求职能部门经理对配合度不够的团队成员给出解决办法。 ✅ 与所有团队成员共享项目分配矩阵,重点关注每个成员的职责。 与这名高级工程师讨论以往项目中的合作历史。 询问这名高级工程师是否要更改项目职责。 ✨ 关键词：冲突问题、团队成员配合度不够是信任或责任问题 2️⃣ ✅ 💡 解析：团队成员配合度不够,是信任或责任问题,可以通过团建或基本规则解决;没有按要求提供必要的报告信息,是规则问题,可以通过强调基本规则来解决。选项中只有 2️⃣ 和规则有关,责任分配矩阵就是关于工作职责的规则,可以解决题目问题。1️⃣ 甩锅行为,不选;3️⃣ 虽然和团队成员面对了,但说的是不相干的事情,没有直面问题;4️⃣ 屈从于团队成员的错误行为了。本题也可以直接当成问题成员套路题目,找基本规则或面对冲突,也是选 2️⃣。 九、一名关键项目干系人(相关方)与项目团队成员讨论了项目事宜,团队成员得知,其中一个项目交付成果进度超前,预计会在今年内完成。但按照目前的进度来看,这并不现实,团队成员将此问题报告给了项目经理。项目经理该如何处理这一问题? 邀请所有干系人(相关方)召开紧急会议来澄清此问题。 让团队成员向这名关键干系人(相关方)提供一份符合实际的进度计划。 立即将当前项目报告重新发送给所有干系人(相关方)。 ✅ 确定问题的根本原因,并在项目沟通中予以解决。 ✨ 关键词：沟通问题、干系人问题 4️⃣ ✅ 💡 解析：中文翻译没有体现出题目原本的时态问题。题目的第2行应该是虚拟语气,即:关键干系人认为一个可交付成果应提前、在今年内完成;但团队成员认为无法实现。本题或当成进度变更问题,但没有相应选项;或当成干系人问题,应管理干系人期望,2️⃣ 4️⃣ 都是在管理干系人,4️⃣ 明显比 2️⃣ 更全面、周到。1️⃣ 没有必要将干系人问题公开化;3️⃣ 只需要针对提出不合理要求的干系人即可,没有必要针对所有干系人。 十、某项目团队的成员分散在不同地方,他们在整理项目交付之中的数据,质量审查结果表明提供的数据存在问题。项目经理该做什么来解决这一问题? ✅ 提供数据收集指南。 建立集中式质量团队。 为数据收集团队赋能。 请最终用户验证数据。 ✨ 关键词：沟通问题 1️⃣ ✅ 💡 解析：虚拟团队,成员提供给项目经理的数据有误,这属于虚拟团队沟通问题,应在选项中找沟通管理计划或远程沟通工具,但选项中没有。1️⃣ 可以理解为沟通管理计划中对内收集信息的计划要求,近似于沟通管理计划,可以选。2️⃣ 否定了虚拟团队的可行性,错误;3️⃣ 题目中看不出是士气问题,排除;4️⃣ 已确认数据有误,没有必要自扬家丑。","link":"/2024/08/19/pmp_test_daily_20240819/"},{"title":"PMP 考试 - 每日练习 2024&#x2F;08&#x2F;21","text":"仅供自己复习使用。如果侵权请联系删除。 一、一个复杂项目涉及许多干系人(相关方),项目分阶段执行,每个阶段都有明确的项目计划,并且定期进行了跟踪。在项目结束进行绩效测评时,结果表明预算超支而且进度落后。这种绩效差异的原因是什么? 没有准确完成项目状态报告。 成本和进度计划的估算没有考虑缓冲空间。 ✅ 没有对变更请求的范围进行严格控制。 ❌ 没有对项目成本和进度计划进行整合和跟踪。 ✨ 关键词：绩效、预算超支、进度落后 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：本题信息不能锁定任何一个唯一答案,选 2️⃣ 3️⃣ 4️⃣ 皆有可能,题目和答案仅供参考。题目强调了项目复杂,有很多干系人,有明确计划,且定期跟踪,但进度、成本绩效都不好。1️⃣ 不是问题原因,和题目问题无关;2️⃣ 忽略了为已知未知风险预留时间和成本储备,是一个可能的原因;3️⃣ 干系人多,变更失控,也是可能的原因;4️⃣ 监控不到位,也是可能的原因。老师们最终的意见是,5人选 3️⃣,2人选 4️⃣,1人选 2️⃣ (就本人),未能统一。 二、某组织指派一名项目经理负责一个处于执行阶段的项目,项目经理注意到该项目缺乏策略,未能促进社区成员的参与,社区成员现在正向公司提出投诉,要求不得推进项目。项目经理应该如何解决这一问题? 让管理层出面解决社区对项目的不满。 ❌ 寻求非常规策略,与干系人(相关方)完成项目愿景。 ✅ 请机构的发言人传达项目对干系人(相关方)的意义。 激励团队成员重新思考该项目及其目标。 ✨ 关键词：干系人问题 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：典型的干系人问题,应管理干系人参与。1️⃣ 麻烦高层,错误;2️⃣ 一上来就使用“非常规策略”对付干系人,从题干中看不出有任何必要性,且非常规策略很可能是不符合法律或职业道德的,2️⃣ 排除;3️⃣ 属于管理干系人参与,通过宣传共同的利益来影响干系人,可以选;4️⃣ 甩锅给团队成员,不妥。 三、项目经理收到供应商的电子邮件,其中说明一批电脑的发货要再延迟一周,得知这次延迟之后,团队查看了进度计划,提醒了部门经理,并根据新的预计交付日期做出了调整,项目经理应该在哪里记录这些变更? 供应商的网站。 ✅ 项目团队的网站。 公司的外部网站。 软件制造商的网站。 ✨ 关键词：进度（基准）变更、信息公布 2️⃣ ✅ 💡 解析：进度基准调整后,应在哪里记录?本题可以按变更批准后的套路来判断,变更批准后,应通记录在变更日志,并知干系人(受变更影响的人,主要是团队和客户)。四个选项中,相比而言,该变更最应该通知的是项目团队,其他关系都不很直接和绝对。 四、在规范审查期间,一名团队成员表示公司设计的其中一个部件可能存在版权问题,项目经理接下来该做什么? 指出这可以协商,因为这是设计规范的一部分。 ❌ 请设计师在审查期间再次确认设计规范。 ✅ 将此问题提交给合规团队,以确定有效性和影响。 让团队重新设计部件,以避免版权问题。 ✨ 关键词：合规问题 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：典型的合规问题。2️⃣ 3️⃣ 之间,找合规团队确认一下是否侵权显然比 2️⃣ 更加专业。 五、项目团队不清楚干系人(相关方)团队对于项目可交付成果的期望,导致项目团队变得效率低下。为使项目重回正轨,项目经理应该先做什么? ✅ 让干系人(相关方)团体参与进来,了解他们对项目的期望。 将项目团队召集到工作会议中,以便明确定义项目的每个可交付成果。 为项目发起人创建一份快报,将成本绩效指数(CPI)和进度绩效指数(SPI)报告分享给干系人(相关方)团体。 让每个团队成员停止工作,并通知干系人(相关方)团体。 ✨ 关键词：干系人需求、管理干系人参与 1️⃣ ✅ 💡 解析：本题关键词“不清楚干系人对可交付成果的期望”,即需求不明确,应先了解干系人需求。1️⃣ 是让干系人参与,了解干系人需求,正确；2️⃣ 让团队闭门造车,确定可交付成果,错误；3️⃣ 与题目问题无关；4️⃣ 消极等待,而不是积极解决问题。 六、A公司首次开发和推出一种全新复杂原型项目,进度十分紧张,产品满足客户的期望至关重要。项目经理应该如何支持项目的实施并加速证明项目的价值? 查看组织过程资产,确保交付预期价值。 确保在规划阶段明确定义工作包。 ✅ 创建基于频繁发布的计划,以测试产生的价值。 增添一项市场研究任务,以确定客户期望的价值。 ✨ 关键词：快速交付价值 3️⃣ ✅ 💡 解析：进度紧张,如何加速证明(交付)项目的价值?敏捷的增量交付可以加速交付结果并实现商业价值。1️⃣ 前后联系不大,比较空洞的说法;2️⃣ 强调的是预测型方法,不能加速或提前交付价值;3️⃣ 说的是增量型方法,是题目问题的正解;4️⃣ 题目问题的是如何加速交付价值,而非收集需求。另外,从加速证明项目价值角度理解,应该是项目结果进入运营创造了价值,才能证明项目的价值,因此就是加速、尽早交付。 七、项目经理收到干系人(相关方)的反馈,称任务优先级存在冲突,而执行发起人发送的信息含混不清,让人无法确定项目组织的指示。项目经理该做什么? 核实项目协议的目标。 ✅ 对所有必要的参与方进行调研,以达成共识。 评估干系人(相关方)的参与需求。 ❌ 评估优先级并确定目标。 ✨ 关键词：干系人需求、冲突 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：题干的意思是项目需求不明确,干系人之间的意见有分歧,应收集需求并达成一致意见。1️⃣ 项目目标是宏观的,具体需求还需要找干系人收集;2️⃣ 让干系人参与收集需求,是需求问题的正解;3️⃣ 闭门造车,没有让干系人直接参与;4️⃣ 与 3️⃣ 一样,也是避免造车。 八、某团队成员接到任命,要在项目中担任一个新职位,在查看过往的绩效评估资料后,项目经理发现这名团队成员并不具备足够的知识来执行所分配的任务。项目经理该怎么做? 将此事上报给管理人员,请求将这名团队成员调到更符合其能力水平的职位。 与人力资源部门讨论此事,采取行动为这名队员实施绩效改造计划。 ✅ 针对这名团队成员的不良绩效提供建设性反馈,并鼓励他/她在下一年度取得提升。 让其他团队成员针对这项任务提供直接支持,明年再将此任务分配给这名团队成员。 ✨ 关键词：团队成员能力问题 3️⃣ ✅ 💡 解析：团队成员能力不够,应该向其提供培训、指导,但选项中没有,只能使用排除法。1️⃣ 不应上报,后半句调换岗位也不妥,1️⃣ 排除;2️⃣ 不是 HR 的责任,是项目经理的责任;3️⃣ 向其提供建设性反馈和鼓励其提升,相对较好,可以选;4️⃣ 换人,也不妥。 九、项目经理新加入到组织中,并且正在考虑引入敏捷法,他/她在思考该组织的一些特征。这些特征更易于支持跨部门协作的敏捷原则。项目经理应该纳入哪三项变更?(选择三项) 长期预算限制和组织的详细情况介绍。 ✅ 转变其对看待、审视和评估员工方式的组织意愿。 ✅ 项目、项目集和项目组合管理职能的集中化或者分散化。 ❌ 短期预算限制和组织的详细情况说明。 ✅ 高管层的变更意愿。 ✨ 关键词：推广敏捷、纳入变更 3️⃣ 4️⃣ 5️⃣ ❌ -&gt; 2️⃣ 3️⃣ 5️⃣ ✅ 💡 解析：想在组织内推广敏捷方法,高管和组织层面的支持肯定是重要因素,因为自上而下推广比自下而上要容易很多,2️⃣ 5️⃣ 可选性;相对于职能型管理,敏捷方法和项目管理方法本身都是在推崇分散化管理,因此 3️⃣ 也是需要考虑的重要因素;预算和推广敏捷方法与否没有直接关系,敏捷方法的主要目的是降低风险,提升客户满意度,因此 1️⃣ 4️⃣ 排除。 十、在敏捷项目中,项目负责人应该如何让干系人(相关方)及时了解当前已实现的价值? 根据要求向干系人(相关方)提供他们需要的最新消息。 发送包含所有重要信息的每周状态报告。 请求干系人(相关方)参与每日项目会议。 ✅ 请求干系人(相关方)参加迭代演示的结尾部分。 ✨ 关键词：敏捷、信息发射源 4️⃣ ✅ 💡 解析：敏捷项目已实现的价值、功能,通过定期的冲刺评审会议向干系人展示。四个选项中,4️⃣ 的说法最接近这个意思。","link":"/2024/08/21/pmp_test_daily_20240821/"},{"title":"PMP 考试 - 每日练习 2024&#x2F;08&#x2F;22","text":"仅供自己复习使用。如果侵权请联系删除。 一、一份客户反馈表显示,客户对项目的进度感到满意,但对透明度和沟通不满意,项目经理分析了反馈并采取补救措施,项目经理应采取哪三种措施?(选择三项) ✅ 每日与客户召开电话会议,分享总体项目状态并获取反馈。 ✅ 征求客户对报告模板内容的意见,并在需要时进行更新。 建议修改反馈表,根据输入自动计算项目总体评分。 与高级管理人员和客户会面,讨论项目总体评分较低的原因。 ✅ 每周与团队和客户举行会议,讨论功能、风险和问题的状态。 ✨ 关键词：透明度不满意、沟通不满意、干系人需求 1️⃣ 2️⃣ 5️⃣ ✅ 💡 解析：本题是典型的沟通问题,五选三,可以使用排除法,排除不合适的两个选项即可。1️⃣ 每日与客户的电话会议,是一种具体的沟通方式,可以提供比较充分的信息;2️⃣ 说的是沟通需求分析,是沟通问题的正解;3️⃣ 针对沟通问题,没有这种说法,排除;4️⃣ 虽然是与干系人会面,但讨论的不是沟通问题,排除;5️⃣ 与 1️⃣ 类似,也是一种具体的沟通方式,且比 1️⃣ 的频率更合适。五个选项中,3️⃣ 4️⃣ 相对较差,其他三个选项的是在解决沟通问题,可以选。 二、负责人刚刚开始一个项目,项目情况特殊,要求紧急交付,没有时间进行项目团队建设,所以团队也没有机会享受组建团队的过程。项目负责人首先应该做什么? 强调项目的目标,确保团队朝着目标努力,并采用包容性协商方法。。 ✅ 提供信任环境,让每个团队成员都有能力,有技术,并愿意与其他团队成员一起协作。 鼓励团队以任务为导向,让他们能够更快向客户交付增量产品。 提供没有阻碍的环境,让团队能够高效处理任务。 ✨ 关键词：团建作用（建立信任） 2️⃣ ✅ 💡 解析：新项目,及时时间紧急,也要尽可能地开展团队建设活动,这是管理团队的基本原则。1️⃣ 忽略了团队建设工作,不妥;2️⃣ 还是在努力的进行团队建设,提高个人能力以及团队协作氛围,正确;3️⃣ 与 1️⃣ 类似,忽略了团队建设工作;4️⃣ 只强调了消除障碍,说法没有错误,但说的与团队建设工作没有直接关系。本题属于欲擒故纵题目,考验大家的原则是否坚定。 三、项目由于团队资源被重新分配给组织内更关键的项目而暂时搁置,在项目准备重启时,项目经理应该如何确保为项目团队正确分配项目资源? 在为项目分配资源之前确保关键项目已经完成。 查看分配给低优先级项目的资源,用于替代被抽调的团队成员。 ✅ 识别项目资源并了解相关技能和能力。 ❌ 查看项目要求并识别已适当调整的项目资源。 ✨ 关键词：确保为项目团队正确分配项目资源 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：如何分配项目资源?应根据工作任务本身的需要,结合资源类型和资源技能来安排。1️⃣ 说法错误,因为资源可以兼职服务于项目;2️⃣ 资源是否可以分配,主要看资源工作是否满负荷,是否有可用时间;3️⃣ 是分配资源的正解;4️⃣ 前半句没有问题,但后半句不知所云。四个选项,只有 3️⃣ 说到了点上,其他都不相干或不重要。 四、项目发起人明确表示将按照增加的价值来衡量项目的成功,项目负责人接下来应该做什么? 筹备一个指导委员会。 确保每日会议以价值为主要着眼点。 ✅ 按优先级列出可交付成果的批准机制。 ❌ 检查不同的项目交付方法。 ✨ 关键词： 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：因为项目的成功是按交付的价值衡量的,而项目的价值主要体现在可交付成果上,因此,应尽量交付价值高的可交付成果。要实现这一目标,必须先对项目可交付成果进行优先级排序,确保交付的结果都是价值最高的任务。1️⃣ 与题目问题无关；2️⃣ 与题目问题无关；3️⃣ 正确；4️⃣ 与题目问题无关。 五、项目经理已完成项目管理计划,正准备召开综合规划会议以确定项目基准进度计划,为了确保得到项目干系人(相关方)的支持,项目经理应该做什么? 召开会议之前拟定并分发进度计划草案。 ❌ 尽早筹划会议并利用组织过程资产(OPAs)。 邀请具有类似项目经验的项目经理参加规划会议。 ✅ 确保所有职能部门和业务单位都有人出席会议。 ✨ 关键词：获得干系人支持、管理干系人 2️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：制定好项目基准进度计划后,如何召开会议获得干系人的批准?应让干系人对计划进行反馈,再获得干系人对计划的批准或认可。1️⃣ 是正确说法,但不重要;2️⃣ 与 1️⃣ 一样不重要,且本问题与组织过程资产无关;3️⃣ 没有这个说法,也没有必要这样做;4️⃣ 要获得干系人支持,让干系人参与会议很重要。本题也可以简单当成干系人问题,即如何获得干系人对项目的支持,选项中只有 4️⃣ 是管理干系人的正确选项。 六、一个正在进行的项目中,干系人(相关方)要求只有一周时间完成市场调查和业务分析,而业务分析师提出的时间是六周,项目经理该怎么做? 由于这个要求与项目初始目标相矛盾,应该中断项目的。而且如果有必要,应启动一个有新目标的新项目。 ✅ 与分析师合作来决定如何满足干系人(相关方)的要求。 与上级管理层沟通,表明干系人(相关方)的要求不能为项目增加价值。 继续按初始计划推进,因为新的要求超出了项目范围。 ✨ 关键词：冲突 2️⃣ ✅ 💡 解析：两名重要干系人就同一个问题产生了巨大的意见分歧,可以当成冲突问题,尽量让双方达成一致意见,但选项中没有,只能使用排除法。1️⃣ 中断项目,是很负面的建议,排除;2️⃣ 虽然说是一边倒的做法,但如果不能达成一致意见,首先还是要争取满足干系人需求,比 4️⃣ 选项主动;3️⃣ 与管理层无关,且后半句说法不合适;4️⃣ 也是一边倒,直接否定了干系人的要求,很被动。1️⃣ 3️⃣ 直接排除,2️⃣ 4️⃣ 之间,2️⃣ 较主动。 七、项目经理负责一个关键制造生产系统并管理着一个项目,需要将准备报废的输送机系统升级为现代输送机系统。部门副总裁近期宣布了一项重大人事重组计划,现在已经生效。要尽可能避免项目中断,项目经理应该先采取哪两项措施?(选择两项) ✅ 召集团队成员一起协作并分享信息。 联系副总裁了解这次人事变动的原因。 联系输送机供应商以提供正式的延迟通知。 ✅ 与项目发起人会面,了解更多看法。 向副总裁提供一份报告,说明人事变动的影响。 ✨ 关键词：重大人事重组计划 1️⃣ 4️⃣ ✅ 💡 解析：公司裁人,项目经理应如何避免项目被中止?外部事业环境因素严重影响项目,这符合上报条件,在上报之前,应先记录、分析影响。1️⃣ 可以理解为分析影响,可以选;2️⃣ 木已成舟,公司的既定政策,了解原因也于事无补;3️⃣ 未必一定延迟,有可能被终止,3️⃣ 不必然,也相对不重要;4️⃣ 属于上报发起人,并有可能获得更多支持,正确;5️⃣ 会考虑对项目影响并可以拯救项目的是发起人,5️⃣ 找错人了。 八、在一个快速跟进项目中,项目经理意识到某些高级团队成员的任务分配过多,他们要承担多个项目任务,这些团队成员没有按要求及时汇报任务的进展和状态,或者根本没有汇报,项目经理应该采用什么方法来解决这个问题? 与职能部门经理讨论如何通过培训来提高这些高级成员的绩效。 ✅ 与职能部门经理讨论如何为团队增加更多资源。 与项目规划人员商量重新安排一些活动,以减轻压力。 与这些高级成员商量,留出时间辅导其他同事,并将任务委派给其他同事。 ✨ 关键词：资源冲突、资源超负荷 2️⃣ ✅ 💡 解析：典型的资源超负荷(资源冲突)问题,应找资源的职能经理协商、谈判,以获取职能经理在资源使用方面对项目的支持、配合,但选项中没有。使用排除法,1️⃣ 不是团队成员能力不够,且即使能力不够也不用麻烦职能经理;2️⃣ 当成资源不够,问职能经理申请更多资源,在没有最佳选择时,可以考虑;3️⃣ 资源的时间安排是职能经理控制的,项目规划人员没有此权力;4️⃣ 资深团员连自身任务都没时间完成,更没有时间去指导其他同事,且任务委派是由职能经理负责的,不是团员自己能决定转移给别人的。 九、项目经理正在制定项目沟通规划,有大量干系人相关方关注项目进展,为了让所有干系人(相关方)掌握最新情况,项目经理就不同的沟通机制咨询了专家的意见,项目经理接下来该做什么? 指派一名团队成员,专门负责干系人(相关方)的沟通要求。 安排定期视频会议,与干系人(相关方)一起审查项目状态。 选择外包的专用热线和帮助平台,供干系人(相关方)致电了解项目状态信息。 ✅ 建立项目知识库并建立干系人(相关方)登记册,按需从中查询信息。 ✨ 关键词：沟通方式、大量干系人、拉式沟通 4️⃣ ✅ 💡 解析：典型的沟通问题,应查看或更新沟通管理计划,或对干系人进行沟通需求分析,4️⃣ 可以理解为进行沟通需求分析,可以选。1️⃣ 沟通管理的责任人是项目经理,不应授权给某一团队成员负责;2️⃣ 采取千人一面的沟通方法,不符合定制化沟通原则;3️⃣ 与 2️⃣ 一样,是千人一面的沟通方式。 十、最近结束的质量审计未通过,按照审计结果,需要完成多个行动事项,新上任的项目经理正和团队一起审查项目状态,他们确定了新的干系人(相关方),并且可能需要为项目增添新的审计资源。项目经理接下来该做什么? ✅ 实施干系人(相关方)参与计划。 实施整体变更控制。 更新质量管理计划。 更新风险管理计划。 ✨ 关键词：新的干系人 1️⃣ ✅ 💡 解析：识别新的干系人之后,应该怎么办?应记录在干系人登记册中,进行干系人分析并制定干系人参与计划,然后管理干系人(实施干系人参与计划)。只有 1️⃣ 说的是干系人管理活动,其他都与题目问题无关。由于英文的语序问题,本题中的“审计资源”应该就是确定(识别)的新干系人。","link":"/2024/08/22/pmp_test_daily_20240822/"},{"title":"PMP 考试 - 每日练习 2024&#x2F;08&#x2F;23","text":"仅供自己复习使用。如果侵权请联系删除。 一、某项目经理对组织中的一个重要项目使用敏捷法,已识别的一个风险是该项目需要高水平的技术能力来完成多个可交付成果。作为服务型领导,为了降低或减轻此风险,项目经理该怎么做? 请职能部门经理指派团队中最熟练的技术人员,而不考虑其当前的任务分配。 与项目发起人会面,移除需要高技术能力来开发的可交付成果。 ✅ 预测培训和辅导方面的预算,确保团队完成良好的培训,能够应对项目的所有技术风险。 监控风险,一旦风险变成现实,使用管理储备来减轻风险。 ✨ 关键词：团队成员能力问题 3️⃣ ✅ 💡 解析：该风险应对方式是提升团队的技术技能。这可以通过培训实现,3️⃣ 的说法就是通过培训解决问题,是本题最好的答案。1️⃣ 找职能经理增加高技能成员,不如内部培训、提升更主动、更节省,不是最佳选择;2️⃣ 麻烦发起人了,且非常消极、被动,再者,消减范围要通过变更流程,由 CCB 而非发起人批准;4️⃣ 已知-未知风险,不应使用管理储备。 二、某公司的转型过程导致一名项目团队成员将离开团队,从而会影响项目的完整交付。项目经理该怎么做? 让这名团队成员在离开之前与同事进行适当的交接。 与转型团队讨论在项目结束前留下这名团队成员的可能性。 将在项目结束前让这名团队成员离职的影响告知更高级别的管理人员。从而让管理人员参与解决此问题。 ✅ 在团队会议中探讨这名团队成员离职的影响并制定行动计划。 ✨ 关键词：团队成员离职、风险 4️⃣ ✅ 💡 解析：团队成员离职,一般当成风险识别,应首先分析影响,再制定应对策略,4️⃣ 是此类问题的标准答案。1️⃣ 虽然没有分析影响,但属于正确做法的,包含在 4️⃣ 之内,或在 4️⃣ 之后执行。2️⃣ 比较被动,且即使留下来了,矩阵型组织的项目经理无法为其提供编制、工资;有学员会说,该团员可能只是离开团队,不是离职,如果这样,该成员是否能留下,应找其职能经理协商、谈判;3️⃣ 项目经理的责任,无须麻烦高层。 三、某项目经理带一个矩阵型组织工作,负责管理一个内部软件开发项目,该项目意在减少公司内部追踪系统中的冲突,完成(干系人)相关方分析后,经理安排与职能部门经理举行介绍会,以协调对项目的支持。在确定每个干系人(相关方)的关注度和投入度后,项目经理将团队召集到一起。项目经理接下来该怎么做? 更新干系人(相关方)登记册,移除对项目结果缺乏关注度或投入度的干系人(相关方)。 检查资源分解结构,确定如何解决干系人(相关方)对项目缺乏投入度问题。 评估干系人(相关方),并从工作分解结构中移除分配给未加入的干系人(相关方)的工作包。 ✅ 创建权力/影响网络,根据干系人(相关方)影响项目结果的能力对他们进行分类。 ✨ 关键词：干系人参与计划、干系人分析 4️⃣ ✅ 💡 解析：干系人识别后,下一步做什么?下一步应进行干系人分析,制定并实施干系人参与计划,4️⃣ 正确,说的是干系人分析。1️⃣ 此时重点应是记录新的干系人,而非删除干系人,且干系人是否应删除,要根据其和项目的关联性,而非其态度;2️⃣ 资源分解结构显示的是项目所需资源,不包括外部干系人;3️⃣ 工作包主要是分配给团队成员,而非干系人。2️⃣ 3️⃣ 都与管理干系人无关,1️⃣ 是管理干系人的错误说法。 四、敏捷团队参与了新领域的项目,他们一直在根据假设和有限的技能来制定项目决策,导致了返工和延误。项目经理应该怎么做? 记录返工和延误,并在经验教训会议上进行讨论。 查看假设并与团队进行详细讨论。 评估差距并向专家寻求必要的指导。 4️⃣ 承担起辅导团队的责任,防止进一步延误。 ✨ 关键词：敏捷、团队成员能力我呢提 4️⃣ ✅ 💡 解析：题目暗示,敏捷团队技能有限,且经验不够(根据假设做决策),应对其进行培训、指导。1️⃣ 没有抓住根本问题;2️⃣ 与 1️⃣ 类似,针对的还是表面现象;3️⃣ 敏捷团队能力不够,应由仆人式领导的项目经理负责培训、指导;4️⃣ 符合敏捷项目仆人式领导的定位。 五、一位项目经理正在处理一个金融领域的敏捷产品研发项目,在关键项目验收的执行过程中,项目经理注意到团队的速度落后于可交付成果的要求。此外,这是该团队首次采用敏捷生命周期。项目经理应采取什么措施才能满足最后期限的要求? 采用技术型管理风格。 采用服务型领导风格。 采用指导性风格。 采用有想象力的风格。 ✨ 关键词：领导风格、敏捷型项目的项目经理属于仆人式领导风格 2️⃣ ✅ 💡 解析：敏捷型项目的项目经理属于仆人式领导风格,即服务型领导,2️⃣ 正确。本题考基本概念,不多解释了。 六、当一位关键干系人(相关方)提供了关于客户对某些产品功能的信息时,此对一个项目团队正在计划即将开展的迭代工作。技术领导希望继续致力于有关产品的一些新功能的工作,但是产品负责人希望添加一些新任务,以对关键干系人(相关方)的反映作出响应。项目经理该做什么? 要求产品负责人为下一个冲刺的新任务确定优先级。 继续执行计划,并要求进行变更请求审查。 要求技术领导开始处理新任务。 ✅ 与团队协同工作,优先处理那些可以增加更多价值的任务。 ✨ 关键词：敏捷、代办事项优先级 4️⃣ ✅ 💡 解析：本题答案有争议。从一般原则来说,应该由产品负责人负责更新待办项列表,但本题中,“技术领导”和“产品负责人”分别希望添加一些新任务,他们两位属于地位平等的干系人。如果选 1️⃣,产品负责人就属于既当运动员,又当裁判员了,有失公允,在本题中属于“人治”而非“法治”;4️⃣ 按照价值来判断哪位干系人希望添加的功能更优先,符合敏捷的基本原则,属于“法治”而非“人治”。个人认为 4️⃣ 更好。 七、某项目经理正在领导一个业务转移项目,发起人同意,从项目业绩中收益的四个资金团队将提供所有项目资金。在项目开始时,其中一个业务团队拒绝提供资金。项目经理该做什么? 与其他三个业务团队沟通,并请求他们提供额外的资金,以此来弥补四个团队带来的资金损失。 终止项目,直至发起人解决资金缺口时为止。 ✅ 让关键干系人(相关方)参与解决资金缺口问题,沟通其带来的影响,并获得发起人的批准,以推进完成解决方案。 继续实施此项目,并积极寻找替代性的资金投入。 ✨ 关键词：管理干系人参与 3️⃣ ✅ 💡 解析：典型的干系人问题,应管理干系人参与。1️⃣ 回避了不提供资金的业务团队,没有面对;2️⃣ 项目经理没有权限终止项目;3️⃣ 让干系人参与,是管理干系人的一个重要方式,正确;4️⃣ 类似于 1️⃣,还是没有直面不提供资金的业务团队。 八、在对测试结果进行评审期间,项目经理得知进度计划可能出现延误,原因是一位团队成员的模块存在缺陷。团队成员的士气低落。项目经理该做什么来应对这种情况? 在会议中讨论此问题,并确保团队成员的交付具有良好的质量,这样项目经理不会受到影响了。 将此问题上报至职能部门经理,以确保团队成员符合所需的资源需求开展工作。 请求替换该成员至另一个可能更适合其表现良好的项目中。 ✅ 提醒团队遵守基本规则,与团队成员召开会议,确定任何技能缺口,并提供额外的培训。 ✨ 关键词：团队存在障碍 4️⃣ ✅ 💡 解析：某一团队成员的绩效有问题(开发的结果有缺陷),导致士气低落。有问题,要面对,应先确定团队成员绩效不好的原因,然后有针对性地解决。1️⃣ 此类负面问题不宜公开处理;2️⃣ 团队成员的绩效问题,不需要上报,也不是职能经理的责任;3️⃣ 换团队成员是逃避责任的错误做法;4️⃣ 前半句与题目关系不大,但也没有毛病,后半句非常契合题目,是正确做法。 九、某项目经理正与多个干系人(相关方)协同工作,以确保他们的努力与新项目的目标是一致的。项目经理应做什么来确保顺利达成一致? ❌ 为项目创建关键绩效指标(KPIS)和度量指标,专门用于解决每个干系人(相关方)的需求。 ✅ 从干系人(相关方)那里获得关于项目应该采用哪些度量指标的一致同意。 从同一个项目组合中的类似项目中获取关键KPIS和度量指标。 确保在干系人(相关方)的互动中充分获得项目范围。 ✨ 关键词：与干系人就新项目的目标达成一致 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：题目问如何与干系人就新项目的目标达成一致？项目目标应包含一系列的成功标准,如时间、成本、范围、质量等,见 PMBOK 第 6 版 1.2.6.4 第二段的内容，1.2.6.4 还强调“主要干系人和项目经理应就这些问题达成共识并予以记录”。这些成功标准必须获得干系人的同意,1️⃣ 3️⃣ 没有找干系人,2️⃣ 4️⃣ 都强调找干系人,但 4️⃣ 只包括范围,而且没有强调度量指标。 十、项目经理正在制定项目管理计划,目的是使用新技术构建和落实特别定制的员工门户网站。该门户网站将提供自助服务,如时间跟踪,报告结果更新以及个人详细信息,内部人员不具备这项新技术方面的经验。项目经理应该做些什么来弥补技能缺口并将风险最小化? 搭建平台,并利用内部资源管理实施工作,从而降低成本。 将整体实施工作外包,并要求在其中包含为期1个月的保修和支持。 利用内部资源搭建平台,分配时间以进行在职培训并提供相应鼓励。 ✅ 利用内部资源来开发平台,分配预算和时间,以进行在职和外部培训。 ✨ 关键词：培训、降低风险 4️⃣ ✅ 💡 解析：团队成员缺少技术经验,首先考虑通过培训来解决。3️⃣ 4️⃣ 都是培训,但题目强调了“内部人员不具备这项新技术方面的经验”,内部交叉培训就排除了,专门的培训一般是要花钱的,因此 4️⃣ 比 3️⃣ 更准确。","link":"/2024/08/23/pmp_test_daily_20240823/"},{"title":"PMP 考试 - 易错和令人困惑的问题集（一）","text":"仅供自己复习使用。如果侵权请联系删除。 一、从事软件开发项目的项目经理向软件开发人员询问任务的状态，开发人员回应称，该任务已在 1 周前交付，并提到该交付是通过特定的项目管理软件报告的。项目经理下一步该怎么做？ 审查干系人参与计划，并交流哪种技术可用于开发、传输和存储项目工件。 让软件开发人员参与进来，让他们使用这个项目管理软件，然后进行一次培训师培训活动，以确保每个人都能使用它。 ❌ 研究项目管理软件，以了解它是如何工作的，并将其作为可接受的软件来保存项目工件。 ✅ 评审沟通管理计划，并传达哪种技术将被用于开发、传输和存储项目工件。 ✨ 关键词：沟通问题、敏捷 3️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：典型的沟通问题，开发人员完成任务却没有有效汇报项目经理，找沟通管理计划。本题也可以当成规则问题，但选项中没有。 🤔 没有明确的关键词指向了敏捷。并且敏捷并不强调状态报告和沟通管理计划。 二、一个项目成功地交付了它的产品成果，并且客户满意度很高。但是，在内部审计期间，发现缺少某些必要的流程文档和批准，项目被评估为不符合。项目经理下一步该怎么做？ ❌ 与项目管理办公室 (PMO) 一起审查最新的项目管理标准，并对质量管理计划进行修改。 ✅ 执行质量保证，根据质量管理计划审查流程并找出差距。 用丢失的文档和批准来检查和更新项目文档存储库。 改变质量管理流程，以符合项目目标。 ✨ 关键词：质量管理、没有遵守公司的流程文档化和审批的要求，这属于不遵守公司流程的问题，即质量保证问题 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：结果没问题，但没有遵守公司的流程文档化和审批的要求，这属于不遵守公司流程的问题，即质量保证问题。应进行治理保证，确保流程被遵守，2️⃣ 正确。 📖 PMBOK：管理质量有时被称为“质量保证”，但“管理质量”的定义比“质量保证”更广，因其可用于非项目工作。在项目管理中，质量保证着眼于项目使用的过程，旨在高效地执行项目过程，包括遵守和满足标准，向干系人保证最终产品可以满足他们的需要、期望和需求。管理质量包括所有质量保证活动，还与产品设计和过程改进有关。管理质量的工作属于质量成本框架中的一致性工作。 三、项目已经准备好开工，资源已经配置好。开发经理随后通知项目经理，由于家庭紧急情况，关键资源不再可用。开发经理表示，所有其他开发人员都被分配到其他项目，任何开发人员都没有能力承担额外的工作。接下来项目经理应该做些什么来满足这种资源需求呢？ 根据项目优先级确定资源分配选项。 ✅ 对现有资源分配进行更改，并通知开发经理。 ❌ 与发起人会面，以确定如何调整时间表的基线。 将情况告知发起人，并要求延长目标完成日期。 ✨ 关键词：基准变更 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：本题答案在 1️⃣ 2️⃣ 之间争议很大。当缺乏资源并且无法获得额外的资源时，只能对现有资源进行资源平衡（向非关键路径要资源），解决资源不足的问题，即 2️⃣ 选项。1️⃣ 如果将描述改成“根据任务的优先级确定资源分配选项”，则可以理解为是在做资源平衡工作，但 1️⃣ 强调的是“根据项目优先级”，资源不够用时对项目进行优先级排序确定资源使用顺序，这是公司高层的权力，不是项目经理的权力，因此个人认为 1️⃣ 不合适。3️⃣ 4️⃣ 都麻烦发起人了，不选。本题争议很大，本解释纯属个人意见，仅供参考。 🤔 虽然是越早进行风险（资源离职请假等视为风险）处理越好，且还处于项目初期，但站在这个角度麻烦发起人反而是不对的。因此 3️⃣ 和 4️⃣ 其实不该选，而 2️⃣ 是最保守的选择，不会错。 📖 需要向发起人上报的场景： 政府出台的新政策、法规影响项目（包括正面、负面影响）。 识别了影响整个组织或其他项目的风险。 项目经理发现商业论证有误（应先重新论证,再上报发起人）。 项目危害社会、公众利益了。 由于外界因素，项目被迫暂停了。 新任项目经理发现前任项目经理虚报项目的当前绩效。 出现职业道德问题，如歧视性政策，弄虚作假，违法行为等。 超出项目经理能力范围（多与相关方问题有关，如项目经理反复多次说服未果）。 四、一位项目经理正在领导一个混合项目，为一家旅游业初创公司开发应用程序。由于不可预见的事件，由于新的旅行限制，许多客户将无法使用功能和整体解决方案。项目经理首先应该做什么？ 释放团队，帮助他们在项目中发挥潜力。 ✅ 向组织的管理层询问关于项目方向的建议。 ❌ 评估环境变更，并建议项目的支点。 如果无法达到商业价值，则暂停项目，并收集经验教训。 ✨ 关键词：事业环境因素改变 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：外部事业环境因素严重影响项目，此类问题符合上报情况，2️⃣ 正确。另外，题目关键词是“许多客户将无法使用功能和整体解决方案”，整体解决方案不能使用，则整个项目存在的价值、意义需要重新考虑，项目终止的可能性很大，终止项目是发起人的权力，因此也应上报。1️⃣ 解散项目团队的意思，这要等发起人终止项目的命令；3️⃣ 项目存在的基础发生动摇，项目经理无权坚持继续执行项目；4️⃣ 暂停项目也是项目发起人才有的权力。 五、在每日站会上，开发人员指出一个待办事项将不会交付，因为他们需要在接下来的几天里意外休假。待办事项是用户在下一个冲刺评审中所期望的功能的先决条件。项目负责人应该怎么做？ 要求开发人员推迟休假，直到待办事项列表项目交付完毕。 ✅ 要求开发经理提供几天的替代人员。 ❌ 与产品负责人合作，变更冲刺代办事项列表中的优先级。 与产品负责人合作，通知用户功能延迟。 ✨ 关键词：敏捷、待办事项优先级 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：团队成员辞职、请假，一般当成风险识别处理，要分析影响并制定和实施风险应对措施。1️⃣ 很被动、勉强，而且没有考虑团队成员的权益；2️⃣ 找替代人员，属于具体的风险应对措施；3️⃣ 如果不找替换人员，会影响迭代开发速度，但不影响待办项列表的优先级；4️⃣ 躺平、不作为，更加被动。排除法，2️⃣ 相对较好，当成风险应对。 🤔 待办项列表的优先级不会收到影响，因此 3️⃣ 有明显错误可以排除。 六、项目团队成员识别了采购风险，并向项目发起人发送了一封强调风险的电子邮件，发起人将邮件转发给项目经理，询问进一步的细节。在与发起人交谈后，项目经理决定采取预防措施。项目经理应该和他们的团队一起审阅哪一份文件？ ❌ 风险管理计划。 质量管理计划。 沟通管理计划。 ✅ 采购管理计划。 ✨ 关键词：识别了新的风险、预防措施 1️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：采购中风险管理，要依据风险管理计划还是采购管理计划来执行？查看 PMBOK 第 6 版 11.1.3.1 风险管理计划内容，和 12.1.3.1 采购管理计划内容，我们会发现，前者内容不涉及采购工作，而后者内容包括了“风险管理事项”，因此选 4️⃣。 七、一位 CEO 要求项目经理提供一个将在 4 年内执行的长期项目的预算估计，项目经理应该怎么做？ ✅ 包括事业环境因素。 进行自下而上的估算。 ❌ 包括预计通货膨胀率。 进行类比估算。 ✨ 关键词：成本估算 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：本题考制定预算时需要考虑的因素（输入），1️⃣ 3️⃣ 都正确，但从 1️⃣ 中包括 3️⃣，且比 3️⃣ 更全面。本题考点在制定预算过程的输入中有直接显示。本题也可以当成常识问题。","link":"/2024/07/01/pmp_test_what_confuses_me_01/"},{"title":"PMP 考试 - 易错和令人困惑的问题集（二）","text":"仅供自己复习使用。如果侵权请联系删除。 一、经过几次迭代之后，项目经理决定将产品展示给一个关键的干系人，干系人的反馈是团队在许多特性上错过了标记，项目经理应该做些什么来避免将来出现这种情况？ ❌ 与所有关键干系人召开需求收集会议，再次评估范围，并根据会议重新安排和待办项的优先次序 ✅ 安排充分的冲刺演示，以收集干系人的早期反馈，并相应地调整计划。 将设计思维实践纳入产品生命周期，以更好地理解产品的角色，并更有效地匹配他们的需 求。 评估团队的技能，寻找有产品设计经验的人，并分配给那个人重建产品界面的任务。 ✨ 关键词：敏捷、错过标记（验收不通过）、避免 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：敏捷项目，多次迭代后，干系人说结果不符合要求。这种情况本不应该出现，因为敏捷项目强调每次迭代结束都应让干系人进行迭代（冲刺）评审（验收），问题应该及早发现，而不是多次迭代后才发现。2️⃣ 正确，即每次冲刺结束都要让干系人验收（冲刺评审会上演示结果）；1️⃣ 敏捷项目不仅要根据冲刺前收集的需求执行，还要根据冲刺后的评审意见调整，1️⃣ 不能解决全部问题；3️⃣ 敏捷强调根据反馈随时调整，3️⃣ 还是幻想能一劳永逸地收集到需求；4️⃣ 不是团队技能问题。 🤔 敏捷中干系人对产品不满意似乎都可以让他们参与迭代评审会议解决，或是在加入待办列表前确定需求对应的 DoD。 二、在项目规划阶段，项目经理被告知，在另一个部门实施所需的 IT 系统之前，他们不能开始一项活动。项目经理应该怎么做? 快速跟进这种依赖性，以避免延误项目。 执行整体变更控制。 ✅ 在项目日程中包含相关性。 ❌ 要求 IT 部门对所需的系统进行优先级排序，以满足时间表的要求。 ✨ 关键词：依赖外部因素、强制性依赖关系应当成项目制约因素先记录下来 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：题目描述了一种外部强制性依赖关系，应当成项目制约因素先记录下来，即选 3️⃣。 1️⃣ 强制性依赖关系是不能并行的（快速跟进只用于选择型依赖关系）；2️⃣ 是否需要变更，题目没有暗示，如果需要也在 3️⃣ 之后考虑；4️⃣ 项目经理未必有这个权力，多项目的资源优先级一般由公司高层根据战略计划确定。 三、一位项目经理从一位营销分析师那里了解到，竞争对手刚刚发布了一份新闻稿，宣布将推出一款采用特定创新技术的产品。项目经理对此表示担忧，因为该公司正在启动一个涉及相同创新技术的项目。新项目的一个关键目标是该产品将率先上市，并赢得创新技术。项目经理接下来应该做什么？ ✅ 在问题日志中记录问题，并上报给项目发起人。 通知项目发起人并建议取消项目。 ❌ 审查项目章程中的项目目标和成功标准。 请研发领导决定下一步措施。 ✨ 关键词：事业环境因素改变 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：（外部的）事业环境因素影响项目，这属于需要上报的情况。此类题目的套路顺序是：记录（问题日志或风险登记册）​——&gt; 分析影响 ——&gt; 上报发起人 ——&gt; 规划和实施应对1️⃣ 正确。2️⃣ 太消极，不是项目经理该做的；3️⃣ 是项目规划时考虑的，与题目问题无关；4️⃣ 甩锅、失职的行为。 🤔 “审查项目章程中的项目目标和成功标准”并不是在分析影响，即使是也在记录之后，这么看来选 1️⃣ 无懈可击。 四、一位项目经理正在为一家大公司管理一个创新项目。项目经理计划使用电子邮件作为主要沟通渠道，但是产品负责人更喜欢使用另一种经过批准的沟通工具，而不是电子邮件。项目经理应该怎么办？ 联系发起人，请求关于项目团队要使用的沟通工具的指导。 ✅ 根据产品负责人的偏好更新沟通管理计划，并分发给团队。 ❌ 建议团队开始使用产品负责人建议的沟通工具。 要求产品负责人使用电子邮件，因为使用其他工具会增加工作量。 ✨ 关键词：冲突、沟通问题 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：PO 不喜欢当前的沟通方式，属于典型的沟通问题。沟通问题，找沟通管理计划，2️⃣ 正确。1️⃣ 不应麻烦发起人；3️⃣ 没有上升到沟通计划的高度；4️⃣ 不符合项目沟通管理原则。 🤔 沟通管理计划中会囊括沟通工具的要求，因此这里需要上升到沟通管理计划。同时沟通问题、冲突问题，一般直接解决，无须记录在问题日志。 五、项目可交付成果预期的当前增量收入没有满足业务案例要求。可交付成果已经关闭并移交给运营团队，项目经理应采取哪两项措？（选择两项） 与项目发起人一起审查问题并提交变更请求。 向产品经理和业务部门报告问题。 ✅ 分析业务收益标准和假设。 ❌ 与运营团队讨论该问题，以评估费用超支。 ✅ 安排项目评审会议来分析根本原因。 ✨ 关键词：交付成果已经关闭 3️⃣ 4️⃣ ❌ -&gt; 3️⃣ 5️⃣ ✅ 💡 解析：因为项目已完成且移交给了运营团队，此时发现的问题即使要修复也是运营团队的事情。对项目经理而已，唯一能做的就是当成经验教训，以避免未来再次发生。5️⃣ 找问题原因，属于典型的总结经验教训，可以选；3️⃣ 也有可能是项目最初的商业论证有误，以及制约因素和假设条件论证不充分导致，因此也应进行分析。1️⃣ 2️⃣ 4️⃣ 都与总结经验教训无关。 🤔 即使项目已经关闭也可以安排项目评审会议。 六、一个项目即将完成。发起人已经在询问项目管理办公室 (PMO)，项目经理何时被指派主持一个新计划的计划会议。项目经理下一步该怎么做？ 回顾组织过程资产 (OPAs) 以获得清晰性。 ✅ 结束前记录经验教训。 ❌ 有关后续步骤，请参考项目章程。 确认已满足完成 (DoD) 的定义。 ✨ 关键词：结束前一个项目 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：本题属于典型的“上一个项目……下一个项目”题型，重点是上一个项目的经验教训，本题选 2️⃣。 七、在项目规划阶段，项目经理召集了一次会议，与代表不同身份的最终用户的多个干系人讨论产品办事项列表。只有一位执行经理出席了会议。项目经理应该怎么做？ ❌ 单独会见每个干系人，收集产品待办事项列表地输入，并开始项目计划。 根据之前地经验教训对产品代办事项进行优先排序，完成项目计划规划。 ✅ 重新安排会议，以确保大多数干系人都出席了产品待办事项讨论。 继续会议以保持项目正常进行，并开始对产品待办事项进行优先排序。 ✨ 关键词：管理干系人参与、干系人问题、收集干系人需求 1️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：题目中的会议，是收集干系人对敏捷项目范围意见（价值、优先级等）的研讨会，应尽量让干系人一起参加，3️⃣ 最好。1️⃣ 会出现摁下葫芦起来瓢的情况，效率低；2️⃣ 刻舟求剑，闭门造车，错误；4️⃣ 忽略了大部分干系人的意见，必然给将来验收带来隐患。 🤔 只是一次会议出现这样的问题，重新安排会议似乎没有什么不妥。但如果是多次都这样，是否就需要会见干系人确认原因？","link":"/2024/07/02/pmp_test_what_confuses_me_02/"},{"title":"PMP 考试 - 易错和令人困惑的问题集（三）","text":"仅供自己复习使用。如果侵权请联系删除。 一、一位项目经理正在领导一个跨组织的项目。该项目正在替换一个平台，在该平台上构建了 15 个业务部门使用的各种解决方案。该项目是一个大型工作计划的一部分，并且一些资源与由各自的业务单元发起的计划之外的其他项目共享。项目经理应该首先咨询哪些干系人来管理相互依赖关系? ❌ 项目发起人。 ✅ 其他项目经理。 业务部门经理。 项目经理。 ✨ 关键词：咨询哪些干系人来管理相互依赖关系 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：本题答案在 2️⃣ 3️⃣ 之间稍有争议。如果将题目中的“依赖关系”理解为共享资源之间的依赖关系，则找其他项目经理更合适。即使理解为 15 个业务部门之间的依赖关系，也不应该选 3️⃣，因为项目中各个因素之间的依赖关系应该由项目经理识别和管理。 🤔 还是原则问题，能不找发起人尽量不找发起人。 📖 需要向发起人上报的场景： 政府出台的新政策、法规影响项目（包括正面、负面影响）。 识别了影响整个组织或其他项目的风险。 项目经理发现商业论证有误（应先重新论证,再上报发起人）。 项目危害社会、公众利益了。 由于外界因素，项目被迫暂停了。 新任项目经理发现前任项目经理虚报项目的当前绩效。 出现职业道德问题，如歧视性政策，弄虚作假，违法行为等。 超出项目经理能力范围（多与相关方问题有关，如项目经理反复多次说服未果）。 二、（⚠️ 错了 2 次 ⚠️）一家公司被授予一个项目，该项目位于一个危险的位置，给员工带来了多种高风险。需要帮助对员工进行有关主要安全和健康因素的培训。该项目正在进行中，并使用混合方法。该项目将在多个地点进行，同时进行多个开发迭代。项目经理应如何处理这种情况? 分配和使用部分项目应急储备用于培训目的。 ❌ 就医疗和安全支持服务与当地主管部门协商合同并建立合作关系。 ✅ 执行回顾并更新风险登记册和资源管理计划中有关培训的必要预算。 只雇佣了解仓库危险的当地资源，为当地社区提供就业机会。 ✨ 关键词：安全问题不能忽视 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：题目的核心问题是需要培训以避免或应对项目现场风险。1️⃣ 培训成本或者是项目正常预算的一部分或者由公司提供，一般不做为应急储备；2️⃣ 强调让当地主管部门配合健康和安全工作，而忽略了员工培训工作本身；3️⃣ 使用资源管理计划中安排的培训预算，正确；4️⃣ 类似于 2️⃣ 还是投机取巧，不想培训了。 🤔 2️⃣ 的解释有点勉强，不过 3️⃣ 属于流程正确可以选。 三、（⚠️ 错了 2 次 ⚠️）在一个正在进行的住宅项目进入生命周期 1 年后，市政当局宣布了一项新的法规，该法规将对项目的进度和预算产生重大影响。项目经理下一步该怎么做? ❌ 执行定性风险分析并更新风险登记册。 ✅ 通过集成的变更控制流程提交变更请求。 更新问题日志，并在下一次指导委员会会议上进行讨论。 估计相关成本，并相应增加项目预算。 ✨ 关键词：事业环境因素、必须遵守法规 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：典型的新法规影响项目。正确流程：记录 ——&gt; 分析影响 ——&gt; 上报发起人 ——&gt; 采取措施1️⃣ 政府已宣布，因此不是风险，题目已强调将产生重大影响，更无须定性分析。2️⃣ 没有前几个选项，2️⃣ 属于具体应对措施，对应“对进度和预算产生重大影响”。3️⃣ 前半句没问题，后半句“下一次”和“指导委员会”都错误;4️⃣ 忽略了变更流程。 🤔 还是风险和问题的界定问题，题目已经确定影响那就是问题了，可以排除 1️⃣。 四、一名 IT 项目经理被推荐给一家提供质量保证专业服务的新的高评级供应商，该项目经理计划在一个新项目中聘用该质量保证供应商，但他们的价格不符合项目预算。项目经理下一步该怎么做? 与管理团队讨论这个问题。 ❌ 让项目干系人参与进来。 用较低的费率更新合同。 ✅ 让采购团队参与。 ✨ 关键词：采购问题 2️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：已经选定了供应商，但其价格不符合项目预算，因此在合同签订前必须进行价格谈判，以满足项目预算。PMBOK 第 6 版 12.2.2.5 中说“谈判应由采购团队中拥有合同签署职权的成员主导”， 因此 4️⃣ 正确。本题的考点就是采购谈判的主谈人。 📖 谈判应由采购团队中拥有合同签署职权的成员主导。 五、（⚠️ 错了 2 次 ⚠️）一个营销团队正在计划一项多年计划，该计划将包括许多跨职能的干系人。项目经理已被指派，目前正处于项目计划阶段。项目经理应该首先开发哪一项? 产品待办项列表和要交付的特性的识别。 ❌ 商业论证和范围文件。 ✅ 满足团队需求的沟通管理计划。 纳入已知风险的风险管理计划。 ✨ 关键词：项目计划阶段首先做什么、跨职能的干系人、以及进入计划阶段，即项目批准阶段之后 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：本题选项都很特别，答案争议很大。项目计划阶段，项目经理要做什么？开放式问题，使用排除法。1️⃣ 是按敏捷方法中工作内容，但从敏捷过程来说，属于敏捷方法的启动过程；2️⃣ 商业论证应该是在批准项目前进行的工作，与题目强调的计划阶段不符；3️⃣ 沟通管理计划主要是获取和发布信息的计划，本题中的“跨职能的干系人”可以理解为参与项目的团队成员，类似于跨地区团队，跨职能团队也需要重点关注沟通问题，3️⃣ 的说法虽然有点狭隘，但 1️⃣ 2️⃣ 4️⃣ 都有明显错误时，可以考虑；4️⃣ 风险管理计划是一个程序型计划，具体风险不记录其中，而是记录在风险登记册。 🤔 商业论证应该是在批准项目前进行的工作，这里明显可以把 2️⃣ 排除。 六、一家公司使用敏捷实践承担了一个大型的转型项目。项目发起人要求项目经理向项目团队推广在预期转换中识别的新价值，项目经理应该做什么？ 在冲刺规划期间添加一个用户故事，对符合新价值观的行为给予认可。 在每天的站立会议之前，向团队发送一封包含新价值的标准电子邮件。 ✅ 组织一次团队会议，重点讨论与转型相关的新价值。 ❌ 在冲刺回顾中，表彰团队成员符合新价值观的行为。 ✨ 关键词：敏捷、推广一种新的价值观 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：发起人希望在项目团队中推广一种新的价值观，如何推广？1️⃣ 将推广工作当成一个待办项，错误，待办项强调的是项目交付（客户的）结果；2️⃣ 仅仅给团队成员发电子邮件，作用非常有限；3️⃣ 和团队一起开会讨论研究，应该是一种比较常见的普遍做法；4️⃣ 回顾会议的主要目的是总结经验教训，识别问题，且冲刺回顾都在冲刺结束后进行，不是很合适的奖励时间。 🤔 看不懂，不知道什么是“推广一种新的价值”，原来是价值观。","link":"/2024/07/03/pmp_test_what_confuses_me_03/"},{"title":"PMP 考试 - 易错和令人困惑的问题集（四）","text":"仅供自己复习使用。如果侵权请联系删除。 一、作为临时任务的一部分，一个项目经理在每日状态会议期间领导一个业务项目，发现该项目经理以前的部门没有完成一项任务，这延迟了当前的选代。项目经理应该怎么做？ ❌ 在障碍板上创建一个条目并分配它。 ✅ 邀请项目团队参加分组会议，以确定解决方案。 利用前部门的关系网，寻求帮助。 将问题上报给产品负责人，以确定后续步骤。 ✨ 关键词：以前的部门没有完成一项任务延迟了当前的选代、敏捷 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：敏捷团队集体对结果负责，某个人工作延误，也应由团队一起承担责任并解决。2️⃣ 可以理解为在每日站会后，另外召集团队会议解决这个问题，符合敏捷团队的工作原则；1️⃣ 项目经理在敏捷项目中，不负责分配任务；3️⃣ 不是专业做法；4️⃣ 甩锅、躺平的行为，不想解决问题。 🤔 题干中有个关键词“每日状态会议”，因此可以判断是敏捷项目，1️⃣ 因为项目经理不能分配任务而错误。难懂的题目下次还是框关键词来尝试解决。 二、一个敏捷主管收到了同一个任务相互矛盾的状态更新，如何从团队中获得准确的状态? 仔细审查可交付成果并确定正确的状态。 指派一个人负责这项任务。 ✅ 为每项任务建立一个清晰的完成 (DoD) 定义。 ❌ 鼓励团队成员一起工作。 ✨ 关键词：敏捷、相互矛盾的状态更新、准确的状态 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：“同一任务相互矛盾的状态更新”，即某一任务，有人认为已完成，有人认为未完成。首先应明确定义该任务的完成标准，才能防止题目描述的扯皮现象，3️⃣ 最优先。3️⃣ 是 1️⃣ 的前提，因此不选 3️⃣；2️⃣ 与谁负责该任务无关；4️⃣ 与团队是否一起工作无关。 🤔 并非我认为的沟通问题或冲突问题。 三、八个人在一个项目上工作了很长时间，范围发生了重大变化，产品负责人也更换了多次。团队成员感觉与项目脱节了，项目经理应该做什么来确保团队与目标一致？ 请新产品负责人解释项目的重要性。 通过电子邮件向团队发送业务需求的详细概述。 ✅ 与团队一起审查项目章程。 ❌ 促进对项目愿景的讨论。 ✨ 关键词：范围变化、员工感觉脱节了 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：题目关键词是“（项目）目标”。章程中包含并强调项目目标，3️⃣ 正确。本题考基本概念，不多解释了。 ❓ “项目愿景”不也是目标吗？不理解，但是下次还是选更严谨规范的吧。 四、一个敏捷项目正处于 10 次迭代中的第六次迭代。在迭代评审之后，团队收到了来自干系人的反馈，这可能会导致产品的变更。项目经理应该采取哪两项措施？（选择两项） ❌ 向干系人询问此变更的优先级。 ✅ 请产品负责人审查产品待办项列表。 ✅ 请团队成员分析这一变化的影响。 请求发起人批准变更请求。 要求团队成员在下一次迭代中包含变更。 ✨ 关键词：敏捷、产品可能变更 1️⃣ 2️⃣ ❌ -&gt; 2️⃣ 3️⃣ ✅ 💡 解析：敏捷项目，新需求（变更）应列入待办项列表并排列优先级顺序，这两项工作的最终责任人是产品负责人，2️⃣ 包含了这两项工作，正确；3️⃣ 添加了新任务，必然对项目的工作量、速度以及最终产品结果造成影响，3️⃣ 也有必要。1️⃣ 待办项列表的优先级最终由 PO 确定；4️⃣ 敏捷项目不走变更流程；5️⃣ 是否添加、什么时候添加任务，由 PO 决定。 🤔 “1️⃣ 待办项列表的优先级最终由 PO 确定”尝试使用这个绝对的概念做一段时间题目试试。 五、一个项目经理在混合项目中扮演敏捷主管的角色，正在处理团队成员之间的冲突，应该使用什么策略来处理这个冲突？ ✅ 将冲突分为两类：积极的和消极的。 ❌ 将冲突分类：结构性冲突和人际冲突。 将冲突放在共享的冲突列表中，并确保它是可见的。 在日常的敏捷中回顾冲突，以便及时处理它们。 ✨ 关键词：敏捷主管、冲突问题 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：PMBOK 第 6 版 9.5.2.1 中说：“如果管理得当，意见分歧有利于提高创造力和改进决策。假如意见分歧成为负面因素……”。PMBOK 中将冲突也分为积极（正面）的，如不同意见；和消极（负面）的，如无原则的对抗。因此 1️⃣ 可以考虑。2️⃣ 结构性冲突纯属陌生词汇，项目中也未必存在；3️⃣ 4️⃣ 都是将冲突公开化，不符合 PMBOK 第 6 版 9.5.2.1 中强调的“尽早并通常在私下处理冲突”原则。 📖 新概念：冲突分为积极（正面）的，如不同意见；和消极（负面）的。​ 六、（⚠️ 错了 2 次 ⚠️）对 IT 项目缺乏透明度感到沮丧的关键干系人拒绝了参加新项目会议的邀请。敏捷项目经理应该怎么做才能让项目干系人参与进来？ 向干系人提交项目管理计划，并向他们保证他们将定期收到项目更新。 ❌ 将干系人介绍给项目团队，并邀请他们参加 IT 团队的下一次迭代评审会议。 ✅ 通过遵守项目承诺与干系人建立信任，并使用演示会议收集反馈和重新调整目标。 使用干系人映射来记录下一次选代计划会议的影响和兴趣水平。 ✨ 关键词：管理干系人参与、不信任项目方（缺乏透明度感到沮丧）​ 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：如何管理不信任项目方的关键干系人？没有信任就没有沟通，此刻当务之急是重建信任，3️⃣ 抓住了问题重点。1️⃣ 前半句无必要，后半句对方未必相信；2️⃣ 通过介绍给团队认识，就能改变关键干系人拒绝参加会议的态度的可能性不大；4️⃣ 还是忽略了这是一个信任问题，而非是否了解干系人沟通需求的问题。 🤔 并非干系人感到不满意就是沟通问题，像这种情况“缺乏透明度感到沮丧”后续可以判断为信任问题。 七、一名项目经理被分配到一个教育项目，目标是培训应用程序开发人员。交付成果之一是为客户活动项目中的优秀学生提供实习机会，但是客户目前没有足够的项目在进行中。项目经理决定创建几个内部项目，以确保实习机会。项目经理应该采取哪三项措施来实现这一场景，而不增加客户的成本？（选择三项） ✅ 使用项目的应急预算。 ✅ 创建新内部项目范围的变更请求。 影响客户启动一个新项目。 ✅ 用内部项目创建新范围的工作分解结构 (WBS)。 ❌ 管理交付的质量。 ✨ 关键词：范围变更、不增加客户成本 2️⃣ 4️⃣ 5️⃣ ❌ -&gt; 1️⃣ 2️⃣ 4️⃣ ✅ 💡 解析：本题在 1️⃣ 2️⃣ 4️⃣ 和 1️⃣ 4️⃣ 5️⃣ 之间争议较大。创建内部项目，为优秀学生提供实习机会，关键词是“不增加客户成本”。1️⃣ 使用应急储备不额外增加成本，可以选；2️⃣ 范围变更虽然花钱，但 2️⃣ 强调 了“内部项目”，不会增加客户的成本；4️⃣ WBS 分解机构可以使用不同的方式，创建新的 WBS 让学生练手是可以的。3️⃣ 必然增加客户成本，不符合题目要求；5️⃣ 质量成本的承担原则是“谁受益，谁花钱”，质量投入的受益方一般都是产品的接受和使用者，因此 5️⃣ 使用的还是客户成本。 🤔 质量成本的承担原则是“谁受益，谁花钱”，投入的受益方一般都是产品的接受和使用者，一般为客户本身。","link":"/2024/07/04/pmp_test_what_confuses_me_04/"},{"title":"PMP 考试 - 易错和令人困惑的问题集（五）","text":"仅供自己复习使用。如果侵权请联系删除。 一、（⚠️ 错了 2 次 ⚠️）项目经理被分配到一个时间表长、范围复杂的项目。客户需要一个高层次的、长期的计划，以及能够立即发挥作用的东西，随着项目的进展，向产品添加功能。项目经理应该如何计划和交付这个项目？ ❌ 使用带有工作分解结构 (WBS) 的预测方法来规划项目，然后使用敏捷方法来执行项目，以增量方式交付价值。 使用预测方法和遵循计划的工作分解结构 (WBS) 来规划项目，并在项目结束时交付价值。 ✅ 首先与客户就最小可行产品 (MVP) 达成一致，并立即交付，然后在项目结束时发布范围的剩余部分。 选择敏捷方法并根据最佳实践管理项目，以确保向客户交付价值。 ✨ 关键词：混合项目、（目标是）高层次的、（周期是）长期、能够立即发挥作用的东西、敏捷 1️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：题目强调的立即发挥作用（增量交付），随时添加功能（迭代开发），都是敏捷方法的特点。3️⃣ 4️⃣ 之间，3️⃣ 前半句强调了“立即发挥作用的东西”即 MVP，比 4️⃣ 更直接、具体。1️⃣ 2️⃣ 是预测型做法，排除。 二、在一个开发新药品的项目中，项目经理被告知关于项目材料的政府法规发生了变化。项目经理应该怎么做？ 审查采购文件并根据需要修改要求。 ✅ 与团队一起研究新的法规，并评估对项目变量是否有任何影响。 更新应急计划，将此问题考虑在内。 ❌ 与干系人会面，更新风险登记册和风险管理计划。 ✨ 关键词：事业环境因素改变、必须合规 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：政府出台新法规，或法规出现变化，除记录（问题日志或风险登记册）之外，首先要分析对项目的影响，2️⃣ 正确。3️⃣ 在 2️⃣ 之后考虑；4️⃣ 目前见干系人没有必要，且更新风险管理计划不妥。 🤔 4️⃣ 存在“更新风险管理计划”的明显错误，居然没看出来 😓。 三、（⚠️ 错了 2 次 ⚠️）一名拥有高度复杂项目相关经验的高级员工正在寻求晋升，以便能够加入该项目。该员工就该项目提出了建议。项目章程最近获得批准，项目经理应该如何处理员工的请求？ ✅ 通过回顾从类似项目中吸取的经验教训，评估员工的建议。 ❌ 创建一个凸显模型，以确定员工是否会对项目产生影响。 请项目发起人重新查看项目章程，考虑员工的建议。 评估员工的影响力和权力，看员工是否会增加价值。 ✨ 关键词：项目章程批准后、资源希望加入、变更管理 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：题目涉及两个问题：1. 是否纳入该资源？2. 如何对待该资源提出的建议。排除法，2️⃣ 4️⃣ 都是管理干系人的做法，获取资源主要考虑能力问题，2️⃣ 4️⃣ 排除；3️⃣ 让发起人考虑员工建议，不妥；1️⃣ 根据经验教训评估员工建议，可以选。 🤔 凸显模型和评估影响力权力是管理干系人的做法，确实可以排除。但是为什么工具不可以灵活运用，存疑。先就事论事，评估建议，选 1️⃣。 四、一名项目经理领导一个混合项目，与现场团队成员一起开发牙科设备。一名牙医，也是主要投资者之一，参加了一次冲刺审查会议，对设备的概念和预期性能提出了问题和疑问。项目经理应该怎么做？ 邀请投资者参加冲刺回顾会议，与团队讨论设备概念和预期性能的改进。 ❌ 邀请项目发起人参加冲刺审查会议，并就设备的概念和预期性能召开 QSA（质量体系评定）会议。 邀请产品负责人和团队讨论设备的概念和预期性能。 ✅ 邀请投资者参加设计审查会议，介绍设备的概念和预期性能，并在会议中包括 QSA（质量体系评定）。 ✨ 关键词：混合项目、干系人对设备的概念和预期性能提出了问题和疑问 2️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：投资者对结果不放心，属于相关方问题。投资者对设备的概念和预期性能有疑问，那就邀请此投资者参加设计审查会议，以给他介绍设备的概念和预期性能。这才是最积极正面的相关方管理措施。不选 2️⃣ 因为冲刺审查会是在迭代结束时开的，属于事后，而 4️⃣ 是开发之前。 🤔 新概念：敏捷存在“设计审查会议”。​ 五、在一个正在进行的项目中，一个关键资源向项目经理询问项目的目的。如果它符合组织的战略，项目经理应该与关键资源分享什么？ ✅ 更新的效益管理计划。 ❌ 更新的范围管理计划。 更新的项目管理计划。 更新的沟通管理计划。 ✨ 关键词：资源向项目经理询问项目的目的 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：项目早期的文件强调战略计划，如项目章程、商业论证、效益管理计划等。本题出处见 PMBOK 33 页第 2 个小黑点，或见《过程中实践指南》1.10 内容。 🤔 考虑到项目是创造价值的，1️⃣ 也能选出来。但是“项目早期的文件强调战略计划，如项目章程、商业论证、效益管理计划等”的概念更好。 六、一个项目经理正在领导一个按时且在预算之内的项目。在每周与团队的会议中，项目经理发现下周到期的任务之一没有分配的可用资源，该资源当前分配给了另一个项目。项目经理应该做些什么来管理这种情况？ 请采购部门提供不同的资源。 ❌ 根据资源的可用性更改计划。 要求发起人按原计划获取资源。 ✅ 联系其他项目经理请求资源。 ✨ 关键词：资源冲突 2️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：题目考如何获取资源。项目经理获取资源主要由三个途径：和职能经理或资源经理谈判，和其他项目的项目管理团队谈判，从供应商处获得。该资源虽然被分配给了另一个项目，但如果其工作任务没有满负荷，依然可以通过和该项目的项目经理谈判，来分享该资源，4️⃣ 正确。 🤔 项目经理获取资源主要由三个途径： 和职能经理或资源经理谈判。 和其他项目的项目管理团队谈判 从供应商处获得。","link":"/2024/07/05/pmp_test_what_confuses_me_05/"},{"title":"PMP 考试 - 易错和令人困惑的问题集（六）","text":"仅供自己复习使用。如果侵权请联系删除。 一、一个房舍管理系统 (BMS) 项目正处于试运行阶段，很快将移交给业务小组。然而，项目经理指出，项目和运营团队都无法正确运行该系统 (BMS)。因此，项目时间表被推迟的风险增加了。项目经理应该做些什么来避免这种情况？ 在项目的早期阶段分配了一个专门的移交团队。 ✅ 在项目计划中为房舍管理培训分配适当的资源。 对 BMS 做了一些调整，使之更适合团队。 ❌ 将两个团队召集到一个联合会议上来解决问题。 ✨ 关键词：避免 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：从“避免”角度来说，应事先采取措施，防止无人能够正确运营该系统的情况出现，2️⃣ 培训资源，可以避免该情况。1️⃣ 当成了移交问题，判断错误；3️⃣ 4️⃣ 都是事后措施，不符合“避免”。 🤔 4️⃣ 强调了“联合会议上来解决问题”是事后措施确实可以排除；但是 3️⃣ 不是事前措施吗？不懂。下次优先培训来解决运营团队的使用困难吧。 二、（⚠️ 错了 2 次 ⚠️）一个项目经理开始了一个复杂的炼油项目。虽然项目处于初始阶段，但是发起人一直要求最重要的项目里程碑的具体日期。项目经理何时能够提供所需的信息？ ❌ 在规划阶段，将执行范围定义、活动持续时间和排序流程。 尽可能快，因为尽早制定进度计划可以大大避免项目延迟。 接近项目结束时，因为预测将更加准确，并且大多数风险已经得到缓解。 ✅ 在启动过程中，因为它与项目合同和项目章程的创建同时发生。 ✨ 关键词：何时能提供里程碑日期 1️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：题目问的是，项目经理最早什么时候可以提供项目里程碑信息？里程碑信息最早出现在项目章程中，见 PMBOK 第 6 版第 81 页第六个小黑点。 🤔 新概念：里程碑信息最早出现在项目章程中。 三、一名关键团队成员最近经历了一些影响其绩效的个人问题。项目经理注意到该团队成员的情绪状况影响了团队其他成员的表现。项目经理应该如何处理这种情况？ ✅ 通过建立共情文化，帮助所有团队成员学会处理自己的情绪。 将关键团队成员分开，在他们情绪恢复期间替换他们。 ❌ 与团队会面，讨论如何处理情绪问题。 请求人力资源部门提供情感上的帮助。 ✨ 关键词：障碍 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：团队成员的个人遭遇影响了他自己的情绪和其他团员的表现。项目经理应帮助消除负面情绪，解决该问题。2️⃣ 是很消极的做法；3️⃣ 此时强调理性，有指责团队不理性的意思，不近人情 (冷血)；4️⃣ 甩锅行为；1️⃣ 相对比较好，积极、主动、正面。 四、一个项目团队正在识别将要修建的跨河桥梁的项目风险。团队需要发出参加风险研讨会的邀请，以更好地了解所涉及的风险。项目经理在发出邀请时应该使用哪个分发列表？ ❌ 具有该领域经验的职能经理、团队成员和外部顾问。 团队成员、工程师和气象专家。 ✅ 团队成员、具有该领域经验的项目外部顾问以及客户。 气象专家、职能经理和团队成员。 ✨ 关键词：风险分析方法 1️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：识别风险需要干系人参与，越全面越好。1️⃣ 都是公司内部人员；2️⃣ 3️⃣ 中的气象专家、工程师等，都可以被 3️⃣ 中的“具有该领域经验的项目外部顾问”包含，因此 3️⃣ 最全面。 🤔 参与风险分析的人越全面越好。 五、在项目实施过程中，项目团队在内部审查后发现了一个新的机会。项目团队同意该机会不在项目范围内，项目经理决定更新风险登记册并将该机会上报给更高级别。项目经理接下来应该如何处理该机会? 与其他项目分享这个机会。 建立应急储备以支持这个机会。 ❌ 进一步监控机会。 ✅ 不需要更多的行动。 ✨ 关键词：机会不在项目范围内 3️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：本题出处见 PMBOK 第六版第 444 页规划风险应对过程第一个小黑点“上报”一段的最后一行，“机会一旦上报，就不再由项目团队做进一步监督”，选 4️⃣。2️⃣ 建立应急储备不是上报，是主动接受。 🤔 新概念：机会一旦上报，就不再由项目团队做进一步监督。 六、一个项目经理正在管理一个项目。这个项目有一个新的发起人领导削减预算，作为一个仆人式领导者，这个项目经理应该如何处理团队的预算削减？ ❌ 通知项目发起人预算缩减将需要一个进度表和范围缩减。 通知每个团队成员，他们必须释放一部分预算，但必须按计划进行，不改变范围。 与计划协调员和财务分析师会面，告诉他们要减少哪些预算行，以及在哪里释放时差。 ✅ 与团队协作，评估变更对项目的影响，并推荐更新的项目计划。 ✨ 关键词：如何处理团队的预算削减、成本变更、可以当成事业环境因素变化导致的新风险 1️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：仆人式领导，强调让项目团队当家做主。1️⃣ 2️⃣ 3️⃣ 都是越俎代庖，直接发号施令，只有符合或 接近于仆人式领导。项目预算被消减，也可以当成事业环境因素变化导致的新风险（识别），风险识别后，应分析影响、制定应对策略，还是 4️⃣ 正确。 🤔 仆人式领导，强调让项目团队当家做主。","link":"/2024/07/06/pmp_test_what_confuses_me_06/"},{"title":"PMP 考试 - 易错和令人困惑的问题集（七）","text":"仅供自己复习使用。如果侵权请联系删除。 一、项目经理刚刚指派负责某个大型项目。项目经理已与所有相关方举行了启动会议，启动会预定开始前的几分钟，项目经理收到两位相关方发来的抱歉便条，因为他们无法参会。这些相关方的支持对于项目成功非常重要。在这种情况下，项目经理该做什么？ 推迟会议，直至所有相关方都能参会。 ✅ 告知这些相关方启动会将继续举行随后将详细情况告知他们。 ❌ 说明参加启动会的重要性，并请求他们重新安排其他事务。 告知项目客户某些相关方很棘手。 ✨ 关键词：干系人参与问题 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：相关方不参加会议问题,但本题有特殊性,就是会前几分钟才知道。1️⃣ 来不及了；3️⃣ 未必有效；4️⃣ 是抱怨不是解决问题。排除法选 2️⃣，给他们发会议纪要。 🤔 即使是相关方的支持对于项目成功非常重要也并不是一定必须要参加项目启动大会。 二、（⚠️ 错了 2 次 ⚠️）一位项目经理正在管理一个内部软件开发项目，该项目计划在 1 个月内完成。一旦系统上线，项目应该开始看到价值，但是一些干系人缺乏对它将如何为组织提供价值的理解。项目经理下一步该怎么做？ 请发起人确定新项目的要求，以监控和报告收益的实现情况。 ✅ 在项目结束前，指导团队实施效益管理计划并跟踪成果。 ❌ 与干系人协调，确保利益管理计划与目标一致。 用任务和资源更新工作分解结构 (WBS) 和项目进度表，以跟踪效益的实现。 ✨ 关键词：干系人缺乏对项目价值的理解 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：如何向干系人证明项目将提供的价值？本题考的是项目效益管理计划的作用，见 PMBOK33 页第一段第一行，2️⃣ 正确。3️⃣ 的说法似是而非，项目目标是根据效益管理计划制定的，而不是相反，而且不是通过“与干系人协调”实现一致的。 🤔 强调概念：项目目标是根据效益管理计划制定。​ 三、为了保证质量，对项目执行计划中使用的流程进行了质量审核。审核员提出的一个不符合问题，就是没有项目风险评审会议的出席名单。为什么出席名单很重要？ ❌ 项目中的标准做法是召开风险审查会议，会议应有与会记录。 ✅ 与会者名单是与适当的项目团队成员召开风险审查会议的证据。 这是一个显示会议出席人数的记录。 这是一份记录在经验教训登记册中的文件。 ✨ 关键词：管理质量、风险评审会的（人员）出席名单 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：题目问的是为什么出席名单很重要，出席名单能够验证我们开的风险审查会到底有没有找适当的人来进行评审，即 2️⃣ 选项中所提及的“适当的项目团队成员”。1️⃣ 不对，“会议应有与会记录”这是为了记录而记录，形式主义，没有说到点子上；2️⃣ 才说明了名单记录的意义。 四、（⚠️ 错了 2 次 ⚠️）项目经理有一个来自其他项目的共享资源团队，他们在项目到期前三天处理一个客户项目。团队通知项目经理，由于某个组件未能按时交付，项目将被延迟。共享资源的优先级冲突导致组件延迟交付。项目经理应该采取什么措施来防止这种延迟发生？ 更新了风险管理计划并记录了项目的经验教训。 根据工作分解结构 (WBS) 重组项目团队。 ✅ 与其他项目的干系人保持持续的沟通。 ❌ 使用资源管理计划来确定其他项目的影响。 ✨ 关键词：共享资源（成员）的优先级冲突导致组件延迟交付、防止、资源冲突 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：由于优先级问题，由共享资源提供的组件延迟交付，本质上，这属于资源冲突问题，应找共享资源的职能经理协商（谈判）来防止、避免。选项中没有出现职能经理，出现了其他项目干系人（3️⃣ 选项），即共享这些资源的其他项目的项目经理，也可以选。 🤔 资源冲突的找人顺序：先所属的职能经理，再其他项目的干系人。 五、一个敏捷项目正处于第七次迭代中，从项目开始就要适应多种变化，例如法规变化、技术创新、市场竞争和其他变化。项目经理应该做些什么来管理这些进入项目的连续变化？ 要求产品负责人停止适应范围的进一步变更。 ✅ 利用产品负责人来监控外部环境。 ❌ 适应当前迭代中的关键和紧急变更。 建议产品负责人在单独的项目中执行变更。 ✨ 关键词：管理事业因素变化 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：敏捷项目，问做什么来管理这些进入项目的连续变化？多种变化要反映到产品代办列表的变更，而产品负责人对此负责，选 2️⃣。1️⃣ 拒绝变更，错误；3️⃣ 选项只将目光放在当前迭代，很短浅，且紧急变更是预测型的内容；4️⃣ 是胡说八道。 🤔 敏捷项目中，多种变化要反映到产品代办列表的变更，而产品负责人对此负责。 六、项目出现问题，数据集成团队和数据迁移团队有重叠的领域，不清楚谁将负责这些领域的交付，项目经理下一步应该做什么? 审查项目范围以协调项目团队。 ✅ 审查资源管理计划以协调项目团队。 评审项目集成计划以协调项目团队。 ❌ 审查工作分解结构 (WBS)，以协调项目团队。 ✨ 关键词：任务分配问题、工作重叠（工作撞车）​、责任分配矩阵 (RACI, RAM)​ 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：工作重叠（工作撞车），是责任分配的问题。预测型项目的责任分配通过 RAM、RACI 来实现，包含在资源管理计划中，选 2️⃣。 📖 责任分配矩阵 (RAM)​：记录活动和人的对应关系。RACI 矩阵：A (Accountable) 负责；R (Responsible) 执行；C (Cousult) 咨询；I (Inform) 知情。资源管理计划包含以上两者。 七、在批准项目管理计划的会议上，项目经理意识到演示文稿中有太多的细节，以至于许多干系人没有积极参与到流程中。干系人同意范围、目标和时间表，但没有给予他们实质性的思考。项目经理应该如何着手? ❌ 停止会议，重新安排一个更简洁的演示时间。 ✅ 在重新召集另一个审批会话之前，设置信息审核会话。 获得批准，并承诺通过电子邮件向利益相关方发送更多信息，以澄清技术细节。 尽快获得批准并结束会议。 ✨ 关键词：管理干系人参与 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：审批项目管理计划时，演示内容有太多细节，干系人认同主要内容，但没有给予实质性的批准。项目团队应重新编辑演示内容，以获得干系人对计划的批准，2️⃣ 正确。虽然 1️⃣ 也是重新安排会议，但 2️⃣ 强调事先进行交互式沟通，明显比 1️⃣ 更完善；3️⃣ 4️⃣ 都忽略了题目描述的问题。","link":"/2024/07/07/pmp_test_what_confuses_me_07/"},{"title":"PMP 考试 - 易错和令人困惑的问题集（八）","text":"仅供自己复习使用。如果侵权请联系删除。 一、在新项目的早期阶段，项目经理被替换。新项目经理发现业务团队不支持项目。在与团队讨论这些问题后，确定该项目没有得到高级管理层的全力支持。新项目经理下一步该怎么做？ 向干系人发送描述情况的状态报告，并请求一般帮助。 要求业务团队清楚地定义他们对迄今为止已完成的项目工作的问题。 ✅ 研究干系人分析，了解哪些干系人拥有最大的影响力，并寻求他们的帮助。 ❌ 请高级管理人员更多地参与项目，并提供全力支持。 ✨ 关键词：业务团队不支持项目、项目没有得到高级管理层的全力支持、干系人问题 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：项目没有得到高层支持，也是干系人问题，应管理干系人。1️⃣ 当成了沟通问题；2️⃣ 当成了项目本身的技术问题，判断错误；3️⃣ 是管理干系人的正确选项；4️⃣ 不是专业做法，不如 3️⃣。 🤔 4️⃣ 的做法是对的，但是如果当作彻底的干系人问题，应该先登记干系人再管理参与。 二、在项目的最后阶段，客户的项目经理发生了变化，项目经理如何避免项目关闭延迟？ ✅ 更新干系人参与计划。 ❌ 审查最新的项目状态报告，并向干系人提供最新信息。 将案例上报给客户的管理团队。 提前向客户开具工程款发票。 ✨ 关键词：最后阶段、干系人变化 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：重要干系人发生改变，应首先更新干系人登记册和干系人管理计划，1️⃣ 正确。 三、项目经理规划项目，并确定特定项目任务的法规要求将会改变。这将发生在项目执行阶段的中途，并将影响一些关键工人的执照，这将变得不合规。项目经理应该怎么做? ✅ 现在就开始安排关键员工的培训，以确保合规性。 因为项目已经开始，所以保持当前的关键工人。 ❌ 更新项目章程，以确保新的立法得以实施。 开始招聘有执照的新员工。 ✨ 关键词：风险管理、风险应对 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：合规性问题。项目团队必须遵守所有合规要求，1️⃣ 4️⃣ 考虑到了合规性，但 4️⃣ 没有考虑员工的利益，不如 1️⃣ 好。资源的使用，先考虑现有资源，再考虑外部资源。 四、（⚠️ 错了 2 次 ⚠️）一位运营经理不断提出对项目给公司带来的好处的担忧，而有些担忧在大多数情况下是正确的，这些担忧导致了项目会议的延迟，项目经理应该如何处理？ 与运营总监讨论会议延迟，并就这些问题寻求支持。 ✅ 审查运营经理关注的问题，并确保这些问题得到解决。 将问题上报给项目发起人，并讨论解决问题的选项。 ❌ 将运营经理关注的问题纳入风险登记册，并分配缓解风险的措施。 ✨ 关键词：干系人的担忧、担忧导致了项目会议的延迟、干系人问题、管理干系人参与 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：典型的干系人问题，应管理干系人参与。1️⃣ 根本问题是担忧，而不是延迟；2️⃣ 属于管理干系人的做法，可以选；3️⃣ 没有必要上报；4️⃣ 干系人问题，当成风险是在逃避责任。 🤔 应该更关注问题的本身，而不是奇怪的点，例如：这些担忧导致了项目会议的延迟。1️⃣ 未发生 3️⃣ 不该麻烦发起人，干系人管理确实选 2️⃣。 五、在有虚拟团队的跨国多地点项目中，项目经理已经建立了项目基线。项目经理发现多个风险因素已经出现，项目经理在项目规划阶段没有预见到这些风险。项目经理应该如何计算才能解决这一严峻的预算形势？（选择两项） ✅ 项目中的应急控制和更新基准。 ❌ 项目中的缓解控制。 项目中的收益管理控制。 ✅ 项目中的整体变更控制。 货币汇率。 ✨ 关键词：识别到新的风险、应急储备不够（成本基准需要变更）、因为是未知 - 未知风险，因此需要使用到管理储备 1️⃣ 2️⃣ ❌ -&gt; 1️⃣ 4️⃣ ✅ 💡 解析：成本基准（预算）制定后，出现了很多未知 - 未知风险，应该怎么解决？1️⃣ 未知 - 未知风险出现应采取权变措施、使用管理储备，会改变 BAC，1️⃣ 的判断没有问题；2️⃣ 陌生词汇，不考虑；3️⃣ 与题目无关；4️⃣ 使用管理储备，增加 BAC 需要走整体变更控制流程，4️⃣ 也正确；5️⃣ 题目没有提及忽略了汇率风险。 🤔 因为是未知 - 未知风险，需要使用到管理储备，而 BAC（完工预算）中仅包含应急储备,因此动用管理储备会增加 BAC。BAC 改变即为成本基准改变，需要走变更流程。​ 六、项目经理被分配到一个正在进行的复杂项目中。团队在每次迭代中交付价值，然而，交付物是内部的，客户并不知道交付物。项目经理应该采取什么行动？ 要求内部销售团队让客户了解交付的价值。 ✅ 评估各种交付方案，以便立即向客户展示价值。 ❌ 告知客户进度，并更新他们的最终交付成果。 等待一个重要的里程碑完成，然后通知客户进度。 ✨ 关键词：交付物是内部的，客户并不知道交付物、敏捷项目、干系人参与 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：敏捷项目，为了促进成功，符合客户要求，应在每次迭代审查会议上向客户演示交付的价 值，而不能等最终完成时再给客户展示。 🤔 错过了敏捷的关键词“迭代”，不应该。","link":"/2024/07/08/pmp_test_what_confuses_me_08/"},{"title":"PMP 考试 - 易错和令人困惑的问题集（九）","text":"仅供自己复习使用。如果侵权请联系删除。 一、一名初级项目经理很高兴开始与一家电信公司合作他们的第一个项目，一名高级项目经理决定就项目管理的挑战以及如何取得成功对初级项目经理进行培训。高级项目经理应该告诉初级项目经理利用哪三个工件来确保项目成功？（选三项） ✅ 组织过程资产。 ❌ 过去项目的经验教训记录。 ❌ 历史问题日志。 ✅ 项目范围说明书。 ✅ 项目管理计划。 ✨ 关键词：确保项目成功 1️⃣ 2️⃣ 3️⃣ ❌ -&gt; 1️⃣ 4️⃣ 5️⃣ ✅ 💡 解析：五个选项都与项目成功有关，但 1️⃣ 包括了 2️⃣ 3️⃣，因此选三项的话，1️⃣ 4️⃣ 5️⃣ 更好。 🤔 “组织过程资产”中包含“过去项目的经验教训记录”和“历史问题日志”。 二、某电力公司的项目经理正在开展一个改善配电网络的战略项目。其中一个关键可交付成果需要项目技术总监的批准。由于该技术总监请假一个月，该项目现在已经延迟了两周。项目经理本应采取什么措施来避免发生这种问题？ 执行风险减轻应对措施，防止进一步的延迟。 ✅ 制定所有干系人（相关方）的名单，包括该技术总监。 ❌ 管理干系人（相关方）参与并安排决策会议。 推进项目的执行并及时通知干系人（相关方）。 ✨ 关键词：干系人请假导致延迟、关键路径、本应采取什么 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：项目执行中途，一个事业环境因素严重影响项目，如何避免？此类问题一般都是在项目早期的风险识别（包括制约因素、假设条件）问题。1️⃣ 4️⃣ 都是事后措施，排除；2️⃣ 3️⃣ 之间，2️⃣ 更符合识别制约因素、假设条件，可以避免题目描述的问题；而 3️⃣ 严格来说更像事后措施且不解决题目问题。 🤔 关键干系人的请假可以当作事业环境因素。 三、某个软件迁移项目中发生了冲突。项目团队的大多数人希望实施一种可以快速取得成果，但会产生高运营成本的策略。一些项目团队成员已获得高级管理层中关键干系人（相关方）的支持。但是，项目经理将更多精力放在迁移阶段，以求降低运营成本。时间在流逝，而项目没有进展。为了解决这个冲突，项日经理应该使用哪种冲突解决方法？ ✅ 强迫/命令。 妥协/调解。 撤退/回避。 ❌ 安排/讨论 (Arrange/discuss)。 ✨ 关键词：项目经理与团队的冲突 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：典型的冲突解决问题。关键词是“时间在流逝,而项目没有进展”，提示情况紧急，需要采取果断措施，因此选 1️⃣。2️⃣ 3️⃣ 选项都不对应上述关键词，4️⃣ 是陌生词汇，不能选。 🤔 “安排/讨论 (Arrange/discuss)​”是陌生词汇，不能在解决冲突中使用。 📖 五种常用的冲突解决策略： 撤退/回避：从冲突中退出。 缓和/包容：强调一致性而非差异；为维持和谐与关系而退让一步。 妥协/调解：为暂时或部分解决冲突，寻找能让各方都在一定程度上满意的方案；有时会导致“双输”结果。 强迫/命令：以牺牲他方为代价，推行某一方的观点。​通常是用权力强行解决紧急问题（在这里符合题目环境），常常导致“一赢一输”结果。 合作/解决问题：综合考虑不同观点和意见，采用合作的态度和开放式对话引导各方达成共识和承诺，可以带来双赢局面。 四、在项目进行到一半的内部审查期间，一个承担了 30% 工作量的子团队请求例外处理，这将花费数百万美元的支持费用。项目经理首先应该做什么？ ✅ 启动变更控制流程。 更新风险登记册。 ❌ 召开团队会议。 告知项目发起人。 ✨ 关键词：变更 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：项目子项目团队提出一个重大变更，内部变更从具体操作来说，应先分析影响，再通知客户。但归根结底也还是变更问题，1️⃣ 选项包括对内部变更的处理，属于变更问题的通吃选项。3️⃣ 相对比较含糊，即使 3️⃣ 的意思是“和团队一起分析变更影响”，也包含在 1️⃣ 的范围之内了。 🤔 课上老师确实讲过关于这种题目，优先选走变更，但是直觉总是先讨论分析是否有必要进行变更。不管了，后面都选严格的走变更流程试试。 五、（⚠️ 错了 2 次 ⚠️）一位项目经理在一家全球性企业工作，该企业最近实施了敏捷方法来交付其项目。在一次冲刺计划会议上，该项目经理注意到，团队中存在若干个决策问题。项目经理该怎么做？ ✅ 为这支项目团队提供明确的责任承担环境。 请项目团队详细描述用户故事。 ❌ 要求项目负责人审查待办事项列表的优先级。 让项目发起人担任冲突协调人。 ✨ 关键词：敏捷、决策问题 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：敏捷方法，强调自组织团队，即项目经理应向项目团队充分授权。而本题恰恰又强调 了“团队存在……决策问题”，最可能的原因就是团队未被充分授权导致。1️⃣ 中“提供明确的责任承担环境”，即向团队授权的意思，正确。2️⃣ 题目没有涉及这个问题；3️⃣ 没有这个说法；4️⃣ 与 3️⃣ 一样，也是错误说法。 🤔 “决策问题”后续可以往“授权”的方向考虑，这题完全没有意识到和授权有关。 六、一位项目经理被指派负责一个混合项目。除了针对特定产品流召开每日站会外，还每周召开全体团队会议。项目经理可以采取什么主要措施来消除障碍？ ❌ 定期与团队成员举行面对面会议，讨论受阻的问题。 ✅ 与 Scrum 主管合作，找出需要项目经理加以干预的障碍。 让团队的单点联系人 (SPOC) 对障碍提出清晰的看法。 要求项目管理办公室 (PMO) 提供流状态更新。 ✨ 关键词：消除障碍 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：（仆人式领导）项目经理如何消除障碍？开放式问题，使用排除法。1️⃣ 敏捷或混合型项目，消除障碍的责任人是项目经理，团队成员只负责提出障碍、问题。2️⃣ 团队提出的涉及内部协作、技术方案选择的问题、障碍，应由自组织团队解决，项目经理负责解决除此之外的其他问题、障碍；2️⃣ 说的是先确认哪些障碍应该由项目经理负责解决，正确。3️⃣ 甩锅行为，且敏捷型没有“团队单点联系人”这个说法。4️⃣ 与题目问题无关。 🤔 这里默认项目经理 = Scrum 主管因此第一时间排除了 2️⃣，实际上敏捷项目中一般不设置项目经理，项目经理可以选择成为 Scrum 主管。而题目明确是混合项目，因此可能同时存在项目经理和 Scrum 主管。反正之后的题目先默认敏捷项目可以存在项目经理和 Scrum 主管吧。 七、一位项目经理正在制定项目进度计划。项目经理应该使用哪些项目工件来确定任务和依赖关系？ ✅ 风险登记册、资源日历、项目章程。 采购目录、个人发展计划、风险登记册。 解决方案架构、变更管理计划、项目章程。 干系人（相关方）图、解决方案架构、风险登记册。 ✨ 关键词：制定项目进度计划（的输入） 1️⃣ ✅ 💡 解析：本题考制定进度计划的输入。根据制定进度计划过程（参见讲义或电子版 PMBOK 第 6 版）的输入，没有一个选项完全正确。1️⃣ 错在项目章程；2️⃣ 错在采购目录和个人发展计划；3️⃣ 三条内容全错；4️⃣ 错在干系人图和解决方案架构。相对而言 1️⃣ 错的较少，选 1️⃣。本题是一道错题，仅供参考。 🤔 制定项目进度计划不需要项目章程。​📖 制定进度计划的输入： 项目管理计划 进度管理计划 范围基准 项目文件 活动属性 活动清单 假设日志 估算依据 持续时间估算 经验教训登记册 里程碑清单 项目进度网络图 项目团队派工单 资源日历 资源需求 风险登记册 协议 事业环境因素 组织过程资产","link":"/2024/07/09/pmp_test_what_confuses_me_09/"},{"title":"PMP 考试 - 易错和令人困惑的问题集（十）","text":"仅供自己复习使用。如果侵权请联系删除。 一、一位项目经理正在领导一个建设单户出租房屋的项目。购买该地产是为了使士地所有者的利润最大化。项目经理获悉，该市可能计划会改变该地区的分区，以允许在一块士地上设置多处出租物业。业主要求项目经理监督该风险。项目经理应考虑使用哪些风险策略? 升级、规避、利用、接受。 缓解、转移、分担、升级。 ❌ 分担、增强、转移、接受。 ✅ 升级、利用、分担、增强。 ✨ 关键词：事业环境因素可能改变、风险应对、风险策略 3️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：本题考风险应对策略，但翻译有严重问题。题目描述的明显是一个机会，因此必须选 择机会的应对策略。选项中的“升级”即上报；“利用”即开拓；“缓解”即减轻；“增强”即提高。四个选项中，只有 4️⃣ 选项都是机会的应对策略，其他选项中都存在威胁的应对策略，因此选 4️⃣。 二、一位项目经理正在领导一个资源分布于不同地点的全球项目。干系人（相关方）对需求的理解各不相同。项目经理正在尝试了解哪些需求/输入对项目而言最重要。请选择项目经理应采取的两项用于对干系人（相关方）进行分类的举措？（选择两项） ✅ 根据干系人（相关方）在公司中的职权对其进行优先排序。 根据最有发言权的干系人（相关方）的意见，对干系人（相关方）进行优先排序。 ✅ 根据干系人（相关方）对项目实施的影响能力对其进行分组。 根据地理位置对干系人（相关方）进行分组。 ❌ 根据干系人（相关方）的职能角色对其进行优先排序。 ✨ 关键词：干系人排序 3️⃣ 5️⃣ ❌ -&gt; 1️⃣ 3️⃣ ✅ 💡 解析：如何对干系人进行分类（排序）？应根据干系人的权力大小、利益高低、影响大小、 作用高低等来对干系人进行分类（排序）。1️⃣ 按权力，正确；3️⃣ 按影响力，正确；2️⃣ 按发言权，没有这个说法；4️⃣ 按地理位置，错误；5️⃣ 按角色，也错误。 🤔 对干系人进行排序的要素： 权力（职位）大小 利益高低 影响大小 作用高低 无关其发言权、职能角色！ 三、（⚠️ 错了 2 次 ⚠️）某个项目正在开始其最后一次选代。在计划会议期间，一名团队成员告诉大家，一项关键可交付成果无法在迭代结束时交付。项目经理该怎么做？ 更新问题日志并上报至项目发起人。 ✅ 与干系（相关方）会面，讨论缓解计划。 ❌ 寻求帮助，以提高团队按时交付的能力。 要求项目延期，以交付承诺的范围。 ✨ 关键词：最后一次迭代、无法交付 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：项目最后一次迭代有可交付成果不能按时完成。此时有两个选择：1、忽略该可交付成果，按时结束迭代以便交付；2、延长迭代时间，以便完成该可交付成果后再交付。无论选择哪一项，都应征求关键干系人的意见（按时发布更重要还是完成该可交付成果更重要），2️⃣ 正确。1️⃣ 没有必要麻烦发起人；3️⃣ 远水不解近渴，且提高团队能力的责任人是项目经理；4️⃣ 是可以选择的措施，但应先征求干系人意见。 🤔 计划会议期间觉得不能交付就确定不能交付了？存疑。 不过下次再出现“最后一次选代”，会优先进行忽略或者延期的选择。 四、（⚠️ 错了 2 次 ⚠️）项目经理收到了来自客户的一项索赔，原因是所交付的成果不能正常工作，项目经理调查原因后发现，该可交付成果之前被外包给了一家外部供应商，而自己并不知情。什么主要工具本可以帮助该项目经理识别这种情况？ ❌ 风险登记册。 范围基准。 干系人（相关方）登记册。 ✅ 沟通管理计划。 ✨ 关键词：外包成果不能正常工作、风险外包 1️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：可交付成果被外包以及完成后不能正常工作，项目经理都是事后才知道，这属于内部沟通沟通问题，4️⃣ 沟通管理计划没有制定或执行好所导致。1️⃣ 可以解释可交付成果被外包，但不能解释可交付成果不能正常工作；2️⃣ 题目描述的两个问题都不能解释；3️⃣ 题目描述的是事实问题，不是情绪问题（干系人问题）。 🤔 对“可交付成果之前被外包给了一家外部供应商”判断为风险外包是对的。但是对于不可用的情况不知情，可以这么理解：如果有人知情，风险会上升到问题层面；如果不知情那么应该进行沟通，4️⃣ 没有问题。 五、（⚠️ 错了 2 次 ⚠️）一个项目己经错过了其最后两个截止期限，并且项目经理决定从预测法改为敏捷方法。快速评估显示，团队中不存在资源制约因素或技术差距。项目经理应该做些什么来增加实现下一个目标的机会？ ❌ 利用日常团队会议，为项目团队排定优先次序，消除关键障碍和阻碍。 ✅ 引入敏捷教练来加速新方法的使用，增加项目成功的机会。 评估项目的工作分解结构 (WBS)，并寻找机会排除高风险项目。 扩大团队规模，以弥补错过的截止期限，并使项目回到正轨。 ✨ 关键词：项目已经延期、预测改为敏捷 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：项目经理如何在项目将预测型方法转换为敏捷方法？开放式问题，使用排除法。1️⃣ 项目团队不存在优先次序问题，如果理解为排列产品待办项优先级，则 1️⃣ 的时机、责任人都错误；2️⃣ 引入敏捷专业人士（或第三方）帮助推广敏捷方法，正确；3️⃣ 不是敏捷项目的做法，是预测型做法；4️⃣ 与题目问题无关。 🤔 混合项目或者转型项目的时候，不能一概判断项目经理 = 敏捷教练。敏捷项目中，优先次序由产品经理排，1️⃣ 可以排除。 六、一位新团队成员和一位新项目经理同时加入了组织。这名新团队成员已将标记为“请告知”的电子邮件转发给了新项目经理。内容似乎是一名经验更丰富的成员命令其他团队成员执行超出其职责范围的任务。项目经理接下来该做什么？ 参考干系人（相关方）参与计划。 与人力资源 (HR) 团队协商。 ✅ 参考组织过程资产 (OPAs) 。 ❌ 咨询项目组合经理。 ✨ 关键词：新项目经理 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：初看题目考的是问题成员，但没有面对或基本规则的选项。结合题目选项，题目中的关键词“新项目经理……加入组织”，暗示项目经理没有经验，与选项 3️⃣ 参考组织过程资产对应。即本题考点是，项目经理没有经验，应查看组织过程资产或寻求主题专家帮助，3️⃣ 正确。1️⃣ 管理团队成员不上升到干系人参与计划；2️⃣ 4️⃣ 与他们无关，PMP 考试中，这二者一般都不选。 🤔 是存在看到“新项目经理”之后注意“组织过程资产”的秘笈。 七、一个项目章程已获批准。项目经理需要与团队沟通情况，然而一些团队成员正在休假。项目经理接下来该做什么？ 安排一次与现有团队召开的启动会议。 启动规划过程，并确定团队成员的角色。 ❌ 确定所有主要和次要干系人（相关方）。 ✅ 启动项目工作，但记录风险。 ✨ 关键词：章程获批 3️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：本题答案在 2️⃣ 4️⃣ 之间有争议。章程的批准意味着项目的正式启动，2️⃣ 4️⃣ 的前半句都没有问题，区别在于后半句。2️⃣ 的后半句也正常，但与题目中“团队成员正在休假”无任何对应关系；而 4️⃣ 的后半句记录风险，与团队成员正在休假（无法沟通情况）对应，个人认为 4️⃣ 更好。1️⃣ 说法错误，启动会议 (kick-off meeting) 是在计划批准后，而非章程批准后召开的；3️⃣ 是项目工作，但与题目强调的“与团队沟通情况”、“一些团队成员正在休假”无关。 🤔 项目在计划阶段的大致流程：","link":"/2024/07/10/pmp_test_what_confuses_me_10/"},{"title":"PMP 考试 - 易错和令人困惑的问题集（十一）","text":"仅供自己复习使用。如果侵权请联系删除。 一、某高级理人员向项目经理报告了一个软件错误。而项目团队报告说该错误是一个已知问题，只是未告知这名高级管理人员。为了防止这种沟通不畅的问题再次发生，项目经理该怎么做？ ❌ 查看干系人（相关方）参与计划，确定是否应将这名高级管理人员加入到该计划。 ✅ 更新干系人（相关方）登记册，将这名高级管理人员纳入所有沟通范围。 邀请这名高级管理人员参加项目会议，让他/她了解最新的项目状态。 与这名高级管理人员会面，简单介绍相关的报告和上报流程。 ✨ 关键词：沟通问题、干系人登记册 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：重要信息没有主动通知干系人，本质上还是沟通问题。1️⃣ 质疑是否该管理这个干系人，是明显错误的想法；2️⃣ 前半句是管理干系人，后半句是管理沟通，正确；3️⃣ 从沟通角度来说，是在刁难该干系人，不是正确的沟通问题解决方式；4️⃣ 是在指责该干系人没有遵守报告和上报流程，错误。 🤔 “将这名高级管理人员纳入所有沟通范围。​”并不是一个极端的做法。 二、Scrum 团队交付的项目必须符合法规要求。在设计研讨会上，开发人员推荐了几个方案，但无法就具体实施哪个方案达成一致。为了解决这个问题，项目经理应该采取哪两项措施？（选择两项） ✅ 让每个人表明自己对各个方案的同意程度。 让产品负责人选择最佳方案。 ❌ 将团队分成小组，以汇总调查结果。 ✅ 审查所有方案并确定其中最优的一项。 使用石川图选择最佳方案。 ✨ 关键词：敏捷、团队决策 1️⃣ 3️⃣ ❌ -&gt; 1️⃣ 4️⃣ ✅ 💡 解析：本题考决策技术。1️⃣ 公平、民主，类似于名义组技术，是常用的群体决策技术，可以选；2️⃣ 不符合自组织团队的决策原则，也不是好的决策技术；3️⃣ 没有这种决策技术；4️⃣ 多中选优，属于决策树技术，可以使用；5️⃣ 石川图是用于找根本原因的，不是决策技术。 三、某个项目管理办公室 (PMO) 一直在尝试针对项目管理框架实施适应型方法。项目经已接到要求，需要在下一个项目中使用适应型工具。该公司对适应型工具的认知度很低，许多干系人（相关方）都对转向混合方法感到担忧，项目经理该怎么做？ 向 PMO 提出建议，指出现在不是针对项目开始实施新工具的适当时机。 编制变更请求，就该新的项目框架寻求获得指导委员会批准。 ❌ 在定期状态报告和沟通管理计划中纳入这些工具的使用和对其收益的监督。 ✅ 引入一家第三方公司，由其为该特定项目开发并实施一个混合型框架。 ✨ 关键词：切换到敏捷 3️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：敏捷方法推广的套路题目。敏捷方法推广，有三个基本方式或原则：1、从小的简单的项目开始；2、先使用混合型方法；3、引入第三方咨询公司来帮助推广。本题 4️⃣ 选项符合了其中两个原则，最好。1️⃣ 因噎废食，不推广了，错误；2️⃣ 推广敏捷方法，不是变更，也不需要指导委员会批准；3️⃣ 敏捷并不强调状态报告和沟通管理计划，且关键问题是公司对敏捷方法认知度低，可以培训、指导、说服，而状态报告和沟通计划，主要用于预测型项目反映项目绩效，与题目问题无关。 🤔 敏捷方法推广，有三个基本方式或原则： 从小的简单的项目开始。 先使用混合型方法。 引入第三方咨询公司来帮助推广。 四、某组织的首席信息官 (CIO) 决定将开发团队从旧的遗留系统迁移到采用新技术的新体系架构之中。这支开发团队在项目开始前只进行过自我培训。首席信息官已确认，该项目并不重要，也没有额外预算用于雇用新技术专业人员。项目经理应该采取哪项措施？ 要求开发团队参加更多课程，以增加他们的知识。 ❌ 在制定风险管理计划时，考虑组织的风险承受能力。 ✅ 执行影响分析，以确定项目是否需要其他资源。 要求发起人划拨额外预算来雇用专业开发团队。 ✨ 关键词：成本不足以雇用新技术专业人员 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：高管给出一个错误指令（PMP 考试中，任何人说项目不重要都不成立），是否应该雇佣新技术专业人员，应根据项目具体需要。此类问题，或用正确做法的好处来说服干系人，或者坚持正确做法，3️⃣ 即实事求是的正确做法。1️⃣ 如果需要培训，也应是项目经理安排，而非让团队自己去花钱上课；2️⃣ 意思是接受团队能力不够这一风险，错误；4️⃣ 应先分析影响，再决定是否申请额外预算雇佣专业团队。 🤔 新概念：“PMP 考试中，任何人说项目不重要都不成立”，或用正确做法的好处来说服干系人，或者坚持正确做法。 五、一家制造公司的项目经理获悉，近期交付的设备初始测试出现问题。这台设备不符合标准设计规范，并导致问询被转交给了职能员工。项目经理首先该做什么来解决这一问题? ✅ 审查初始测试程序和执行情况。 评估环境和个人因素。 评估设备的技术文档。 ❌ 了解干系人（相关方）之间的沟通。 ✨ 关键词：质量问题 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：质量问题或缺陷，85% 以上的原因和责任都是管理问题，及流程是否科学、合理，以及流程是否被认真地执行了。1️⃣ 2️⃣ 3️⃣ 4️⃣ 都是为质量缺陷找原因，2️⃣ 4️⃣ 都甩锅给了团队成员和干系人；3️⃣ 项目经理不需要懂具体的技术规范；1️⃣ 管理者的责任是从流程、规范、执行方面杜绝发生问题的可能性，正确。 🤔 质量问题既然发生就是明确发生，重新审视质量管理和质量控制流程。当时选 4️⃣ 本意是想确认情况，没有往逃避方面想。 六、在一次回顾会议上，项目经理指出，在制品 (WIP) 过多，需要减少数量。为什么要减少 WIP？ ✅（过多的）WIP 隐藏了过程中的瓶颈 。 ❌（过多的）WIP 难以进行可视化和监督。 （过多的）WIP 能够減少提前量和周期时间。 （过多的）WIP 能够最大化资源分配。 ✨ 关键词：WIP 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：本题有文字游戏的成分，要认真分析选项的说法。在制品 (WIP) 过多，会影响交付周期，而减少在制品 (WIP) 的目的是“减少提前量和周期时间”，但不能选 3️⃣，因为 3️⃣ 前面缺少了“减少”两字。对应题目提问，四个选项前面都隐藏了“过多的”三字，应把这三个字加上才符合题目问题的逻辑。加上“过多的”三个字后，3️⃣ 4️⃣ 的说法都背道而驰，错误；2️⃣ WIP 技术本身就是为了可视化和监督，多、少都可以监督，因此 2️⃣ 说法错误；1️⃣ 过多的 WIP 隐藏了过程中的瓶颈，正是要减少 WIP 限制的目的，逻辑正确。 📖 看板方法利用列进入和退出策略以及限制 WIP（Work in Progress, 在制品）等制约因素, 可提供一目了然的工作流、瓶颈、阻碍和整体状态信息。此外，看板作为一个工具也可运用于其他敏捷实践（如 SCRUM、极限编程等）中作为面向所有干系人的信息发射源，提供团队工作状态的最新信息。在看板方法中，完成工作比开始新工作更为重要。从未完成的工作中无法获得任何价值，因此团队将协作实施和遵从在制品 (WIP) 限制，即每一列中正在并行的任务不可超过一定的数量，让整个系统中的每份工作尽快得以“完成”。🤔 对应了答案中的“（过多的）WIP 隐藏了过程中的瓶颈” 七、由于价格上涨，一位敏捷项目经理发现，可用的项目资金不足以按最初计划在即将到来的迭代中增加一名团队成员，项目预算和发布截止期限都很紧张，现有的跨职能团队经验丰富。项目经理首先应该采取什么方法？ ❌ 要求职能经理为项目寻找一位经验较少、成本较低的团队成员。 ✅ 请求当前团队分析新增资源的计划工作。 要求业务干系人（相关方）减少产品所需的功能数量。 推迟聘用额外资源，直到市场有利于在项目要求范围内开展工作。 ✨ 关键词：敏捷、成本不够新增团队成员 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：敏捷项目，无法新增资源，首先考虑让现有资源多分担任务，其次可以减少当前迭代的任务量，无论选择哪一个，都应先选 2️⃣，即分析原计划的任务量。1️⃣ 题目已经否定了增加资源的可能性，排除；3️⃣ 减少当前迭代任务，是开发团队能做主的事情，不需要向业务干系人申请；4️⃣ 推迟工作开展，错误做法。 🤔 敏捷项目，无法新增资源，首先考虑让现有资源多分担任务，其次可以减少当前迭代的任务量。可是正常的情况下加班是必不选的，存疑。","link":"/2024/07/11/pmp_test_what_confuses_me_11/"},{"title":"PMP 考试 - 易错和令人困惑的问题集（十二）","text":"仅供自己复习使用。如果侵权请联系删除。 一、多支敏捷团队一直在并行开发一款新产品的软件组件。在一支团队的冲刺审查会议上，一名团队成员提到，其组件测试出现延迟，原因是所需的组件直到冲刺的后期才可供使用。项目经理本应采取什么措施来防止延迟发生？ 确认 Scrum 主管已在冲刺计划期间核查了情况。 ✅ 确保 Scrum of Scrums 以正确的方式传达了一个适当的发布系列。 确认产品经理正确优化了冲刺待办项列表。 确保两支团队的成员达成一致。 ✨ 关键词：敏捷、依赖关系 2️⃣ ✅ 💡 解析：敏捷项目的依赖关系（团队成员之间及其任务的相互配合、协调）出现了问题，如何避免？敏捷项目的依赖关系是通过每日站会或 Scrum of Scrums 来管理和协调的，2️⃣ 正确。本题是考每日站会或 Scrum of Scrums 作用的基本概念题目，不多解释了。 🤔 新概念：敏捷项目的依赖关系是通过每日站会或 Scrum of Scrums 来管理和协调依赖关系的。​ 二、一位项目经理新得到任命，负责领导一个协作工具部署项目。在首次会议期间，项目经理发现，一些成员提到的是“现场调查清单”，而其他成员提到的是“现场先决条件模版”。项目经理担心，这种情况可能会导致误解。项目经理应该如何解决这一问题，并达成共识？ 向项目发起人和客户提出问题。 要求项目管理办公室 (PMO) 予以澄清。 ✅ 与团队成员一起标准化项目中使用的术语。 ❌ 与团队成员一起强化项目沟通管理计划。 ✨ 关键词：术语不一致 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：团队合作过程中使用的语言不一致，应该先统一术语，以避免误解，提高沟通效率，3️⃣ 是正解。1️⃣ 2️⃣ 都是甩锅行为，排除；4️⃣ 沟通管理计划主要强调信息的接收和发布方式，术语不一致，是配置管理问题，不是沟通问题。 🤔 新概念：术语不一致，是配置管理问题，不是沟通问题。​ 三、在某个项目的规划阶段，高级管理层批准了从一家供应商处购买硬件设备的预算。在此项目的执行阶段，项目经理意识到，在规划阶段错误地使用了旧版本的预算。项目经理应如何避免将来发生这种情况？ 更新预算，使其符合当前的定价。 ❌ 指派一名团队成员跟踪文档的最新版本。 ✅ 为所有项目文档保留一个唯一的存储库。 获得发起人针对新预算的批准。 ✨ 关键词：使用了错误的预算（文件） 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：使用了错误版本的文件，属于配置管理问题，也可以简单当成存储或沟通问题，3️⃣ 可以选。1️⃣ 治标不治本，不能杜绝类似问题发生；2️⃣ 不是系统解决问题的正确做法；4️⃣ 和 1️⃣ 一样，不能彻底解决问题。 🤔 新概念：使用了错误版本的文件，也属于配置管理问题。​ 四、一位新项目经理参加了一个正在进行的项目的首次团队会议。为了获得更多关于项目的信息，项目经理应该首先向团队询问什么？ ✅ 进度绩效指数 (SPI) 的现状如何？ ❌ 内部和外部干系人（相关方）都是谁？ 预计有哪些重大项目风险即将发生？ 该项目的预期收益是什么？ ✨ 关键词：新项目经理参加了一个正在进行的项目、首先了解什么 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：对于中途加入的项目经理，了解项目管理计划和当前项目绩效信息是当务之急，1️⃣ 正确。并且，大多数项目问题都会直接影响项目进度，因此 SPI、SV 是判断项目健康与否直观指标。2️⃣ 3️⃣ 4️⃣ 都不是最需要关注的信息。 🤔 新概念：对于中途加入的项目经理，了解项目管理计划和当前项目绩效信息是当务之急。​ 五、一支从事软件开发项目的团队目前正在使用在线存储库来合并他们的本地解决方案。但是，由于互联网连接质量较差，他们似乎无法访问在线存储库。项目经理应如何解决此问题并继续开展项目工作? ✅ 将此问题添加到项目问题日志中。 利用每日站会与团队讨论这一问题。 向项目发起人提出这一问题。 ❌ 查看项目风险日志，并应用记录在案的风险响应措施。 ✨ 关键词：新的制约因素 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：项目识别了一个制约因素（限制条件），可以直接当成问题，记录在问题日志并去处理，1️⃣ 正确。2️⃣ 每日站会上不讨论问题；3️⃣ 不应麻烦发起人；4️⃣ 刚刚识别的制约因素，不可能已经记录在风险登记册并制定了应对措施，且 4️⃣ 中的“风险日志”是风险报告，不是用来记录风险和应对措施的。 🤔 项目过程中识别的类似“互联网连接质量较差”可以当作制约因素，和问题一样处理。并且风险日志（风险报告）不等于风险登记册。 六、在之前的一次冲刺中，一支项目团队未能按照产品负责人指定的需求执行工作。现在，团队正在进行下一次迭代的规划会议。在提交迭代目标之前，项目负责人应该审查哪两项？（选择两项） ✅ 任务优先级。 ✅ 故事点估算。 每日站会纪要。 ❌ 在制品 (WIP) 限制。 验收标准。 ✨ 关键词：提交迭代目标之前 PO 审查什么 2️⃣ 4️⃣ ❌ -&gt; 1️⃣ 2️⃣ ✅ 💡 解析：本题答案在 1️⃣ 2️⃣ 和 1️⃣ 5️⃣ 之间有争议。题目关键词是“未能按照产品负责人指定的需求执行工作”，可以理解为团队工作结果不符合 PO 指定的工作内容（优先级）和任务量，从这个角度，应 1️⃣ 2️⃣ 合适，分别对应优先级和任务量。也可以理解为团队的工作结果不满足质量标准，从这个角度则 1️⃣ 5️⃣ 更合适。本人倾向于 1️⃣ 2️⃣，因为如果是质量标准不满足，题目一般会强调缺陷、错误等，从题目描述来看，应该指的是工作内容、工作量不符合 PO 要求。 七、一位项目经理被指派接替一个混合项目。在第一次会议上，项目发起人表示很沮丧，并询问该新项目经理如何能确保预算、时间表和范围不会出现意外变更。与此同时，产品负责人询问，这支团队处理这个项目需要多长时间，因为他们还有其他工作要做。该项目具有高度的不确定性，而且受到严格法规的强烈影响。项目经理下一步应该进行哪些分析？ 干系人（相关方）分析。 ✅ 项目管理计划分析。 ❌ 预算分析。 沟通管理计划分析。 ✨ 关键词：分析新的项目 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：新接手项目的项目经理，要回答干系人提出的各种问题，应先查看项目管理计划、项目当前的绩效水平（SPI、CPI 等），才能对项目整体情况做出大致的判断。四个选项中，只有 2️⃣ 包括了比较全面的信息，能覆盖题目干系人提出的问题，其他三个选项都有局限。本题也可以简单理解为，新上任的项目经理，要了解项目情况，应查看项目管理计划和当前绩效信息。 🤔 和本业的问题四强调了同一个概念：对于中途加入的项目经理，了解项目管理计划和当前项目绩效信息是当务之急。​","link":"/2024/07/12/pmp_test_what_confuses_me_12/"},{"title":"PMP 考试 - 易错和令人困惑的问题集（十三）","text":"仅供自己复习使用。如果侵权请联系删除。 一、一位项目经理正在实施一个新的时间管理系统项目，该系统将在未来三个月内在整个组织内上线。一些经理对过渡期存有疑虑。项目经理应该如何在上线和切换过程中与各经理保持一致？ ❌ 组织与各经理一同进行冲刺审查，并根据层级结构进行分组。 组织与组织中的所有高级经理进行一次全天的冲刺审查。 ✅ 为所有经理组织冲刺审查，根据部署进度计划对他们进行分组， 在过渡结束前一个月，为新业务部门组织一次冲刺审查。 ✨ 关键词：与干系人协作 1️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：“如何在上线和切换过程中与（组织内的）各经理保持一致”，可以理解为是组织中各部门的整合、协调问题，也可以理解为在敏捷项目执行过程中不断获得干系人反馈以确保结果符合要求。1️⃣ 前半句没有问题，后半句中的“层级结构”违背项目管理以及敏捷的沟通原则；2️⃣ 冲刺审查应定期举行，而不是一天完成；3️⃣ 前半句没有问题，后半句的意思是根据上线和切换进度对部门进行分类（协调），也没有问题；4️⃣ 冲刺审查应定期进行，4️⃣ 的说法与 2️⃣ 一样错误。 🤔 新概念：“层级结构违背项目管理以及敏捷的沟通原则。​” 二、在解决方案的开发过程中，最终用户表示，他们希望尽快拿到产品，项目经理与从事过类似项目的团队成员会面，以起草初步的时间和成本估算。在会议期间，项目发起人和产品负责人之间发生了冲突，项目经理应如何在与会者之间达成共识？ ✅ 分享两种方案的估算结果，并要求与会者使用投票技术。 计算两种估算结果的平均值，并和与会者分享。 ❌ 在和与会者分享之前，与专家一起审查这两项估算结果。 展示两项估算结果，并让与会者参与修订。 ✨ 关键词：冲突、决策方式 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：项目发起人和产品负责人对时间、成本估算意见分歧，如何达成共识？题目中强调了“从事过类似项目的团队成员”，暗示应让团队成员参与，1️⃣ 中的投票属于群体决策技术，与题目暗示对应，且与题目问题“在与会者之间达成共识”对应，可以选。2️⃣ 估算结果应尽量符合实际情况，不应简单平均；3️⃣ 与题目强调的“在与会者之间达成共识”不符；4️⃣ 后半句没有 1️⃣ 的做法专业。 三、一个项目已经进入收尾阶段。工作已经基本完成，并且项目经理希望开始项目的收尾过程。项目经理应确保在收尾过程之前做好哪些准备？ 已召开经验教训总结会议。 ❌ 已完成移交和可交付成果验收。 ✅ 项目合同约定的可交付成果已验收。 组织过程资产 (OPAs) 已更新。 ✨ 关键词：收尾前的工作 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：本题考实施项目收尾之前的准备工作。1️⃣ 2️⃣ 4️⃣ 都是收尾工作，而非收尾前的准备工作，只有 3️⃣ 属控制采购工作，属于项目收尾前必须完成的，正确。 📖 收尾过程组的输出： 项目文件更新 经验教训登记册 最终产品、服务或结果移交 最终报告 组织过程资产更新 四、一位项目经理负责记录从之前的项目中汲取的经验教训。该项目经理发现，由于没有考虑团队的休假时间，进度计划发生了许多变更。项目经理应如何防止在其下一个项目中发生这种情况？ ✅ 分析组织过程资产 (OPAs)。 分析事业环境因素 (EEFs). ❌ 查阅资源管理计划。 查阅员工管理计划。 ✨ 关键词：防止再次发生 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：“如何防止问题再次发生”，标准答案包括经验教训、根本原因分析、问题日志等。1️⃣ 包括了经验教训，可以选。其他选项都与防止再次发生无直接联系。 🤔 “如何防止问题再次发生”，标准答案包括经验教训、根本原因分析、问题日志等。 五、在一次辅导会议中，项目经理向一名初级项目经理简单介绍了使用挣值管理 (EVM) 方法来管理项目的益处，初级项目经理应该参考什么？ ✅ S 曲线。 累积流图。 ❌ 看板面板。 水晶图。 ✨ 关键词：挣值管理、图标参考 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：题目问的是挣值方法的好处，但选项中只有 S 曲线与挣值有关，是挣值技术的基础 BAC 的表现方方式，其他与挣值方法都无关。因此本题应理解为，要使用挣值方法，首先要创建什么？选 1️⃣ 正确。 🤔 挣值法评价曲线如下图所示，下图的横坐标表示时间，纵坐标则表示费用。BCWS 曲线为计划工作量的预算费用曲线，表示项目投入的费用随时间的推移在不断积累，直至项目结束达到它的最大值，所以曲线呈 S 形状，也称为 S 曲线。ACWP 已完成工作量的实际费用，同样是进度的时间参数，随项目推进而不断增加的，也是呈 S 形的曲线。利用挣值法评价曲线可进行费用进度评价，图中所示的项目，执行效果不佳，即费用超支，进度延误，应采取相应的补救措施。 六、一个项目经理正在管理一个具有高度不确定性的复杂研究项目，要求实现 一种机制来度量可交付成果的质量。使用混合方法时，可以使用哪些技术来实现这一目标？ ❌ 日常 Scrum 和产品负责人质量评估。 ✅ Scrum 主评审和质量看板方法。 结对工作和顾客角色法。 限时选代和站立评审会议。 ✨ 关键词：度量可交付成果的质量、质量控制 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：题目中的“度量可交付成果质量”不能简单地理解为“检查”（质量控制），因为敏捷方法在质量管理方面更加强调“全员参与”、“第一次就把事情做对（零缺陷）”等质量保证概念。1️⃣ 后半句有问题，因为产品负责人在冲刺评审过程才有机会进行质量的评估，属于事后的外部检查和验收，时间不对且属于甩锅行为；2️⃣ 前半句没有大问题，后半句强调全员参与，发现缺陷随时解决，符合敏捷质量管理原则；3️⃣ 前半句可以预防质量缺陷，但后半句与质量管理无关，陌生词汇；4️⃣ 两个概念都与质量无直接关系。 🤔 PO 对理解相关方的需求和需求优先级负主要责任；敏捷团队的所有人对质量负责。 七、在经验教训研讨会期间，一个干系人提到该项目不成功，因为它没有交付预期的商业价值。项目经理应该如何解决这个问题？ ❌ 与干系人一起评审项目管理计划任务。 与干系人一起审查项目管理计划预算。 ✅ 与干系人一起评审业务效益管理计划。 与干系人一起审查沟通管理计划。 ✨ 关键词：没有交付预期的商业价值、没有达到需求、效益管理计划 1️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：本题关键词是“成功”和“商业价值”。项目是否成功，是否交付了预期的商业价值，可以对比项目效益管理计划。效益管理计划和项目管理计划描述了项目创造的商业价值如何能够 成为组织持续运营的一部分，包括使用的（商业价值）测量指标。测量指标可以合适商业价值并确认项目是否成功。1️⃣ 概念太大，不聚焦；3️⃣ 直接对应，虽然描述多了“业务（商业）”两字， 但不影响理解。 🤔 项目价值优先参考“效益管理计划”。","link":"/2024/07/13/pmp_test_what_confuses_me_13/"},{"title":"PMP 考试 - 易错和令人困惑的问题集（十四）","text":"仅供自己复习使用。如果侵权请联系删除。 一、项目经理负责一个价值数百万美元的会议中心项目，在施工期间一场大火烧毁了建筑。项目经理本应采取什么措施来确保这种类型的风险不会显著影响项目成本？ 接受风险。 ❌ 减轻风险。 ✅ 转移风险。 消除风险。 ✨ 关键词：数百万美元损失、风险 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：本题考风险应对策略。可以按照常识，灾害类风险一般都采用买保险的方式来应对，属于转移 3️⃣。按 PMBOK 风险管理策略的分类，严重风险（威胁）一般采取回避和转移，本题没有回避策略，所以选转移。另外之前版本的 PMBOK 签订，转移策略适用于财务后果严重的风险，价值数百万美元的建筑被毁，属于财务后果严重，适用于转移策略。 🤔 新概念：“严重风险（威胁）一般采取回避和转移。​” 二、多个敏捷团队正在处理产品可交付成果。在最后几次迭代中，有一个团队接收其他团队发来的几条计划外非生产支持请求，这影响了团队的速度和计划内可交付成果。在这种情况下，项目经理该怎么做？ 让团队在每次迭代中满足大部分请求。 ✅ 让团队专注于计划内可交付成果，不要开展任何计划外活动。 告诉团队尽可能完成计划内可交付成果和收到的请求。 ❌ 告知其他团队的成员，将这些请求直接添加到迭代待办事项列表中。 ✨ 关键词：团队接收其他团队发来的几条计划外非生产支持请求、计划外非生产要求 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：题目关键词“计划外非生产要求”，即与项目无关的工作，这是不应该执行的工作，也不应列入待办项列表，2️⃣ 正确。1️⃣ 3️⃣ 都是满足计划外非生产请求，错误；4️⃣ 让列入待办项列表，错误。 🤔 新概念：“计划外非生产要求 = 与项目无关的工作，这是不应该执行的工作。​” 三、一位项目经理最近加入了一家小公司。该公司的首席运营官 (COO) 要求团队跳过流程中的一些步骤，以便更快地工作。项目经理希望确保将来不会跳过这些步骤。项目经理应该怎么做？ ❌ 通知所有团队成员必须完成流程中的所有步骤。 将问题上报给其他行政领导成员。 ✅ 与团队和首席运营官一起安排流程步骤的评审。 重新设计流程，以便团队可以更快地行动。 ✨ 关键词： 1️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：COO 对团队提出的要求不符合项目经理的希望，本题可以当成典型的干系人问题，应管理干系人。3️⃣ 是与当事人面对、开会（用这些步骤的作用、意义来说服 COO），是经典的管理干系人选项。本题也可以当成过程改进问题（过程是否需要改进），因为涉及 COO 和团队，因此强调他们参与，也是选 3️⃣。1️⃣ 没有面对干系人；2️⃣ 不需要上报；4️⃣ 与题目描述矛盾了。 四、一家公司正在开发新产品。在项目规划期间，法律部门的干系人不参加任何项目会议，对产品设计不感兴趣。项目经理应该如何处理这种情况？ 将问题上报给项目发起人并寻求帮助。 ❌ 让项目干系人参与进来，确保所有需求都被捕获。 ✅ 审查干系人参与计划和沟通策略。 审查产品需求并更新干系人登记册。 ✨ 关键词：管理干系人参与 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：典型的干系人问题，法律部门的人员对项目不配合，应管理干系人。3️⃣ 根据干系人参与计划来管理他，正确且很专业，管理干系人需要使用沟通技术，3️⃣ 后半句也没问题。1️⃣ 不应麻烦发起人；2️⃣ 泛泛而谈，没有具体措施，不解决问题；4️⃣ 前半句是企图排除该干系人（看产品需求与该干系人关系大不大），后半句是想删除该干系人，因为一般是在添加、删除干系人时，才强调更新登记册，4️⃣ 的意思非常负面、被动。 五、某敏捷团队接到一个项目任务，要求对政府重点产品实施变更。团队需要在六个月内完成这项任务。该团队领导接下来该做什么？ 创建项目章程和工作说明书 (SOW)，评估变更和变更范围。 ✅ 为该需求创建高层级的故事集 (Eple)，并开始安排需求讨论会。 创建完成此变更所需的全部故事，将故事记录在待办事项列表中，其根据商业验收进行优先级排序。 只为下一个冲刺创建全部故事，跳过故事集，直至下一个冲刺。 ✨ 关键词：敏捷、高层级需求 2️⃣ ✅ 💡 解析：敏捷项目，团队首先要做什么？开放式问题，用排除法。1️⃣ 项目经理可以创建项目章程，但不能创建 SOW（由客户、发起人提供），而本题问题的不是项目经理做什么，而是团队做什么；另外，1️⃣ 的后半句明显不符合敏捷方法，排除。2️⃣ 重点在后半句，找干系人收集需求，敏捷的需求可以用故事来反映，故事可以像 WBS 一样分解为高层级的故事（史诗级故事）和最底层故事，2️⃣ 的说法没有问题。3️⃣ 敏捷方法不主张也不可能一开始就将所有故事创建出来，另外 3️⃣ 的后半句排序依据也是严重错误。4️⃣ 否定了用户故事（待办项）的细分、细化过程，不妥。 🤔 新概念：“项目经理可以创建项目章程，但不能创建 SOW，SOW 由客户、发起人提供。​” 六、一个国际客户联系了一个软件开发公司来开发一个软件产品，并且指派了一个敏捷项目经理。在一次评审会议上，客户抱怨在最初汇报中提到的一个功能沒有实现。项目经理应该怎么做？ ✅ 在优先需求列表中包括提到的特性。 指派一名团队成员立即开始该功能的工作。 ❌ 查看原始项目文档以确认。 将其视为变更请求，并评估对项目目标的影响。 ✨ 关键词：敏捷、功能没有实现、验收不通过 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：验收不通过，不是问原因，而是问下一步怎么办？如何是预测型项目，3️⃣ 优先，先看看是我们忘了做，还是对方一开始就没有提。但本题是敏捷型项目，客户有权力在任何时候提出新需求，敏捷团队应随时将新需求列入待办项列表，并根据优先级顺序完成，1️⃣ 正确。2️⃣ 是否立即开始工作，要根据优先级顺序，且不是“指派一名成员”；3️⃣ 在敏捷项目中，没有意义，即使原始文档中没有记录，现在也应纳入待办项列表；4️⃣ 敏捷项目不需要变更管理流程。 🤔 以后功能没有实现优先不往质量方面想。 七、在项目规划阶段，项目经理意识到项目绩效可以根据预算偏差和收入来衡量，但是没有考虑整个项目进度。项目经理应该做什么？ 根据绩效审查和更新项目进度。 审查进度基准，并考虑采用进度绩效指标。 研制一种时间、成本和范围跟踪方法。 为项目采用正式的变更管理流程。 ✨ 关键词：项目绩效测量 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：项目绩效测量应同时考虑范围（包括质量）、进度、成本，而不能仅仅根据成本。挣值技术就是同时考虑范围、进度、成本的一种绩效测量方法，3️⃣ 正确。1️⃣ 说的是如何更新进度而非测量进度指标；2️⃣ 是测量进度的方法，但没有 3️⃣ 全面；4️⃣ 与题目问题无关。","link":"/2024/07/14/pmp_test_what_confuses_me_14/"},{"title":"PMP 考试 - 易错和令人困惑的问题集（十五）","text":"仅供自己复习使用。如果侵权请联系删除。 一、在项目的早期阶段，没有及时执行缓解行动，因此，项目进度受到影响。几个项目干系人现在对延迟感到沮丧。项目经理本应该如何处理这个问题？ 发现并报告了问题。 ❌ 监控和控制问题。 ✅ 确定适当的应对措施并付诸实施。 向受影响的干系人传达任何已确定的行动。 ✨ 关键词：缓解行动、本应 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：题目问“本应如何处理这个问题”。导致问题的原因是“没有及时执行缓解行为”，及时执行缓解行动就可以避免这个问题，3️⃣ 正确。1️⃣ 应及时采取行动而非仅仅报告；2️⃣ 不是预防工作，且没有 3️⃣ 具体；4️⃣ 如果题目问下一步怎么办，4️⃣ 是可以考虑的选项，而题目不是这样问的。 二、一家公司指派了一名项目经理来完成确定新项目所需资源这一初始任务，项目经理应该咨询什么？ ❌ 公司的历史组织项目工件。 公司的项目责任分配矩阵 (RAM)。 ✅ 公司的资源管理计划。 公司的资源日历。 ✨ 关键词：新项目、规划资源 1️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：题目问题可以概括为：新项目经理如何估算（识别）资源？根据《PMP 备考资料》96 页第 2 段“资源管理计划”下第一小黑点“识别资源”——“识别和量化项目所需团队和实物资源的方法”，选 3️⃣。 📖 资源管理计划 (Resource management plan) 可能包括（但不限于）： 识别资源。 获取资源。 角色与职责。 项目组织架构图。项目组织架构图以图形方式展示项目团队成员及其报告关系。基于项目的需要，项目组织架构图可以是正式或非正式的，非常详细或高度概括的。 项目团队资源管理。关于如何定义、配备、管理和最终解散项目团队资源的指南。 培训。针对项目成员的培训策略。 团队建设。建设项目团队的方法。 资源控制。 认可计划。将给予团队成员哪些认可和奖励,以及何时给予。 三、在敏捷团队回顾中，一个项目团队成员提到代码质量正在下降，这可能会导致将来的返工，随着时间的推移，这种返工可能会变得难以管理。项目经理应该怎么做？ ✅ 帮助团队创建完成 (DoD) 的定义，以提高交付质量。 ❌ 将测试项目添加到待办事项列表中，以定期评估质量。 扩大团队以提高项目质量。 比较改进质量的成本和失败的成本，并调整预算。 ✨ 关键词：敏捷、质量 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：题目提到质量正在下降，说明质量的测试是有在进行的，否则质量下降这一信息无法获知。光是定期评估质量并不能提升质量，2️⃣ 排除。敏捷非常重视每个用户故事的完成的定义 (DoD)，即每个故事都要达到相应的质量标准才能算完成，这是提升质量的有效方法，选 1️⃣。还有，敏捷实践指南有描述，敏捷的痛点和解决痛点的可能性，关于返工和技术债务，都提到了DoD。代码质量下降，通过DOD解决，可以当成基本原则。 🤔 敏捷的质量管理可以与 DoD 挂钩。代码质量下降，通过DOD解决，可以当成基本原则。​ 四、项目经理新加入到组织中，并且正在考虑引入敏捷法，他在思考该组织的一些特征。这些特征更易于支持跨部门协作的敏捷原则。项目经理应该纳入哪三项变更？（选择三项） 长期预算限制和组织的详细情况介绍。 ✅ 转变其对看待、审视和评估员工方式的组织意愿。 ✅ 项目、项目集和项目组合管理职能的集中化或者分散化。 ❌ 短期预算限制和组织的详细情况说明。 ✅ 高管层的变更意愿。 ✨ 关键词：推广敏捷、纳入变更 3️⃣ 4️⃣ 5️⃣ ❌ -&gt; 2️⃣ 3️⃣ 5️⃣ ✅ 💡 解析：想在组织内推广敏捷方法，高管和组织层面的支持肯定是重要因素，因为自上而下推广比自下而上要容易很多，2️⃣ 5️⃣ 可选性；相对于职能型管理，敏捷方法和项目管理方法本身都是在推崇分散化管理，因此 3️⃣ 也是需要考虑的重要因素；预算和推广敏捷方法与否没有直接关系，敏捷方法的主要目的是降低风险，提升客户满意度，因此 1️⃣ 4️⃣ 排除。 五、在敏捷项目中,项目负责人应该如何让干系人（相关方）及时了解当前已实现的价值？ 根据要求向干系人（相关方）提供他们需要的最新消息。 发送包含所有重要信息的每周状态报告。 请求干系人（相关方）参与每日项目会议。 ✅ 请求干系人（相关方）参加迭代演示的结尾部分。 ✨ 关键词：敏捷、信息发射源、已实现的价值和功能 4️⃣ ✅ 💡 解析：敏捷项目已实现的价值、功能，通过定期的冲刺评审会议向干系人展示。四个选项中，4️⃣ 的说法最接近这个意思。 🤔 新概念：敏捷项目已实现的价值、功能，通过定期的冲刺评审会议向干系人展示。​ 六、参与项目的团队成员分布在不同的时区。因此，这支跨职能虚拟团队很难在正常工作时间 内同步召开会议。项目经理应该如何处理这个问题？ 在时区时差较小的其他国家/地区聘用团队成员。 要求团队成员更改其会议时间。 ✅ 在一个时区举行会议，并与其他时区的人分享会议成果。 ❌ 录制会议，并将记录提供给其他团队成员。 ✨ 关键词：虚拟会议、会议缺席 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：处于不同时区的虚拟团队，如何召开会议?标准答案应是各地区的团队一起协商会议时间和形式。1️⃣ 是更换团队成员，因噎废食，错误做法；2️⃣ 其实质是要求部分时区的团队在非工作时间参见会议，否则该要求毫无意义；3️⃣ 说的是正常召开会议，会后给不能参与会议的团队发送会议纪要，符合有人缺席会议时的原则；4️⃣ 会议视频或音频，并不是会议纪要，4️⃣ 不如 3️⃣。 🤔 新概念：向会议缺席者发送会议纪要。​ 七、一位客户要求了解测试规范的最新进度。其中一个规范由于外部问题而失败，但团队成员指出，在实际情景中不会发生这种情况。项目经理的下一步该做什么？ ✅ 审查质量测量结果，并向客户通报项目管理计划中记录的项目状态。 让团队批准测试，因为这只是一个不会影响发布的测试用例。 ❌ 坚持让团队继续进行测试，直到所有测试用例都通过为止，并推迟所有当前活动。 要求项目发起人给予更多时间来评估测试用例，因为这将确保测试工作能彻底完成。 ✨ 关键词：质量问题 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：质量缺陷零容忍，测试失败就是质量缺陷，不能侥幸认为现实中不会发生。1️⃣ 是如实向客户通报，没有大的问题；2️⃣ 是造假、欺骗，错误；3️⃣ 态度是正确的，但忽略了客户要了解进度的需求，有暂时隐瞒测试失败的嫌疑，没有 1️⃣ 好；4️⃣ 与发起人无关。","link":"/2024/07/15/pmp_test_what_confuses_me_15/"},{"title":"PMP 考试 - 易错和令人困惑的问题集（十六）","text":"仅供自己复习使用。如果侵权请联系删除。 一、在修改项目任务时，一位项目经理注意到，有一项关键任务计划在四个月后执行，这项任务需要在系统关闭期间执行。在修改系统关闭计划后，项目经理确认下一次系统关闭将在两个月后进行，而再后一次将在 10 个月后进行。项目经理首先应该做什么？ ✅ 与项目团队一起调整项目进度计划，以便在下一次系统关闭期间执行关键任务。 ❌ 将关键任务重新安排在第二次系统关闭期间，因为该计划任务无法提前完成。 要求运营团队在四个月内安排一次系统关闭，以便与关键任务完成日期保持一致。 通知发起人，由于系统关闭日程与项目进度计划不匹配，项目无法按计划交付 ✨ 关键词：外部制约因素 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：本题的情景是：外部制约因素影响项目的进度计划。制约因素无法改变，必须接受，即调整进度计划以适应制约因素，1️⃣ 正确。2️⃣ 也是在适应制约因素，但进度必然延误，不是首选；3️⃣ 比较被动，未必可行；4️⃣ 更加被动，不符合项目经理职业道德。 🤔 新概念：外部制约因素影响项目的进度计划，制约因素无法改变，必须接受，调整计划。​ 二、某项目经理正与多个干系人（相关方）协同工作，以确保他们的努力与新项目的目标是一致的。项目经理应做什么来确保顺利达成一致？ ❌ 为项目创建关键绩效指标 (KPIS) 和度量指标，专门用于解决每个干系人（相关方）的需求。 ✅ 从干系人（相关方）那里获得关于项目应该采用哪些度量指标的一致同意。 从同一个项目组合中的类似项目中获取关键 KPIS 和度量指标。 确保在干系人（相关方）的互动中充分获得项目范围。 ✨ 关键词：与干系人就新项目的目标达成一致 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：题目问如何与干系人就新项目的目标达成一致？项目目标应包含一系列的成功标准，如时间、成本、范围、质量等，见 PMBOK 第 6 版 1.2.6.4 第二段的内容，1.2.6.4 还强调“主要干系人和项目经理应就这些问题达成共识并予以记录”。这些成功标准必须获得干系人的同意，1️⃣ 3️⃣ 没有找干系人，2️⃣ 4️⃣ 都强调找干系人，但 4️⃣ 只包括范围，而且没有强调度量指标。 🤔 新概念：项目目标应包含一系列的成功标准，如时间、成本、范围、质量等。​主要干系人和项目经理应就这些问题达成共识并予以记录。​与干系人的沟通及尽量避免闭门造车。 三、在将项目投入生产之前，一名新项目经理加入团队，项目经理了解到，运营问题妨碍任务按时完成。项目经理应该审查哪个过程？ ✅ 控制风险。 ❌ 控制范围。 控制质量。 控制进度。 ✨ 关键词：运营问题妨碍任务完成 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：运营问题妨碍项目完成（移交给运营），属于项目中遇到的制约因素（当成假设失败也行）。针对制约因素或假设条件的管理，属于风险管理范畴，选 1️⃣。 🤔 新概念：针对制约因素或假设条件的管理，属于风险管理范畴。​ 四、在不确定时期 (uncertain period) 开发项目时，必须避免预算偏差方面的风险。这应该使用哪一个合同类型？ ✅ 总价加经济价格调整合同 (FP-EPA)。 ❌ 工料合同 (T&amp;M)。 总价加激励费用合同 (FPIF)。 成本加激励费用合同 (CPIF)。 ✨ 关键词：不确定时期、避免预算偏差 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：本题考合同类型的特点。合同周期很长时，应使用总价加经济价格调整合同，以防止原材料价格或汇率波动带来的成本风险，选 1️⃣。 🤔 新概念：合同周期很长时，应使用总价加经济价格调整合同，以防止原材料价格或汇率波动带来的成本风险。​ 五、在项目规划期间，项目经理识别到多个风险。为减轻这些风险的影响，项目经理应该怎么做？ 将风险规避视为风险应对策略。 ❌ 遵循先前项目的风险管理计划。 执行储备分析。 ✅ 执行决策树分析并让干系人参与应对措施选择过程。 ✨ 关键词：规划期间、识别到多个风险、减轻风险影响 2️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：风险管理问题。很多风险识别后，如何减轻风险影响？实施风险应对措施，才能减轻风险影响。1️⃣ 很多风险，应具体情况具体分析，未必一定都用规避；2️⃣ 刻舟求剑，错误做法；3️⃣ 储备分析多指风险监控期间，对比剩余储备与剩余风险是否对应，不适合本题情景；4️⃣ 前半句决策树稍显生硬，但后半句很稳妥、全面。四个选项都不好，4️⃣ 相对可以选。 🤔 新概念：实施风险应对措施，才能减轻风险影响。并且干系人可以参与风险应对措施的选择过程。​ 六、项目团队正通过估算每个工作包来制定项目预算。团队使用过往项目的统计值和历史数据。这使用的是什么估算工具或技术？ 储备分析。 ❌ 类比估算。 专家判断。 ✅ 参数估算。 ✨ 关键词：过往项目、统计值、历史数据 2️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：本题考估算工具。“通过估算每个工作包来制定项目预算”，这属于自下而上估算，选项中没有。“统计值”、“历史数据”（数据库）则是参数估算关键词，可以选 4️⃣。 🤔 新概念：“统计值”、“历史数据”（数据库）则是参数估算关键词。​不过需要注意的是，类比估算也是基于之前项目进行的估算，不过是更为整体的粗略估算。 七、在一个新的产品改进项目启动过程中，项目经理发现历史数据表明，一个类似项目曾导致客户投诉，称相比先前的产品版本，改进后产品的用户体验更差。项目经理如何才能防止该新项目出现这种结果？ ❌ 界定高层级风险，并在完成工作分解结构后制定风险减轻计划。 将一个用户焦点小组确定为对结果有很大影响的外部干系人。 ✅ 聘用顾问进行效益分析，并将分析结果作为项目章程的输入内容。 聘用多名外部用户对产品进行验收测试。 ✨ 关键词：用户体验更差、未实现预期价值（效益） 1️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：题目问题可以归纳为：如何确保新项目比原版更有价值？这属于商业论证的范畴，可以通过成本效益分析，来论证一下，以确保新项目比原版本具有更高价值，选 3️⃣。","link":"/2024/07/16/pmp_test_what_confuses_me_16/"},{"title":"PMP 考试 - 易错和令人困惑的问题集（十七）","text":"仅供自己复习使用。如果侵权请联系删除。 一、在实施一个关键项目的可交付成果时，新的监管经理对可交付成果是否遵守某一环境法表示关注，项目经理下一步应该做什么？ 修改可交付成果以遵守环境法，并将结果告知新的监管经理。 提交一份变更请求，从范围中删除可交付成果以遵守该环境法。 ✅ 签发一份变更请求，将监管经理纳入项目的干系人参与计划。 ❌ 在风险登记册中记录一项可交付成果风险，并与项目团队制定减轻计划。 ✨ 关键词：新的监管经理 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：本题关键词“新的监管经理”，这属于识别了新的相关方，应首先更新相关方登记册、相关方参与计划，3️⃣ 正确，当然，更新干系人参与计划无须走变更流程，但走了也没错。1️⃣ 2️⃣ 4️⃣ 都是 3️⃣ 之后再考虑的问题。当识别新的干系人和变更问题同时存在时，一般先考虑更新干系人登记册和干系人参与计划。 🤔 新概念：识别新的相关方，首先更新相关方登记册、相关方参与计划。​ 二、产品团队正在运用原型法开展工作，以交付一个为期多年的业务计划，几个用户故事需要更长时间才能交付。项目经理该做什么？ ❌ 在回顾会议上确定风险和解决方法。 ✅ 确定跨职能部门依赖关系，并规划在下一个迭代中应用一个探针。 在提供项目更新期间，并将延误的情况告知干系人。 发现沟通管理计划中的不足并相应地解决它们。 ✨ 关键词：几个用户故事需要更长时间才能交付（估算问题） 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：敏捷工具概念题。探针（刺探 Spike），是包含在迭代计划中创建的专门用来获取知识或回答问题的任务，用来帮助团队了解如何处理其他任务，从而可以对其进行估算。编写用户故事时，如果无法很好地对其估算用户故事点是，可以创建一个“探针”，做一些实际工作，来寻求解决问题的方法，2️⃣ 正确。 📖 关于刺探（Spike 也称探测、探针）：刺探是一个简短的研究性试验。团队可以运用刺探来熟悉新技术或新领域、证明他们前面做出的假设、评估解决问题或风险的选项、或提升对用户故事工作量估算的确定性。​注意，刺探本身应该足够小（一个小时间盒），以便在迭代中计时。一旦试验目的达到，刺探就会停止。 三、项目经理结束了一个重要的组织转型项目，项目发起人通知项目经理，由于信息是保密的，所有项目文件应直接交付给他们，而不是上传到项目知识经验库。项目经理下一步应该做什么？ 将文件交给发起人，并删除所有项目记录。 ❌ 建议给予访问控制的程序，以提供受限访问。 ✅ 将发起人的请求告知审计团队。 按照原始流程发布文件。 ✨ 关键词：组织经验教训、需要保密、供审计的项目文件 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：项目文件有保密性，不能直接归档以供审计，而应以可以保密的方式保存。而文件不归档，会影响审计工作，因此 3️⃣ 正确。1️⃣ 错在“删除所有记录”；2️⃣ 违背了发起人要求；4️⃣ 根本没有考虑保密。本题可以当成常识问题，使用排除法，也是选 3️⃣。 四、项目经理正在为一个新的备受推崇的客户管理一个项目，商业论证正在纳入项目章程，该章程定义了项目结束日期，但未定义中间的里程碑。由于满足中间里程碑是客户的主要优先事项，项目经理下一步应该做什么？ 在风险登记册中包含中间项目里程碑成就。 ✅ 与团队讨论如何增强监控和报告方法。 ❌ 根据该信息分析客户的组织实践。 与发起人一起审查商业论证，以了解高层级的进度风险。 ✨ 关键词：缺乏里程碑 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：里程碑在进度计划中显示重要的进度控制节点，没有定义里程碑，应定义，以便对项目进度进行监控。1️⃣ 张冠李戴，错误；2️⃣ 与题目问题对应，可以选；3️⃣ 有放弃设置里程碑的意思，排除；4️⃣ 商业论证与进度风险没有联系，胡说八道。 🤔 新概念：里程碑在进度计划中显示重要的进度控制节点，主要还是与进度有关。 五、在一起为制定项目章程而召开的会议期间。项目经理发现未识别商业需求，并且未执行成本数据分析，项目经理首先应该做什么？ ❌ 更新商业论证。 继续制定项目章程。 立即拒绝该项目。 ✅ 向项目发起人提出建议。 ✨ 关键词：未识别商业需求 1️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：发起一个项目的过程顺序是，先确定商业需求 (SOW)，根据商业需求进行商业论证，根据商业论证制定和批准项目章程。题目描述显示，未确定 SOW，也未执行商业论证，这两件事都要先做，排除法选 4️⃣。1️⃣ 没偶执行成本分析，即没有进行商业论证，何谈更新？2️⃣ 制定章程的两个前提工作没有做，2️⃣ 也不合适；3️⃣ 消极做法，不考虑。本题出的有点含糊，仅做参考。 🤔 顺序：缺定商业需求 (SOW) -&gt; 进行商业论证 （&lt;-&gt; 成本效益分析）-&gt; 制定项目章程 -&gt; 项目章程被批准 -&gt; 制定项目管理计划 六、项目开工会议的召开已计划好了，项目经理希望避免在验收过程中再次经历过去与此客户的误解和延误。项目经理应该在这次会议上提交什么？ 风险管理计划、变更管理计划和组织流程资产。 工作绩效数据、变更管理计划和工作分解结构。 ✅ 质量指标、责任分配矩阵和里程碑清单。 ❌ 范围管理计划、质量管理计划和需求跟踪矩阵。 ✨ 关键词：开工会议、防止与客户的误解和延误 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：开工会议要向干系人介绍项目管理计划，并分配角色、获得承诺。1️⃣ 没有实体计划；2️⃣ 工作绩效数据在执行后才产生，开工会议上不可能展示；3️⃣ 三个都是实体内容，相对其他选项中的计划，重要性高得多；4️⃣ 前两个都是程序计划，在开工会议上的重要性有限，加上需求跟踪矩阵，4️⃣ 重要性也比不上 3️⃣。 七、一个呼叫中心设施建在一个住宅社区附近。配有一台发电机，以维持不间断的电力供应，项目完工后几个月，该社区的市政办公室收到居民对噪音水平的投诉。若要避免这个问题，项目经理应该关注哪一点？ 问题管理。 ✅ 风险管理。 ❌ 沟通管理。 采购管理。 ✨ 关键词：执行项目时未考虑到的因素在项目结束后发生 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：执行项目时，没有考虑到噪音扰民问题，从项目角度来说，属于假设失败（假设不会扰民），或根本没有识别该假设条件，即风险识别问题，2️⃣ 相对较好。其实本题本质上是相关方管理问题，忽略了住宅区的居民，但选项中没有相关方管理选项。 🤔 本应当作干系人问题，是可以作为风险识别问题。","link":"/2024/07/17/pmp_test_what_confuses_me_17/"},{"title":"PMP 考试 - 易错和令人困惑的问题集（十八）","text":"仅供自己复习使用。如果侵权请联系删除。 一、一个项目正在一个远程，可交付成果的一部分是完整的，但下一部分取决于设备的安装才能继续。供应商表示虽然项目经理根据计划已准备好交付该设备，但他们无法找到将其运输到现场的方法。若要避免这个问题，项目经理应该事先做什么？ 创建具有缓冲时间的交付进度计划。 执行自制或外购计划。 ✅ 完成详细的采购管理计划。 制定更为详细的风险管理计划。 ✨ 关键词：采购供应商相关的风险、采购中的范围遗漏 3️⃣ ✅ 💡 解析：采购中的范围遗漏，如何避免采购中的风险？采购中的风险管理要使用采购管理计划，而非风险管理计划。因为采购管理计划中包括“风险管理事宜”，而风险管理计划中没有提及采购，选 3️⃣。 🤔 新概念：采购中的风险管理要使用采购管理计划。​ 二、在项目执行阶段，某些活动会延迟，因为供应商未能按时交货。这种情况之前在项目早期阶段发生过。若要避免再次发生这个问题，项目经理应该事先做什么？ ❌ 在首次发生该问题时调用合同的供应商处罚条款。 在采购管理计划中定义产品交付日期。 ✅ 进行因果分析以执行纠正措施。 将该问题包含在变更管理计划中，并定期监控该问题。 ✨ 关键词：供应商延迟交货、活动延迟、防止再次发生 1️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：发生过的问题再次发生使用问题日志（选项没有），也可以通过总结经验教训来防止再次发生（选项没有）。结合选，进行根本原因分析，也可以避免问题再次发生，见《PMP 备考资料》133 页最后一段最后一行。 🤔 发生过的问题再次发生时的顺序：记录问题日志 -&gt; 总结经验教训 -&gt; 根本原因分析，供应商导致的问题也是这么处理。 三、项目经理担心团队的目标与一些相关方的需求不一致，PMO 希望团队在收集需求时付出更多努力，关于需求收集的工具与场景，描述正确的是（选两项）？ ✅ 线框图可以帮助用户理解及澄清需求，尤其适用于客户对需求不明确时建立原型。 ✅ 故事地图可以业务流的方式，全景式展示需求。 ❌ 用户故事应该尽可能的描述详细，以便于清晰反映用户需求。 KANO 分析强调将用户的需求转化成产品的功能。 ✨ 关键词：收集需求的工具 2️⃣ 3️⃣ ❌ -&gt; 1️⃣ 2️⃣ ✅ 💡 解析：敏捷收集需求的工具，说法正确的是哪些。1️⃣ 属于原型法，2️⃣ 属于用户故事，都是常见的敏捷收集需求的工具，正确。3️⃣ 用户故事不应详细描述，而是用一两句话简要描述；4️⃣ 是排序工具，说法错误。 🤔 新概念：线框图 = 原型法。用户故事不应详细描述，而是用一两句话简要描述。​ 四、根据新产品的开发过程，市场部门开始把业务和用户需求直接增加到敏捷的文档中。哪些产品信息应该增加到对应的文档（选两项）？ ✅ 产品能提供具有竞争力的差异化优势，要把它加入到产品未完事项。 关于用户购物时如何处理信用卡数据的隐私的描述，把它放入到产品愿景。 ✅ 成功测试的确认表明用户错误也得到妥善处理，放入到 DOD。 ❌ 关于在执行迭代中的障碍，把它放入到代办事项清单。 ✨ 关键词：敏捷 3️⃣ 4️⃣ ❌ -&gt; 1️⃣ 3️⃣ ✅ 💡 解析：产品信息对应的正确文档。1️⃣ 差异性优势，可以理解为差异性功能，放入待办项，正确；2️⃣ 很具体的功能，不应放入产品愿景，产品愿景强调目标、方向等；3️⃣ 所有缺陷都已得到解决，应该作为完成时定义 (DOD)，正确；4️⃣ 障碍应列入障碍日志或问题日志，而不是待办项清单。 🤔 重要概念：敏捷项目中，障碍应列入障碍日志或问题日志，而不是待办项清单。​ 五、在一个开发工具的项目结束时，一位干系人对所花费的时间、精力和金钱提出质疑。项目经理组织与所有干系人举行会议，接着发生几次争论。若要防止这种沟通失败，项目经理应该事先使用什么项目文件？ 项目进度计划。 批准的预算。 ✅ 项目管理计划。 ❌ 效益分析。 ✨ 关键词：干系人冲突 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：本题不是沟通问题，因为干系人质疑的对象不是信息、沟通，而是时间、成本、精力。项目经理与干系人见面，属于管理干系人参与。但没有搞定，最可能的原因是没有为该干系人制定合适的干系人参与计划，3️⃣ 中包含该计划，选 3️⃣。","link":"/2024/07/18/pmp_test_what_confuses_me_18/"},{"title":"日语翻译 - PO 文 - レゾナンス：無限号列車公式（5 篇）","text":"来自レゾナンス官方推特的 5 篇 PO 文。与レゾ百科有关。 来源：X.com PO 主：レゾナンス：無限号列車公式 链接：⭐️レゾ百科ー現世束縛装置⭐️ 🌟 单词： 形態形成場｜モーフィック・フィールド 形態形成場は，「同じものは同じ形態になりやすくなる」原理（形態共鳴）や，「繰返し起きたことは将来も起きやすくなる」原理を実現するものとして，捉えることができる。 発射｜はっしゃ⓪ 混構｜こんこう 結晶｜けっしょう⓪ 二次的｜にじてき⓪ 劣等｜れっとう⓪ 保つ｜たもつ② 奇異｜きい① 放つ｜はなつ② 精錬｜せいれん⓪ 成形｜せいけい⓪ 物質｜ぶっしつ⓪ 放出｜ほうしゅつ⓪ 深眠者｜しんみんしゃ 変異｜へんい① 現世束縛装置┏━━━━━━━━━━━━━━━━┓⭐️レゾ百科ー現世束縛装置⭐️┗━━━━━━━━━━━━━━━━┛ 現代人類の工学の奇跡であり、強化された人類自身のモーフィックフィールドを発射はっしゃすることで、混構体の侵入を排除し、モーフィックフィールド汚染の影響をなくすことができる。 现代人类工程学的奇迹，通过发射增强的人类自身的形态形成场，可以排除混构体的侵入，消除形态形成场污染的影响。 劣等混構結晶┏━━━━━━━━━━━━━━━━━┓⭐️レゾ百科ー劣等混構結晶⭐️┗━━━━━━━━━━━━━━━━━┛ 混構結晶けっしょうよりも採取が容易な二次的にじてきなモーフィックフィールドの産物のため、劣等れっと混構結晶と呼ばれる。エネルギー源として使用できる。 由于是比混构结晶更容器开采的二次的形态形成场的产物，因此被叫做劣等混构结晶。可以被作为能量源使用。 昇格者┏━━━━━━━━━━┓⭐️レゾ百科ー昇格者⭐️┗━━━━━━━━━━┛ モーフィックフィールド汚染を受けた後も理性を保ちたもち、外見にほとんど変化なし、しかも特殊な能力に目覚めた人間の個体。 即使受到形态形成场的污染也能保持理性，从外表来看几乎没有变化，但是觉醒了特殊的能力的人类个体。 混構結晶┏━━━━━━━━━━━━━━┓⭐️レゾ百科ー混構結晶⭐️┗━━━━━━━━━━━━━━┛ 奇異きいの光を放つはなつ結晶体、通常は混構腺体から精錬せいれんされたもの。混構結晶は本質的ではモーフィックフィールドによって成形せいけいされていない物質ぶっしつ。モーフィックフィールド制御技術を使用することで、あらゆる材料ざいりょうに製作し、或いは直接的にエネルギーを放出ほうしゅつできる。 释放出奇异的光的结晶体，通常是从混构腺体精炼而来。混构晶体本质上是不通过形态形成场生成的物质。通过使用形态形成场的控制技术，可以将（混构晶体）制作成各种材料，或事直接释放出能量。 深眠者┏━━━━━━━━━━┓⭐️レゾ百科ー深眠者⭐️┗━━━━━━━━━━┛ モーフィックフィールド汚染を受けた後、理性を失い、外見にも変異へんいが生じた人間の個体。 受到形态形成场的污染后，失去了理性，外表也发生了变异的人类个体。","link":"/2024/10/11/post_x_resonancejp_hyakka_01/"},{"title":"PostgreSQL 学习笔记（一）使用 Docker 部署 PostgreSQL 数据库","text":"前言数据库最好跑在数台单独的虚拟机上来确保高可用。不过我的边缘业务并没有那么高需求，即使所有服务器都 Down 了也有 Cloudflare 代理业务用的服务器做最后一层保障，因此怎么方便怎么来吧。 方案概述 安装 Docker 环境 确定容器运行参数 启动容器 测试连接数据库 操作步骤一、安装 Docker 环境参考：Ubuntu 20.04 从官方源安装最新的 Docker 二、确定容器运行参数 参数 值 解释 POSTGRES_USER postgres 数据库管理员用户 POSTGRES_PASSWORD my_postgresql_password 数据库管理员密码 PGDATA /var/lib/postgresql/data/pgdata PostgreSQL 数据存储目录 三、启动容器映射下目录做适当的数据持久化： 宿主机目录 容器目录 /rab/docker/postgresql/data /var/lib/postgresql/data 然后创建目录： 1mkdir -vp /rab/docker/postgresql/data 映射下端口： 宿主机端口 容器端口 5432 5432 123456789docker run -d \\ --name postgresql \\ --restart=unless-stopped \\ -e POSTGRES_USER=postgres \\ -e POSTGRES_PASSWORD=my_postgresql_password \\ -e PGDATA=/var/lib/postgresql/data/pgdata \\ -v /rab/docker/postgresql/data:/var/lib/postgresql/data \\ -p 5432:5432 \\ postgres:latest 之后 docker ps 看下是否正常运行： 12docker ps -adocker logs postgresql 四、测试连接数据库服务器的防火墙需要放行 5432 端口，云服务厂商有安全组的话也需要放行。之后用账户 postgres 和密码 my_postgresql_password 连接数据库即可：结束。","link":"/2024/09/17/postgresql_note_01_latest_docker/"},{"title":"6 周时间通过 AWS Certified Solutions Architect – Associate 架构师助理级别认证考试","text":"考试编号为 SAA-C03，复习时间约为 6 周，包括考试费总花费 1200 元（其中网课多花了 400，视个人情况可以省下来）。考试方式选取的是前往指定 Pearson VUE 考点而非在线考试。 前言首先要明确的是：如果你的公司或客户不在使用 AWS 的服务，且你暂时还不能参与软件架构的设计，那么这个证书（包括它涉及到的知识）都很难帮助你更轻松地应对工作。举个例子，这是 SAA-C03 认证中的一道考题：不难发现考试的重点在于向 AWS 的迁移以及如何实现平稳过渡或进行排障，它跟我们认知中的普通的大型软件架构搭建很不一样。 如果你希望通过学习提高自己同时又并不在使用 AWS 的服务，可能 Oracle Java 或是 K8s 相关的证书会更适合你，毕竟他们的难度也适中且使用面也更广。 但如果你已经权衡好并准备开始 AWS 服务的学习了，那希望下面的内容能帮助到你，也祝你和我一样顺利通过考试！ 大致流程 我原本在备考的博文里说了想先完成 CLF 从业者资格认证的考试再尝试 SAA 的，不过由于在过完 CLF 的官方教程后，发觉它是完成针对新的从业者的培训，即使只是多花 25 美金就能多个证书也实在没有什么性价比，因此放弃了。 流程会涉及到 CLF 基础的再牢固，你也可以选择性跳过： 注册 AWS 账号 入门 AWS 服务（CLF 内容学习） 任意针对 SAA-C03 考试内容的网课 大量刷 SAA-C03 的题目 考试预约 参与考试 查阅成绩、领取徽章和下一场考试的半价券 详细过程一、注册 AWS 账号这里涉及到三个账号，我有点忘记是不是可以复用了： AWS 云服务平台的根用户，用以启动各云服务进行测试：亚马逊云服务 AWS 官方技能培训网课的用户：AWS Skill Builder AWS 认证平台的用户，用以预约考试等：AWS Certification 二、入门 AWS 服务 我在 9 月份学的，大概花了 2 天时间。 这里的入门指的就是 CLF 内容学习。这一部分我觉得官方的视频教程就足够了：AWS Cloud Practitioner Essentials，官方用 7 个小时的时间通过咖啡店的例子通俗地讲解了 AWS 各服务的特点和使用场景，不枯燥甚至可以说是有趣的。你可以和我一样一边听课一边整理要点笔记：CLF - 备考（学习）笔记，它会帮助你在之后的 SAA-03 学习前构建知识体系。 三、任意针对 SAA-C03 考试内容的网课 2024/11/13 ~ 2024/11/27，我大约花了 14 天时间。 我听的是这两个： Ultimate AWS Certified Solutions Architect Associate 2025（社交媒体上都称主讲人为小黄老师） AWS 解决方案架构师认证助理级 (SAA-C03) 中文视频培训课程 2024 小黄老师的课广受好评，并且 Udemy 大的小的折扣活动基本都参与，能做到大概 15 刀左右入手。纯英文授课，有中文字幕。而第二个沉默恶魔老师的课偏贵，我当时和其他课合买折算下来也花了 500 多。纯中文授课，并且 PPT 做的也很精美。但是似乎已经很久没有更新考点了，缺的点需要在刷题的时候自己再调查补充。 同时 iloveaws.cn 的 SAP 课程距今已经 4 年了，内容比较老且90% 的内容与 SAA 课重叠，不推荐购买。SAA 的课程相比之下内容更新、结构也更清晰，预算允许的话可以考虑。 两个老师的课，任选其一过一遍即可。 V 站和小红书还提到了 B 站上挨踢茶馆 UP 主等的免费课，如果实在不愿意投入太多也可以尝试下。 免费课可以拿我的笔记做下对照，看看是否辐射到了所有考点： ⭐ AWS 知识点 - 亚马逊虚拟私有云 (Amazon Virtual Private Cloud, VPC) AWS 知识点 - 迁移 AWS 知识点 - 机器学习 (ML, Machine Learning) ⭐ AWS 知识点 - AWS Organizations 和 Control Tower AWS 知识点 - 成本 AWS 知识点 - Docker 容器和 ECS AWS 知识点 - 无服务器应用程序 AWS 知识点 - EC2 AWS 知识点 - 部署和管理 AWS 知识点 - 数据库 AWS 知识点 - 弹性负载均衡器和弹性伸缩 AWS 知识点 - IAM (Identity and Access Management) AWS 知识点 - S3 (Simple Storage Service) AWS 知识点 - 云安全 (Cloud Security) AWS 知识点 - DNS、缓存与性能优化（包括 AWS Route 53） AWS 知识点 - 块和文件存储 AWS 知识点 - 监控、日志和审计 讲到笔记，正好列下我认为 SAA-C03 考试中逐渐变难的几个点： 跨 VPC 和本地数据库组网 AWS Organizations 相关的权限管理 各服务的价格对比 各服务的不同容灾措施的 RTO 和 RPO 网课涉及到这些方面的可以听细致点，同时理清楚，防止之后做题再迷糊。 四、大量刷 SAA-C03 的题目 2024/12/17 ~ 2024/12/19，我大约花了 30 天时间。 ⭐ 这是我认为最最关键的一步！你甚至可以不上网课靠刷题通过考试！我的正式考试 65 题起码有 50 题是一模一样的原题，选项的排序都没变。题库是这个：AWS Certified Solutions Architect - Associate SAA-C03 Actual Exam Questions截至 2024/12/23 题库中有 1019 道题目，后续依然会持续添加。几个注意的点： 其中 No.1 ~ No.500 是比较简单的，而 No.500 ~ No.600 是陡然间变难的，再之后就是难易参半了。 ⭐ 我的很多正式考题出现在 500 题以后，如果时间不充裕的话，优先从后往前刷吧。 ⭐ 推荐用英文刷，中文总是不够准确，并且很多不认识的云服务用英文拼词反而一下子就能知道它是什么了。 前 100 道会很痛苦，你会发现大量知识点缺失，但请好好补充，毕竟考试范围就只有这么多，全掌握了就能过了。 推荐结合题目底下的社区评论做下错题解析，有利于记忆： 可以去闲鱼买课，均价 50 你可以问店主要纯题目、题目加答案和题目加答案加社区解析三份文件。 二刷的话，就可以将题目翻译成中文做了，有助于提速和记题。我自己正式考试只花了 40 分钟，很多题目看到选项就能选了。PDF 文档翻译可以用 DeepL 翻译文件，淘宝的共享账号也很便宜就几块钱。 五、考试预约我是去线下的 Pearson VUE 考点参与考试的，如果你在一二线城市应该会比较方便。 在预约考试 (Schedule an exam) 页面选择 SAA-C03 选择前往 Pearson VUE 考试中心参加考试 选择简体中文作为考试语言 勾选附近的一个或多个考点 选择最终考点和考试时间 确认并缴费（似乎只支持 VISA 和万事达信用卡） 有折扣券的话在缴费页面可以填入，AWS 不定期会发放考试的折扣券，最近一次是在 2024/12/12：Join the Get AWS Certified: Associate Challenge或者你也可以在闲鱼上购买。 之后你就会收到一封邮件，上面标注了你的个人信息以及考试时间：⭐ 注意最终通知你的考试时间！非常非常重要！它可能和你的预约时间不一样！一切以邮件为准！到这一步考试预约就结束了，安安心心调整等待考试日吧！ 六、参加考试⭐ 考试需要提前 15 分钟到考场，同时需要携带身份证和驾照/护照/社保卡总计 2 件可以证明身份的材料。Pearson VUE 各考点每天的开门和关门时间不知道一不一样，我去的苏州云奥是早上 9 点到下午 5 点 30 的，因此需要在这之前考完。如果你是正常按照预约参加的话，那么时间肯定是够的，但如果你临时堵车或是来不及，可以尝试联系考点稍微推迟下时间。考试界面大概长这样（最后一题答完再点下一道会进入检查页面，在那里可以选择从头开始再检查一遍）： 七、查阅成绩、领取徽章和下一场考试的半价券成绩能在考试结束 5 个小时后知晓，通过的话 Credly 会通知你可以领取徽章了： 在这之后再过 7 ~ 8 小时 AWS 才会通知你成绩可查： 回到 AWS 的培训中心，就能下载具体成绩了： 同时还能看到考过后的权益，最有用的应该是那张 50% 折扣的券了，可以为下一场 SAP-C02 考试省下 150 美金： 最后祝你也能顺利通过考试 🎉 🎉 🎉","link":"/2024/12/22/saa_after_exam/"},{"title":"SAA 认证 - 备考准备","text":"关于开始 SAA (AWS Certified Solutions Architect - Associate) 架构师助理级别考试的备考准备及路线规划。此篇文章仅仅是规划，我个人通过 SAA-C03 考试的经验可以参考：在 2024 年预约并通过 SAA-C03 AWS 架构师助理级别认证考试 从 2019 将个人项目的基础设施从阿里云迁移到 AWS 云服务器后，每月账单就是只增不减。随着使用需求的增加，趁着上一个考试等出成绩的空档（6 ～ 8 周），尝试着把 AWS 的 SAA 认证考试给过掉吧。 前人经验 📺 我是如何通过亚马逊云系统架构师专业认证 AWS Solution Architect Professional （SAP）的认证的？ 虽然讲的是 SAP 考试，但是看完之后对考试概念、准备、流程有了一个大概的了解。 📃 如何通过 AWS certified solution architect associate (SAA) 📺 How I passed the AWS Solutions Architect Associate Exam in 1 month 2021 📃 三周速通 AWS Certified Solutions Architect - Associate（SAA-C03) 经验分享 📃 2023 年四周通关 AWS 证书 CLF + SAA 经验笔记分享贴 这篇博文里介绍了在 AWS 考试没有促销活动的情况下，通过考 CLF 拿到 50% 优惠券，然后再考 SAA 的经验。 📃 AWS Certified Cloud Practitioner 证书学习心得 CLF 相关。 📃 【小记】AWS Cloud Practitioner备考心得 CLF 相关。 备考资料CLF 【AWS CLF 官网】AWS Certified Cloud Practitioner - 展示 AWS 云服务和云计算的基础知识 SAA 【AWS SAA 官网】AWS 认证解决方案架构测试 AWS 认证考试 - AWS 云服务 【AWS 云服务基本概念的官方教程】AWS Skill Builder - AWS Technical Essentials 【付费视频课】Ultimate AWS Certified Solutions Architect Associate SAA-C03 广受好评的课程。我购入的价格是 20 刀，可以参考。 【博文】AWS Certified Solutions Architect – Associate SAA-C03 Exam Learning Path 当然不止这篇，博主其他 AWS 相关文章也很有参考价值。 【付费试题】Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam 我的规划 先巩固 CLF 相关的知识，大概花费 2 周左右的时间。 在 CLF 学习完成后，开始 SAA 的学习，预计会花费 6 周左右的时间。 在这总共 8 周的时间内，等待 SAA 的报考优惠，如果有的话就跳过 CLF 直接报考 SAA，否则就花费 100 + 150 * 0.5 = 175 刀参加两场考试。","link":"/2024/09/01/saa_prepare_for_exam/"},{"title":"SAA 考试每日练习 - 2024&#x2F;11&#x2F;04","text":"来源：AWS解决方案架构师认证-助理级(SAA-C03)仿真练习题3 题，免费题库，题目质量不高，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： vendorn. 供应商，小贩 troubleshootv. 检修，分析难题 secureadj. 安心的，安全的 | v. 使安全；担保，保护；使获得 grantv. 同意；准予；承认 | n. 拨款；授权；合法转让 optionallyadv. 随意地；可选择地；选择性地 specify明确说明；具体指定；详细说明 durationn. 持续时间，期间 consistv. 组成，构成；存在于 architecturen. 建筑学，建筑业；结构 layern. 层, 层次, 表层, 阶层 | v. 把……分层堆放 vulnerableadj. 易受攻击的；易受伤害的；（身体上或感情上）脆弱的 architectn. 建筑师，设计师；缔造者，创造者 efficientadj. 效率高的，高效的 accomplishv. 完成 featuren. 特色，特征；特写；特色节目 | v. 以……为特色；为……加特写；起重要特色，占重要地位 optimaladj. 最适宜的, 最理想的, 最好的 optimizev. 使最优化；使尽可能有效 financialadj. 金融的；财政的；财务的 lustren. 光泽；光彩；光辉；声望；荣誉 一、Share an object with othersAn application hosted on AWS is experiencing performance problems, and the application vendor wants to perform an analysis of the log file to troubleshoot further. The log file is stored on Amazon S3 and is 10 GB in size. The application owner will make the log file available to the vendor for a limited time.What is the MOST secure way to do this? Enable public read on the S3 object and provide the link to the vendor. Upload the file to Amazon WorkDocs and share the public link with the vendor. ✅ Generate a presigned URL and have the vendor download the log file before it expires. ❌ Create an IAM user for the vendor to provide access to the S3 bucket and the application. Enforce multi-factor authentication. ✨ 关键词：S3、临时访问、Share an object with others 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：Share an object with others - All objects by default are private. Only the object owner has permission to access these objects. However, the object owner can optionally share objects with others by creating a presigned URL, using their own security credentials, to grant time-limited permission to download the objects.When you create a presigned URL for your object, you must provide your security credentials, specify a bucket name, an object key, specify the HTTP method (GET to download the object) and expiration date and time. The presigned URLs are valid only for the specified duration.Anyone who receives the presigned URL can then access the object. For example, if you have a video in your bucket and both the bucket and the object are private, you can share the video with others by generating a presigned URL.Reference: https://docs.aws.amazon.com/AmazonS3/latest/dev/ShareObjectPreSignedURL.html 二、Using Amazon S3 Origins, MediaPackage Channels, and Custom Origins for Web DistributionsOrganizers for a global event want to put daily reports online as static HTML pages. The pages are expected to generate millions of views from users around the world. The files are stored in an Amazon S3 bucket. A solutions architect has been asked to design an efficient and effective solution.Which action should the solutions architect take to accomplish this?1. Generate presigned URLs for the files.2. Use cross-Region replication to all Regions.3. Use the geoproximity feature of Amazon Route 53.4. ✅ Use Amazon CloudFront with the S3 bucket as its origin. ✨ 关键词：S3、Different Regions 4️⃣ ✅ 💡 解析：Using Amazon S3 Buckets for Your Origin.When you use Amazon S3 as an origin for your distribution, you place any objects that you want CloudFront to deliver in an Amazon S3 bucket. You can use any method that is supported by Amazon S3 to get your objects into Amazon S3, for example, the Amazon S3 console or API, or a third-party tool. You can create a hierarchy in your bucket to store the objects, just as you would with any other Amazon S3 bucket.Using an existing Amazon S3 bucket as your CloudFront origin server doesn’t change the bucket in any way; you can still use it as you normally would to store and access Amazon S3 objects at the standard Amazon S3 price. You incur regular Amazon S3 charges for storing the objects in the bucket.Using Amazon S3 Buckets Configured as Website Endpoints for Your Origin.You can set up an Amazon S3 bucket that is configured as a website endpoint as custom origin with CloudFront.When you configure your CloudFront distribution, for the origin, enter the Amazon S3 static website hosting endpoint for your bucket. This value appears in the Amazon S3 console, on the Properties tab, in the Static website hosting pane. For example: http://bucket-name.s3-website-region.amazonaws.comFor more information about specifying Amazon S3 static website endpoints, see Website endpoints in the Amazon Simple Storage Service Developer Guide.When you specify the bucket name in this format as your origin, you can use Amazon S3 redirects and Amazon S3 custom error documents. For more information about Amazon S3 features, see the Amazon S3 documentation.Using an Amazon S3 bucket as your CloudFront origin server doesn’t change it in any way. You can still use it as you normally would and you incur regular Amazon S3 charges.Reference: https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/DownloadDistS3AndCustomOrigins.html 三、Amazon FSx for LustreA solutions architect is designing storage for a high performance computing (HPC) environment based on Amazon Linux. The workload stores and processes a large amount of engineering drawings that require shared storage and heavy computing.Which storage option would be the optimal solution? ❌ Amazon Elastic File System (Amazon EFS) ✅ Amazon FSx for Lustre Amazon EC2 instance store Amazon EBS Provisioned IOPS SSD (io1) ✨ 关键词：HPC、shared storage 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：Amazon FSx for Lustre is a new, fully managed service provided by AWS based on the Lustre file system. Amazon FSx for Lustre provides a high-performance file system optimized for fast processing of workloads such as machine learning, high performance computing (HPC), video processing, financial modeling, and electronic design automation (EDA).FSx for Lustre allows customers to create a Lustre filesystem on demand and associate it to an Amazon S3 bucket. As part of the filesystem creation, Lustre reads the objects in the buckets and adds that to the file system metadata. Any Lustre client in your VPC is then able to access the data, which gets cached on the high- speed Lustre filesystem. This is ideal for HPC workloads, because you can get the speed of an optimized Lustre file system without having to manage the complexity of deploying, optimizing, and managing the Lustre cluster.Additionally, having the filesystem work natively with Amazon S3 means you can shut down the Lustre filesystem when you don’t need it but still access objects in Amazon S3 via other AWS Services. FSx for Lustre also allows you to also write the output of your HPC job back to Amazon S3.Reference: https://d1.awsstatic.com/whitepapers/AWS%20Partner%20Network_HPC%20Storage%20Options_2019_FINAL.pdf","link":"/2024/11/04/saa_test_daily_20241104/"},{"title":"SAA 考试每日练习 - 2024&#x2F;11&#x2F;10","text":"来源：AWS解决方案架构师认证-助理级(SAA-C03)仿真练习题5 题，免费题库，题目质量不高，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： accidentaladj. 意外的，偶然的；不测的；非本质的；附带的 | n. 偶然，临时符，变音记号 deletionn. 删除，（遗传学上染色体的）缺失，删除部分 migratev. 移动，迁移；（鸟类、动物等）随季节而迁徙；移民；转移 infrastructuren. （国家或机构的）基础设施 一、Amazon S3 versioningA company hosts a static website within an Amazon S3 bucket. A solutions architect needs to ensure that data can be recovered in case of accidental deletion.Which action will accomplish this? ✅ Enable Amazon S3 versioning. Enable Amazon S3 Intelligent-Tiering. Enable an Amazon S3 lifecycle policy. Enable Amazon S3 cross-Region replication. ✨ 关键词：S3 版本控制、意外删除后的恢复 1️⃣ ✅ 💡 解析：Data can be recover if versioning enable, also it provide a extra protection like file delete,MFA delete. MFA. Delete only works for CLI or API interaction, not in the AWS Management Console. Also, you cannot make version DELETE actions with MFA using IAM user credentials. You must use your root AWS account. 二、Amazon RDS Read ReplicasA company is migrating a three-tier application to AWS. The application requires a MySQL database. In the past, the application users reported poor application performance when creating new entries. These performance issues were caused by users generating different real-time reports from the application during working hours.Which solution will improve the performance of the application when it is moved to AWS?1. Import the data into an Amazon DynamoDB table with provisioned capacity. Refactor the application to use DynamoDB for reports.2. Create the database on a compute optimized Amazon EC2 instance. Ensure compute resources exceed the on-premises database.3. ✅ Create an Amazon Aurora MySQL Multi-AZ DB cluster with multiple read replicas. Configure the application reader endpoint for reports.4. Create an Amazon Aurora MySQL Multi-AZ DB cluster. Configure the application to use the backup instance of the cluster as an endpoint for the reports. ✨ 关键词：Amazon RDS 读写分离、Amazon RDS Read Replicas 3️⃣ ✅ 💡 解析：无。 三、Amazon S3 to save static webpage content and use CloudFrontA company hosts a static website on-premises and wants to migrate迁移 the website to AWS. The website should load as quickly as possible for users around the world. The company also wants the most cost-effective solution.What should a solutions architect do to accomplish this? Copy the website content to an Amazon S3 bucket. Configure the bucket to serve static webpage content. Replicate the S3 bucket to multiple AWS Regions. ✅ Copy the website content to an Amazon S3 bucket. Configure the bucket to serve static webpage content. Configure Amazon CloudFront with the S3 bucket as the origin. Copy the website content to an Amazon EBS-backed Amazon EC2 instance running Apache HTTP Server. Configure Amazon Route 53 geolocation routing policies to select the closest origin. Copy the website content to multiple Amazon EBS-backed Amazon EC2 instances running Apache HTTP Server in multiple AWS Regions. Configure Amazon CloudFront geolocation routing policies to select the closest origin. ✨ 关键词：Amazon S3、Static webpage content、CloudFront 2️⃣ ✅ 💡 解析：What Is Amazon CloudFront?Amazon CloudFront is a web service that speeds up distribution of your static and dynamic web content, such as .html, .css, .js, and image files, to your users.CloudFront delivers your content through a worldwide network of data centers called edge locations. When a user requests content that you’re serving with CloudFront, the user is routed to the edge location that provides the lowest latency (time delay), so that content is delivered with the best possible performance. Using Amazon S3 Buckets for Your Origin.When you use Amazon S3 as an origin for your distribution, you place any objects that you want CloudFront to deliver in an Amazon S3 bucket. You can use any method that is supported by Amazon S3 to get your objects into Amazon S3, for example, the Amazon S3 console or API, or a third-party tool. You can create a hierarchy in your bucket to store the objects, just as you would with any other Amazon S3 bucket.Using an existing Amazon S3 bucket as your CloudFront origin server doesn’t change the bucket in any way; you can still use it as you normally would to store and access Amazon S3 objects at the standard Amazon S3 price. You incur regular Amazon S3 charges for storing the objects in the bucket.Reference:https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.htmlhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/DownloadDistS3AndCustomOrigins.html 四、Amazon Elastic File SystemA product team is creating a new application that will store a large amount of data. The data will be analyzed hourly and modified by multiple Amazon EC2 Linux instances. The application team believes the amount of space needed will continue to grow for the next 6 months.Which set of actions should a solutions architect take to support these needs?1. Store the data in an Amazon EBS volume. Mount the EBS volume on the application instances.2. ✅ Store the data in an Amazon EFS file system. Mount the file system on the application instances.3. Store the data in Amazon S3 Glacier. Update the vault policy to allow access to the application instances.4. Store the data in Amazon S3 Standard-Infrequent Access (S3 Standard-IA). Update the bucket policy to allow access to the application instances. ✨ 关键词：Amazon EFS、modified by multiple Amazon EC2 2️⃣ ✅ 💡 解析：Amazon Elastic File System (Amazon EFS) provides a simple, scalable, fully managed elastic NFS file system for use with AWS Cloud services and on-premises resources. It is built to scale on demand to petabytes without disrupting applications, growing and shrinking automatically as you add and remove files, eliminating the need to provision and manage capacity to accommodate growth.Amazon EFS is designed to provide massively parallel shared access to thousands of Amazon EC2 instances, enabling your applications to achieve high levels of aggregate throughput and IOPS with consistent low latencies.Amazon EFS is well suited to support a broad spectrum of use cases from home directories to business-critical applications. Customers can use EFS to lift-and- shift existing enterprise applications to the AWS Cloud. Other use cases include: big data analytics, web serving and content management, application development and testing, media and entertainment workflows, database backups, and container storage.Amazon EFS is a regional service storing data within and across multiple Availability Zones (AZs) for high availability and durability. Amazon EC2 instances can access your file system across AZs, regions, and VPCs, while on-premises servers can access using AWS Direct Connect or AWS VPN.Reference:https://aws.amazon.com/efs/ 五、Amazon FSxA company is migrating from an on-premises infrastructure to the AWS Cloud. One of the company’s applications stores files on a Windows file server farm that uses Distributed File System Replication (DFSR) to keep data in sync. A solutions architect needs to replace the file server farm.Which service should the solutions architect use?1. Amazon EFS2. ✅ Amazon FSx3. Amazon S34. AWS Storage Gateway ✨ 关键词：Windows file server farm 2️⃣ ✅ 💡 解析：Amazon FSx 让您可以轻松且经济高效地在云中启动、运行和扩展功能丰富的高性能文件系统。该服务具备可靠性、安全性、可扩展性和丰富的功能，可以为大量工作负载提供支持。Amazon FSx 建立在最新的 AWS 计算、网络和磁盘技术之上，可提供高性能和更低的 TCO。作为一项完全托管的服务，它可以处理硬件配置、补丁和备份，使您能够腾出时间专注于应用程序、最终用户和业务。Amazon FSx 允许你在四个广泛使用的文件系统之间进行选择：NetApp ONTAP、OpenZFS、Windows File Server 和 Lustre。这种选择通常取决于您对给定文件系统的熟悉程度，或者将文件系统的功能集、性能概况和数据管理能力与您的工作负载要求相匹配。Reference:https://aws.amazon.com/cn/fsx/","link":"/2024/11/10/saa_test_daily_20241110/"},{"title":"SAA 考试每日练习 - 2024&#x2F;11&#x2F;11","text":"来源：AWS解决方案架构师认证-助理级(SAA-C03)仿真练习题3 题，免费题库，题目质量不高，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： spreadv. 传播，扩散，展开，散布 | n. 传播，蔓延，扩展，散布 | adj. 广大的，大幅的，（宝石）薄而无光泽的 replican. 复制品, 仿制品 primaryadj. 首要的，主要的；最初的；原本的；第一手的，直接的；初级的，小学的；初等的 | n. 初选者；原色 attachv. 系；绑；附上；把…固定；认为有重要性（或意义、价值、分量等）；喜欢，依恋 boundariesn. 分界线，边界 一、Placement groupsA solutions architect is designing a high performance computing (HPC) workload on Amazon EC2. The EC2 instances need to communicate to each other frequently and require network performance with low latency and high throughput.Which EC2 configuration meets these requirements?1. ✅ Launch the EC2 instances in a cluster placement group in one Availability Zone.2. Launch the EC2 instances in a spread placement group in one Availability Zone.3. Launch the EC2 instances in an Auto Scaling group in two Regions and peer the VPCs.4. Launch the EC2 instances in an Auto Scaling group spanning multiple Availability Zones. ✨ 关键词：HPC、low latency、high throughput、Placement groups 1️⃣ ✅ 💡 解析：When you launch a new EC2 instance, the EC2 service attempts to place the instance in such a way that all of your instances are spread out across underlying hardware to minimize correlated failures. You can use placement groups to influence the placement of a group of interdependent instances to meet the needs of your workload. Depending on the type of workload.Cluster “” packs instances close together inside an Availability Zone. This strategy enables workloads to achieve the low-latency network performance necessary for tightly-coupled node-to-node communication that is typical of HPC applications.Reference:https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html Amazon EC2 实例的置放群组： 为了满足工作负载的需求，您可以将一组相互依赖的 EC2 实例启动到一个置放群组中，以影响它们的置放。 创建置放群组无需支付费用。 置放群组 英文 备注 集群 Cluster 将一个可用区内靠近的实例打包在一起。通过使用该策略，工作负载可以实现所需的低延迟网络性能，以满足高性能计算（HPC）应用程序通常使用的紧密耦合的节点到节点通信的要求。 分区 Partition 将实例分布在不同的逻辑分区上，以便一个分区中的实例组不会与不同分区中的实例组使用相同的基础硬件。该策略通常为大型分布式和重复的工作负载所使用，例如，Hadoop、Cassandra 和 Kafka。 分布 Spread 将一小组实例严格放置在不同的基础硬件上，以减少相关的故障。 二、Amazon RDS Read ReplicasAn application running on AWS uses an Amazon Aurora Multi-AZ deployment for its database. When evaluating performance metrics, a solutions architect discovered that the database reads are causing high I/O and adding latency to the write requests against the database.What should the solutions architect do to separate the read requests from the write requests?1. Enable read-through caching on the Amazon Aurora database.2. Update the application to read from the Multi-AZ standby instance.3. ✅ Create a read replica and modify the application to use the appropriate endpoint.4. ❌ Create a second Amazon Aurora database and link it to the primary database as a read replica. ✨ 关键词：Multi-AZ、Database、读写分离、Amazon RDS Read Replicas 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：Amazon RDS Read Replicas provide enhanced performance and durability for RDS database (DB) instances. They make it easy to elastically scale out beyond the capacity constraints of a single DB instance for read-heavy database workloads. You can create one or more replicas of a given source DB Instance and serve high-volume application read traffic from multiple copies of your data, thereby increasing aggregate read throughput. Read replicas can also be promoted when needed to become standalone DB instances. Read replicas are available in Amazon RDS for MySQL, MariaDB, PostgreSQL, Oracle, and SQL Server as well asAmazon Aurora.For the MySQL, MariaDB, PostgreSQL, Oracle, and SQL Server database engines, Amazon RDS creates a second DB instance using a snapshot of the source DB instance. It then uses the engines’ native asynchronous replication to update the read replica whenever there is a change to the source DB instance. The read replica operates as a DB instance that allows only read-only connections; applications can connect to a read replica just as they would to any DB instance.Amazon RDS replicates all databases in the source DB instance.Amazon Aurora further extends the benefits of read replicas by employing an SSD-backed virtualized storage layer purpose-built for database workloads.Amazon Aurora replicas share the same underlying storage as the source instance, lowering costs and avoiding the need to copy data to the replica nodes. For more information about replication with Amazon Aurora, see the online documentation.Reference:https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.htmlhttps://aws.amazon.com/rds/features/read-replicas/ 三、IAM Permissions boundariesA company allows its developers to attach existing IAM policies to existing IAM roles to enable faster experimentation and agility. However, the security operations team is concerned that the developers could attach the existing administrator policy, which would allow the developers to circumvent any other security policies.How should a solutions architect address this issue? Create an Amazon SNS topic to send an alert every time a developer creates a new policy. Use service control policies to disable IAM activity across all account in the organizational unit. Prevent the developers from attaching any policies and assign all IAM duties to the security operations team. ✅ Set an IAM permissions boundary on the developer IAM role that explicitly denies attaching the administrator policy. ✨ 关键词：IAM、permissions boundary、IAM 实体的权限边界 4️⃣ ✅ 💡 解析：Reference:https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_boundaries.htmlAWS 对于 IAM 实体（用户或角色）支持权限边界。权限边界是一个高级功能，它使用托管策略设置基于身份的策略可以为 IAM 实体授予的最大权限。实体的权限边界仅允许实体执行其基于身份的策略和权限边界同时允许的操作。","link":"/2024/11/11/saa_test_daily_20241111/"},{"title":"SAA 考试每日练习 - 2024&#x2F;11&#x2F;12","text":"来源：AWS解决方案架构师认证-助理级(SAA-C03)仿真练习题3 题，免费题库，题目质量不高，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： paralleladj. 平行的，并列的 | v. 与……同时发生；与……相似；与…媲美；比得上 | n. 平行线，极其相似的人（或情况、事件等） looselyadv. 宽松地；松散地；不精确地 couplev. 结合；交配 | n. 夫妻；情侣；一对，一双；不确定的小数目，两个，两三个，几个 durableadj. 耐用的, 耐久的, 长期的, 长久的 | n. 耐久品 scalingn. 测量, 【电】定标, 电子法计算电脉冲, 推列 | v. “scale” 的现在分词 scenarion. 方案；设想; 可能发生的事，可能出现的情况，设想的场景；（电影、戏剧等的）剧情梗概 predictiveadj. 预测的, 预言的, 前瞻的 maintenancen. 维护，保养；维持；（依法应负担的）生活费，抚养费 machineryn. 机构, （统称）机器, （尤指）大型机器, 机器的运转部分 equipmentn. 设备, 装备, 器材, 配备 一、Cross Region EC2 AMI CopyA company’s application is running on Amazon EC2 instances in a single Region. In the event of a disaster, a solutions architect needs to ensure that the resources can also be deployed to a second Region.Which combination of actions should the solutions architect take to accomplish this? (Choose two.) Detach a volume on an EC2 instance and copy it to Amazon S3. ✅ Launch a new EC2 instance from an Amazon Machine Image (AMI) in a new Region. Launch a new EC2 instance in a new Region and copy a volume from Amazon S3 to the new instance. ✅ Copy an Amazon Machine Image (AMI) of an EC2 instance and specify a different Region for the destination. Copy an Amazon Elastic Block Store (Amazon EBS) volume from Amazon S3 and launch an EC2 instance in the destination Region using that EBS volume. ✨ 关键词：EC2、多区域 2️⃣ 4️⃣ ✅ 💡 解析：We know that you want to build applications that span AWS Regions and we’re working to provide you with the services and features needed to do so. We started out by launching the EBS Snapshot Copy feature late last year. This feature gave you the ability to copy a snapshot from Region to Region with just a couple of clicks. In addition, last month we made a significant reduction (26% to 83%) in the cost of transferring data between AWS Regions, making it less expensive to operate in more than one AWS region.Today we are introducing a new feature: Amazon Machine Image (AMI) Copy. AMI Copy enables you to easily copy your Amazon Machine Images between AWS Regions. AMI Copy helps enable several key scenarios including: Simple and Consistent Multi-Region Deployment “” You can copy an AMI from one region to another, enabling you to easily launch consistent instances based on the same AMI into different regions.Scalability “” You can more easily design and build world-scale applications that meet the needs of your users, regardless of their location.Performance “” You can increase performance by distributing your application and locating critical components of your application in closer proximity to your users.You can also take advantage of region-specific features such as instance types or other AWS services.Even Higher Availability “” You can design and deploy applications across AWS regions, to increase availability.Once the new AMI is in an Available state the copy is complete.Reference: https://aws.amazon.com/blogs/aws/ec2-ami-copy-between-regions/ 二、Amazon Simple Queue Service &amp; Scaling Based on Amazon SQSA solutions architect is designing the cloud architecture for a new application being deployed on AWS. The process should run in parallel并行的 while adding and removing application nodes as needed based on the number of jobs to be processed. The processor application is stateless. The solutions architect must ensure that the application is loosely coupled and the job items are durably stored.Which design should the solutions architect use? Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch configuration that uses the AMI. Create an Auto Scaling group using the launch configuration. Set the scaling policy for the Auto Scaling group to add and remove nodes based on CPU usage. Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch configuration that uses the AMI. Create an Auto Scaling group using the launch configuration. Set the scaling policy for the Auto Scaling group to add and remove nodes based on network usage. ✅ Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of items in the SQS queue. Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of messages published to the SNS topic. ✨ 关键词：SQS 3️⃣ ✅ 💡 解析：Amazon Simple Queue Service (SQS) is a fully managed message queuing service that enables you to decouple and scale microservices, distributed systems, and serverless applications. SQS eliminates the complexity and overhead associated with managing and operating message oriented middleware, and empowers developers to focus on differentiating work. Using SQS, you can send, store, and receive messages between software components at any volume, without losing messages or requiring other services to be available. Get started with SQS in minutes using the AWS console, Command Line Interface or SDK of your choice, and three simple commands.SQS offers two types of message queues. Standard queues offer maximum throughput, best-effort ordering, and at-least-once delivery. SQS FIFO queues are designed to guarantee that messages are processed exactly once, in the exact order that they are sent.There are some scenarios where you might think about scaling in response to activity in an Amazon SQS queue. For example, suppose that you have a web app that lets users upload images and use them online. In this scenario, each image requires resizing and encoding before it can be published. The app runs on EC2 instances in an Auto Scaling group, and it’s configured to handle your typical upload rates. Unhealthy instances are terminated and replaced to maintain current instance levels at all times. The app places the raw bitmap data of the images in an SQS queue for processing. It processes the images and then publishes the processed images where they can be viewed by users. The architecture for this scenario works well if the number of image uploads doesn’t vary over time. But if the number of uploads changes over time, you might consider using dynamic scaling to scale the capacity of your Auto Scaling group.Reference: https://aws.amazon.com/sqs/#:~:text=Amazon%20SQS%20leverages%20the%20AWS,queues%20provide%20nearly%20unlimited%20throughput https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-using-sqs-queue.html 三、Amazon Kinesis Data StreamsA manufacturing company wants to implement predictive前瞻的 maintenance维护 on its machinery equipment. The company will install thousands of IoT sensors that will send data to AWS in real time. A solutions architect is tasked with implementing a solution that will receive events in an ordered manner for each machinery asset and ensure that data is saved for further processing at a later time.Which solution would be MOST efficient? ✅ Use Amazon Kinesis Data Streams for real-time events with a partition for each equipment asset. Use Amazon Kinesis Data Firehose to save data to Amazon S3. Use Amazon Kinesis Data Streams for real-time events with a shard for each equipment asset. Use Amazon Kinesis Data Firehose to save data to Amazon EBS. Use an Amazon SQS FIFO queue for real-time events with one queue for each equipment asset. Trigger an AWS Lambda function for the SQS queue to save data to Amazon EFS. Use an Amazon SQS standard queue for real-time events with one queue for each equipment asset. Trigger an AWS Lambda function from the SQS queue to save data to Amazon S3. ✨ 关键词：Amazon Kinesis Data、S3 1️⃣ ✅ 💡 解析：无。","link":"/2024/11/12/saa_test_daily_20241112/"},{"title":"SAA 考试每日练习 - 2024&#x2F;11&#x2F;13","text":"来源：AWS解决方案架构师认证-助理级(SAA-C03)仿真练习题3 题，免费题库，题目质量不高，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： desiren. 愿望，欲望；情欲 | v. 渴望 | adj. 渴望的，想要的，预期的 restrictv. 限制，约束；限定 fulfillv. 做完(工作), 达到(目的), 应验(预言等), 满足(希望) maintainv. 维持；维修，保养；赡养，负担，支持；主张，断言；保卫，守住 一、Auto ScalingAn application runs on Amazon EC2 instances across multiple Availability Zones. The instances run in an Amazon EC2 Auto Scaling group behind an Application Load Balancer. The application performs best when the CPU utilization of the EC2 instances is at or near 40%.What should a solutions architect do to maintain the desired performance across all instances in the group? Use a simple scaling policy to dynamically scale the Auto Scaling group. ✅ Use a target tracking policy to dynamically scale the Auto Scaling group. Use an AWS Lambda function to update the desired Auto Scaling group capacity. ❌ Use scheduled scaling actions to scale up and scale down the Auto Scaling group. ✨ 关键词：Auto Scaling group（自动扩展组）、target tracking policy（目标跟踪扩展策略）、simple scaling policy（简单扩展策略）、scheduled scaling actions（预先的扩展动作） 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：考点为扩展策略的分类和使用场景： 动态扩展策略： 目标跟踪扩展策略：根据设置的整个组的指标（例如平均 CPU 使用率）动态地调整实例数量。 简单扩展策略：指标触发某个值之后，就做什么（扩容几台实例等）。 步进扩展策略：指标触发某个值之后，就做什么（扩容几台实例等）；指标再触发什么条件后，再做什么…… 计划扩展策略：定义 Auto Scaling 要扩展的时间，以及我们想要扩展多少个实例。 主要针对可以预见的、比方说早上用户多的情况，扩展实例数量。 预测性扩展策略：根据先前发生的事件的历史记录预测将要发生的事件，然后在特定的时间扩缩实例。 题目中有指定的 40% CPU 使用率目标，因此选 2️⃣ target tracking policy。 二、VPC endpointsA company has application running on Amazon EC2 instances in a VPC. One of the applications needs to call an Amazon S3 API to store and read objects. The company’s security policies restrict限制 any internet-bound traffic from the applications.Which action will fulfill these requirements and maintain security?1. ✅ Configure an S3 interface endpoint.2. ❌ Configure an S3 gateway endpoint.3. Create an S3 bucket in a private subnet.4. Create an S3 bucket in the same Region as the EC2 instance. ✨ 关键词：私网、S3 网关终端节点、VPC endpoints 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：A VPC endpoint enables you to privately connect your VPC to supported AWS services and VPC endpoint services powered by AWS PrivateLink without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection. Instances in your VPC do not require public IP addresses to communicate with resources in the service. Traffic between your VPC and the other service does not leave the Amazon network.An interface endpoint is an elastic network interface with a private IP address from the IP address range of your subnet that serves as an entry point for traffic destined to a supported service. Interface endpoints are powered by AWS PrivateLink, a technology that enables you to privately access services by using private IPaddresses. AWS PrivateLink restricts all network traffic between your VPC and services to the Amazonnetwork. You do not need an internet gateway, a NAT device, or a virtual private gateway.Reference:https://aws.amazon.com/blogs/aws/new-vpc-endpoint-for-amazon-s3/https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints.html中文文档：使用接口 VPC 端点访问 AWS 服务。 三、Amazon EFSA company is hosting a web application on AWS using a single Amazon EC2 instance that stores user-uploaded documents in an Amazon EBS volume. For better scalability and availability, the company duplicated the architecture and created a second EC2 instance and EBS volume in another Availability Zone, placing both behind an Application Load Balancer. After completing this change, users reported that each time they refreshed the website, they could see one subset of their documents or the other, but never all of the documents at the same time.What should a solutions architect propose to ensure users see all of their documents at once? Copy the data so both EBS volumes contain all the documents. Configure the Application Load Balancer to direct a user to the server with the documents. ✅ Copy the data from both EBS volumes to Amazon EFS. Modify the application to save new documents to Amazon EFS. Configure the Application Load Balancer to send the request to both servers. Return each document from the correct server. ✨ 关键词：Amazon EFS 3️⃣ ✅ 💡 解析：Amazon EFS provides file storage in the AWS Cloud. With Amazon EFS, you can create a file system, mount the file system on an Amazon EC2 instance, and then read and write data to and from your file system. You can mount an Amazon EFS file system in your VPC, through the Network File System versions 4.0 and 4.1 (NFSv4) protocol. We recommend using a current generation Linux NFSv4.1 client, such as those found in the latest Amazon Linux, Redhat, and Ubuntu AMIs, in conjunction with the Amazon EFS Mount Helper. For instructions, see Using the amazon-efs-utils Tools.For a list of Amazon EC2 Linux Amazon Machine Images (AMIs) that support this protocol, see NFS Support. For some AMIs, you’ll need to install an NFS client to mount your file system on your Amazon EC2 instance. For instructions, see Installing the NFS Client.You can access your Amazon EFS file system concurrently from multiple NFS clients, so applications that scale beyond a single connection can access a file system. Amazon EC2 instances running in multiple Availability Zones within the same AWS Region can access the file system, so that many users can access and share a common data source.How Amazon EFS Works with Amazon EC2:Reference:https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html#how-it-works-ec2视频课截图：","link":"/2024/11/13/saa_test_daily_20241113/"},{"title":"SAA 考试每日练习 - 2024&#x2F;11&#x2F;14","text":"来源：AWS解决方案架构师认证-助理级(SAA-C03)仿真练习题4 题，免费题库，题目质量不高，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： approximatelyadv. 大约，大概，约莫 secureadj. 安心的；安全的；牢固的；有把握的；稳定的 | v. 使安全；担保，保护；（使）获得 consistentadj. 一致的；始终如一的；连续的；持续的；相符的；符合的；相互连贯的 一、AWS Web Application Firewall (WAF) - Block IP addressA company’s website is used to sell products to the public. The site runs on Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer(ALB). There is also an Amazon CloudFront distribution, and AWS WAF is being used to protect against SQL injection attacks. The ALB is the origin for theCloudFront distribution. A recent review of security logs revealed an external malicious IP that needs to be blocked from accessing the website.What should a solutions architect do to protect the application? ❌ Modify the network ACL on the CloudFront distribution to add a deny rule for the malicious IP address. ✅ Modify the configuration of AWS WAF to add an IP match condition to block the malicious IP address. Modify the network ACL for the EC2 instances in the target groups behind the ALB to deny the malicious IP address. Modify the security groups for the EC2 instances in the target groups behind the ALB to deny the malicious IP address. ✨ 关键词：CloudFront、WAF、Block IP address 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：Reference:https://aws.amazon.com/blogs/aws/aws-web-application-firewall-waf-for-application-load-balancers/ 二、AWS account root user accessA solution architect has created a new AWS account and must secure AWS account root user access.Which combination of actions will accomplish this? (Choose two.) ❌ Ensure the root user uses a strong password. ✅ Enable multi-factor authentication to the root user. Store root user access keys in an encrypted Amazon S3 bucket. ✅ Add the root user to a group containing administrative permissions. Apply the required permissions to the root user with an inline policy document. ✨ 关键词：root user、permissions 1️⃣ 2️⃣ ❌ -&gt; 2️⃣ 4️⃣ ✅ 💡 解析：无。 三、Amazon S3 One Zone-IAA data science team requires storage for nightly log processing. The size and number of logs is unknown and will persist for 24 hours only.What is the MOST cost-effective solution? Amazon S3 Glacier ❌ Amazon S3 Standard Amazon S3 Intelligent-Tiering ✅ Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) ✨ 关键词：nightly log、persist for 24 hours only 2️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：Reference:https://aws.amazon.com/s3/storage-classes/#Unknown_or_changing_access Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) S3 单区 - IA 适用于不常访问、但在需要时要求快速访问的数据。 四、AWS Snowball &amp; AWS Direct Connect &amp; AWS Site-to-Site VPNA recently acquired company is required to build its own infrastructure on AWS and migrate multiple applications to the cloud within a month. Each application has approximately 50 TB of data to be transferred. After the migration is complete, this company and its parent company will both require secure使安全 network connectivity with consistent throughput from their data centers to the applications. A solutions architect must ensure one-time data migration and ongoing network connectivity.Which solution will meet these requirements?1. AWS Direct Connect for both the initial transfer and ongoing connectivity.2. AWS Site-to-Site VPN for both the initial transfer and ongoing connectivity.3. ✅ AWS Snowball for the initial transfer and AWS Direct Connect for ongoing connectivity.4. ❌ AWS Snowball for the initial transfer and AWS Site-to-Site VPN for ongoing connectivity. ✨ 关键词：50 TB Data one-time migration、two companies connect 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：Reference:https://docs.aws.amazon.com/dms/latest/userguide/CHAP_LargeDBs.htmlhttps://aws.amazon.com/directconnect/","link":"/2024/11/14/saa_test_daily_20241114/"},{"title":"SAA 考试每日练习 - 2024&#x2F;11&#x2F;15","text":"来源：AWS解决方案架构师认证-助理级(SAA-C03)仿真练习题3 题，免费题库，题目质量不高，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： restrictv. 限制，约束；限定 combinationn. 结合，联合，混合；数字密码 一、Amazon RDSA company’s production application runs online transaction processing (OLTP) transactions on an Amazon RDS MySQL DB instance. The company is launching a new reporting tool that will access the same data. The reporting tool must be highly available and not impact the performance of the production application.How can this be achieved? Create hourly snapshots of the production RDS DB instance. ✅ Create a Multi-AZ RDS Read Replica of the production RDS DB instance. ❌ Create multiple RDS Read Replicas of the production RDS DB instance. Place the Read Replicas in an Auto Scaling group. Create a Single-AZ RDS Read Replica of the production RDS DB instance. Create a second Single-AZ RDS Read Replica from the replica. ✨ 关键词：access the same data、highly available、not impact the performance of the production application、只读、多可用区 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：Reference:https://aws.amazon.com/blogs/database/best-storage-practices-for-running-production-workloads-on-hosted-databases-with-amazon-rds-or-amazon-ec2/ 二、VPC endpointsA company has application running on Amazon EC2 instances in a VPC. One of the applications needs to call an Amazon S3 API to store and read objects. The company’s security policies restrict any internet-bound traffic from the applications.Which action will fulfill these requirements and maintain security?1. ✅ Configure an S3 interface endpoint.2. ❌ Configure an S3 gateway endpoint.3. Create an S3 bucket in a private subnet.4. Create an S3 bucket in the same Region as the EC2 instance. ✨ 关键词：S3、VPC、restrict any internet-bound traffic 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：A VPC endpoint enables you to privately connect your VPC to supported AWS services and VPC endpoint services powered by AWS PrivateLink without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection. Instances in your VPC do not require public IP addresses to communicate with resources in the service. Traffic between your VPC and the other service does not leave the Amazon network.An interface endpoint is an elastic network interface with a private IP address from the IP address range of your subnet that serves as an entry point for traffic destined to a supported service. Interface endpoints are powered by AWS PrivateLink, a technology that enables you to privately access services by using private IPaddresses. AWS PrivateLink restricts all network traffic between your VPC and services to the Amazonnetwork. You do not need an internet gateway, a NAT device, or a virtual private gateway.Reference:https://aws.amazon.com/blogs/aws/new-vpc-endpoint-for-amazon-s3/https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints.html 🤔 困惑：应该选 2️⃣ 不是吗？ 三、Cross Region EC2 AMI CopyA company’s application is running on Amazon EC2 instances in a single Region. In the event of a disaster, a solutions architect needs to ensure that the resources can also be deployed to a second Region.Which combination of actions should the solutions architect take to accomplish this? (Choose two.) Detach a volume on an EC2 instance and copy it to Amazon S3. ✅ Launch a new EC2 instance from an Amazon Machine Image (AMI) in a new Region. Launch a new EC2 instance in a new Region and copy a volume from Amazon S3 to the new instance. ✅ Copy an Amazon Machine Image (AMI) of an EC2 instance and specify a different Region for the destination. Copy an Amazon Elastic Block Store (Amazon EBS) volume from Amazon S3 and launch an EC2 instance in the destination Region using that EBS volume. ✨ 关键词：EC2 异地迁移、Cross Region EC2 AMI Copy 2️⃣ 4️⃣ ✅ 💡 解析：We know that you want to build applications that span AWS Regions and we’re working to provide you with the services and features needed to do so. We started out by launching the EBS Snapshot Copy feature late last year. This feature gave you the ability to copy a snapshot from Region to Region with just a couple of clicks. In addition, last month we made a significant reduction (26% to 83%) in the cost of transferring data between AWS Regions, making it less expensive to operate in more than one AWS region.Today we are introducing a new feature: Amazon Machine Image (AMI) Copy. AMI Copy enables you to easily copy your Amazon Machine Images between AWS Regions. AMI Copy helps enable several key scenarios including:Simple and Consistent Multi-Region Deployment “” You can copy an AMI from one region to another, enabling you to easily launch consistent instances based on the same AMI into different regions.Scalability “” You can more easily design and build world-scale applications that meet the needs of your users, regardless of their location.Performance “” You can increase performance by distributing your application and locating critical components of your application in closer proximity to your users.You can also take advantage of region-specific features such as instance types or other AWS services.Even Higher Availability “” You can design and deploy applications across AWS regions, to increase availability.Once the new AMI is in an Available state the copy is complete.Reference:https://aws.amazon.com/blogs/aws/ec2-ami-copy-between-regions/","link":"/2024/11/15/saa_test_daily_20241115/"},{"title":"SAA 考试每日练习 - 2024&#x2F;11&#x2F;16","text":"来源：AWS解决方案架构师认证-助理级(SAA-C03)仿真练习题7 题，免费题库，题目质量不高，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： retainedv. 保留；保持；保存 indefinitelyadv. 无限期地 concurrentlyadv. （正式）同时发生或完成地 branchn. 树枝；（公司或组织的）分店，分部；（政府或公安机关的）部门，机构；（学科或家族的）分支 | v. 发出新枝；岔开，分岔；出现分歧 effortn. 力气；精力；努力；费力，痛苦；有组织的活动 overheadadv. 在头顶上，在空中，在高处 | adj. 在头上的，高架的 | n. 经常性开支，营运费用 fetchv. （去）拿来，（去）请来，售得（…的价钱） | n. 拿，取；取物的距离；风浪区；诡计，计谋 legacyn. 遗产, 遗赠财物, 遗留问题, 后遗症 | adj. （计算机系统或产品）已停产的 一、Amazon S3A company runs an application on a group of Amazon Linux EC2 instances. The application writes log files using standard API calls. For compliance reasons, all log files must be retained indefinitely and will be analyzed by a reporting tool that must access all files concurrently.Which storage service should a solutions architect use to provide the MOST cost-effective solution? Amazon EBS Amazon EFS Amazon EC2 instance store ✅ Amazon S3 ✨ 关键词：API calls、retained indefinitely、analyzed by a reporting tool、MOST cost-effective 4️⃣ ✅ 💡 解析：应用程序运行在一组 EC2 实例上，通过 API 写日志，为了审计原因需要无限期保留日志，并将用来分析，要求迅速能被使用。还要是最便宜的方案。按量付费的 EFS 和 S3 似乎都可以，不过由于可以使用 S3 Select 等工具进行存储桶检索，因此更合适。 对比下 EFS 和 S3 的价格： 存储类型 EFS S3 Standard $0.30 $0.023 IA $0.016 $0.0125 Archive $0.008 $0.00099 ~ $0.004 且从详细价格对照表上来看，S3 总是更加便宜。 二、AWS SnowballA solutions architect is tasked with transferring 750 TB of data from a network-attached file system located at a branch office Amazon S3 Glacier. The solution must avoid saturating the branch office’s low-bandwidth internet connection.What is the MOST cost-effective solution? Create a site-to-site VPN tunnel to an Amazon S3 bucket and transfer the files directly. Create a bucket VPC endpoint. Order 10 AWS Snowball appliances and select an S3 Glacier vault as the destination. Create a bucket policy to enforce VPC endpoint. Mount the network-attached file system to Amazon S3 and copy the files directly. Create a lifecycle policy to S3 objects to Amazon S3 Glacier. ✅ Order 10 AWS Snowball appliances and select an Amazon S3 bucket as the destination. Create a lifecycle policy to transition the S3 objects to Amazon S3 Glacier. ✨ 关键词：750 TB of data、low-bandwidth internet connection 4️⃣ ✅ 💡 解析：公司需要在低网络带宽的前提下，将 750 TB 的文件存放到 S3 归档存储中。并使用最便宜的方式。肯定需要使用 AWS Snowball 家族产品，而 2️⃣ 中的 VPC endpoint 不知所云，排除掉后选 4️⃣。 三、Amazon Kinesis Data FirehoseA company captures clickstream data from multiple websites and analyzes it using batch processing. The data is loaded nightly into Amazon Redshift and is consumed by business analysts. The company wants to move towards near-real-time data processing for timely insights. The solution should process the streaming data with minimal effort and operational overhead.Which combination of AWS services are MOST cost-effective for this solution? (Choose two.)1. Amazon EC22. ✅ AWS Lambda3. ❌ Amazon Kinesis Data Streams4. ✅ Amazon Kinesis Data Firehose5. Amazon Kinesis Data Analytics ✨ 关键词：data from multiple websites、operational overhead 2️⃣ 3️⃣ ❌ -&gt; 2️⃣ 4️⃣ ✅ 💡 解析：从多个网站收集数据并通过批处理分析，数据每晚会被加载到 Redshift 数据湖中，公司希望近乎实时地处理这些数据。需要使用最少操作的方式。由于 Amazon Data Firehose 官方文档中就介绍了它和 Lambda 整合处理数据流的功能，更简单，因此在这里更加合适。 Amazon Kinesis Data Streams 是一种可大规模扩展、高度持久的数据摄取和处理服务，针对流式传输数据进行了优化。您可以配置数以万计的数据创建器，连续不断地将数据传输到 Kinesis 数据流。数据将在几毫秒内传输到您的 Amazon Kinesis 应用程序，这些应用程序将按生成顺序接收数据记录。Amazon Kinesis Data Streams 与多项 AWS 服务集成，其中包括以近乎实时的方式转换流数据并将其传输到 Amazon S3 等数据湖的 Amazon Kinesis Data Firehose、用于托管流处理的适用于 Apache Flink 的亚马逊托管服务、用于事件或记录处理的 AWS Lambda、用于私有连接的 AWS PrivateLink、用于指标和日志处理的 Amazon Cloudwatch 以及用于服务器端加密的 AWS KMS。 四、Scaling Based on Amazon SQSA solutions architect is designing the cloud architecture for a new application being deployed on AWS. The process should run in parallel while adding and removing application nodes as needed based on the number of jobs to be processed. The processor application is stateless. The solutions architect must ensure that the application is loosely coupled and the job items are durably stored.Which design should the solutions architect use? Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch configuration that uses the AMI. Create an Auto Scaling group using the launch configuration. Set the scaling policy for the Auto Scaling group to add and remove nodes based on CPU usage. ❌ Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch configuration that uses the AMI. Create an Auto Scaling group using the launch configuration. Set the scaling policy for the Auto Scaling group to add and remove nodes based on network usage. ✅ Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of items in the SQS queue. Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of messages published to the SNS topic. ✨ 关键词：based on the number of jobs to be processed、stateless 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：There are some scenarios where you might think about scaling in response to activity in an Amazon SQS queue. For example, suppose that you have a web app that lets users upload images and use them online. In this scenario, each image requires resizing and encoding before it can be published. The app runs on EC2 instances in an Auto Scaling group, and it’s configured to handle your typical upload rates. Unhealthy instances are terminated and replaced to maintain current instance levels at all times. The app places the raw bitmap data of the images in an SQS queue for processing. It processes the images and then publishes the processed images where they can be viewed by users. The architecture for this scenario works well if the number of image uploads doesn’t vary over time. But if the number of uploads changes over time, you might consider using dynamic scaling to scale the capacity of your Auto Scaling group.Reference:https://aws.amazon.com/sqs/#:~:text=Amazon%20SQS%20leverages%20the%20AWS,queues%20provide%20nearly%20unlimited%20throughputhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/as-using-sqs-queue.html 五、Network Load BalancerA gaming company has multiple Amazon EC2 instances in a single Availability Zone for its multiplayer game that communicates with users on Layer 4. The chief technology officer (CTO) wants to make the architecture highly available and cost-effective.Which should a solutions architect do to meet these requirements? (Choose two.)? Increase the number of EC2 instances. Decrease the number of EC2 instances. ✅ Configure a Network Load Balancer in front of the EC2 instances. Configure an Application Load Balancer in front of the EC2 instances. ✅ Configure an Auto Scaling group to add or remove instances in multiple Availability Zones automatically. ✨ 关键词：single Availability Zone、highly available、game server 3️⃣ 5️⃣ ✅ 💡 解析：A Network Load Balancer functions at the fourth layer of the Open Systems Interconnection (OSI) model. It can handle millions of requests per second. After the load balancer receives a connection request, it selects a target from the target group for the default rule. It attempts to open a TCP connection to the selected target on the port specified in the listener configuration.When you enable an Availability Zone for the load balancer, Elastic Load Balancing creates a load balancer node in the Availability Zone. By default, each load balancer node distributes traffic across the registered targets in its Availability Zone only. If you enable cross-zone load balancing, each load balancer node distributes traffic across the registered targets in all enabled Availability Zones. For more information, see Availability Zones.If you enable multiple Availability Zones for your load balancer and ensure that each target group has at least one target in each enabled Availability Zone, this increases the fault tolerance of your applications. For example, if one or more target groups does not have a healthy target in an Availability Zone, we remove the IP address for the corresponding subnet from DNS, but the load balancer nodes in the other Availability Zones are still available to route traffic. If a client doesn’t honor the time-to-live (TTL) and sends requests to the IP address after it is removed from DNS, the requests fail.For TCP traffic, the load balancer selects a target using a flow hash algorithm based on the protocol, source IP address, source port, destination IP address, destination port, and TCP sequence number. The TCP connections from a client have different source ports and sequence numbers, and can be routed to different targets. Each individual TCP connection is routed to a single target for the life of the connection.For UDP traffic, the load balancer selects a target using a flow hash algorithm based on the protocol, source IP address, source port, destination IP address, and destination port. A UDP flow has the same source and destination, so it is consistently routed to a single target throughout its lifetime. Different UDP flows have different source IP addresses and ports, so they can be routed to different targets.An Auto Scaling group contains a collection of Amazon EC2 instances that are treated as a logical grouping for the purposes of automatic scaling and management. An Auto Scaling group also enables you to use Amazon EC2 Auto Scaling features such as health check replacements and scaling policies. Both maintaining the number of instances in an Auto Scaling group and automatic scaling are the core functionality of the Amazon EC2 Auto Scaling service.The size of an Auto Scaling group depends on the number of instances that you set as the desired capacity. You can adjust its size to meet demand, either manually or by using automatic scaling.An Auto Scaling group starts by launching enough instances to meet its desired capacity. It maintains this number of instances by performing periodic health checks on the instances in the group. The Auto Scaling group continues to maintain a fixed number of instances even if an instance becomes unhealthy. If an instance becomes unhealthy, the group terminates the unhealthy instance and launches another instance to replace it.Reference:https://docs.aws.amazon.com/elasticloadbalancing/latest/network/introduction.htmlhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroup.html 六、Amazon RDS Read ReplicasA company’s website is using an Amazon RDS MySQL Multi-AZ DB instance for its transactional data storage. There are other internal systems that query this DB instance to fetch data for internal batch processing. The RDS DB instance slows down significantly the internal systems fetch data. This impacts the website’s read and write performance, and the users experience slow response times.Which solution will improve the website’s performance? Use an RDS PostgreSQL DB instance instead of a MySQL database. Use Amazon ElastiCache to cache the query responses for the website. Add an additional Availability Zone to the current RDS MySQL Multi.AZ DB instance. ✅ Add a read replica to the RDS DB instance and configure the internal systems to query the read replica. ✨ 关键词：Amazon RDS MySQL、只读副本 4️⃣ ✅ 💡 解析：You can reduce the load on your source DB instance by routing read queries from your applications to the read replica. Read replicas allow you to elastically scale out beyond the capacity constraints of a single DB instance for read-heavy database workloads. Because read replicas can be promoted to master status, they are useful as part of a sharding implementation.To further maximize read performance, Amazon RDS for MySQL allows you to add table indexes directly to Read Replicas, without those indexes being present on the master.Reference:https://aws.amazon.com/rds/features/read-replicas 七、Amazon Kinesis Data FirehoseA company has a legacy application that process data in two parts. The second part of the process takes longer than the first, so the company has decided to rewrite the application as two microservices running on Amazon ECS that can scale independently.How should a solutions architect integrate the microservices?1. Implement code in microservice 1 to send data to an Amazon S3 bucket. Use S3 event notifications to invoke microservice 2.2. Implement code in microservice 1 to publish data to an Amazon SNS topic. Implement code in microservice 2 to subscribe to this topic.3. ✅ Implement code in microservice 1 to send data to Amazon Kinesis Data Firehose. Implement code in microservice 2 to read from Kinesis Data Firehose.4. ❌ Implement code in microservice 1 to send data to an Amazon SQS queue. Implement code in microservice 2 to process messages from the queue. ✨ 关键词：解耦、队列 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：无。程序 2 的处理速度比 1 的慢，但是对于 Data（数据）而非 Message 或 Task 似乎 Amazon Kinesis Data 系更加合适。","link":"/2024/11/16/saa_test_daily_20241116/"},{"title":"SAA 考试每日练习 - 2024&#x2F;11&#x2F;17","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam10 题 (No.1 ~ No.10)，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： ingestsv. 食入, 摄入, 咽下 varyv. （使）改变，使多样化；变化；不同，有差异 drasticallyadv. 彻底地；激烈地 servesv. 服务；提供；接待；任期为；为…工作，服役 | n. 发球 coordinatev. （使）协调，（使）相配合；使（身体各部位）动作协调 | n. 坐标；（衣服、家具等）搭配，协调 | adj. 同等的，并列的；坐标的 modernizev. 使（制度、方法等）现代化，使（设备、概念等）现代化 resiliencyn. 跳回(回弹，弹力，弹性变形，冲击值) scalabilityn. 〔测〕可量测性；可扩展性 frequentlyadv. 频繁地, 时常, 不断地 rarelyadv. 很少，罕有，不常 low-latencyadj. 低延迟的 principaln. 校长；院长；负责人；主要演员；本金；委托人；主犯 | adj. 首要的；主要的；最重要的；资本的；本金的 一、S3 Transfer AccelerationA company collects data for temperature, humidity, and atmospheric pressure in cities across multiple continents洲，大陆. The average volume of data that the company collects from each site daily is 500 GB. Each site has a high-speed Internet connection.The company wants to aggregate the data from all these global sites as quickly as possible in a single Amazon S3 bucket. The solution must minimize operational complexity.Which solution meets these requirements? ✅ Turn on S3 Transfer Acceleration on the destination S3 bucket. Use multipart uploads to directly upload site data to the destination S3 bucket. ❌ Upload the data from each site to an S3 bucket in the closest Region. Use S3 Cross-Region Replication to copy objects to the destination S3 bucket. Then remove the data from the origin S3 bucket. Schedule AWS Snowball Edge Storage Optimized device jobs daily to transfer data from each site to the closest Region.Use S3 Cross-Region Replication to copy objects to the destination S3 bucket. Upload the data from each site to an Amazon EC2 instance in the closest Region. Store the data in an Amazon Elastic Block Store (Amazon EBS) volume. At regular intervals, take an EBS snapshot and copy it to the Region that contains the destination S3 bucket. Restore the EBS volume in that Region. ✨ 关键词：500 GB、high-speed Internet connection、save into a single Amazon S3 bucket 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：题目背景是公司从多个洲的城市收集数据，从每个网站（洲或城市）收集数据的大小是 500 GB，之间有高速互联网连接。需要将这些数据尽快传到单个 S3 存储桶。要求最简单的架构。这是 S3 Transfer Acceleratio 的使用场景。 S3 Transfer Acceleration S3 远距离上传和下载更快Amazon S3 Transfer Acceleration (S3TA) 可将与 Amazon S3 之间的内容传输速度加快 50-500%，以便大型对象远距离传输。拥有具有广泛用户的 Web 或移动应用程序或托管在远离其 S3 存储桶之处的应用程序的客户可以在 Internet 上体验长时间且可变的上传和下载速度。 S3 Transfer Acceleration (S3TA) 减少了可能影响传输的 Internet 路由、拥塞和速度的变化，并在逻辑上缩短了远程应用程序到 S3 的距离。S3TA 通过 Amazon CloudFront 遍布全球的边缘站点和 AWS 支柱网络来路由流量，并通过使用网络协议优化，从而提高了传输性能。您可以在 S3 控制台上点击几下打开 S3TA，并使用速度比较工具从您的位置测试其优势。使用 S3TA，您只需为加速的传输付费。 不选 2️⃣ S3 Cross-Region Replication 的原因是它更偏向于制造副本的容灾场景。并且如果你使用复制的话，还需要删除源桶中的数据，较为繁琐。 👨‍👨‍👦‍👦 社区讨论：General line: Collect huge amount of the filesacross multiple continentsConditions: High speed Internet connectivityTask:aggregate the data from all in a single S3 bucketRequirements:as quickas possible, minimize operational complexity Correct answer A:S3 Transfer Acceleration because: ideally works with objects for long-distance transfer (usesEdge Locations) can speed up content transfers to and from S3 as much as 50-500% use cases: mobile &amp; web application uploadsand downloads, distributed office transfers, data exchange with trusted partners. Generally for sharing of large data sets between companies, customers can set up special access to theirS3 buckets with accelerated uploads to speed data exchangesand the pace of innovation. B - about disaster recoveryC - about transferring data between your local environment and the AWS CloudD - about disaster recovery 二、Amazon AthenaA company needs the ability to analyze the log files of its proprietary application. The logs are stored in JSON format in an Amazon S3 bucket. Queries will be simple and will run on-demand. A solutions architect needs to perform the analysis with minimal changes to the existing architecture.What should the solutions architect do to meet these requirements with the LEAST amount of operational overhead? ❌ Use Amazon Redshift to load all the content into one place and run the SQL queries as needed. Use Amazon CloudWatch Logs to store the logs. Run SQL queries as needed from the Amazon CloudWatch console. ✅ Use Amazon Athena directly with Amazon S3 to run the queries as needed. Use AWS Glue to catalog the logs. Use a transient Apache Spark cluster on Amazon EMR to run the SQL queries as needed. ✨ 关键词：logs are stored in JSON format in an Amazon S3 bucket、Amazon Redshift 1️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：日志以 JSON 格式保存在了 S3 存储桶中，需要按需进行检索。要求对当前架构有最小修改。最简单的架构。这是 Amazon Athena 的使用场景。 Amazon Athena 灵活轻松地分析包含它的 PB 级数据 Amazon Athena 是一项基于开源框架的无服务器交互式分析服务，支持开源表和文件格式。Athena 提供了一种简化、灵活的方法来分析包含它的 PB 级数据。从 Amazon Simple Storage Service（S3）数据湖和超过 30 个数据来源（包括本地数据来源，或使用 SQL 或 Python 的其他云系统）分析数据或构建应用程序。Athena 基于开源 Trino 和 Presto 引擎以及 Apache Spark 框架构建，无需进行预配或配置。 3️⃣ 当然也能解决问题，将数据导入 Redshift 之后在进行检索，但是对比 1️⃣ 更复杂因此不选。 👨‍👨‍👦‍👦 社区讨论：Keyword: Queries will be simple and will run on-demand. Minimal changes to the existing architecture. A: Incorrect - We have to do 2 step. load all content to Redshift and run SQL query (This is simple query so we can you Athena, for complex query we will apply Redshit)B: Incorrect - Our query will be run on-demand so we don’t need to use CloudWatch Logs to store the logs.C: Correct - This is simple query we can apply Athena directly on S3D: Incorrect - This take 2 step: use AWS Glue to catalog the logsand use Sparkto run SQL query 三、AWS OrganizationsA company uses AWS Organizations to manage multiple AWS accounts for different departments. The management account has an Amazon S3 bucket that contains project reports. The company wants to limit access to this S3 bucket to only users of accounts within the organization in AWS Organizations.Which solution meets these requirements with the LEAST amount of operational overhead? ✅ Add the aws PrincipalOrgID global condition key with a reference to the organization ID to the S3 bucket policy. Create an organizational unit (OU) for each department. Add the aws:PrincipalOrgPaths global condition key to the S3 bucket policy. Use AWS CloudTrail to monitor the CreateAccount, InviteAccountToOrganization, LeaveOrganization, and RemoveAccountFromOrganization events. Update the S3 bucket policy accordingly. Tag each user that needs access to the S3 bucket. Add the aws:PrincipalTag global condition key to the S3 bucket policy. ✨ 关键词：IAM、AWS Organizations、S3 bucket policy 1️⃣ ✅ 💡 解析：需要将 S3 存储桶中的产品报告分享给 AWS Organizations 中的用户。最少操作。这是 PrincipalOrgID 的使用场景。 AWS:PrincipalOrgID 条件键 AWS:PrincipalOrgID 条件键您可以使用此条件键将过滤条件应用于基于资源的策略的主体元素。您可以将任何字符串运算符（例如 StringLike）与此条件一起使用，并将 Amazon Organizations ID 指定为其值。 条件键 说明 运算符 值 aws:PrincipalOrgID 验证访问资源的主体是否属于您组织中的账户。 所有字符串运算符 任何Amazon Organizations ID 👨‍👨‍👦‍👦 社区讨论：aws:PrincipalOrgID Validates if the principal accessing the resource belongs to an account in your organization. The following condition keysare especially useful with AWS Organizations:aws:PrincipalOrgID – Simplifies specifying the Principal element in a resource-based policy.This global key providesan alternative to listing all the account IDs for all AWS accounts in an organization. Instead of listing all of the accounts that are members of an organization, you can specify the organization ID in the Condition element. aws:PrincipalOrgPaths – Use this condition key to match members of a specific organization root,an OU, or its children.The aws:PrincipalOrgPaths condition key returns true when the principal (root user, IAM user, or role) making the request is in the specified organization path. A path isa text representation of the structure of an AWS Organizationsentity. 四、VPC Gateway EndpointAn application runs on an Amazon EC2 instance in a VPC. The application processes logs that are stored in an Amazon S3 bucket. The EC2 instance needs to access the S3 bucket without connectivity to the internet.Which solution will provide private network connectivity to Amazon S3? ✅ Create a gateway VPC endpoint to the S3 bucket. Stream the logs to Amazon CloudWatch Logs. Export the logs to the S3 bucket. Create an instance profile on Amazon EC2 to allow S3 access. Create an Amazon API Gateway API with a private link to access the S3 endpoint. ✨ 关键词：S3 bucket、gateway VPC endpoint 1️⃣ ✅ 💡 解析：运行在 VPC 中的 EC2 实例想要不经由互联网访问 S3 存储桶。这是 网关终端节点（只支持 S3 和 DynamoDB​）的最佳使用场景。 👨‍👨‍👦‍👦 社区讨论：Keywords: EC2 in VPC EC2 instance needs to access the S3 bucket without connectivity to the internet A: Correct - Gateway VPC endpoint can connect to S3 bucket privately without additional costB: Incorrect - You can set up interface VPC endpoint for CloudWatch Logs for private networkfrom EC2 to CloudWatch. But from CloudWatch to S3 bucket: Log data can take up to 12 hours to become available forexport and the requirement only need EC2 to S3C: Incorrect - Create an instance profile just grant access but not help EC2 connect to S3 privatelyD: Incorrect - API Gateway like the proxy which receive networkfrom out site and it forward request to AWS Lambda, Amazon EC2,Elastic Load Balancing products such as Application Load Balancers or Classic Load Balancers, Amazon DynamoDB, Amazon Kinesis, or any publiclyavailable HTTPS-based endpoint. But notS3 五、EFSA company is hosting a web application on AWS using a single Amazon EC2 instance that stores user-uploaded documents in an Amazon EBS volume. For better scalability and availability, the company duplicated the architecture and created a second EC2 instance and EBS volume in another Availability Zone, placing both behind an Application Load Balancer. After completing this change, users reported that, each time they refreshed the website, they could see one subset of their documents or the other, but never all of the documents at the same time.What should a solutions architect propose to ensure users see all of their documents at once? Copy the data so both EBS volumes contain all the documents Configure the Application Load Balancer to direct a user to the server with the documents ✅ Copy the data from both EBS volumes to Amazon EFS. Modify the application to save new documents to Amazon EFS Configure the Application Load Balancer to send the request to both servers. Return each document from the correct server ✨ 关键词：EFS、分布式数据不一致 3️⃣ ✅ 💡 解析：公司从又在另一个可用区部署了一个使用 EBS 的 EC2 实例，并将其放置在 ALB 后，这导致了用户会随机在既存的一台和新的机器中跳转，存在上传了文件之后被跳转到另一台机器的情况。使用 EFS 解决，之后两台 EC2 实例都使用着一个 EFS。 这里需要注意的是：EFS 是 区域 级别的资源，它将数据存储在多个可用区中。 六、AWS SnowballA company uses NFS to store large video files in on-premises network attached storage. Each video file ranges in size from 1MB to 500 GB. The total storage is 70 TB and is no longer growing. The company decides to migrate the video files to Amazon S3. The company must migrate the video files as soon as possible while using the least possible network bandwidth.Which solution will meet these requirements? Create an S3 bucket. Create an IAM role that has permissions to write to the S3 bucket. Use the AWS CLI to copy all files locally to the S3 bucket. ✅ Create an AWS Snowball Edge job. Receive a Snowball Edge device on premises. Use the Snowball Edge client to transfer data to the device. Return the device so that AWS can import the data into Amazon S3. Deploy an S3 File Gateway on premises. Create a public service endpoint to connect to the S3 File Gateway. Create an S3 bucket. Create a new NFS file share on the S3 File Gateway. Point the new file share to the S3 bucket. Transfer the data from the existing NFS file share to the S3 File Gateway. Set up an AWS Direct Connect connection between the on-premises network and AWS. Deploy an S3 File Gateway on premises. Create a public virtual interface (VIF) to connect to the S3 File Gateway. Create an S3 bucket. Create a new NFS file share on the S3 File Gateway. Point the new file share to the S3 bucket. Transfer the data from the existing NFS file share to the S3 File Gateway. ✨ 关键词：70 TB、using the least possible network bandwidth、AWS Snowball 2️⃣ ✅ 💡 解析：公司又总量 70 TB 且不再增长的适配文件需要存储，并决定将其迁移到 S3，使用最少的网络带宽。这是 AWS Snowball 的最佳使用场景，申请 Snowball 设备，等收到设备后在本地将数据转移至 Snowball 设备，然后寄给 AWS。 AWS Snowcone：14TB 的可用存储容量。 Snowball Edge Storage Optimized：80TB 硬盘驱动器 (HDD) 容量，用于块卷和与 Amazon S3 兼容的对象存储。 Snowball Edge Compute Optimized：80TB 可用 HDD 容量，用于与 Amazon S3 兼容的对象存储或与 Amazon EBS 兼容的块卷。28TB 可用 NVMe SSD 容量，用于与 Amazon EBS 兼容的块卷。同时性能更强、也支持添加 GPU 设备。 AWS Snowmobile：是一个 45 英尺长的加固集装箱，由一台半挂卡车牵引，一次可以传输高达 100PB 的数据。 七、Fan OutA company has an application that ingests incoming messages. Dozens of other applications and microservices then quickly consume these messages. The number of messages varies变化 drastically激烈地 and sometimes increases suddenly to 100,000 each second. The company wants to decouple the solution and increase scalability.Which solution meets these requirements? Persist the messages to Amazon Kinesis Data Analytics. Configure the consumer applications to read and process the messages. Deploy the ingestion application on Amazon EC2 instances in an Auto Scaling group to scale the number of EC2 instances based on CPU metrics. ❌ Write the messages to Amazon Kinesis Data Streams with a single shard. Use an AWS Lambda function to preprocess messages and store them in Amazon DynamoDB. Configure the consumer applications to read from DynamoDB to process the messages. ✅ Publish the messages to an Amazon Simple Notification Service (Amazon SNS) topic with multiple Amazon Simple Queue Service (Amazon SQS) subscriptions. Configure the consumer applications to process the messages from the queues. ✨ 关键词：Data Stream、messages number varies drastically、consume these messages 3️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：需要消费数量变化的数据消息。典型的 Fan Out 架构场景，最终的消费者应用程序肯定是连接 SQS 的。 这里社区讨论中提到了吞吐量，最新的 SQS 已经不限制吞吐量了： 无限吞吐量：标准队列支持使每个 API 操作的每秒事务数 (TPS) 几乎不受限制。 不过 FIFO 队列任然有限制： 高吞吐量：默认情况下，FIFO 队列每秒最多支持 300 条消息（每秒 300 次发送、接收或删除操作）。如果每次操作批处理 10 条消息（最多），FIFO 队列每秒最多可支持 3,000 条消息。如果您需要更高的吞吐量，可以在 Amazon SQS 控制台上为 FIFO 启用高吞吐量模式，该模式将支持每秒多达 24,000 条消息（使用批处理），或者在不进行批处理的情况下每秒最多支持 2,400 条消息。 👨‍👨‍👦‍👦 社区讨论：By default,an SQS queue can handle a maximum of 3,000 messages per second. However, you can request higher throughput by contacting AWS Support. AWS can increase the message throughput for your queue beyond the default limits in increments of 300 messages per second, up to a maximum of 10,000 messages per second. It’s important to note that the maximum number of messages per second that a queue can handle is not the same as the maximum number of requests per second that the SQS API can handle.The SQS API is designed to handle a high volume of requests per second, so it can be used to send messages to your queue at a rate that exceeds the maximum message throughput of the queue. 八、EC2 Auto ScalingA company is migrating a distributed application to AWS. The application serves提供 variable workloads. The legacy platform consists of a primary server that coordinates协调 jobs across multiple compute nodes. The company wants to modernize the application with a solution that maximizes resiliency弹性 and scalability可扩展性.How should a solutions architect design the architecture to meet these requirements? Configure an Amazon Simple Queue Service (Amazon SQS) queue as a destination for the jobs. Implement the compute nodes with Amazon EC2 instances that are managed in an Auto Scaling group. Configure EC2 Auto Scaling to use scheduled scaling. ✅ Configure an Amazon Simple Queue Service (Amazon SQS) queue as a destination for the jobs. Implement the compute nodes with Amazon EC2 instances that are managed in an Auto Scaling group. Configure EC2 Auto Scaling based on the size of the queue. Implement the primary server and the compute nodes with Amazon EC2 instances that are managed in an Auto Scaling group. Configure AWS CloudTrail as a destination for the jobs. Configure EC2 Auto Scaling based on the load on the primary server. Implement the primary server and the compute nodes with Amazon EC2 instances that are managed in an Auto Scaling group. Configure Amazon EventBridge (Amazon CloudWatch Events) as a destination for the jobs. Configure EC2 Auto Scaling based on the load on the compute nodes. ✨ 关键词：variable workloads、SQS、EC2 Auto Scaling 2️⃣ ✅ 💡 解析：公司既有的框架中，有一台主要的服务器来分配工作负载，希望在迁移到 AWS 后最大化弹性和扩展性。使用 SQS + EC2 弹性扩展组可以解决问题。而 1️⃣ 和 2️⃣ 对比的话，显然计划扩展不如根据 SQS 队列长度扩展来的好。 👨‍👨‍👦‍👦 社区讨论：A - incorrect:Schedule scaling policy doesn’t make sense.C, D - incorrect: Primary server should not be in same Auto Scaling group with compute nodes. 九、S3 and it’s lifecycle policyA company is running an SMB file server in its data center. The file server stores large files that are accessed frequently频繁地 for the first few days after the files are created. After 7 days the files are rarely少见地，罕有地 accessed. The total data size is increasing and is close to the company’s total storage capacity. A solutions architect must increase the company’s available storage space without losing low-latency低延迟的 access to the most recently accessed files. The solutions architect must also provide file lifecycle management to avoid future storage issues.Which solution will meet these requirements? Use AWS DataSync to copy data that is older than 7 days from the SMB file server to AWS. ✅ Create an Amazon S3 File Gateway to extend the company’s storage space. Create an S3 Lifecycle policy to transition the data to S3 Glacier Deep Archive after 7 days. Create an Amazon FSx for Windows File Server file system to extend the company’s storage space. Install a utility on each user’s computer to access Amazon S3. Create an S3 Lifecycle policy to transition the data to S3 Glacier Flexible Retrieval after 7 days. ✨ 关键词：data size is increasing and is close to the company’s total storage capacity、without losing low-latency access、SMB 2️⃣ ✅ 💡 解析：文件最初的几天访问频繁，7 天之后访问次数很少。文件总规模仍在扩大且快要触及公司存储上限。需要扩容并确保对最常访问文件的低延迟。还需要使用生命周期策略来覆盖未来的存储问题。可能要使用到 S3 与其生命周期策略，在 2️⃣ 和 4️⃣ 中选择的话，2️⃣ 的操作更简单，且使用了 AWS 提供的解决方案。 什么是 Amazon S3 文件网关 AWS Storage Gateway 可以连接本地 IT 环境与 AWS 存储基础设施。通过使用此组合，可以使用行业标准文件协议（如网络文件系统 (NFS)）和服务器消息块 (SMB) 在 Amazon S3 中存储和检索对象。A S3 File Gateway simplifies file storage in Amazon S3, integrates to existing applications through industry-standard file system protocols, and provides a cost-effective alternative to on-premises storage. It also provides low-latency access to data through transparent local caching. A S3 File Gateway manages data transfer to and from AWS, buffers applications from network congestion, optimizes and streams data in parallel, and manages bandwidth consumption. Amazon S3 File Gateway 使用了文件缓存来确保低延迟（使用 AWS 的网络传输似乎也能保证低延迟？）。 👨‍👨‍👦‍👦 社区讨论：B answwer is correct. low latency is only needed for newer files. Additionally, File GW provides low latencyaccess by caching frequentlyaccessed files locally so answer is B 十、Amazon SQS FIFO queueA company is building an ecommerce web application on AWS. The application sends information about new orders to an Amazon API Gateway REST API to process. The company wants to ensure that orders are processed in the order that they are received.Which solution will meet these requirements? Use an API Gateway integration to publish a message to an Amazon Simple Notification Service (Amazon SNS) topic when the application receives an order. Subscribe an AWS Lambda function to the topic to perform processing. ✅ Use an API Gateway integration to send a message to an Amazon Simple Queue Service (Amazon SQS) FIFO queue when the application receives an order. Configure the SQS FIFO queue to invoke an AWS Lambda function for processing. Use an API Gateway authorizer to block any requests while the application processes an order. Use an API Gateway integration to send a message to an Amazon Simple Queue Service (Amazon SQS) standard queue when the application receives an order. Configure the SQS standard queue to invoke an AWS Lambda function for processing. ✨ 关键词：ensure that orders are processed in the order that they are received、Amazon SQS FIFO queue 2️⃣ ✅ 💡 解析：需要按照顺序处理消息。FIFO SQS 的最佳使用场景。 Amazon SQS 功能 FIFO 队列 “正好一次”处理：消息只交付一次，在使用者处理并删除它之前一直可用。队列中不会引入重复项。 先进先出交付：严格保持消息的发送和接收顺序（即先进先出）。","link":"/2024/11/17/saa_test_daily_20241117/"},{"title":"SAA 考试每日练习 - 2024&#x2F;11&#x2F;18","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam10 题 (No.11 ~ No.20)，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： credentialn. 凭证；国书 | adj. 〈罕〉信任的 | v. 提供证明书（或证件） maintenancen. 维护，保养；维持；（依法应负担的）生活费，抚养费 rotatev. （使）旋转，（使）转动；（使）轮流 ecommercen. 电子商务（electronic commerce） degradev. 贬低，侮辱；（使）降级；降解；退化 inspectionn. 检查，视察，查看，审视 visualizationn. 可视化，形象化 durableadj. 耐用的，耐久的，长期的，长久的 | n. 耐久品 trackn. 小路，小径；足迹，踪迹；跑道；轨道；路线；一首歌曲；音轨；工作方向；思路 | v. 跟踪，追踪；留下印迹；沿轨道运行 modificationn. 修改；改造；改变；缓和；减轻；修改后的形式，变体；修饰，限定 three-tier三层架构（表示层，应用层，数据层） 一、AWS Secrets ManagerA company has an application that runs on Amazon EC2 instances and uses an Amazon Aurora database. The EC2 instances connect to the database by using user names and passwords that are stored locally in a file. The company wants to minimize the operational overhead of credential management.What should a solutions architect do to accomplish this goal? ✅ Use AWS Secrets Manager. Turn on automatic rotation. Use AWS Systems Manager Parameter Store. Turn on automatic rotation. Create an Amazon S3 bucket to store objects that are encrypted with an AWS Key Management Service (AWS KMS) encryption key. Migrate the credential file to the S3 bucket. Point the application to the S3 bucket. Create an encrypted Amazon Elastic Block Store (Amazon EBS) volume for each EC2 instance. Attach the new EBS volume to each EC2 instance. Migrate the credential file to the new EBS volume. Point the application to the new EBS volume. ✨ 关键词：AWS Secrets Manager 1️⃣ ✅ 💡 解析：题目背景有有应用程序连接到 EC2 实例，之前使用账号密码作认真，公司希望改用更简单的。使用 AWS Secrets Manager 显然是可以达到需求并且也是最简单的。什么是 AWS Secrets Manager？ 借助 AWS Secrets Manager，您可以在数据库凭证、应用程序凭证、OAuth 令牌、API 密钥和其他密钥的整个生命周期内对其进行管理、检索和轮换。 对于您的组织可能拥有的其他类型的密钥： AWS 凭证 – 建议使用 AWS Identity and Access Management 加密密钥 – 建议使用 AWS Key Management Service SSH 密钥 – 建议使用 Amazon EC2 Instance Connect 私有密钥和证书 – 建议使用 AWS Certificate Manager 回到题目，社区里有人提到了 2️⃣ 中的 AWS Systems Manager Parameter Store 不支持自动轮换，因此错误。AWS Systems Manager Parameter Store 要实施密码轮换生命周期，请使用 AWS Secrets Manager。您可以使用 Secrets Manager 在数据库凭证、API 密钥和其他密钥的整个生命周期内对其进行轮换、管理和检索。 👨‍👨‍👦‍👦 社区讨论：B is wrong because parameter store does not support auto rotation, unless the customer writes it themselves, A is the answer. READ!!! AWS Secrets Manager isa secrets management service that helps you protect access to your applications, services, and IT resources.This service enables you to rotate, manage,and retrieve database credentials, API keys,and other secrets throughout their lifecycle. 二、CloudFrontA global company hosts its web application on Amazon EC2 instances behind an Application Load Balancer (ALB). The web application has static data and dynamic data. The company stores its static data in an Amazon S3 bucket. The company wants to improve performance and reduce latency for the static data and dynamic data. The company is using its own domain name registered with Amazon Route 53.What should a solutions architect do to meet these requirements? ✅ Create an Amazon CloudFront distribution that has the S3 bucket and the ALB as origins. Configure Route 53 to route traffic to the CloudFront distribution. Create an Amazon CloudFront distribution that has the ALB as an origin. Create an AWS Global Accelerator standard accelerator that has the S3 bucket as an endpoint Configure Route 53 to route traffic to the CloudFront distribution. Create an Amazon CloudFront distribution that has the S3 bucket as an origin. Create an AWS Global Accelerator standard accelerator that has the ALB and the CloudFront distribution as endpoints. Create a custom domain name that points to the accelerator DNS name. Use the custom domain name as an endpoint for the web application. ❌ Create an Amazon CloudFront distribution that has the ALB as an origin. Create an AWS Global Accelerator standard accelerator that has the S3 bucket as an endpoint. Create two domain names. Point one domain name to the CloudFront DNS name for dynamic content. Point the other domain name to the accelerator DNS name for static content. Use the domain names as endpoints for the web application. ✨ 关键词：static data and dynamic data、reduce latency 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：全球公司希望对网站提速，网站有静态资源也有动态数据。仅仅使用 CloudFront CDN 似乎就能解决问题（缓存静态资源、优化到源站的线路）。 题目的重点在辨别 CloudFront 和 Global Accelerator。CloudFront 是 CDN，比较好理解了：缓存内容、优化线路、安全保护、集成 WAF 等 AWS 安全服务。 而关于 Global Accelerator：AWS Global Accelerator 使用 AWS 全球网络提升应用程序的可用性、性能和安全性 利用 AWS 全球基础设施的性能、安全性和可用性，在其中一个 Global Accelerator 边缘站点载入您的用户流量。用户可以通过静态 IP 地址访问您的应用程序端点，享受独立于 DNS 的确定性路由。 全局负载均衡：将来自全球不同地区的用户流量智能地路由至最近的AWS边缘位置，从而降低延迟并提供更快的响应速度。 客户 IP 保持：确保来自同一 IP 地址的请求始终路由到同一终端节点，适用于需要保持用户会话的应用程序。 TCP/UDP 支持：支持 TCP 和 UDP 协议，适用于各种应用程序，包括 HTTP、HTTPS、游戏、流媒体等。 非常适合 VoIP 语音应用等。 👨‍👨‍👦‍👦 社区讨论：Answer is AExplanation - AWS Global Accelerator vs CloudFront They both use the AWS global networkand itsedge locationsaround the world Both services integrate with AWS Shield for DDoS protection. CloudFront Improves performance for both cacheable content (such as imagesand videos) Dynamic content (such as API acceleration and dynamic site delivery) Content is served at the edge Global Accelerator Improves performance for a wide range of applications over TCP or UDP Proxying packetsat the edge to applications running in one or more AWS Regions. Good fit for non-HTTP use cases, such as gaming (UDP), IoT (MQTT), or Voice over IP Good for HTTP use cases that require static IP addresses Good for HTTP use cases that required deterministic, fast regional failover 三、AWS Secrets ManagerA company performs monthly maintenance维护 on its AWS infrastructure. During these maintenance activities, the company needs to rotate使流转 the credentials for its Amazon RDS for MySQL databases across multiple AWS Regions.Which solution will meet these requirements with the LEAST operational overhead? ✅ Store the credentials as secrets in AWS Secrets Manager. Use multi-Region secret replication for the required Regions. Configure Secrets Manager to rotate the secrets on a schedule. Store the credentials as secrets in AWS Systems Manager by creating a secure string parameter. Use multi-Region secret replication for the required Regions. Configure Systems Manager to rotate the secrets on a schedule. Store the credentials in an Amazon S3 bucket that has server-side encryption (SSE) enabled. Use Amazon EventBridge (Amazon CloudWatch Events) to invoke an AWS Lambda function to rotate the credentials. Encrypt the credentials as secrets by using AWS Key Management Service (AWS KMS) multi-Region customer managed keys. Store the secrets in an Amazon DynamoDB global table. Use an AWS Lambda function to retrieve the secrets from DynamoDB. Use the RDS API to rotate the secrets. ✨ 关键词：AWS Secrets Manager 1️⃣ ✅ 💡 解析：公司计划每月轮转数据库认证密钥。选 1️⃣ AWS Secrets Manager 完美符合需求。AWS Systems Manager 不支持流转排除 2️⃣；密钥存储在 S3 中并非最佳实践排除 3️⃣；KMS 是用来存储管理加密密钥的而非认证密钥，4️⃣ 也不对。 👨‍👨‍👦‍👦 社区讨论：Keywords: rotate the credentials for its Amazon RDS for MySQL databasesacross multiple AWS Regions LEAST operational overhead A: Correct - AWS Secrets Manager supports Encrypt credential for RDS, DocumentDb, Redshift, other DBsand key/value secret. multi-region replication. Remote base on schedule B: Incorrect - Secure string parameter onlyapply for ParameterStore. All the data in AWS Secrets Manager is encryptedC: Incorrect - don’t mention about replicate S3 across region.D: Incorrect - So many steps compare to answer A =)) 四、More Database ReplicasA company runs an ecommerce电子商务 application on Amazon EC2 instances behind an Application Load Balancer. The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. The Auto Scaling group scales based on CPU utilization metrics. The ecommerce application stores the transaction data in a MySQL 8.0 database that is hosted on a large EC2 instance.The database’s performance degrades降低，劣化 quickly as application load increases. The application handles more read requests than write transactions. The company wants a solution that will automatically scale the database to meet the demand of unpredictable read workloads while maintaining high availability.Which solution will meet these requirements? Use Amazon Redshift with a single node for leader and compute functionality. Use Amazon RDS with a Single-AZ deployment Configure Amazon RDS to add reader instances in a different Availability Zone. ✅ Use Amazon Aurora with a Multi-AZ deployment. Configure Aurora Auto Scaling with Aurora Replicas. Use Amazon ElastiCache for Memcached with EC2 Spot Instances. ✨ 关键词：multiple Availability Zones、more read requests than write transactions、 3️⃣ ✅ 💡 解析：应用程序运作在跨可用区的弹性扩容架构上，之前的数据库是 MySQL 8.0 并且运行在 EC2 实例上，公司希望数据库也能视工作负载自动扩容。Amazon Aurora 是最佳选择，可以在多个可用去横向扩容，选 3️⃣。 👨‍👨‍👦‍👦 社区讨论：C, AURORA is 5x performance improvement over MySQL on RDS and handles more read requests than write,; maintaining high availability = Multi-AZ deployment 五、Traffic MirroringA company recently migrated to AWS and wants to implement a solution to protect the traffic that flows in and out of the production VPC. The company had an inspection检查，审查 server in its on-premises data center. The inspection server performed specific operations such as traffic flow inspection and traffic filtering. The company wants to have the same functionalities in the AWS Cloud.Which solution will meet these requirements? Use Amazon GuardDuty for traffic inspection and traffic filtering in the production VPC. ❌ Use Traffic Mirroring to mirror traffic from the production VPC for traffic inspection and filtering. ✅ Use AWS Network Firewall to create the required rules for traffic inspection and traffic filtering for the production VPC. Use AWS Firewall Manager to create the required rules for traffic inspection and traffic filtering for the production VPC. ✨ 关键词：inspection 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：公司需要对进出 VPC 的流量进行保护，之前公司有自己的托管审查机器，并希望在 AWS 云架构上使用一样的方案。这里题目理解错了，以为是要事后审核，实际上是要进行实时的审查（和阻断），因此 3️⃣ 是最佳答案。通过 AWS Network Firewall 建立规则审核进出 VPC 的流量。 GuardDuty 是一项服务，为您的 AWS 基础设施和资源提供智能威胁检测。它通过持续监控 AWS 环境中的网络活动和账户行为来识别威胁。 👨‍👨‍👦‍👦 社区讨论：AWS NetworkFirewall isa managed firewall service that provides filtering for both inbound and outbound networktraffic. It allows you to create rules for traffic inspection and filtering, which can help protect your production VPC.Option 1️⃣: Amazon GuardDuty isa threat detection service, not a traffic inspection or filtering service.Option 2️⃣:Traffic Mirroring isa feature that allows you to replicate and send a copy of networktraffic from a VPC to another VPC or on-premises location. It is not a service that performs traffic inspection or filtering.Option 4️⃣: AWS Firewall Manager isa security management service that helps you to centrally configure and manage firewalls across your accounts. It is not a service that performs traffic inspection or filtering. 六、Data visualizations and policyA company hosts a data lake on AWS. The data lake consists of data in Amazon S3 and Amazon RDS for PostgreSQL. The company needs a reporting solution that provides data visualization可视化 and includes all the data sources within the data lake. Only the company’s management team should have full access to all the visualizations. The rest of the company should have only limited access.Which solution will meet these requirements? ❌ Create an analysis in Amazon QuickSight. Connect all the data sources and create new datasets. Publish dashboards to visualize the data. Share the dashboards with the appropriate IAM roles. ✅ Create an analysis in Amazon QuickSight. Connect all the data sources and create new datasets. Publish dashboards to visualize the data. Share the dashboards with the appropriate users and groups. Create an AWS Glue table and crawler for the data in Amazon S3. Create an AWS Glue extract, transform, and load (ETL) job to produce reports. Publish the reports to Amazon S3. Use S3 bucket policies to limit access to the reports. Create an AWS Glue table and crawler for the data in Amazon S3. Use Amazon Athena Federated Query to access data within Amazon RDS for PostgreSQL. Generate reports by using Amazon Athena. Publish the reports to Amazon S3. Use S3 bucket policies to limit access to the reports. ✨ 关键词：visualizations、policy 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：需求是对数据湖（包括 S3 和 RDS for PostgreSQL 数据库的数据）生产报表，并只提供给公司管理层查看。数据湖生产报表通过 Amazon QuickSight 实现，但是 Amazon QuickSight 控制面板只支持用户和组权限（这和 CloudWatch 的有点类似）。 您可以与账户中的特定用户或组或者 Amazon QuickSight 账户中的所有人共享控制面板和视觉对象。您也可以与互联网上的任何人共享。 Amazon QuickSight 超大规模的商业智能整合 而题目中的另一个服务 AWS Glue，则是一项完全托管的 ETL（提取、转换和加载）服务，使您能够轻松而经济高效地对数据进行分类、清理和扩充，并在各种数据存储和数据流之间可靠地移动数据。什么是 AWS Glue？ AWS Glue 是一项无服务器数据集成服务，可让使用分析功能的用户轻松发现、准备、移动和集成来自多个来源的数据。您可以将其用于分析、机器学习和应用程序开发。它还包括用于编写、运行任务和实施业务工作流程的额外生产力和数据操作工具。通过使用 AWS Glue，您可以发现并连接到 70 多个不同的数据来源，并在集中式数据目录中管理您的数据。您可以直观地创建、运行和监控“提取、转换、加载（ETL）”管道，以将数据加载到数据湖中。此外，您可以使用 Amazon Athena、Amazon EMR 和 Amazon Redshift Spectrum 立即搜索和查询已编目数据。 它更适合用来做汇总、转移和加载，而非生产报表。 👨‍👨‍👦‍👦 社区讨论：Keywords: Data lake on AWS. Consists of data in Amazon S3 and Amazon RDS for PostgreSQL. The company needsa reporting solution that provides data VISUALIZATION and includes ALL the data sources within the data lake. 1️⃣ - Incorrect: Amazon QuickSight only support users(standard version) and groups (enterprise version). usersand groups only exists without QuickSight. QuickSight don’t support IAM. We use usersand groups to view the QuickSight dashboard2️⃣ - Correct:asexplained in answer A and QuickSight is used to created dashboard from S3, RDS, Redshift, Aurora, Athena, OpenSearch, Timestream3️⃣ - Incorrect:This way don’t support visulization and don’t mention how to process RDS data4️⃣ - Incorrect:This way don’t support visulization and don’t mention how to combine data RDS and S3 七、EC2 instances connect S3 bucket with IAM rolesA company is implementing a new business application. The application runs on two Amazon EC2 instances and uses an Amazon S3 bucket for document storage. A solutions architect needs to ensure that the EC2 instances can access the S3 bucket.What should the solutions architect do to meet this requirement? ✅ Create an IAM role that grants access to the S3 bucket. Attach the role to the EC2 instances. Create an IAM policy that grants access to the S3 bucket. Attach the policy to the EC2 instances. Create an IAM group that grants access to the S3 bucket. Attach the group to the EC2 instances. ❌ Create an IAM user that grants access to the S3 bucket. Attach the user account to the EC2 instances. ✨ 关键词：EC2 instances、S3 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：很经典的赋予 EC2 IAM 角色 使其能够访问 S3 存储桶，临时密钥会由 STS 生成，选 1️⃣。 👨‍👨‍👦‍👦 社区讨论：Always remember that you should associate IAM roles to EC2 instances 八、SQS and LambdaAn application development team is designing a microservice that will convert large images to smaller, compressed images. When a user uploads an image through the web interface, the microservice should store the image in an Amazon S3 bucket, process and compress the image with an AWS Lambda function, and store the image in its compressed form in a different S3 bucket.A solutions architect needs to design a solution that uses durable耐用的, stateless components to process the images automatically.Which combination of actions will meet these requirements? (Choose two.) ✅ Create an Amazon Simple Queue Service (Amazon SQS) queue. Configure the S3 bucket to send a notification to the SQS queue when an image is uploaded to the S3 bucket. ✅ Configure the Lambda function to use the Amazon Simple Queue Service (Amazon SQS) queue as the invocation source. When the SQS message is successfully processed, delete the message in the queue. Configure the Lambda function to monitor the S3 bucket for new uploads. When an uploaded image is detected, write the file name to a text file in memory and use the text file to keep track踪迹 of the images that were processed. Launch an Amazon EC2 instance to monitor an Amazon Simple Queue Service (Amazon SQS) queue. When items are added to the queue, log the file name in a text file on the EC2 instance and invoke the Lambda function. Configure an Amazon EventBridge (Amazon CloudWatch Events) event to monitor the S3 bucket. When an image is uploaded, send an alert to an Amazon ample Notification Service (Amazon SNS) topic with the application owner’s email address for further processing. ✨ 关键词：SQS、Lambda 1️⃣ 2️⃣ ✅ 💡 解析：需要将用户上传的图片存入 S3 存储桶，然后进行压缩，之后存入另一个 S3 存储桶。非常适合引入 SQS 队列，大图片存储用 S3 存储桶发送消息，触发 Lambda 函数进行压缩之后存入压缩后的 S3 存储桶。 👨‍👨‍👦‍👦 社区讨论：To design a solution that uses durable, stateless components to process imagesautomatically,a solutionsarchitect couldconsider the following actions:Option A involves creating an SQS queue and configuring the S3 bucket to send a notification to the queue when an image isuploaded.Thisallows the application to decouple the image upload process from the image processing processand ensuresthat the image processing process is triggered automatically when a new image is uploaded.Option B involves configuring the Lambda function to use the SQS queue as the invocation source. When the SQS message issuccessfully processed, the message is deleted from the queue.Thisensures that the Lambda function is invoked only once perimage and that the image is not processed multiple times. 九、Gateway Load BalancerA company has a three-tier三层架构（表示层，应用层，数据层） web application that is deployed on AWS. The web servers are deployed in a public subnet in a VPC. The application servers and database servers are deployed in private subnets in the same VPC. The company has deployed a third-party virtual firewall appliance from AWS Marketplace in an inspection VPC. The appliance is configured with an IP interface that can accept IP packets.A solutions architect needs to integrate the web application with the appliance to inspect all traffic to the application before the traffic reaches the web server.Which solution will meet these requirements with the LEAST operational overhead? Create a Network Load Balancer in the public subnet of the application’s VPC to route the traffic to the appliance for packet inspection. Create an Application Load Balancer in the public subnet of the application’s VPC to route the traffic to the appliance for packet inspection. ❌ Deploy a transit gateway in the inspection VPConfigure route tables to route the incoming packets through the transit gateway. ✅ Deploy a Gateway Load Balancer in the inspection VPC. Create a Gateway Load Balancer endpoint to receive the incoming packets and forward the packets to the appliance. ✨ 关键词：inspection 3️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：Web 服务部署在公有子网，后端应用和数据库部署在私有子网，现在有一个第三方的虚拟防火墙应用部署在了审核 VPC 中，这个应用有一个 IP 接口并可以接受 IP 包。架构师需要让流量在到达 Web 服务之前经过防火墙。使用最简单的架构。审核场景优先使用的就是 Gateway Load Balancer（网关负载均衡器）。Gateway Load Balancer（网关负载均衡器） 网关负载均衡器可帮助您轻松部署、扩展和管理第三方虚拟设备。它为您提供了一个网关，用于在多个虚拟设备之间分配流量，同时根据需求增加或缩减流量。这样可以减少网络中潜在的故障点并提高可用性。 ⭐ ALB (Application Load Balancer) 工作在 OSI 的第 7 层（应用层），通过请求内容（路径、HOST 和查询字符串等）做出路由决策；HTTP、HTTPS 协议。 ⭐ NLB (Network Load Balancer) 工作在 OSI 的第 4 层（传输层），主要通过 IP 协议数据做出路由决策；适用于超高性能、极低延迟和大规模 TLS 卸载的使用场景；TCP、UDP、TLS 和 TCP_UDP 协议。 ⭐ GLB (GWLB, Gateway Load Balancer) 工作在 OSI 的第 3 层（网络层），将进入流量转发到监听规则中指定的目标组；适用于虚拟设备前端，如防火墙、入侵检测、防御系统和深度数据包检测系统等；监听所有端口的所有数据包；与虚拟设备使用 Geneve 协议，6081 端口交换流量。 而 Transit Gateway 是用来组网的，类似 ZeroTier。 十、EBS snapshotsA company wants to improve its ability to clone large amounts of production data into a test environment in the same AWS Region. The data is stored in Amazon EC2 instances on Amazon Elastic Block Store (Amazon EBS) volumes. Modifications修改，改造 to the cloned data must not affect the production environment. The software that accesses this data requires consistently high I/O performance.A solutions architect needs to minimize the time that is required to clone the production data into the test environment.Which solution will meet these requirements? Take EBS snapshots of the production EBS volumes. Restore the snapshots onto EC2 instance store volumes in the test environment. Configure the production EBS volumes to use the EBS Multi-Attach feature. Take EBS snapshots of the production EBS volumes. Attach the production EBS volumes to the EC2 instances in the test environment. Take EBS snapshots of the production EBS volumes. Create and initialize new EBS volumes. Attach the new EBS volumes to EC2 instances in the test environment before restoring the volumes from the production EBS snapshots. ✅ Take EBS snapshots of the production EBS volumes. Turn on the EBS fast snapshot restore feature on the EBS snapshots. Restore the snapshots into new EBS volumes. Attach the new EBS volumes to EC2 instances in the test environment. ✨ 关键词：clone large amounts of production data on EBS、minimize the time 4️⃣ ✅ 💡 解析：公司需要迁移大量受保护的数据到同区域的测试环境中，数据目前存放在 EBS 卷上，克隆数据不能对生产环境造成影响，而生产环境的应用要求高 IO 标签。还要求尽可能快地完成数据拷贝。无法之间拷贝，那就只能创建快照，再通过快照重建为 EBS 硬盘。由于还需要尽可能快，因此这里还有个考点：Amazon EBS fast snapshot restore（Amazon EBS 快速快照还原）Amazon EBS 快速快照还原 Amazon EBS 快速快照还原（FSR）使您能够从创建时已完全初始化的快照创建卷。这会消除首次访问块时对其执行 I/O 操作的延迟。使用快速快照还原创建的卷可以立即交付其所有预置性能。 👨‍👨‍👦‍👦 社区讨论：https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-fast-snapshot-restore.htmlAmazon EBS fast snapshot restore (FSR) enables you to create a volume from a snapshot that is fully initialized at creation.This eliminates the latency of I/O operations on a block when it isaccessed for the first time. Volumes that are created using fast snapshot restore instantly deliver all of their provisioned performance.","link":"/2024/11/18/saa_test_daily_20241118/"},{"title":"SAA 考试每日练习 - 2024&#x2F;11&#x2F;20","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam5 题 (No.31 ~ No.40)，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： near-real-time近实时的 financialadj. 财政的，财务的，金融的，有钱的 transactionn. 交易，生意；处理，办理 sensitiveadj. 敏感的；灵敏的；脆弱的；易受伤害的；感光的；敏锐的；神经质的；容易生气的；善解人意的，体恤的 retrievaln. 取回，索回，数据检索 large-scale大规模 一、AWS ConfigA company that hosts its web application on AWS wants to ensure all Amazon EC2 instances. Amazon RDS DB instances. and Amazon Redshift clusters are configured with tags. The company wants to minimize the effort of configuring and operating this check.What should a solutions architect do to accomplish this? ✅ Use AWS Config rules to define and detect resources that are not properly tagged. Use Cost Explorer to display resources that are not properly tagged. Tag those resources manually. Write API calls to check all resources for proper tag allocation. Periodically run the code on an EC2 instance. Write API calls to check all resources for proper tag allocation. Schedule an AWS Lambda function through Amazon CloudWatch to periodically run the code. ✨ 关键词：AWS configuring 1️⃣ ✅ 💡 解析：一般情况下看见 AWS configuring 资源配置相关的，都是选 AWS Config。什么是 AWS Config？ AWS Config 提供了您 AWS 账户中 AWS 资源配置的详细视图。这些信息包括资源之间的关联方式以及资源以前的配置方式，让您了解资源的配置和关系如何随着的时间的推移而更改。 👨‍👨‍👦‍👦 社区讨论：Answer from ChatGPT: Yes, you can use AWS Config to create tags for your resources. AWS Config isa service that enables you to assess,audit,and evaluate the configurations of your AWS resources. You can use AWS Config to create rules that automatically tag resources when theyare created or when their configurations change. To create tags for your resources using AWS Config, you will need to create an AWS Config rule that specifies the tag keyand value you want to use and the resources you want to apply the tag to. You can then enable the rule and AWS Config will automaticallyapply the tag to the specified resources when theyare created or when their configurations change. 二、Static WebsiteA development team needs to host a website that will be accessed by other teams. The website contents consist of HTML, CSS, client-side JavaScript, and images.Which method is the MOST cost-effective for hosting the website? Containerize the website and host it in AWS Fargate. ✅ Create an Amazon S3 bucket and host the website there. Deploy a web server on an Amazon EC2 instance to host the website. Configure an Application Load Balancer with an AWS Lambda target that uses the Express.js framework. ✨ 关键词：静态网站托管、cost-effective 2️⃣ ✅ 💡 解析：纯静态网站托管使用 S3 即可。 👨‍👨‍👦‍👦 社区讨论：client-side JavaScript. the website is static, so it must be S3. 三、Amazon Kinesis Data StreamsA company runs an online marketplace web application on AWS. The application serves hundreds of thousands of users during peak hours. The company needs a scalable, near-real-time近实时的 solution to share the details of millions of financial财务的 transactions交易，生意 with several other internal applications. Transactions also need to be processed to remove sensitive敏感的 data before being stored in a document database for low-latency retrieval检索.What should a solutions architect recommend to meet these requirements? Store the transactions data into Amazon DynamoDB. Set up a rule in DynamoDB to remove sensitive data from every transaction upon write. Use DynamoDB Streams to share the transactions data with other applications. ❌ Stream the transactions data into Amazon Kinesis Data Firehose to store data in Amazon DynamoDB and Amazon S3. Use AWS Lambda integration with Kinesis Data Firehose to remove sensitive data. Other applications can consume the data stored in Amazon S3. ✅ Stream the transactions data into Amazon Kinesis Data Streams. Use AWS Lambda integration to remove sensitive data from every transaction and then store the transactions data in Amazon DynamoDB. Other applications can consume the transactions data off the Kinesis data stream. Store the batched transactions data in Amazon S3 as files. Use AWS Lambda to process every file and remove sensitive data before updating the files in Amazon S3. The Lambda function then stores the data in Amazon DynamoDB. Other applications can consume transaction files stored in Amazon S3. ✨ 关键词：remove sensitive data 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：题目场景是公司每小时服务数十万用户，需要分享财务数据给内部的多个应用。系统需要是弹性的、近实时的，同时需要对财务数据去除敏感信息，还需要将其存储文档数据库以支持低延迟检索。毫无疑问需要使用 Amazon Kinesis Data 相关服务，重点是 Amazon Kinesis Data Firehose 还是 Amazon Kinesis Data Streams。社区存在一些争议，不过偏向 3️⃣ Amazon Kinesis Data Streams 的更多占 87%。 来看下这两个服务的区别： Amazon Kinesis Data Streams：更偏向于（纯粹的）可以存储数据的数据管道，对管道内数据的提取、处理高度自定义。数据处理后可以存入 DynamoDB 等另外的服务中。 Amazon Kinesis Data Firehose：更偏向于对数据处理的工作流：数据一旦进入流，就会经由可能的 Lambda 函数等处理层，然后迅速的传入 S3 等存储层。 因此针对题目场景，两个服务都行，不过问题是 Amazon Kinesis Data Firehose 不支持将数据存入 DynamoDB，这是个明显错误。什么是 Amazon Data Firehose？了解 Amazon Data Firehose 中的数据传输截至 2024 年 11 月只支持 6 种存储： Amazon S3 Amazon Redshift（数据仓库） OpenSearch Service Splunk（Splunk 是一个运营智能工具，用于实时分析机器生成的数据） HTTP 端点 Snowflake 👨‍👨‍👦‍👦 社区讨论：I would go for C.The tricky phrase is “near-real-time solution”, pointing to Firehouse, but it can’t send data to DynamoDB, so it leaves us with C as best option.Kinesis Data Firehose currently supports Amazon S3, Amazon Redshift, Amazon OpenSearch Service,Splunk, Datadog, NewRelic, Dynatrace,Sumologic, LogicMonitor, MongoDB,and HTTP End Point as destinations. 四、AWS Config &amp; AWS CloudTrailA company hosts its multi-tier applications on AWS. For compliance, governance, auditing, and security, the company must track configuration changes on its AWS resources and record a history of API calls made to these resources.What should a solutions architect do to meet these requirements? Use AWS CloudTrail to track configuration changes and AWS Config to record API calls. ✅ Use AWS Config to track configuration changes and AWS CloudTrail to record API calls. Use AWS Config to track configuration changes and Amazon CloudWatch to record API calls. Use AWS CloudTrail to track configuration changes and Amazon CloudWatch to record API calls. ✨ 关键词：configuration、record a history of API calls 2️⃣ ✅ 💡 解析：涉及到记录 AWS 资源的 API 操作历史，需要使用 CloudTrail。 CloudTrail 通过跟踪用户活动和 API 使用，支持审计、安全监控和操作故障排除。CloudTrail 记录、持续监控和保留与您的 AWS 基础设施中操作相关的账户活动，让您能够控制存储、分析和修复操作。 CloudWatch 是监控 AWS 资源和应用程序状态的，不选。 👨‍👨‍👦‍👦 社区讨论：CloudTrail - Track user activityand API call history.Config - Assess,audits,and evaluates the configuration and relationships of tag resources. 五、DDoS attacksA company is preparing to launch a public-facing web application in the AWS Cloud. The architecture consists of Amazon EC2 instances within a VPC behind an Elastic Load Balancer (ELB). A third-party service is used for the DNS. The company’s solutions architect must recommend a solution to detect and protect against large-scale大规模 DDoS attacks.Which solution meets these requirements? Enable Amazon GuardDuty on the account. Enable Amazon Inspector on the EC2 instances. Enable AWS Shield and assign Amazon Route 53 to it. ✅ Enable AWS Shield Advanced and assign the ELB to it. ✨ 关键词：detect and protect against large-scale DDoS attacks、third-party DNS 4️⃣ ✅ 💡 解析：AWS Shield Standard 也提供了基础的 DDoS 防御能力，应该也能使用。不过之后看社区讨论指出了 Amazon Route 53 并非第三方 DNS 服务，是明显错误，可以排除 3️⃣，选 4️⃣。 👨‍👨‍👦‍👦 社区讨论：C is incorrect because question saysThird party DNS and route 53 is AWS proprietary","link":"/2024/11/20/saa_test_daily_20241120/"},{"title":"SAA 考试每日练习 - 2024&#x2F;11&#x2F;19","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam10 题 (No.21 ~ No.30)，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： on-premises就地部署，本地部署 directoryn. 目录，名录；指南；电话号码簿 one-deal-a-day当日折扣 operationaladj. 操作上的，运作中的 infinitelyadv. 非常，极其；无限地，无穷地 scalableadj. 可扩展的 resilientadj. 可迅速恢复的，有适应力的，有弹性（或弹力）的，能复原的 unpredictableadj. 无法预言的，不可预测的，难以预料的，（人）善变的 frequentlyadv. 频繁地, 时常, 不断地 indefinitelyadv. 无限期地 verticaladj. 垂直的，纵向的 in-depth深入细致地, 深入详尽的 identifyv. 确认；认出；鉴定；察觉，发现；显示；说明身份 causen. 原因，事业，病因，理由 | v. 导致，使，引起，产生 proof-of-concept概念验证 quotasn. 配额，定额，指标，限额 significantlyadv. 极大地, 显著地, 大幅度地, 意味深长地; 值得注意的是（用于表示某事非常重要） metrics指标 periodicallyadv. 定期, 周期性, 定期出版地 single sign-on (SSO)单点登录 单点登录（SSO）是一种身份验证解决方案，可让用户通过一次性用户身份验证登录多个应用程序和网站。鉴于当今的用户经常直接从其浏览器访问应用程序，因此组织正在优先考虑改善安全性和用户体验的访问管理策略。SSO 兼具这两方面的优点，因为一旦验证身份，用户就可以访问所有受密码保护的资源，而无需重复登录。 automatedadj. 自动化的 failover故障转移 resource-intensive资源密集型 low-capacity低容量的 一、One-deal-a-day WebsiteAn ecommerce company wants to launch a one-deal-a-day website on AWS. Each day will feature exactly one product on sale for a period of 24 hours. The company wants to be able to handle millions of requests each hour with millisecond latency during peak hours.Which solution will meet these requirements with the LEAST operational overhead? Use Amazon S3 to host the full website in different S3 buckets. Add Amazon CloudFront distributions. Set the S3 buckets as origins for the distributions. Store the order data in Amazon S3. Deploy the full website on Amazon EC2 instances that run in Auto Scaling groups across multiple Availability Zones. Add an Application Load Balancer (ALB) to distribute the website traffic. Add another ALB for the backend APIs. Store the data in Amazon RDS for MySQL. Migrate the full application to run in containers. Host the containers on Amazon Elastic Kubernetes Service (Amazon EKS). Use the Kubernetes Cluster Autoscaler to increase and decrease the number of pods to process bursts in traffic. Store the data in Amazon RDS for MySQL. ✅ Use an Amazon S3 bucket to host the website’s static content. Deploy an Amazon CloudFront distribution. Set the S3 bucket as the origin. Use Amazon API Gateway and AWS Lambda functions for the backend APIs. Store the data in Amazon DynamoDB. ✨ 关键词：LEAST operational overhead 4️⃣ ✅ 💡 解析：题目背景是每天销售一款商品的网站（每日更新），同时能接受住百万级别的访问量并要求低延迟，并且用最简单的架构。首选 S3 + CloudFront 以应对这种大访问量的简单页面需求。1️⃣ 错在不需要存储在多个桶中；2️⃣ 和 3️⃣ 过于复杂。 👨‍👨‍👦‍👦 社区讨论：D because all of the componentsare infinitely scalabledynamoDB, API Gateway, Lambda,and of course s3+cloudfront 二、S3 Intelligent-TieringA solutions architect is using Amazon S3 to design the storage architecture of a new digital media application. The media files must be resilient可迅速恢复的 to the loss of an Availability Zone. Some files are accessed frequently频繁地 while other files are rarely accessed in an unpredictable不可预测的 pattern. The solutions architect must minimize the costs of storing and retrieving the media files.Which storage option meets these requirements? S3 Standard ✅ S3 Intelligent-Tiering S3 Standard-Infrequent Access (S3 Standard-IA) S3 One Zone-Infrequent Access (S3 One Zone-IA) ✨ 关键词：be resilient to the loss of an Availability Zone、Some files are accessed frequently while other files are rarely accessed in an unpredictable pattern 2️⃣ ✅ 💡 解析：需要可恢复，同时有的文件需要频繁访问有的则不可预测。因此 S3 Intelligent-Tiering 这种可以监测对象的访问模式并自动转移文件到不同访问类型的更加合适。 👨‍👨‍👦‍👦 社区讨论：Amazon S3 Intelligent Tiering isa storage class that automatically moves data to the most cost-effective storage tier based on access patterns. It can store objects in two access tiers: the frequent access tier and the infrequent access tier.The frequent access tier is optimized for frequentlyaccessed objectsand is charged at the same rate asS3 Standard.The infrequent access tier is optimized for objects that are not accessed frequentlyand are charged at a lower rate than S3 Standard. 三、S3 Lifecycle configurationA company is storing backup files by using Amazon S3 Standard storage. The files are accessed frequently频繁地 for 1 month. However, the files are not accessed after 1 month. The company must keep the files indefinitely无限期地.Which storage solution will meet these requirements MOST cost-effectively? Configure S3 Intelligent-Tiering to automatically migrate objects ✅ Create an S3 Lifecycle configuration to transition objects from S3 Standard to S3 Glacier Deep Archive after 1 month. Create an S3 Lifecycle configuration to transition objects from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) after 1 month. Create an S3 Lifecycle configuration to transition objects from S3 Standard to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 1 month. ✨ 关键词：accessed frequently for 1 month、not accessed after 1 month 2️⃣ ✅ 💡 解析：文件第一个月频繁访问，而之后需要无限期存储，使用最便宜的方案。使用 S3 Lifecycle 指定策略将文件从 S3 标准 迁移到 S3 Glacier Deep Archive 深度归档是最佳方案。 👨‍👨‍👦‍👦 社区讨论：The storage solution that will meet these requirements most cost-effectively is B: Create an S3 Lifecycle configuration to transition objects from S3 Standard to S3 Glacier Deep Archive after 1 month. Amazon S3 Glacier Deep Archive isa secure, durable,and extremely low-cost Amazon S3 storage class for long-term retention of data that is rarelyaccessed and for which retrieval times of several hoursare acceptable. It is the lowest-cost storage option in Amazon S3, making it a cost-effective choice for storing backup files that are not accessed after 1 month. You can use an S3 Lifecycle configuration to automatically transition objects from S3 Standard to S3 Glacier Deep Archive after 1 month.This will minimize the storage costs for the backup files that are not accessed frequently. 四、AWS Cost ExplorerA company observes an increase in Amazon EC2 costs in its most recent bill. The billing team notices unwanted vertical垂直地 scaling of instance types for a couple of EC2 instances. A solutions architect needs to create a graph comparing the last 2 months of EC2 costs and perform an in-depth细致的 analysis to identify确认 the root cause原因 of the vertical scaling.How should the solutions architect generate the information with the LEAST operational overhead? Use AWS Budgets to create a budget report and compare EC2 costs based on instance types. ✅ Use Cost Explorer’s granular filtering feature to perform an in-depth analysis of EC2 costs based on instance types. Use graphs from the AWS Billing and Cost Management dashboard to compare EC2 costs based on instance types for the last 2 months. Use AWS Cost and Usage Reports to create a report and send it to an Amazon S3 bucket. Use Amazon QuickSight with Amazon S3 as a source to generate an interactive graph based on instance types. ✨ 关键词：perform an in-depth analysis to identify the root cause of the vertical scaling 2️⃣ ✅ 💡 解析：AWS Cost Explorer 可让您直观看到、理解和管理随着时间变化的 AWS 成本和使用情况。通过创建分析成本和使用情况数据的自定义报告，快速入门。高水平分析数据（例如，所有账户的总成本和使用情况），或者更深入地研究成本和使用情况数据，从而发现趋势，查明成本动因素并检测异常情况。 Cost Explorer 通过以下三个功能提供每小时和资源级粒度： 每日粒度的资源级数据 每小时粒度下所有 AWS 服务的成本和使用情况数据（不包括资源级数据） EC2-每小时粒度的实例（弹性计算云）资源级数据精细数据 👨‍👨‍👦‍👦 社区讨论：https://www.examtopics.com/discussions/amazon/view/68306-exam-aws-certified-solutions-architect-associate-saa-c02/ 还有选 3️⃣ 的，理由是图表只在 14 天内可用？The requested result is a graph, so…A - can’t be as the result isa reportB - can’t be as it is limited to 14 days visibility and the graph has to cover 2 monthsC - seems to provide graphsand the best option available,as…D - could provide graphs, BUT involves operational overhead, which has been requested to be minimised. 然而官方很明确表示了会准备过去 12 个月的成本数据进行分析： 您可以在账单与成本管理控制台中利用此程序为您的账户启用 AWS Cost Explorer 成本管理服务。您无法通过 API 启用 AWS Cost Explorer 成本管理服务。在启用 AWS Cost Explorer 成本管理服务以后，AWS 会准备当月和最近 12 个月的成本数据，然后计算未来 12 个月的预测。当月数据在大约 24 个小时内可供查看。其他数据可能需要数天时间。AWS Cost Explorer 成本管理服务至少会每隔 24 小时对您的成本数据进行一次更新。 五、Amazon SQSA company is designing an application. The application uses an AWS Lambda function to receive information through Amazon API Gateway and to store the information in an Amazon Aurora PostgreSQL database.During the proof-of-concept概念验证 stage, the company has to increase the Lambda quotas定额，配额 significantly极大地 to handle the high volumes of data that the company needs to load into the database. A solutions architect must recommend a new design to improve scalability and minimize the configuration effort.Which solution will meet these requirements? Refactor the Lambda function code to Apache Tomcat code that runs on Amazon EC2 instances. Connect the database by using native Java Database Connectivity (JDBC) drivers. Change the platform from Aurora to Amazon DynamoDProvision a DynamoDB Accelerator (DAX) cluster. Use the DAX client SDK to point the existing DynamoDB API calls at the DAX cluster. Set up two Lambda functions. Configure one function to receive the information. Configure the other function to load the information into the database. Integrate the Lambda functions by using Amazon Simple Notification Service (Amazon SNS). ✅ Set up two Lambda functions. Configure one function to receive the information. Configure the other function to load the information into the database. Integrate the Lambda functions by using an Amazon Simple Queue Service (Amazon SQS) queue. ✨ 关键词：minimize the configuration effort 4️⃣ ✅ 💡 解析：使用 SNS 会引发同样的瓶颈，瓶颈不过是从单一 Lambda 函数转移到了接收 SNS 消息的 Lambda 函数。 👨‍👨‍👦‍👦 社区讨论：A - refactoring can be a solution, BUT requiresa LOT of effort - not the answerB - DynamoDB is NoSQL and Aurora isSQL, so it requiresa DB migration…again a LOT of effort, so no the answerC and D are similar in structure, but…C usesSNS, which would notify the 2nd Lambda function… provoking the same bottleneck… not the solutionD usesSQS, so the 2nd lambda function can go to the queue when responsive to keep with the DB load process.Usually the app decoupling helps with the performance improvement by distributing load. In this case, the bottleneckis solved by uses queues… so D is the answer. 六、AWS ConfigA company needs to review its AWS Cloud deployment to ensure that its Amazon S3 buckets do not have unauthorized configuration changes.What should a solutions architect do to accomplish this goal? ✅ Turn on AWS Config with the appropriate rules. Turn on AWS Trusted Advisor with the appropriate checks. Turn on Amazon Inspector with the appropriate assessment template. ❌ Turn on Amazon S3 server access logging. Configure Amazon EventBridge (Amazon Cloud Watch Events). ✨ 关键词：ensure Amazon S3 buckets do not have unauthorized configuration changes 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：AWS Config 提供了您 AWS 账户中 AWS 资源配置的详细视图。这些信息包括资源之间的关联方式以及资源以前的配置方式，让您了解资源的配置和关系如何随着的时间的推移而更改。解题的思路可以直白地：Configuration changes = AWS Config 👨‍👨‍👦‍👦 社区讨论：AWS Trusted Advisor (Option B) isa service that provides best practice recommendations for your AWS resources, but it does not monitor or record changes to the configuration of yourS3 buckets. AWS Trusted Advisor 是一项 Web 服务，可以检查您的 AWS 环境并根据 AWS 最佳实践提供实时建议。Trusted Advisor 可以检查成本优化、性能、安全性、容错能力和服务限制五个类别，并将检查结果与 AWS 最佳实践进行比较。 Amazon Inspector (Option C) isa service that helps you assess the security and compliance of your applications. While it can be used to assess the security of yourS3 buckets, it does not monitor or record changes to the configuration of yourS3 buckets. Amazon Inspector 是一项漏洞管理服务，可自动发现工作负载并持续扫描工作负载以查找软件漏洞和意外网络泄露。 Amazon S3 server access logging (Option D) enables you to log requests made to your S3 bucket. While it can help youidentify changes to yourS3 bucket, it does not monitor or record changes to the configuration of yourS3 bucket. 七、CloudWatch dashboard’s shareA company is launching a new application and will display application metric指标s on an Amazon CloudWatch dashboard. The company’s product manager needs to access this dashboard periodically定期地. The product manager does not have an AWS account. A solutions architect must provide access to the product manager by following the principle of least privilege.Which solution will meet these requirements? ✅ Share the dashboard from the CloudWatch console. Enter the product manager’s email address, and complete the sharing steps. Provide a shareable link for the dashboard to the product manager. Create an IAM user specifically for the product manager. Attach the CloudWatchReadOnlyAccess AWS managed policy to the user. Share the new login credentials with the product manager. Share the browser URL of the correct dashboard with the product manager. Create an IAM user for the company’s employees. Attach the ViewOnlyAccess AWS managed policy to the IAM user. Share the new login credentials with the product manager. Ask the product manager to navigate to the CloudWatch console and locate the dashboard by name in the Dashboards section. Deploy a bastion server in a public subnet. When the product manager requires access to the dashboard, start the server and share the RDP credentials. On the bastion server, ensure that the browser is configured to open the dashboard URL with cached AWS credentials that have appropriate permissions to view the dashboard. ✨ 关键词：access application metric、CloudWatch、PoLP 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：Share a single dashboard and designate specific email addresses of the people who can view the dashboard.Each of these users creates their own password that they must enter to view the dashboard. CloudWatch dashboards 的分享可以不需要 AWS 账户，具体的三种分享方式： （邮箱加密码）Share a single dashboard and designate as many as five email addresses of people who can view the dashboard. Each of these users creates their own password that they must enter to view the dashboard. （公开）Share a single dashboard publicly, so that anyone who has the link can view the dashboard. （使用三方认证等方式）Share all the CloudWatch dashboards in your account and specify a third-party single sign-on (SSO) provider for dashboard access. All users who are members of this SSO provider’s list can access all the dashboards in the account. To enable this, you integrate the SSO provider with Amazon Cognito. The SSO provider must support Security Assertion Markup Language (SAML). For more information about Amazon Cognito, see What is Amazon Cognito? 👨‍👨‍👦‍👦 社区讨论：Answere Ahttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch-dashboard-sharing.htmlShare a single dashboard and designate specific email addresses of the people who can view the dashboard.Each of these users creates their own password that they must enter to view the dashboard. 八、On-premises self-managed Microsoft Active DirectoryA company is migrating applications to AWS. The applications are deployed in different accounts. The company manages the accounts centrally by using AWS Organizations. The company’s security team needs a single sign-on (SSO) solution across all the company’s accounts. The company must continue managing the users and groups in its on-premises self-managed Microsoft Active Directory.Which solution will meet these requirements? Enable AWS Single Sign-On (AWS SSO) from the AWS SSO console. Create a one-way forest trust or a one-way domain trust to connect the company’s self-managed Microsoft Active Directory with AWS SSO by using AWS Directory Service for Microsoft Active Directory. ✅ Enable AWS Single Sign-On (AWS SSO) from the AWS SSO console. Create a two-way forest trust to connect the company’s self-managed Microsoft Active Directory with AWS SSO by using AWS Directory Service for Microsoft Active Directory. Use AWS Directory Service. Create a two-way trust relationship with the company’s self-managed Microsoft Active Directory. Deploy an identity provider (IdP) on premises. Enable AWS Single Sign-On (AWS SSO) from the AWS SSO console. ✨ 关键词：SSO、on-premises self-managed Microsoft Active Directory 2️⃣ ✅ 💡 解析：题目背景是公司以及通过 AWS Organizations 进行了治理，希望增加一个 SSO 认证，并继续在自维护的 Microsoft AD 上管理用户和组等。很显然需要开启 SSO 功能因此在 1️⃣ 和 2️⃣ 里选。这里肯定要使用 AWS Directory Service 服务并至少建立单项信任管理（云信任本地托管），或者之间使用 AD Connector 将云端的作为代理。都没有的话聚焦于 one-way（单向）还是 two-way（双向）认证，虽然我觉得单项也可以，但是 AWS 的文档里明确了需要双向认证：Creating a trust relationship between your AWS Managed Microsoft AD and self-managed AD Amazon Chime、Amazon Connect、亚马逊、亚马逊、亚马逊 QuickSight、亚马 AWS IAM Identity Center逊 WorkSpaces、 WorkDocs WorkMail亚马逊等 AWS 企业应用程序需要双向信任。 AWS Management Console AWS 托管 Microsoft AD 必须能够查询你自行管理的用户和群组 Active Directory. 只能选 2️⃣ 了。 👨‍👨‍👦‍👦 社区讨论：Tricky question!!! forget one-way or two-way. In this scenario, AWS applications (Amazon Chime, Amazon Connect, Amazon QuickSight, AWS Single Sign-On, Amazon WorkDocs, Amazon WorkMail, Amazon WorkSpaces, AWS Client VPN, AWS Management Console, and AWS Transfer Family) need to be able to look up objects from the on-premises domain in order for them to function.This tells you that authentication needs to flow both ways.This scenario requiresa two-way trust between the on-premisesand AWS Managed Microsoft AD domains.It isa requirement of the applicationScenario 2: https://aws.amazon.com/es/blogs/security/everything-you-wanted-to-know-about-trusts-with-aws-managed-microsoft-ad/ 九、VoIP - Global AcceleratorA company provides a Voice over Internet Protocol (VoIP)基于IP的语音传输（英语：Voice over Internet Protocol，缩写为VoIP）是一种语音通话技术，经由网际协议（IP）来达成语音通话与多媒体会议，也就是经由互联网来进行通信。 service that uses UDP connections. The service consists of Amazon EC2 instances that run in an Auto Scaling group. The company has deployments across multiple AWS Regions.The company needs to route users to the Region with the lowest latency. The company also needs automated自动化的 failover故障转移 between Regions.Which solution will meet these requirements? ✅ Deploy a Network Load Balancer (NLB) and an associated target group. Associate the target group with the Auto Scaling group. Use the NLB as an AWS Global Accelerator endpoint in each Region. Deploy an Application Load Balancer (ALB) and an associated target group. Associate the target group with the Auto Scaling group. Use the ALB as an AWS Global Accelerator endpoint in each Region. ❌ Deploy a Network Load Balancer (NLB) and an associated target group. Associate the target group with the Auto Scaling group. Create an Amazon Route 53 latency record that points to aliases for each NLB. Create an Amazon CloudFront distribution that uses the latency record as an origin. Deploy an Application Load Balancer (ALB) and an associated target group. Associate the target group with the Auto Scaling group. Create an Amazon Route 53 weighted record that points to aliases for each ALB. Deploy an Amazon CloudFront distribution that uses the weighted record as an origin. ✨ 关键词：UDP connections、route users to the Region with the lowest latency 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：考点是 AWS Global Accelerator（全球应用程序加速）。AWS Global Accelerator 常见问题 AWS Global Accelerator 是一种联网服务，可以帮助您提高为全球用户提供的应用程序的可用性和性能。AWS Global Accelerator 可以轻松设置、配置和管理。它可以提供静态 IP 地址，从而为您的应用程序提供固定的入口点，并消除了为不同 AWS 区域和可用区管理特定 IP 地址的复杂性。AWS Global Accelerator 始终根据性能将用户流量路由到最佳终端节点，即时针对应用程序运行状况、用户位置和您配置的策略的变化做出反应。您可以从自己的位置使用速度比较工具测试性能优势。与其他 AWS 服务一样，AWS Global Accelerator 也是一种按用量付费的自助服务，无需长期承诺或最低费用。 👨‍👨‍👦‍👦 社区讨论：agree with A,Global Accelerator hasautomatic failover and is perfect for this scenario with VoIPhttps://aws.amazon.com/global-accelerator/faqs/ 十、SnapshotA development team runs monthly resource-intensive资源密集型 tests on its general purpose Amazon RDS for MySQL DB instance with Performance Insights enabled. The testing lasts for 48 hours once a month and is the only process that uses the database. The team wants to reduce the cost of running the tests without reducing the compute and memory attributes of the DB instance.Which solution meets these requirements MOST cost-effectively? Stop the DB instance when tests are completed. Restart the DB instance when required. ❌ Use an Auto Scaling policy with the DB instance to automatically scale when tests are completed. ✅ Create a snapshot when tests are completed. Terminate the DB instance and restore the snapshot when required. Modify the DB instance to a low-capacity低容量的 instance when tests are completed. Modify the DB instance again when required. ✨ 关键词：reduce the cost of running the tests without reducing the compute and memory attributes of the DB instance 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：题目的需求只是每月在 AWS 进行一次数据库测试，用完即删，选择一个最便宜的方式。由于实例等在停止后也依然收费，因此最便宜的方式是存储快照并在需要时重建。 Answer C, you still pay for storage when an RDS database is stopped Not A - By stopping the DB although you are not paying for DB hours you are still paying for Provisioned IOPs , the storage for Stopped DB is more than Snapshot of underlying EBS vol.and Automated Back ups.Not D - Is possible but not MOST cost effective, no need to run the RDS when not needed","link":"/2024/11/19/saa_test_daily_20241119/"},{"title":"SAA 考试每日练习 - 2024&#x2F;11&#x2F;21","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam5 题 (No.36 ~ No.40)，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： strategyn. 策略，战略，策划，战略部署 repeatableadj. 可重复, 有礼貌, 不冒犯人 burstable不稳定的，爆发的 archiven. 档案，档案馆，档案室 | v. 把…存档，把…归档，将（不常用信息）存档 deliveryn. 递送；交付；分娩 ingestv. 食入, 摄入, 咽下 operationallyadv. 操作上 efficientadj. 效率高的，高效的 一、KMS over RegionsA company is building an application in the AWS Cloud. The application will store data in Amazon S3 buckets in two AWS Regions. The company must use an AWS Key Management Service (AWS KMS) customer managed key to encrypt all data that is stored in the S3 buckets. The data in both S3 buckets must be encrypted and decrypted with the same KMS key. The data and the key must be stored in each of the two Regions.Which solution will meet these requirements with the LEAST operational overhead? Create an S3 bucket in each Region. Configure the S3 buckets to use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Configure replication between the S3 buckets. ✅ Create a customer managed multi-Region KMS key. Create an S3 bucket in each Region. Configure replication between the S3 buckets. Configure the application to use the KMS key with client-side encryption. Create a customer managed KMS key and an S3 bucket in each Region. Configure the S3 buckets to use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Configure replication between the S3 buckets. ❌ Create a customer managed KMS key and an S3 bucket in each Region. Configure the S3 buckets to use server-side encryption with AWS KMS keys (SSE-KMS). Configure replication between the S3 buckets. ✨ 关键词：S3、two AWS Regions、KMS（不支持跨区域） 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：这题在 2️⃣ 和 4️⃣ 之间存在争议，不过官方文档中建议了在跨区域使用同一密钥的情况下，使用客户端加密方式。Multi-Region keys in AWS KMS You can use multi-Region keys with client-side encryption libraries, such as the AWS Encryption SDK, the AWS Database Encryption SDK, and Amazon S3 client-side encryption. Client-side and server-side encryption Server-side encryption：你的数据 AWS 帮你加密后再写入磁盘 Client-side encryption：端到端加密，你来加密数据后再发往 AWS 进行保存等处理 二、Session ManagerA company recently launched a variety of new workloads on Amazon EC2 instances in its AWS account. The company needs to create a strategy策略 to access and administer the instances remotely and securely. The company needs to implement a repeatable可重复的 process that works with native AWS services and follows the AWS Well-Architected Framework.Which solution will meet these requirements with the LEAST operational overhead? Use the EC2 serial console to directly access the terminal interface of each instance for administration. ✅ Attach the appropriate IAM role to each existing instance and new instance. Use AWS Systems Manager Session Manager to establish a remote SSH session. ❌ Create an administrative SSH key pair. Load the public key into each EC2 instance. Deploy a bastion host in a public subnet to provide a tunnel for administration of each instance. Establish an AWS Site-to-Site VPN connection. Instruct administrators to use their local on-premises machines to connect directly to the instances by using SSH keys across the VPN tunnel. ✨ 关键词：repeatable process 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：Session Manager 是 AWS Systems Manager 的一项完全托管式功能。借助 Session Manager，您可以管理 Amazon Elastic Compute Cloud（Amazon EC2）实例、边缘设备、本地服务器和虚拟机（VM）。更多信息：AWS Systems Manager Session Manager这里考的其实就是 Session Manager 这项服务。 👨‍👨‍👦‍👦 社区讨论：Option A provides direct access to the terminal interface of each instance, but it may not be practical for administration purposesand can be cumbersome to manage,especially for multiple instances. Option C adds operational overhead and introducesadditional infrastructure that needs to be managed, monitored,and secured. It also requiresSSH key management and maintenance. Option D is complex and may not be necessary for remote administration. It also requiresadministrators to connect from their local on-premises machines, which adds complexityand potential security risks. Therefore, option B is the recommended solution as it provides secure,auditable,and repeatable remote access using IAM rolesand AWS Systems ManagerSession Manager, with minimal operational overhead. 三、Static WebsiteA company is hosting a static website on Amazon S3 and is using Amazon Route 53 for DNS. The website is experiencing increased demand from around the world. The company must decrease latency for users who access the website.Which solution meets these requirements MOST cost-effectively? Replicate the S3 bucket that contains the website to all AWS Regions. Add Route 53 geolocation routing entries. Provision accelerators in AWS Global Accelerator. Associate the supplied IP addresses with the S3 bucket. Edit the Route 53 entries to point to the IP addresses of the accelerators. ✅ Add an Amazon CloudFront distribution in front of the S3 bucket. Edit the Route 53 entries to point to the CloudFront distribution. Enable S3 Transfer Acceleration on the bucket. Edit the Route 53 entries to point to the new endpoint. ✨ 关键词：decrease latency for users、around the world 3️⃣ ✅ 💡 解析：存储在 S3 中因此是静态网站，使用 CloudFront CDN 可以解决延迟问题。 👨‍👨‍👦‍👦 社区讨论：Option A (replicating the S3 bucket to all AWS Regions) can be costlyand complex, requiring replication of data across multiple Regionsand managing synchronization. It may not provide a significant latency improvement compared to the CloudFront solution. Option B (provisioning accelerators in AWS Global Accelerator) can be more expensive as it addsan extra layer of infrastructure (accelerators) and requiresassociating IP addresses with the S3 bucket. CloudFront already includes global edge locationsand provides similar acceleration capabilities. Option D (enabling S3 Transfer Acceleration) can help improve upload speed to the S3 bucket but may not have a significant impact on reducing latency for website visitors. Therefore, option C is the most cost-effective solution as it leverages CloudFront’s caching and global distribution capabilities to decrease latencyand improve website performance. 四、Slow insert on RDS for MySQLA company maintains a searchable repository of items on its website. The data is stored in an Amazon RDS for MySQL database table that contains more than 10 million rows. The database has 2 TB of General Purpose SSD storage. There are millions of updates against this data every day through the company’s website.The company has noticed that some insert operations are taking 10 seconds or longer. The company has determined that the database storage performance is the problem.Which solution addresses this performance issue? ✅ Change the storage type to Provisioned IOPS SSD. Change the DB instance to a memory optimized instance class. Change the DB instance to a burstable（可）爆发的 performance instance class. Enable Multi-AZ RDS read replicas with MySQL native asynchronous replication. ✨ 关键词：database storage performance is the problem 1️⃣ ✅ 💡 解析：IO 瓶颈提升硬盘性能。Amazon EBS 预调配 IOPS SSD 卷 (Provisioned IOPS SSD volumes) 👨‍👨‍👦‍👦 社区讨论：A: Made for high levels of I/O opps for consistent, predictable performance.B: Can improve performance of insert opps, but it’sa storage performance rather than processing power problemC: for moderate CPU usageD: for scale read-only replicasand doesn’t improve performance of insert opps on the primary DB instance 五、Kinesis Data &amp; Analysis &amp; GlacierA company has thousands of edge devices that collectively generate 1 TB of status alerts each day. Each alert is approximately 2 KB in size. A solutions architect needs to implement a solution to ingest and store the alerts for future analysis.The company wants a highly available solution. However, the company needs to minimize costs and does not want to manage additional infrastructure. Additionally, the company wants to keep 14 days of data available for immediate analysis and archive归档 any data older than 14 days.What is the MOST operationally操作上的 efficient效率高的 solution that meets these requirements? ✅ Create an Amazon Kinesis Data Firehose delivery递交 stream to ingest the咽下，处理 alerts. Configure the Kinesis Data Firehose stream to deliver the alerts to an Amazon S3 bucket. Set up an S3 Lifecycle configuration to transition data to Amazon S3 Glacier after 14 days. Launch Amazon EC2 instances across two Availability Zones and place them behind an Elastic Load Balancer to ingest the alerts. Create a script on the EC2 instances that will store the alerts in an Amazon S3 bucket. Set up an S3 Lifecycle configuration to transition data to Amazon S3 Glacier after 14 days. Create an Amazon Kinesis Data Firehose delivery stream to ingest the alerts. Configure the Kinesis Data Firehose stream to deliver the alerts to an Amazon OpenSearch Service (Amazon Elasticsearch Service) cluster. Set up the Amazon OpenSearch Service (Amazon Elasticsearch Service) cluster to take manual snapshots every day and delete data from the cluster that is older than 14 days. Create an Amazon Simple Queue Service (Amazon SQS) standard queue to ingest the alerts, and set the message retention period to 14 days. Configure consumers to poll the SQS queue, check the age of the message, and analyze the message data as needed. If the message is 14 days old, the consumer should copy the message to an Amazon S3 bucket and delete the message from the SQS queue. ✨ 关键词：keep 14 days of data available for immediate analysis、archive any data older than 14 days 1️⃣ ✅ 💡 解析：1️⃣ 的数据通过 Amazon Kinesis Data Firehose 存入 S3，并通过生命周期策略在 14 天后更换存储策略为归档。2️⃣ 启动了 EC2 和 ELB 来完成接受和存入数据这一步骤，过于繁琐。3️⃣ 启动了 Elasticsearch，但是选择删除 14 天后的数据。4️⃣ 启动 SQS 不符合分析需求。 👨‍👨‍👦‍👦 社区讨论：Definitely A, it’s the most operationally efficient compared to D, which requiresa lot of code and infrastructure to maintain. A is mostly managed (firehose is fully managed and S3 lifecyclesare also managed)","link":"/2024/11/21/saa_test_daily_20241121/"},{"title":"SAA 考试每日练习 - 2024&#x2F;11&#x2F;22","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam5 题 (No.41 ~ No.45)，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： concernedadj. 担心的，忧虑的；感兴趣的；关切的，关注的 | v. 涉及，牵涉；让……担忧（“concern”的过去式和过去分词） time-sensitive时间敏感的 long-term长期的 criticaladj. 批评的，批判的；紧要的，关键性的；严重的，危急的；审慎的，严谨的；评论性的；挑剔的；临界的 accidentaladj. 意外的，偶然的；不测的；非本质的；附带的 | n. 偶然，临时符，变音记号 occasionallyadv. 偶尔地 correspondingadj. 符合的，相应的，相关的 | v. “correspond”的现在分词 一、Data flows from SaaSA company’s application integrates with multiple software-as-a-service (SaaS) sources for data collection. The company runs Amazon EC2 instances to receive the data and to upload the data to an Amazon S3 bucket for analysis. The same EC2 instance that receives and uploads the data also sends a notification to the user when an upload is complete. The company has noticed slow application performance and wants to improve the performance as much as possible.Which solution will meet these requirements with the LEAST operational overhead? Create an Auto Scaling group so that EC2 instances can scale out. Configure an S3 event notification to send events to an Amazon Simple Notification Service (Amazon SNS) topic when the upload to the S3 bucket is complete. ✅ Create an Amazon AppFlow flow to transfer data between each SaaS source and the S3 bucket. Configure an S3 event notification to send events to an Amazon Simple Notification Service (Amazon SNS) topic when the upload to the S3 bucket is complete. Create an Amazon EventBridge (Amazon CloudWatch Events) rule for each SaaS source to send output data. Configure the S3 bucket as the rule’s target. Create a second EventBridge (Cloud Watch Events) rule to send events when the upload to the S3 bucket is complete. Configure an Amazon Simple Notification Service (Amazon SNS) topicas the second rule’s target. Create a Docker container to use instead of an EC2 instance. Host the containerized application on Amazon Elastic Container Service (Amazon ECS). Configure Amazon CloudWatch Container Insights to send events to an Amazon Simple Notification Service (Amazon SNS) topic when the upload to the S3 bucket is complete ✨ 关键词：LEAST operational overhead、 2️⃣ ✅ 💡 解析：应该程序接收数据并上传到 S3 存储桶，上传完成后发送通知给客户。现在遇到性能问题。希望使用最简单的架构。上传后的通知可以通过 S3 事件 + SNS 实现，数据的传输 AppFlow 就能实现。 Amazon AppFlow 软件即服务（SaaS）和 AWS 服务之间的自动化数据流 Amazon AppFlow 是一项完全托管的集成服务，让您只需单击几下即可在 Salesforce、Marketo、Slack 和 ServiceNow 之类的软件即服务 (SaaS) 应用程序与 Amazon S3 和 Amazon Redshift 之类的 AWS 服务之间安全地传输数据。使用 AppFlow，您可以根据计划几乎以任何规模按您选择的频率针对业务事件要求或按需运行数据流。您可以配置强大的数据转换功能，例如筛选和验证，以生成丰富、随时可用的数据作为流本身的一部分，无需执行额外步骤。AppFlow 会自动加密动态数据，使用户可以限制与 AWS PrivateLink 集成的 SaaS 应用程序的数据在公共互联网上流动，从而减少暴露于安全威胁之中的风险。 👨‍👨‍👦‍👦 社区讨论：It says “LEAST operational overhead” (ie do it in a way it’s the less workfor me).If you know a little Amazon AppFlow (see the some videos) you’ll see you’ll need time to configure and test it,and at the end cope with the errors during the extraction and load the info to the target.The customer in the example ALREADY has some EC2 that do the work, the only problem is the performance, that WILL be improved scaling out and adding a queue (SNS) to decouple the work of notify the user.The operational load of doing this is LESS that configuring AppFlow. 二、VPC Gateway endpointA company runs a highly available image-processing application on Amazon EC2 instances in a single VPC. The EC2 instances run inside several subnets across multiple Availability Zones. The EC2 instances do not communicate with each other.However, the EC2 instances download images from Amazon S3 and upload images to Amazon S3 through a single NAT gateway. The company is concerned担忧 about data transfer charges.What is the MOST cost-effective way for the company to avoid Regional data transfer charges? Launch the NAT gateway in each Availability Zone. Replace the NAT gateway with a NAT instance. ✅ Deploy a gateway VPC endpoint for Amazon S3. Provision an EC2 Dedicated Host to run the EC2 instances. ✨ 关键词：the MOST cost-effective way、NAT gateway、data transfer charges 3️⃣ ✅ 💡 解析：不同子网、不同可用区的 EC2 实例访问 S3 存在网络传输问题，之前是使用一个 NAT 网关，那么就相当于走公网了，需要改成走私网。毫无疑问选择 网关终端节点（只支持 S3 和 DynamoDB）。 👨‍👨‍👦‍👦 社区讨论：Deploying a gateway VPC endpoint for Amazon S3 is the most cost-effective way for the company to avoid Regional data transfer charges. A gateway VPC endpoint isa network gateway that allows communication between instances in a VPC and a service, such as Amazon S3, without requiring an Internet gateway or a NAT device. Data transfer between the VPC and the service through a gateway VPC endpoint is free of charge, while data transfer between the VPC and the Internet through an Internet gateway or NAT device is subject to data transfer charges. By using a gateway VPC endpoint, the company can reduce its data transfer costs byeliminating the need to transfer data through the NAT gateway to access Amazon S3.This option would provide the required connectivity to Amazon S3 and minimize data transfer charges. 三、Internet bandwidth limitationsA company has an on-premises application that generates a large amount of time-sensitive时间敏感的 data that is backed up to Amazon S3. The application has grown and there are user complaints about internet bandwidth limitations. A solutions architect needs to design a long-term长期的 solution that allows for both timely backups to Amazon S3 and with minimal impact on internet connectivity for internal users.Which solution meets these requirements? Establish AWS VPN connections and proxy all traffic through a VPC gateway endpoint. ✅ Establish a new AWS Direct Connect connection and direct backup traffic through this new connection. Order daily AWS Snowball devices. Load the data onto the Snowball devices and return the devices to AWS each day. Submit a support ticket through the AWS Management Console. Request the removal of S3 service limits from the account. ✨ 关键词：on-premises application、time-sensitive data、timely backups to Amazon S3、minimal impact on internet connectivity for internal users 2️⃣ ✅ 💡 解析：本地部署的应用程序定时存数据到 S3，同时公网用户抱怨网络传输速度。需要长期的解决方案。本地应用程序有公网传输速度瓶颈，又需要使用 S3，似乎需要本地部署基础设施。但是选项中没有，选 2️⃣ 是唯一可以解决公网传输速度瓶颈问题的。 👨‍👨‍👦‍👦 社区讨论：A: VPN also goes through the internet and uses the bandwidthC: dailySnowball transfer is not reallya long-term solution when it comes to cost and efficiencyD: S3 limits don’t change anything here 四、Protect critical data from accidental deletionA company has an Amazon S3 bucket that contains critical关键的 data. The company must protect the data from accidental意外的 deletion.Which combination of steps should a solutions architect take to meet these requirements? (Choose two.) ✅ Enable versioning on the S3 bucket. ✅ Enable MFA Delete on the S3 bucket. ❌ Create a bucket policy on the S3 bucket. Enable default encryption on the S3 bucket. Create a lifecycle policy for the objects in the S3 bucket. ✨ 关键词：critical data、protect from accidental deletion 2️⃣ 3️⃣ ❌ -&gt; 1️⃣ 2️⃣ ✅ 💡 解析：需要对 S3 存储桶进行操作来防止用户误删关键数据。1️⃣ 开启版本支持，可以做到误删后还原。2️⃣ 开启删除时的二步验证。3️⃣ 开启存储桶策略，可以做到保护，但是无法做到授权可访问用户的意外删除。4️⃣ 开启默认加密，无法阻止删除操作。5️⃣ 开启生命周期策略，做文件转移，无法保护其不被删除。 题目似乎聚焦于 architect 误删 这个动作，更多强调的是有权删除的用户不小心删除重要文件。需要做的是保证误删后的立即恢复以及二步验证做确认。 除了 1️⃣ 版本控制 2️⃣ 二步验证以外，官方还推荐进行 Cross-Region Replication 跨区域复制保留副本来应对误删行为。 👨‍👨‍👦‍👦 社区讨论：The correct solution is AB,as you can see here:https://aws.amazon.com/it/premiumsupport/knowledge-center/s3-audit-deleted-missing-objects/ It states the following: To prevent or mitigate future accidental deletions, consider the following features:Enable versioning to keep historical versions of an object.Enable Cross-Region Replication of objects.Enable MFA delete to require multi-factor authentication (MFA) when deleting an object version. 五、Data ingestion with queueA company has a data ingestion workflow that consists of the following: An Amazon Simple Notification Service (Amazon SNS) topic for notifications about new data deliveries An AWS Lambda function to process the data and record metadata The company observes that the ingestion workflow fails occasionally偶尔地 because of network connectivity issues. When such a failure occurs, the Lambda function does not ingest the corresponding相应的 data unless the company manually reruns the job.Which combination of actions should a solutions architect take to ensure that the Lambda function ingests all data in the future? (Choose two.) Deploy the Lambda function in multiple Availability Zones. ✅ Create an Amazon Simple Queue Service (Amazon SQS) queue, and subscribe it to the SNS topic. Increase the CPU and memory that are allocated to the Lambda function. Increase provisioned throughput for the Lambda function. ✅ Modify the Lambda function to read from an Amazon Simple Queue Service (Amazon SQS) queue. ✨ 关键词：the Lambda function does not ingest the corresponding data、SNS 2️⃣ 5️⃣ ✅ 💡 解析：数据处理工作流程：SNS 发送新数据达到的通知，Lambda 处理数据并记录元数据。由于网络原因偶发 Lambda 函数不接受新数据的问题，只能通过公司手动重启工作才能恢复。做什么才能确保 Lambda 处理所有数据。SQS FIFO 队列可以确保数据不丢失和先进先出。没有 FIFO 的话也没有关系，2️⃣ 4️⃣ 就能解决问题。SNS + SQS 是 Fan Out 架构，同时让 Lambda 函数监听 SQS 队列，处理一条消费一条保证不丢失。 👨‍👨‍👦‍👦 社区讨论：A, C, D optionsare out, since Lambda is fully managed service which provides high availabilityand scalability by its ownAnswersare B and E","link":"/2024/11/22/saa_test_daily_20241122/"},{"title":"SAA 考试每日练习 - 2024&#x2F;11&#x2F;23","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam5 题 (No.46 ~ No.50)，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： remediationn. 补救, 纠正, （尤指对环境破坏的）整改 guaranteev. 确保；保证；担保 | n. 保证；担保（书）；保修单 capacityn. 容量，容积；能力；生产力；地位；职位，职责 | adj. （达到最大容量）满的 catalogn. 目录册，产品样本，学校便览，一览表 | v. （为…）编目录，（把…）按目录分类 durableadj. 耐用的，耐久的，长期的，长久的 | n. 耐久品 infrequentlyadv. 不经常地 一、Personally Identifiable InformationA company has an application that provides marketing services to stores. The services are based on previous purchases by store customers. The stores upload transaction data to the company through SFTP, and the data is processed and analyzed to generate new marketing offers. Some of the files can exceed 200 GB in size.Recently, the company discovered that some of the stores have uploaded files that contain personally identifiable information (PII) that should not have been included. The company wants administrators to be alerted if PII is shared again. The company also wants to automate remediation.What should a solutions architect do to meet these requirements with the LEAST development effort? Use an Amazon S3 bucket as a secure transfer point. Use Amazon Inspector to scan the objects in the bucket. If objects contain PII, trigger an S3 Lifecycle policy to remove the objects that contain PII. ✅ Use an Amazon S3 bucket as a secure transfer point. Use Amazon Macie to scan the objects in the bucket. If objects contain PII, use Amazon Simple Notification Service (Amazon SNS) to trigger a notification to the administrators to remove the objects that contain PII. ❌ Implement custom scanning algorithms in an AWS Lambda function. Trigger the function when objects are loaded into the bucket. If objects contain PII, use Amazon Simple Notification Service (Amazon SNS) to trigger a notification to the administrators to remove the objects that contain PII. Implement custom scanning algorithms in an AWS Lambda function. Trigger the function when objects are loaded into the bucket. If objects contain PII, use Amazon Simple Email Service (Amazon SES) to trigger a notification to the administrators and trigger an S3 Lifecycle policy to remove the meats that contain PII. ✨ 关键词：transaction data through SFTP、files can exceed 200 GB in size、the LEAST development effort 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：客户通过 SFTP 上传文件（可达 200 GB），公司依此创建订单。最近公司发现有文件存在个人信息，希望自动化处理。要求最少开发的架构。1️⃣ 存在错误 Amazon Inspector 是用来检测实例和 Lambda 函数等的安全漏洞的。2️⃣ 中使用的 Amazon Macie 是一种数据安全服务，它使用机器学习和模式匹配来发现敏感数据，提供对数据安全风险的可见性，并使您能够自动防御这些风险。这似乎是唯一的选择。3️⃣ 和 4️⃣ 虽然可以实现，但是题目中指定了最少开发量，因此不选。 社区在 2️⃣ 和 4️⃣ 中有争议，不过 Amazon Macie 大规模发现和保护您的敏感数据 提到了： 以经济高效的方式查看存储在 Amazon S3 中的敏感数据。 毫无以为这个就是考点。 👨‍👨‍👦‍👦 社区讨论：Amazon Macie isa data securityand data privacy service that uses machine learning (ML) and pattern matching to discover and protect your sensitive data Macie automatically detectsa large and growing list of sensitive data types, including personally identifiable information (PII) such as names,addresses,and credit card numbers. It also gives you constant visibility of the data securityand data privacy of your data stored in Amazon S3 二、Reserved Instances and guaranteed capacityA company needs guaranteed确保 Amazon EC2 capacity容量 in three specific Availability Zones in a specific AWS Region for an upcoming event that will last 1 week.What should the company do to guarantee the EC2 capacity? Purchase Reserved Instances that specify the Region needed. Create an On-Demand Capacity Reservation that specifies the Region needed. Purchase Reserved Instances that specify the Region and three Availability Zones needed. ✅ Create an On-Demand Capacity Reservation that specifies the Region and three Availability Zones needed. ✨ 关键词：last 1 week 4️⃣ ✅ 💡 解析：公司需要确保跨三个可用区的、在同一区域的 EC2 实例的容量足够应对未来一周的活动。考点是两种实例类型： 按需付费 (On-Demand Instances)：只需要按使用时间付费。 预留实例 (Reserved Instances)：承诺使用 1 或 3 年的 EC2 实例。最高可节省 75% 的成本。 持续一周的话就选择按需实例了。之后为了确保容量，还需要采用 On-Demand Capacity Reservations（按需容量预留） 服务，它需要指定可用区，因此选 4️⃣。 通过使用容量预留，您可以为特定可用区中的 Amazon EC2 实例预留计算容量。对于不同的使用案例，有两种类型的容量预留。 以下是按需容量预留的一些常见使用案例： 扩展事件 - 您可以在业务关键型事件之前创建按需容量预留，以确保在需要时进行扩展。 监管要求和灾难恢复 - 使用按需容量预留来满足高可用性的监管要求，并在不同的可用区或区域中预留容量以进行灾难恢复。 👨‍👨‍👦‍👦 社区讨论：Reserved instancesare for long term so on-demand will be the right choice - Answer D 三、Durable storage and HAA company’s website uses an Amazon EC2 instance store for its catalog目录 of items. The company wants to make sure that the catalog is highly available and that the catalog is stored in a durable耐用的 location.What should a solutions architect do to meet these requirements? Move the catalog to Amazon ElastiCache for Redis. Deploy a larger EC2 instance with a larger instance store. Move the catalog from the instance store to Amazon S3 Glacier Deep Archive. ✅ Move the catalog to an Amazon ElasticFile System (Amazon EFS) file system. ✨ 关键词：highly available、store catalog in a durable location 4️⃣ ✅ 💡 解析：需要使产品目录高度可用，且保存在长久可用的区域中。3️⃣ 不能选应该深度归档后无法使其高度可用，EFS 可以解决这个需求，因此选 4️⃣。 Amazon Elastic File System 无服务器，完全弹性文件存储 Amazon Elastic File System (Amazon EFS) 是一种简单的、无服务器的、可设置且可忽略的弹性文件系统。没有最低消费和设置费用。您只需为实际使用的存储、对不频繁访问存储类中存储的数据的读写访问，以及任何已预置的吞吐量付费。 通过为获得 99.999999999%（11 个 9）的持久性和高达 99.99%（4 个 9）的可用性而设计的完全托管式文件系统，安全可靠地访问文件。 看社区讨论似乎 durable 关键词与高持久性有关。 👨‍👨‍👦‍👦 社区讨论：keyword is “durable” locationA and B is ephemeral storageC takes forever so is not HA,that leaves D 🙋‍♂️ 回复：Yes, if you open EFS home page (https://aws.amazon.com/efs/), Amazon state, “Securely and reliably access your files with a fully managed file system designed for 99.999999999 percent (11 9s) durability and up to 99.99 percent (4 9s) of availability.” 四、File stroage and access infrequentlyA company stores call transcript files on a monthly basis. Users access the files randomly within 1 year of the call, but users access the files infrequently不经常地 after 1 year. The company wants to optimize its solution by giving users the ability to query and retrieve files that are less than 1-year-old as quickly as possible. A delay in retrieving older files is acceptable.Which solution will meet these requirements MOST cost-effectively? Store individual files with tags in Amazon S3 Glacier Instant Retrieval. Query the tags to retrieve the files from S3 Glacier Instant Retrieval. ✅ Store individual files in Amazon S3 Intelligent-Tiering. Use S3 Lifecycle policies to move the files to S3 Glacier Flexible Retrieval after 1 year. Query and retrieve the files that are in Amazon S3 by using Amazon Athena. Query and retrieve the files that are in S3 Glacier by using S3 Glacier Select. Store individual files with tags in Amazon S3 Standard storage. Store search metadata for each archive in Amazon S3 Standard storage. Use S3 Lifecycle policies to move the files to S3 Glacier Instant Retrieval after 1 year. Query and retrieve the files by searching for metadata from Amazon S3. ❌ Store individual files in Amazon S3 Standard storage. Use S3 Lifecycle policies to move the files to S3 Glacier Deep Archive after 1 year. Store search metadata in Amazon RDS. Query the files from Amazon RDS. Retrieve the files from S3 Glacier Deep Archive. ✨ 关键词：cost-effectively、query and retrieve 1-year-old files quickly、delay in retrieving older files 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：需要对存储少于 1 年的数据进行快速检索和获取，对存储超过 1 年的文件允许延迟提取。通过 S3 生命周期策略结合使用 S3 Standard + Standard Glacier Deep Archive 可以解决存储问题，2️⃣ 和 4️⃣ 相比之下使用 Amazon RDS 存放元数据来提供对深度归档文件的检索，比 Amazon Athena + S3 Glacier Select 更贵，因此选 2️⃣。 Amazon Athena 灵活轻松地分析包含它的 PB 级数据 Amazon Athena 是一项基于开源框架的无服务器交互式分析服务，支持开源表和文件格式。Athena 提供了一种简化、灵活的方法来分析包含它的 PB 级数据。从 Amazon Simple Storage Service（S3）数据湖和超过 30 个数据来源（包括本地数据来源，或使用 SQL 或 Python 的其他云系统）分析数据或构建应用程序。Athena 基于开源 Trino 和 Presto 引擎以及 Apache Spark 框架构建，无需进行预配或配置。 S3 Glacier Select Amazon Glacier Select 是对 Amazon Glacier 中的归档数据进行查询的全新方式。Glacier Select 允许直接对存储在 Amazon Glacier 中的数据运行查询，从而只从您的存档中检索所需数据来用于分析。这使您能够降低总体拥有成本，同时将您的数据湖大规模扩展到经济高效的存档存储。 社区对 3️⃣ 和 4️⃣ 存在争议，不过在 AWS 有完善的解决方案情况下，总是需要优先选择对应服务的。这里活跃和非活跃存储的转换使用 Amazon S3 Intelligent-Tiering + S3 存储策略，各自的检索使用 Amazon Athena 和 S3 Glacier Select。 👨‍👨‍👦‍👦 社区讨论：I thinkthe answer is B:Usersaccess the files randomlyS3 Intelligent-Tiering is the ideal storage class for data with unknown, changing, or unpredictable access patterns, independent of object size or retention period. You can use S3 Intelligent-Tiering as the default storage class for virtuallyany workload, especially data lakes, data analytics, new applications,and user-generated content. https://aws.amazon.com/fr/s3/storage-classes/intelligent-tiering/ 五、AWS Systems ManagerA company has a production workload that runs on 1,000 Amazon EC2 Linux instances. The workload is powered by third-party software. The company needs to patch the third-party software on all EC2 instances as quickly as possible to remediate a critical security vulnerability.What should a solutions architect do to meet these requirements? Create an AWS Lambda function to apply the patch to all EC2 instances. Configure AWS Systems Manager Patch Manager to apply the patch to all EC2 instances. Schedule an AWS Systems Manager maintenance window to apply the patch to all EC2 instances. ✅ Use AWS Systems Manager Run Command to run a custom command that applies the patch to all EC2 instances. ✨ 关键词：1,000 Amazon EC2 Linux instances、third-party software、quickly 4️⃣ ✅ 💡 解析：需要在 1000 EC2 实例上尽快都安装一款第三软件。 AWS Systems Manager 在 AWS 以及多云和混合环境中管理您的资源 AWS Systems Manager 是一种管理云和混合 IT 环境的新方法。AWS Systems Manager 提供了一个统一的用户界面，可以简化资源和应用程序管理，缩短检测和解决操作问题的时间，并使您能够轻松安全地大规模操作和管理基础设施。此服务包含了丰富的功能。它定义了围绕使用 Amazon EC2 Systems Manager (SSM) 等产品中的功能进行分组、可视化和问题响应的新体验，支持大量跨资源的操作。 Run Command：是一个用于对实例启用 SSH 的卓越替代品。它让您可以在不登录到服务器的情况下为您的实例提供安全可靠的大规模远程管理，从而取代了对 SSH 防御主机或远程 powershell 的需求。它具有精细的 IAM 权限，可让您限制可以运行某些命令的角色或用户。 自动化操作：可让您将常见 IT 任务定义为一个指定了一系列任务的 JSON 文档。您还可以使用社区发布的文档。这些文档可通过控制台、CLI、软件开发工具包和计划的维护窗口来执行，或通过 CloudWatch 事件基于您的基础设施中的更改来触发。您可以跟踪并记录文档中的每个步骤的执行情况，并针对额外的审批进行提示。它还允许您逐步推出更改并在出现错误时自动停止。您可以直接在资源组上开始执行自动化操作，该操作能够将自身应用于它在组中了解的资源。 Patch Manager：使用 Patch Manager 可以通过安全性相关更新及其他类型的更新自动执行修补托管式节点的过程。您可以使用 Patch Manager 来应用操作系统和应用程序的补丁。（在 Windows Server 上，应用程序支持仅限于更新 Microsoft 发布的应用程序。） 维护时段：可让您在特定时段内安排实例维护和其他中断性任务。 State Manager：让您控制各种服务器配置详情，例如防病毒定义、防火墙设置等。您可以在控制台中定义策略，也可以运行现有脚本、PowerShell 模块或者甚至直接从 S3 或 GitHub 运行 Ansible 操作手册。您可以随时查询 State Manager 以查看实例配置的状态。 虽然社区在 2️⃣ 和 4️⃣ 之间存在争议，但 Patch Manager 的主要设计意图在于在托管式节点上安装与安全性相关的操作系统更新，并且默认情况下，Patch Manager 只安装一小部分旨在提高安全性的补丁。而 Run Command 显然更自由、更符合题目场景。 👨‍👨‍👦‍👦 社区讨论：The primary focus of Patch Manager,a capability of AWS Systems Manager, is on installing operating systems security-related updates on managed nodes. By default, Patch Manager doesn’t install all available patches, but rather a smaller set of patches focused on security. (Ref https://docs.aws.amazon.com/systems-manager/latest/userguide/patch-manager-how-it-works-selection.html)Run Command allows you to automate common administrative tasksand perform one-time configuration changesat scale. (Ref https://docs.aws.amazon.com/systems-manager/latest/userguide/execute-remote-commands.html)Seems like patch manager is meant for OS level patchesand not 3rd partyapplications. And this falls under run command wheelhouse to carry out one-time configuration changes (update of 3rd part application) at scale.","link":"/2024/11/23/saa_test_daily_20241123/"},{"title":"SAA 考试每日练习 - 2024&#x2F;11&#x2F;25","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam8 题 (No.58 ~ No.65)，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： clickstream点击流 separatelyadv. 单独地，分别地 externaladj. 外部的，外面的，外来的 accommodatev. 容纳；适应；提供住宿；顾及 rapidlyadv. 迅速地；很快地；立即 interactv. 交流，交往，互动；相互作用，相互影响 significantadj. 重要的，意义重大的；意味深长的；相当数量的；显著的；表示…的 一、ContainersA company wants to run its critical applications in containers to meet requirements for scalability and availability. The company prefers to focus on maintenance of the critical applications. The company does not want to be responsible for provisioning and managing the underlying infrastructure that runs the containerized workload.What should a solutions architect do to meet these requirements? Use Amazon EC2 instances, and install Docker on the instances. Use Amazon Elastic Container Service (Amazon ECS) on Amazon EC2 worker nodes. ✅ Use Amazon Elastic Container Service (Amazon ECS) on AWS Fargate. Use Amazon EC2 instances from an Amazon Elastic Container Service (Amazon ECS)-optimized Amazon Machine Image (AMI). ✨ 关键词：containers、scalability and availability、does not want to be responsible for the containerized workload 3️⃣ ✅ 💡 解析：应用运行在容器中，公司不希望管理运行容器的架构。这是 Fargate 的最佳使用场景，同时注意它需要与 ECS 和 EKS 搭配使用。 AWS Fargate 适用于容器的无服务器计算 AWS Fargate 与 Amazon Elastic Container Service（Amazon ECS）和 Amazon Elastic Kubernetes Service（Amazon EKS）兼容。选择任何符合 OCI 标准的容器映像，定义内存和计算资源，然后使用无服务器计算运行容器。由于该服务支持多种 CPU 架构和操作系统，因此您可以在各种应用程序中享受这些好处。 👨‍👨‍👦‍👦 社区讨论：Good answer is C:AWS Fargate isa serverless, pay-as-you-go compute engine that lets you focus on building applications without having to manage servers. AWS Fargate is compatible with Amazon Elastic ContainerService (ECS) and Amazon Elastic Kubernetes Service (EKS).https://aws.amazon.com/fr/fargate/ 二、30 TB of clickstreamA company hosts more than 300 global websites and applications. The company requires a platform to analyze more than 30 TB of clickstream点击流 data each day.What should a solutions architect do to transmit传输 and process the clickstream data? Design an AWS Data Pipeline to archive the data to an Amazon S3 bucket and run an Amazon EMR cluster with the data to generate analytics. Create an Auto Scaling group of Amazon EC2 instances to process the data and send it to an Amazon S3 data lake for Amazon Redshift to use for analysis. Cache the data to Amazon CloudFront. Store the data in an Amazon S3 bucket. When an object is added to the S3 bucket. run an AWS Lambda function to process the data for analysis. ✅ Collect the data from Amazon Kinesis Data Streams. Use Amazon Kinesis Data Firehose to transmit the data to an Amazon S3 data lake. Load the data in Amazon Redshift for analysis. ✨ 关键词：30 TB of clickstream、transmit、analyze 4️⃣ ✅ 💡 解析：公司运行了超过 300 个全球网页和应用，需要每天分析超过 30 TB 的点击流数据。数据流首选 Amazon Kinesis Data 系应用，4️⃣ 的处理也不存在问题，通过 Amazon Kinesis Data Firehose 将数据传输到 S3 存储桶中再通过 Redshift 数据湖进行分析。 社区中有些学友选了 1️⃣，来看下 AWS Data Pipeline 和 Amazon EMR (Elastic MapReduce) cluster。什么是 AWS Data Pipeline？ ⚠ AWS Data Pipeline 服务处于维护模式，没有计划新功能或区域扩展。 AWS Data Pipeline 是一项 Web 服务，可用于自动移动和转换数据。使用 AWS Data Pipeline，您可以定义数据驱动的工作流程，以便任务可以依赖于先前任务的成功完成。您可以定义数据转换的参数并 AWS Data Pipeline 强制执行已设置的逻辑。 例如，您可以使用每天将网络服务器的日志存档 AWS Data Pipeline 到亚马逊简单存储服务 (Amazon S3)，然后在这些日志上运行每周一次的亚马逊 EMR (Amazon EMR) 集群以生成流量报告。 Amazon EMR 轻松运行和扩展 Apache Spark、Hive、Presto 以及其他大数据工作负载 Amazon EMR（以前称为 Amazon Elastic MapReduce）是一个托管集群平台，可简化在AWS上运行大数据框架（如 Apache Hadoop 和 Apache Spark）的过程，以处理和分析海量数据。 看起来 1️⃣ 也能解决问题，甚至题目完美符合官方推荐的使用场景。有些人指出了它不能实时处理数据流，有些人则指出它已经不被官方推荐了。总之 4️⃣ 在当前时间点优于 1️⃣。 👨‍👨‍👦‍👦 社区讨论：Option D is the most appropriate solution for transmitting and processing the clickstream data in this scenario.Amazon Kinesis Data Streams isa highly scalable and durable service that enables real-time processing of streaming data at a high volume and high rate. You can use Kinesis Data Streams to collect and process the clickstream data in real-time.Amazon Kinesis Data Firehose isa fully managed service that loads streaming data into data storesand analytics tools. You can use Kinesis Data Firehose to transmit the data from Kinesis Data Streams to an Amazon S3 data lake.Once the data is in the data lake, you can use Amazon Redshift to load the data and perform analysis on it. Amazon Redshift is a fully managed, petabyte-scale data warehouse service that allows you to quicklyand efficientlyanalyze data using SQL and yourexisting business intelligence tools. Option A, which involves using AWS Data Pipeline to archive the data to an Amazon S3 bucket and running an Amazon EMR cluster with the data to generate analytics, is not the most appropriate solution because it does not involve real-time processing of the data. A: Not sure how recent this question is but Data Pipeline is not reallya product AWS is recommending anymore. 三、Redirect HTTP to HTTPSA company has a website hosted on AWS. The website is behind an Application Load Balancer (ALB) that is configured to handle HTTP and HTTPS separately分别地. The company wants to forward all requests to the website so that the requests will use HTTPS.What should a solutions architect do to meet this requirement? Update the ALB’s network ACL to accept only HTTPS traffic. Create a rule that replaces the HTTP in the URL with HTTPS. ✅ Create a listener rule on the ALB to redirect HTTP traffic to HTTPS. Replace the ALB with a Network Load Balancer configured to use Server Name Indication (SNI). ✨ 关键词：use HTTPS 3️⃣ ✅ 💡 解析：有网站托管在 AWS，并前置 ALB 分开处理 HTTP 和 HTTPS 请求。现在希望让所有请求都使用 HTTPS。将 HTTP 请求重定向为 HTTPS 就能够解决问题了，选 3️⃣。 如何使用应用程序负载均衡器将 HTTP 请求重定向至 HTTPS？ ……6. 选择一个负载均衡器，然后选择 HTTP 侦听器。7. 在规则下，选择查看/编辑规则。8. 选择编辑规则以修改现有默认规则，从而将所有 HTTP 请求重定向到 HTTPS。或者，在现有规则之间插入一个规则（如果适合您的用例）。9. 在然后下，删除现有条件。然后，使用重定向到操作添加新条件。10. 对于 HTTPS，请输入 443 端口。…… 👨‍👨‍👦‍👦 社区讨论：C. Create a listener rule on the ALB to redirect HTTP traffic to HTTPS.To meet the requirement of forwarding all requests to the website so that the requests will use HTTPS,a solutionsarchitect can create a listener rule on the ALB that redirects HTTP traffic to HTTPS.This can be done by creating a rule with a condition that matchesall HTTP traffic and a rule action that redirects the traffic to the HTTPS listener.The HTTPS listener should already be configured to accept HTTPS traffic and forward it to the target group. 四、Database credentials automatic rotationA company is developing a two-tier web application on AWS. The company’s developers have deployed the application on an Amazon EC2 instance that connects directly to a backend Amazon RDS database. The company must not hardcode database credentials in the application. The company must also implement a solution to automatically rotate the database credentials on a regular basis.Which solution will meet these requirements with the LEAST operational overhead? Store the database credentials in the instance metadata. Use Amazon EventBridge (Amazon CloudWatch Events) rules to run a scheduled AWS Lambda function that updates the RDS credentials and instance metadata at the same time. Store the database credentials in a configuration file in an encrypted Amazon S3 bucket. Use Amazon EventBridge (Amazon CloudWatch Events) rules to run a scheduled AWS Lambda function that updates the RDS credentials and the credentials in the configuration file at the same time. Use S3 Versioning to ensure the ability to fall back to previous values. ✅ Store the database credentials as a secret in AWS Secrets Manager. Turn on automatic rotation for the secret. Attach the required permission to the EC2 role to grant access to the secret. Store the database credentials as encrypted parameters in AWS Systems Manager Parameter Store. Turn on automatic rotation for the encrypted parameters. Attach the required permission to the EC2 role to grant access to the encrypted parameters. ✨ 关键词：not hardcode database credentials in the application 3️⃣ ✅ 💡 解析：双层架构的系统，并且不希望将数据库信息硬编码在应用程序中。定期轮转数据库认证信息。涉及到密钥的轮转，优先考虑 AWS Secrets Manager，同时 3️⃣ 的解决方式也不存在问题：通过 AWS Secrets Manager 自动轮转数据库认证信息，授予 EC2 实例角色让它能访问密钥。 老生常谈的问题了，AWS Systems Manager Parameter Store 不支持自动轮转。 👨‍👨‍👦‍👦 社区讨论：Secrets manager supports Autorotation unlike Parameter store. 五、AWS Certificate Manager rotate certificateA company is deploying a new public web application to AWS. The application will run behind an Application Load Balancer (ALB). The application needs to be encrypted at the edge with an SSL/TLS certificate that is issued by an external外部的 certificate authority (CA). The certificate must be rotated each year before the certificate expires.What should a solutions architect do to meet these requirements? Use AWS Certificate Manager (ACM) to issue an SSL/TLS certificate. Apply the certificate to the ALB. Use the managed renewal feature to automatically rotate the certificate. Use AWS Certificate Manager (ACM) to issue an SSL/TLS certificate. Import the key material from the certificate. Apply the certificate to the ALUse the managed renewal feature to automatically rotate the certificate. ❌ Use AWS Certificate Manager (ACM) Private Certificate Authority to issue an SSL/TLS certificate from the root CA. Apply the certificate to the ALB. Use the managed renewal feature to automatically rotate the certificate. ✅ Use AWS Certificate Manager (ACM) to import an SSL/TLS certificate. Apply the certificate to the ALB. Use Amazon EventBridge (Amazon CloudWatch Events) to send a notification when the certificate is nearing expiration. Rotate the certificate manually. ✨ 关键词：external CA、rotated each year 3️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：网页应用前置了 ALB，同时需要在边缘节点就开启 SSL 认证，证书来自外部 CA，证书需要每年更新。首先需要明确 ACM 的证书是 区域 级别的。1️⃣ 和 2️⃣ 使用 ACM 签发证书与题目描述的外部 CA 冲突，排除。3️⃣ 和 4️⃣ 的差别在于 ACM 是否可以为外部 CA 自动（续）签发证书，答案是不可以，因此选 4️⃣。 Amazon Certificate Manager 常见问题 问：可以使用 ACM 创建和管理哪些类型的证书？使用 ACM，您可以管理公有证书的生命周期。ACM 的功能取决于证书是否为公有证书、您获得证书的方式，以及证书的部署位置。请参阅“ACM 公有证书”，了解有关公有证书的更多信息。公有证书 – ACM 管理用于 ACM 集成服务（包括 Elastic Load Balancing 和 Amazon API Gateway）的公有证书的续订和部署。已导入证书 – 如果想将第三方证书与 Elastic Load Balancing 或 Amazon API Gateway 配合使用，您可以使用 亚马逊云科技 管理控制台、Amazon CLI 或 ACM API 将该证书导入 ACM。ACM 不会管理已导入证书的续订流程。您负责监控所导入证书的到期日期，并在到期之前续订。您可以使用 亚马逊云科技 管理控制台监控已导入证书的到期日期，并导入新的第三方证书来替换即将到期的证书。 👨‍👨‍👦‍👦 社区讨论：It’sa third-party certificate, hence AWS cannot manage renewal automatically.The closest thing you can do is to send anotification to renew the 3rd party certificate. 六、Cost-effectively stroageA company runs its infrastructure on AWS and has a registered base of 700,000 users for its document management application. The company intends to create a product that converts large .pdf files to .jpg image files. The .pdf files average 5 MB in size. The company needs to store the original files and the converted files. A solutions architect must design a scalable solution to accommodate适应 demand that will grow rapidly迅速地 over time.Which solution meets these requirements MOST cost-effectively? ✅ Save the .pdf files to Amazon S3. Configure an S3 PUT event to invoke an AWS Lambda function to convert the files to .jpg format and store them back in Amazon S3. Save the .pdf files to Amazon DynamoDB. Use the DynamoDB Streams feature to invoke an AWS Lambda function to convert the files to .jpg format and store them back in DynamoDB. Upload the .pdf files to an AWS Elastic Beanstalk application that includes Amazon EC2 instances, Amazon Elastic Block Store (Amazon EBS) storage, and an Auto Scaling group. Use a program in the EC2 instances to convert the files to .jpg format. Save the .pdf files and the .jpg files in the EBS store. Upload the .pdf files to an AWS Elastic Beanstalk application that includes Amazon EC2 instances, Amazon ElasticFile System (Amazon EFS) storage, and an Auto Scaling group. Use a program in the EC2 instances to convert the file to .jpg format. Save the .pdf files and the .jpg files in the EBS store. ✨ 关键词：converts large .pdf files to .jpg image files、grow rapidly、MOST cost-effectively 1️⃣ ✅ 💡 解析：将 .pdf 文件转换为 .jpg 文件，原始文件和转换后的文件都需要保存，文件数量上涨很快。需要最便宜的方案。最便宜的存储方案就是 S3，1️⃣ 的操作也没有问题：S3 的上传操作触发 Lambda 的转换，并将转换后的文件存回 S3。 拓展下，社区讨论中提到了 DynamoDB 有 400 KB 的最大文件大小限制。Amazon DynamoDB 中的服务、账户和表限额 DynamoDB 中的项目大小上限为 400 KB，包括属性名称二进制长度（UTF-8 长度）和属性值长度（同为二进制长度）。属性名称也包含在此大小限制之内。 👨‍👨‍👦‍👦 社区讨论：Option A.Elastic BeanStalkisexpensive,and DynamoDB has a 400KB max to upload files.So Lambda and S3 should be the one. 七、Amazon FSx File GatewayA company has more than 5 TB of file data on Windows file servers that run on premises. Users and applications interact交互 with the data each day.The company is moving its Windows workloads to AWS. As the company continues this process, the company requires access to AWS and on-premises file storage with minimum latency. The company needs a solution that minimizes operational overhead and requires no significant重大的 changes to the existing file access patterns. The company uses an AWS Site-to-Site VPN connection for connectivity to AWS.What should a solutions architect do to meet these requirements? Deploy and configure Amazon FSx for Windows File Server on AWS. Move the on-premises file data to FSx for Windows File Server. Reconfigure the workloads to use FSx for Windows File Server on AWS. Deploy and configure an Amazon S3 File Gateway on premises. Move the on-premises file data to the S3 File Gateway. Reconfigure the on-premises workloads and the cloud workloads to use the S3 File Gateway. Deploy and configure an Amazon S3 File Gateway on premises. Move the on-premises file data to Amazon S3. Reconfigure the workloads to use either Amazon S3 directly or the S3 File Gateway. depending on each workload’s location. ✅ Deploy and configure Amazon FSx for Windows File Server on AWS. Deploy and configure an Amazon FSx File Gateway on premises. Move the on-premises file data to the FSx File Gateway. Configure the cloud workloads to use FSx for Windows File Server on AWS. Configure the on-premises workloads to use the FSx File Gateway. ✨ 关键词：5 TB、Windows file servers、on-premises file storage、minimum latency 4️⃣ ✅ 💡 解析：应用程序需要与 5 TB 大小的文件数据交互，文件存储在 Windows 文件服务器上。需要将应用程序迁移到 AWS，同时需要连接到 AWS 和本地托管文件存储都拥有低延迟。最少操作且对文件访问方式不要有重大变化。公司已经使用了 AWS Site-to-Site VPN 连接到 AWS。这种场景下，需要考虑 AWS 文件网关，又因为是 Windows 系统，因此不能选择 S3 文件网关，2️⃣ 和 3️⃣ 肯定是错了，先排除。然后又要求低延迟，FSx File Gateway 由于拥有缓存属性，因此一定是最好的选择，选 4️⃣。 AWS Storage Gateway 文档 Amazon S3 File Gateway Amazon FSx File Gateway：它提供从本地部署的设施中访问云中的 Amazon FSx for Windows File Server 共享的功能。 Tape Gateway Volume Gateway 不过社区指出了选项 4️⃣ 中存在的 “Move the on-premises file data to the FSx File Gateway” 行为不合理，因为将文件拷贝到缓存中是不合常理的。但是题目考点似乎就是 Amazon FSx File Gateway。 👨‍👨‍👦‍👦 社区讨论：Agree answer is D) Requirementsare: “Usersand applications interact with the data each day” “the company requiresaccess to AWS and on-premises file storage with minimum latency” Explanation: Answer A) will work with the same on-prem &lt;&gt; aws latencyas in answer D) as both use the VPN Connection.Having said this, by using an Amazon FSx File Gateway on premise as the D) scenario mentioned,all users will have a great benefit on using the cache that the FSx File Gateway has on their daily workloads. And that is part of the requierements: “users”, “each day”, “latency” 🙅：D IS WRONG - Its used for caching. you cannot ‘Move the on-premises file data to the FSx File Gateway.’ which is stated in answer D. It pretty sure AWS employee’sare spamming this site with the wrong answers intentionally. 八、Protected health informationA hospital recently deployed a RESTful API with Amazon API Gateway and AWS Lambda. The hospital uses API Gateway and Lambda to upload reports that are in PDF format and JPEG format. The hospital needs to modify the Lambda code to identify protected health information (PHI) in the reports.Which solution will meet these requirements with the LEAST operational overhead? Use existing Python libraries to extract the text from the reports and to identify the PHI from the extracted text. Use Amazon Textract to extract the text from the reports. Use Amazon SageMaker to identify the PHI from the extracted text. ✅ Use Amazon Textract to extract the text from the reports. Use Amazon Comprehend Medical to identify the PHI from the extracted text. Use Amazon Rekognition to extract the text from the reports. Use Amazon Comprehend Medical to identify the PHI from the extracted text. ✨ 关键词：API Gateway、Lambda、turn PDF format and JPEG format、identify protected health information 3️⃣ ✅ 💡 解析：医院部署了 API 网关 并在后端使用 Lambda 将 PDF 转为 JPEG，现在需要添加识别保护的医疗数据的功能。要求最简单的方法。Amazon Textract 是从 PDF 中提取文字数据的 AI 服务，Rekognition 是识别照片中敏感信息的 AI 服务，SageMaker 是供科学家训练机器学习模型的服务，Amazon Comprehend Medical 摘取文本中医疗数据的 AI 服务。选 3️⃣，先提取文字，再摘取医疗信息。 什么是 Amazon Textract？ Amazon Textract 是一种机器学习（ML）服务，从扫描的文档（如PDF）中自动提取文本、手写内容、布局元素和数据。 它不是简单的光学字符识别技术（OCR），而是可以识别、理解并提取文档中的特定数据。 Amazon Rekognition 图像识别 Amazon Rekognition 是一项基于云的图像和视频分析服务，可以轻松地向应用程序添加高级计算机视觉功能。 Amazon SageMaker 机器学习面向每位开发人员和数据科学家 Amazon SageMaker 是一项完全托管的服务，可以帮助开发人员和数据科学家快速构建、训练和部署机器学习 (ML) 模型。SageMaker 完全消除了机器学习过程中每个步骤的繁重工作，让开发高质量模型变得更加轻松。 什么是 Amazon Comprehend Medical？ Amazon Comprehend Medical 可以检测并返回非结构化临床文本中的有用信息，例如医生记录、出院摘要、检验结果、病例记录等。Amazon Comprehend Medical 使用自然语言处理 (NLP) 模型来检测实体，这些实体是对医疗信息 [例如医学状况、药物或受保护的健康信息 (PHI)] 的文本引用。 👨‍👨‍👦‍👦 社区讨论：The correct solution is C: Use Amazon Textract to extract the text from the reports. Use Amazon Comprehend Medical to identify the PHI from the extracted text. Option C: Using Amazon Textract to extract the text from the reports,and Amazon Comprehend Medical to identify the PHI from the extracted text, would be the most efficient solution as it would involve the least operational overhead.Textract is specifically designed forextracting text from documents,and Comprehend Medical isa fully managed service that can accurately identify PHI in medical text.This solution would require minimal maintenance and would not incur anyadditional costs beyond the usage fees forTextract and Comprehend Medical.","link":"/2024/11/25/saa_test_daily_20241125/"},{"title":"SAA 考试每日练习 - 2024&#x2F;11&#x2F;26","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam15 题 (No.66 ~ No.80)，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： approximatelyadv. 大约，大概，约莫 criticaladj. 批评的，批判的；紧要的，关键性的；严重的，危急的；审慎的，严谨的；评论性的；挑剔的；临界的 appropriateadj. 合适的；适当的，相称的 | v. 拨出（款项）；占用，挪用 visibilityn. 可见性，能见度，可见度，能见距离 corruptionn. 腐败，贪污，受贿，贿赂 bastionn. 堡垒，捍卫者，防御工事 transactionn. 交易，生意；处理，办理 instrumentationn. 仪表, 器乐谱写 deliveryn. 递送；交付；分娩 unpredictableadj. 无法预言的，不可预测的，难以预料的，（人）善变的 一、S3 LifestyleA company has an application that generates a large number of files, each approximately大约 5 MB in size. The files are stored in Amazon S3. Company policy requires the files to be stored for 4 years before they can be deleted. Immediate accessibility is always required as the files contain critical重要的 business data that is not easy to reproduce. The files are frequently accessed in the first 30 days of the object creation but are rarely accessed after the first 30 days.Which storage solution is MOST cost-effective? Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Glacier 30 days from object creation. Delete the files 4 years after object creation. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 One Zone-Infrequent Access (S3 One Zone-IA) 30 days from object creation. Delete the files 4 years after object creation. ✅ Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) 30 days from object creation. Delete the files 4 years after object creation. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) 30 days from object creation. Move the files to S3 Glacier 4 years after object creation. ✨ 关键词：stored for 4 years、Immediate accessibility is always required、frequently accessed in the first 30 days、rarely accessed after the first 30 days 3️⃣ ✅ 💡 解析：文件需要存放 4 年，第 1 个月访问频繁，之后偶尔访问，但是需要能立即获取。最便宜的方案。需要立即获取的话，只能使用 S3 标准 + S3 IA 的方式，然后使用生命周期策略，选 3️⃣。 社区对 1️⃣ 和 2️⃣ 还有争议，2️⃣ 明显错误单区 IA 数据一丢就没了。而针对 1️⃣，S3 Glacier 其实也分多种： S3 Glacier Instant Retrieval S3 Glacier Flexible Retrieval S3 Glacier Deep Archive S3 Glacier Deep Archive 长久归档、检索时间 9 小时 ~ 48 小时，已经很熟练了就不介绍了。 Amazon S3 Glacier Instant Retrieval 成本极低的归档存储，提供毫秒级检索能力，适合极少访问的数据 Amazon S3 Glacier Instant Retrieval 是一种归档存储类，可以为很少访问且需要毫秒级检索速度的长期数据提供最低成本的存储。如果您每季度访问一次数据，则与 S3 Standard-Infrequent Access (S3 Standard-IA) 存储类相比，S3 Glacier 即时检索可为您节省高达 68% 的存储成本。它专为很少访问但在性能敏感的用例中仍需要立即访问的数据而设计，例如图像托管、在线文件共享应用程序、医疗成像和健康记录、新闻媒体资产以及基因组学。 S3 Glacier Flexible Retrieval 对于不需要立即访问但需要灵活地免费检索大量数据的归档数据，例如备份或灾难恢复使用场景，请选择 S3 Glacier Flexible Retrieval，它可在几分钟内检索，也可以在 5-12 小时内进行免费批量检索。 对象存储在 S3 Glacier Flexible Retrieval 并不适用于实时访问。访问这些对象，首先启动一个恢复请求，它创建了一个临时的复制的对象，这你可以访问请求时完成。 它们一个适合医疗图像等每季度访问一次的对象，一个适合灾难恢复场景，都不符合题目中偶尔访问的需求。况且考 Glacier 下细分存储类型的题目本身就很少，不用太过纠结。 👨‍👨‍👦‍👦 社区讨论：i think C should be the answer here, Immediate accessibility isalways required as the files contain critical business data that is not easy to reproduce If they do not explicitly mention that theyare using Glacier Instant Retrieval, we should assume that Glacier -&gt; takes more time to retrieve and may not meet the requirements 二、Multi-consumers in SQSA company hosts an application on multiple Amazon EC2 instances. The application processes messages from an Amazon SQS queue, writes to an Amazon RDS table, and deletes the message from the queue. Occasional duplicate records are found in the RDS table. The SQS queue does not contain any duplicate messages.What should a solutions architect do to ensure messages are being processed once only? Use the CreateQueue API call to create a new queue. Use the AddPermission API call to add appropriate合适的 permissions. Use the ReceiveMessage API call to set an appropriate wait time. ✅ Use the ChangeMessageVisibility API call to increase the visibility可见的 timeout. ✨ 关键词：Occasional duplicate records are found in the RDS table 4️⃣ ✅ 💡 解析：多个 EC2 主机消费 SQS 队列信息，处理后插入 RDS 表中，但是出现了消息被消费多次创建多条表数据的情况。做什么来确保消息只被消费一次。通过 ChangeMessageVisibility 来隐藏消息可以确保其他消费者不会重复消费该消息。 ChangeMessageVisibility 将队列中指定报文的可见性超时更改为新值。信息的默认可见性超时为 30 秒。最小值为 0 秒。最大为 12 小时。 例如，如果队列的默认超时时间是 60 秒，而您收到信息后已过去了 15 秒，并且您发送了将可见性超时设置为 10 秒的 ChangeMessageVisibility 调用，那么这 10 秒将从您发出 ChangeMessageVisibility 调用时开始计算。因此，在最初更改可见性超时 10 秒（共 25 秒）后再试图更改可见性超时或删除该信息可能会导致错误。 👨‍👨‍👦‍👦 社区讨论：In case of SQS - multi-consumers if one consumer hasalready picked the message and is processing, in meantime other consumer can pickit up and process the message there by two copiesare added at the end. To avoid this the message is made invisible from the time its picked and deleted after processing.This visibility timeout is increased according to max time taken to process the message 三、AWS Direct Connect &amp; VPNA solutions architect is designing a new hybrid architecture to extend a company’s on-premises infrastructure to AWS. The company requires a highly available connection with consistent low latency to an AWS Region. The company needs to minimize costs and is willing to accept slower traffic if the primary connection fails.What should the solutions architect do to meet these requirements? ✅ Provision an AWS Direct Connect connection to a Region. Provision a VPN connection as a backup if the primary Direct Connect connection fails. Provision a VPN tunnel connection to a Region for private connectivity. Provision a second VPN tunnel for private connectivity and as a backup if the primary VPN connection fails. Provision an AWS Direct Connect connection to a Region. Provision a second Direct Connect connection to the same Region as a backup if the primary Direct Connect connection fails. Provision an AWS Direct Connect connection to a Region. Use the Direct Connect failover attribute from the AWS CLI to automatically create a backup connection if the primary Direct Connect connection fails. ✨ 关键词：highly available connection with consistent low latency、accept slower traffic if the primary connection fails 1️⃣ ✅ 💡 解析：将托管架构迁移到 AWS，要求高可用和低延迟的连接。在主要的网络连接出问题后，愿意接受慢的网络。要求低费用。低延迟连接到 区域 首选 AWS Direct Connect，之后备用连接搭建 VPN 即可。 过一下常见的几个连接方式： AWS Site-to-Site VPN 在公网上建立专有网络 (VPN) 来让本地数据中心连接到 AWS VPC ⭐ VPC 级别的 会创建两条 VPN 隧道进行冗余 AWS VPN CloudHub 将多个 VPC、本地数据中心组网 AWS Client VPN AWS 提供的 VPN 服务 软件 VPC 自己在 EC2 上搭建 VPN AWS Direct Connect(DX) 通过专线连接到 AWS，类似：本地数据中心 &lt;–&gt; AWS Direct Connect 位置 &lt;–&gt; 某区域内的某 VPC 无论那种方案都需要 1 个月以上的时间 Transit VPC 非 AWS 托管 类似 ZeroTier 的异地组网方式 👨‍👨‍👦‍👦 社区讨论：Direct Connect + VPN best of both Direct Connect goes throught 1 Gbps, 10 Gbps or 100 Gbpsand the VPN goes up to 1.25 Gbps.https://docs.aws.amazon.com/whitepapers/latest/aws-vpc-connectivity-options/aws-direct-connect-vpn.html 四、HA databaseA company is running a business-critical web application on Amazon EC2 instances behind an Application Load Balancer. The EC2 instances are in an Auto Scaling group. The application uses an Amazon Aurora PostgreSQL database that is deployed in a single Availability Zone. The company wants the application to be highly available with minimum downtime and minimum loss of data.Which solution will meet these requirements with the LEAST operational effort? Place the EC2 instances in different AWS Regions. Use Amazon Route 53 health checks to redirect traffic. Use Aurora PostgreSQL Cross-Region Replication. ✅ Configure the Auto Scaling group to use multiple Availability Zones. Configure the database as Multi-AZ. Configure an Amazon RDS Proxy instance for the database. Configure the Auto Scaling group to use one Availability Zone. Generate hourly snapshots of the database. Recover the database from the snapshots in the event of a failure. Configure the Auto Scaling group to use multiple AWS Regions. Write the data from the application to Amazon S3. Use S3 Event Notifications to launch an AWS Lambda function to write the data to the database. ✨ 关键词：Amazon Aurora PostgreSQL database that is deployed in a single Availability Zone、highly available 2️⃣ ✅ 💡 解析：公司应用程序部署在 ALB 后面的弹性 EC2 组上，使用了单一区域的 Aurora PostgreSQL 数据库，希望变得高可用且减少数据丢失。最简单的架构。需要跨可用区横向扩展 Aurora PostgreSQL 数据库。 这里需要注意的是，Aurora PostgreSQL 数据库的跨可用区副本只是用来在主库灾难时恢复（提升为主库）用的。 在 Aurora 预置数据库集群中创建第二个、第三个以及更多数据库实例时，Aurora 自动设置从写入器数据库实例到所有其他数据库实例的复制。这些其他数据库实例是只读实例，称为 Aurora 副本。讨论如何在集群中组合写入器和读取器数据库实例时，我们还将其称为读取器实例。 由于读写都在主数据库实例上进行，且灾难场景下的数据库提升 (Promote) 需要数分钟完成，无法进行自动化无缝切换，因此 Amazon RDS Proxy 在此场景下并不必要。 提升过程需要几分钟才能完成。在提升只读副本时，RDS 会停止复制并重启只读副本。完成重启后，只读副本即可作为新数据库实例使用。 Amazon RDS Proxy 提高您的应用程序的扩展性、弹性和安全性 通过使用 Amazon RDS 代理，您可以允许您的应用程序池化和共享数据库连接，以提高其扩展能力。RDS Proxy 通过在保留应用程序连接的同时自动连接到备用数据库实例，使应用程序能够更好地抵御数据库故障。使用 RDS Proxy 还使您能够为数据库强制执行 AWS Identity and Access Management (IAM) 身份验证，并将凭证安全地存储在 AWS Secrets Manager。 👨‍👨‍👦‍👦 社区讨论：By configuring the Auto Scaling group to use multiple Availability Zones, the application will be able to continue running even if one Availability Zone goes down. Configuring the database as Multi-AZ will also ensure that the database remainsavailable in the event of a failure in one Availability Zone. Using an Amazon RDS Proxy instance for the database will allow the application to automatically route traffic to healthy database instances, further increasing the availability of the application.This solution will meet the requirements for high availability with minimal operational effort. 五、NLB and ALBA company’s HTTP application is behind a Network Load Balancer (NLB). The NLB’s target group is configured to use an Amazon EC2 Auto Scaling group with multiple EC2 instances that run the web service.The company notices that the NLB is not detecting HTTP errors for the application. These errors require a manual restart of the EC2 instances that run the web service. The company needs to improve the application’s availability without writing custom scripts or code.What should a solutions architect do to meet these requirements? Enable HTTP health checks on the NLB, supplying the URL of the company’s application. Add a cron job to the EC2 instances to check the local application’s logs once each minute. If HTTP errors are detected. the application will restart. ✅ Replace the NLB with an Application Load Balancer. Enable HTTP health checks by supplying the URL of the company’s application. Configure an Auto Scaling action to replace unhealthy instances. Create an Amazon Cloud Watch alarm that monitors the UnhealthyHostCount metric for the NLB. Configure an Auto Scaling action to replace unhealthy instances when the alarm is in the ALARM state. ✨ 关键词：NLB、HTTP errors 3️⃣ ✅ 💡 解析：公司的应用程序部署在 NLB 后面的弹性 EC2 组上，现在需要添加针对 HTTP 错误重启 EC2 实例的功能，不改现有脚本和代码。NLB 在第 4 层，负责 TCP、UDP 请求，而 ALB 运行在第 7 层，能处理 HTTP、HTTPS 请求，替换为 ALB 并设置健康状态检查，对不通过的实例进行重启操作可以解决这个问题。 社区指出了 NLB 也可以进行 HTTP、HTTPS 错误的检查，但是无法针对 URL 进行提供（筛选）。不过有 ALB 的情况下，ALB 总是更优的、针对 HTTP、HTTPS 错误进行检查的选择。 👨‍👨‍👦‍👦 社区讨论：I would choose A,as NLB supports HTTP and HTTPS Health Checks, BUT you can’t put any URL (as proposed), only the node IPaddresses.So, the solution is C. NLBs support HTTP, HTTPS and TCP health checks:https://docs.aws.amazon.com/elasticloadbalancing/latest/network/target-group-health-checks.html (check HealthCheckProtocol)But NLBs onlyaccept either selecting EC2 instances or IP addresses directlyas targets. You can’t provide a URL to your endpoints, onlya health check path (if you’re using HTTP or HTTPS health checks). 六、DynamoDB point-in-time recoveryA company runs a shopping application that uses Amazon DynamoDB to store customer information. In case of data corruption数据损坏, a solutions architect needs to design a solution that meets a recovery point objective (RPO) of 15 minutes and a recovery time objective (RTO) of 1 hour.What should the solutions architect recommend to meet these requirements? Configure DynamoDB global tables. For RPO recovery, point the application to a different AWS Region. ✅ Configure DynamoDB point-in-time recovery. For RPO recovery, restore to the desired point in time. Export the DynamoDB data to Amazon S3 Glacier on a daily basis. For RPO recovery, import the data from S3 Glacier to DynamoDB. Schedule Amazon Elastic Block Store (Amazon EBS) snapshots for the DynamoDB table every 15 minutes. For RPO recovery, restore the DynamoDB table by using the EBS snapshot. ✨ 关键词：DR、RPO for 15 minutes、RTO for 1 hour 2️⃣ ✅ 💡 解析：应用程序通过 DynamoDB 存储数据，从上次备份到出错控制在 15 分钟，灾难恢复控制在 1 小时。每 15 分钟备份一次，虽然不清楚 point-in-time recovery 服务，但只有 2️⃣ 是最佳选择。 DynamoDB 的时间点备份 Amazon DynamoDB 时间点故障恢复（PITR）提供 DynamoDB 表数据的自动持续备份。时间点故障恢复（PITR）备份由 DynamoDB 完全管理，以每秒粒度提供长达 35 天的恢复点。使用时间点恢复，您不必担心创建、维护或计划按需备份。本部分概述在 DynamoDB 中此过程如何运行。 👨‍👨‍👦‍👦 社区讨论：A - DynamoDB global tables provides multi-Region, and multi-active database, but it not valid “in case of data corruption”. In this case, you need a backup.This solutions isn’t valid.B - Point in Time Recovery is designed asa continuous backup juts to recover it fast. It covers perfectly the RPO,and probably the RTO. https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/PointInTimeRecovery.htmlC - A dailyexport will not cover the RPO of 15min.D - DynamoDB is serverless… so what are these EBS snapshots taken from??? 七、Gateway EndpointA company runs a photo processing application that needs to frequently upload and download pictures from Amazon S3 buckets that are located in the same AWS Region. A solutions architect has noticed an increased cost in data transfer fees and needs to implement a solution to reduce these costs.How can the solutions architect meet this requirement? Deploy Amazon API Gateway into a public subnet and adjust the route table to route S3 calls through it. Deploy a NAT gateway into a public subnet and attach an endpoint policy that allows access to the S3 buckets. Deploy the application into a public subnet and allow it to route through an internet gateway to access the S3 buckets. ✅ Deploy an S3 VPC gateway endpoint into the VPC and attach an endpoint policy that allows access to the S3 buckets. ✨ 关键词：same AWS Region、increased cost in data transfer fees 4️⃣ ✅ 💡 解析：同 区域 运行了从 S3 存储桶上传和下载图片的应用程序，数据传输费用开始上涨。可能存在 VPC 和 S3 没有走内网而走了公网进行连接的问题，使用 网关节点（只支持 S3 和 DynamoDB）可以解决问题。 👨‍👨‍👦‍👦 社区讨论：The correct answer is Option D. Deployan S3 VPC gatewayendpoint into the VPC and attach an endpoint policy that allows access to the S3 buckets.By deploying an S3 VPC gatewayendpoint, the application can access the S3 buckets over a private networkconnection within the VPC,eliminating the need for data transfer over the internet. This can help reduce data transfer feesas well as improve the performance of the application. The endpoint policy can be used to specify which S3 buckets the application hasaccess to. 八、Security GroupA company recently launched Linux-based application instances on Amazon EC2 in a private subnet and launched a Linux-based bastion堡垒 host on an Amazon EC2 instance in a public subnet of a VPC. A solutions architect needs to connect from the on-premises network, through the company’s internet connection, to the bastion host, and to the application servers. The solutions architect must make sure that the security groups of all the EC2 instances will allow that access.Which combination of steps should the solutions architect take to meet these requirements? (Choose two.) Replace the current security group of the bastion host with one that only allows inbound access from the application instances. Replace the current security group of the bastion host with one that only allows inbound access from the internal IP range for the company. ✅ Replace the current security group of the bastion host with one that only allows inbound access from the external IP range for the company. ✅ Replace the current security group of the application instances with one that allows inbound SSH access from only the private IP address of the bastion host. Replace the current security group of the application instances with one that allows inbound SSH access from only the public IP address of the bastion host. ✨ 关键词：bastion host in public subnet、application in private subnet 3️⃣ 4️⃣ ✅ 💡 解析：堡垒机在公有子网，应用程序在私有子网，需要从本地网络通过堡垒机连接到应用程序主机。答案都是针对安全组的操作。堡垒机的安全组需要放行来自公有 IP 的入站流量，应用程序 EC2 需要放行来自堡垒机 IP 的入站流量。 引申 2 点： 安全组没有拒绝规则 有拒绝规则的网络 ACL 是位于 子网 级别的 👨‍👨‍👦‍👦 社区讨论：C because from on-prem networkto bastion through internet (using on-prem resource’s public IP),D because bastion and ec2 is in same VPC, meaning bastion can communicate to EC2 via it’s private IP address 九、Security GroupA solutions architect is designing a two-tier web application. The application consists of a public-facing web tier hosted on Amazon EC2 in public subnets. The database tier consists of Microsoft SQL Server running on Amazon EC2 in a private subnet. Security is a high priority for the company.How should security groups be configured in this situation? (Choose two.) ✅ Configure the security group for the web tier to allow inbound traffic on port 443 from 0.0.0.0/0. Configure the security group for the web tier to allow outbound traffic on port 443 from 0.0.0.0/0. ✅ Configure the security group for the database tier to allow inbound traffic on port 1433 from the security group for the web tier. Configure the security group for the database tier to allow outbound traffic on ports 443 and 1433 to the security group for the web tier. Configure the security group for the database tier to allow inbound traffic on ports 443 and 1433 from the security group for the web tier. ✨ 关键词：web in public subnets、database in a private subnet 1️⃣ 3️⃣ 💡 解析：两层架构，Web 应用在公有子网，数据库在私有子网。安全组配置，公有子网的 EC2 实例面对所有 IP 放行 443 端口的入栈请求，私有子网的数据库实例面对公有子网实例放行 1433 端口的入栈请求。 配置 SQL Server 以侦听特定 TCP 端口 由于端口 1433 是 SQL Server 的已知标准，某些组织指定应更改 SQL Server 端口号以增强安全性。这在某些环境中可能很有用。但是，TCP/IP 体系结构允许端口扫描程序查询打开的端口，因此更改端口号并不是一种可靠的安全措施。 👨‍👨‍👦‍👦 社区讨论：Web Server Rules: Inbound traffic from 443 (HTTPS) Source 0.0.0.0/0 - Allows inbound HTTPS access from any IPv4 address Database Rules : 1433 (MS SQL)The default port to accessa MicrosoftSQL Server database, forexample, on an Amazon RDSinstancehttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/security-group-rules-reference.html 十、Multi-tiered application and overloadA company wants to move a multi-tiered application from on premises to the AWS Cloud to improve the application’s performance. The application consists of application tiers that communicate with each other by way of RESTful services. Transactions处理 are dropped when one tier becomes overloaded. A solutions architect must design a solution that resolves these issues and modernizes the application.Which solution meets these requirements and is the MOST operationally efficient? ✅ Use Amazon API Gateway and direct transactions to the AWS Lambda functions as the application layer. Use Amazon Simple Queue Service (Amazon SQS) as the communication layer between application services. Use Amazon CloudWatch metrics to analyze the application performance history to determine the servers’ peak utilization during the performance failures. Increase the size of the application server’s Amazon EC2 instances to meet the peak requirements. Use Amazon Simple Notification Service (Amazon SNS) to handle the messaging between application servers running on Amazon EC2 in an Auto Scaling group. Use Amazon CloudWatch to monitor the SNS queue length and scale up and down as required. ❌ Use Amazon Simple Queue Service (Amazon SQS) to handle the messaging between application servers running on Amazon EC2 in an Auto Scaling group. Use Amazon CloudWatch to monitor the SQS queue length and scale up when communication failures are detected. ✨ 关键词：multi-tiered application、RESTful、Transactions are dropped when one tier becomes overloaded、modernizes、design a solution 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：应用程序由多层（应用程序）构成，使用 RESTful API 互相通信。目前存在问题某一层过载后处理就会被丢弃。需要最简单的架构进行解决。弹性扩容 + 通过 SQS 解耦是这类“由于某一节点负荷过高导致整体运行效率下降”的通用解，4️⃣ 看起来不存在问题。不过 4️⃣ 中有个错误是 CloudWatch 在检测到通信的失败 (communication failures are detected) 才开始扩容已经太迟了。 并且题目中还有个需求 modernizes，像 1️⃣ 一样使用 Amazon API Gateway 并在后端部署 Lambda 可以实现相同的功能并且由于自带弹性扩展因此更加现代。之后再碰到有 modernizes 和 design a solution 这样关键词的题目需要留意下，是不是要重新考虑架构。 👨‍👨‍👦‍👦 社区讨论：Agree with A&gt;&gt;&gt; Lambda = serverless + autoscale (modernize),SQS= decouple (no more drops) The catch phrase is “scale up when communication failuresare detected” Scaling should not be based on communication failures, that’ll be crying over spilled milk! or rather too late. So D is wrong. 十一、Data sync to S3A company receives 10 TB of instrumentation仪表 data each day from several machines located at a single factory. The data consists of JSON files stored on a storage area network (SAN) in an on-premises data center located within the factory. The company wants to send this data to Amazon S3 where it can be accessed by several additional systems that provide critical near-real-time analytics. A secure transfer is important because the data is considered sensitive.Which solution offers the MOST reliable data transfer? AWS DataSync over public internet ✅ AWS DataSync over AWS Direct Connectz AWS Database Migration Service (AWS DMS) over public internet AWS Database Migration Service (AWS DMS) over AWS Direct Connect ✨ 关键词：10 TB、JSON、SAN in an on-premises data center located within the factory、near-real-time analytics、secure 2️⃣ ✅ 💡 解析：工厂每天有 10 TB 的敏感数据以 JSON 文件形式存在本地，现在需要传输到 S3 存储桶中，并通过其他系统进行近实时的分析。安全敏感数据因此选择 AWS Direct Connect，它在数据到达 AWS Direct Connect 位置后到 AWS 的过程中会走 AWS 的网络。而 AWS Database Migration Service 是本地数据库迁移到 AWS 时使用的。 什么是 AWS DataSync？ AWS DataSync是一项在线数据移动和发现服务，可简化数据迁移，并帮助您在AWS存储服务之间快速、轻松、安全地传输文件或对象数据。 通过使用 DataSync，您可以获得以下好处： 简化迁移规划 - 通过自动数据收集和建议，DataSyncDiscovery 可以最大限度地减少与规划数据迁移到AWS相关的时间、工作量和成本。您可以使用建议为预算计划提供信息，并在迁移临近时重新运行发现任务以验证您的假设。 自动移动数据 - DataSync 使通过网络在存储系统和服务之间移动数据变得更加容易。DataSync自动管理数据传输过程和高性能和安全数据传输所需的基础架构。 安全传输数据 - DataSync 提供端到端安全性，包括加密和完整性验证，以帮助确保您的数据安全、完好无损地到达并随时可用。DataSync通过内置AWS安全机制（例如 AWS Identity and Access Management (IAM) 角色）访问您的AWS存储。它还支持虚拟私有云 (VPC) 终端节点，使您可以选择在不穿越公共互联网的情况下传输数据，并进一步提高了在线复制的数据的安全性。 更快地移动数据 - DataSync 使用专门构建的网络协议和parallel 多线程架构来加快传输速度。这种方法可以加快迁移、用于分析和机器学习的重复数据处理工作流程以及数据保护流程。 降低运营成本 — 采用每千兆字节的固定定价，经济高效地移动数据。DataSync避免编写和维护自定义脚本或使用昂贵的商业传输工具。 看起来 AWS DataSync 本身就已经具备了传输过程中的端到端加密功能，不过有 AWS Direct Connect 的情况下加个保障更好。 👨‍👨‍👦‍👦 社区讨论：DMS is for databasesand here refers to “JSON files”. Public internet is not reliable.So best option is B The most reliable solution for transferring the data in a secure manner would be option B: AWS DataSync over AWS Direct Connect.AWS DataSync isa data transfer service that uses network optimization techniques to transfer data efficientlyand securely between on-premises storage systemsand Amazon S3 or other storage targets. When used over AWS Direct Connect, DataSync can provide a dedicated and secure networkconnection between your on-premises data center and AWS.This can help to ensure a more reliable and secure data transfer compared to using the public internet. 十二、Real-time data ingestion architectureA company needs to configure a real-time data ingestion architecture for its application. The company needs an API, a process that transforms data as the data is streamed, and a storage solution for the data.Which solution will meet these requirements with the LEAST operational overhead? Deploy an Amazon EC2 instance to host an API that sends data to an Amazon Kinesis data stream. Create an Amazon Kinesis Data Firehose delivery递交 stream that uses the Kinesis data stream as a data source. Use AWS Lambda functions to transform the data. Use the Kinesis Data Firehose delivery stream to send the data to Amazon S3. Deploy an Amazon EC2 instance to host an API that sends data to AWS Glue. Stop source/destination checking on the EC2 instance. Use AWS Glue to transform the data and to send the data to Amazon S3. ✅ Configure an Amazon API Gateway API to send data to an Amazon Kinesis data stream. Create an Amazon Kinesis Data Firehose delivery stream that uses the Kinesis data stream as a data source. Use AWS Lambda functions to transform the data. Use the Kinesis Data Firehose delivery stream to send the data to Amazon S3. Configure an Amazon API Gateway API to send data to AWS Glue. Use AWS Lambda functions to transform the data. Use AWS Glue to send the data to Amazon S3. ✨ 关键词：real-time data ingestion architecture、an API、a process that transforms data as the data is streamed、a storage solution 3️⃣ ✅ 💡 解析：为应用程序配置一个实时的数据摄取架构。一个 API、一个转换数据流样式数据的进程、一个存储。要求最少操作的架构。API 可以考虑使用 Amazon API Gateway API，数据流可以考虑 Amazon Kinesis data 系，数据最终存储在 S3 中。3️⃣ 最贴合，在数据流的操作流程种，创建一个 Kinesis Data Firehose 并将 Kinesis data stream 作为数据源，然后用 Lambda 处理数据。 AWS Glue 发现、准备和集成所有任意规模的数据 AWS Glue 是一项无服务器数据集成服务，它简化了发现、准备、移动和集成来自多个来源的数据以进行分析、机器学习（ML）和应用程序开发的工作。 看上去 AWS Glue 更像是为机器学习准备的。而且是由收集数据的功能，不能完成提取 (Extract)、转换 (Transform)、加载 (Load) 的整个流程。 👨‍👨‍👦‍👦 社区讨论：(A) - You don’t need to deployan EC2 instance to host an API - Operational overhead(B) - Same as A(C) - Is the answer(D) - AWS Glue gets data from S3, not from API GW. AWS Glue could do ETL (Extract-Transform-Load) by itself, so don’t need lambda. Non sense.https://aws.amazon.com/glue/ The company needsan API = Amazon API Gateway APIA real-time data ingestion = Amazon Kinesis data streamA process that transforms data = AWS Lambda functionsKinesis Data Firehose delivery stream to send the data to Amazon S3A storage solution for the data = Amazon S3 十三、DynamoDB backupA company needs to keep user transaction data in an Amazon DynamoDB table. The company must retain the data for 7 years.What is the MOST operationally efficient solution that meets these requirements? Use DynamoDB point-in-time recovery to back up the table continuously. ✅ Use AWS Backup to create backup schedules and retention policies for the table. Create an on-demand backup of the table by using the DynamoDB console. Store the backup in an Amazon S3 bucket. Set an S3 Lifecycle configuration for the S3 bucket. Create an Amazon EventBridge (Amazon CloudWatch Events) rule to invoke an AWS Lambda function. Configure the Lambda function to back up the table and to store the backup in an Amazon S3 bucket. Set an S3 Lifecycle configuration for the S3 bucket. ✨ 关键词：transaction data、DynamoDB、retain the data for 7 years 2️⃣ ✅ 💡 解析：公司将数据数据保存在 DynamoDB 表中，需要存放 7 年。需要最高效的解决方案。DynamoDB 本身就高可用，配置定时备份和相关保护策略即可，看上去选 2️⃣。DynamoDB 的 point-in-time recovery 只提供最长 35 天的数据恢复能力，不选。3️⃣ 和 4️⃣ 操作繁琐。 Backup and restore for DynamoDB With on-demand backups, you can create a snapshot backup of your table that DynamoDB stores and manages. You’re charged based on the size and duration of your backups. Using on-demand backup, you can restore your entire DynamoDB table to the exact state it was in when the backup was created. 在 DynamoDB 的备份文档中也并未提及可以直接将备份保存到 S3 中，因此 3️⃣ 还存在错误。 👨‍👨‍👦‍👦 社区讨论：Answer is B“Amazon DynamoDB offers two types of backups: point-in-time recovery (PITR) and on-demand backups. (==&gt; D is not the answer)PITR is used to recover your table to any point in time in a rolling 35 day window, which is used to help customers mitigate accidental deletes or writes to their tables from bad code, maliciousaccess, or usererror. (==&gt; A isn’t the answer)On demand backupsare designed for long-term archiving and retention, which is typically used to help customers meet compliance and regulatory requirements.This is the second of a series of two blog postsabout using AWS Backup to set up scheduled on-demand backups for Amazon DynamoDB. Part 1 presents the steps to set up a scheduled backup for DynamoDB tables from the AWS Management Console.” (==&gt; Not the DynamoBD console and C isn’t the answereither)https://aws.amazon.com/blogs/database/part-2-set-up-scheduled-backups-for-amazon-dynamodb-using-aws-backup/ 十四、On-demand DynamoDBA company is planning to use an Amazon DynamoDB table for data storage. The company is concerned about cost optimization. The table will not be used on most mornings. In the evenings, the read and write traffic will often be unpredictable不可预料的. When traffic spikes occur, they will happen very quickly.What should a solutions architect recommend? ✅ Create a DynamoDB table in on-demand capacity mode. Create a DynamoDB table with a global secondary index. Create a DynamoDB table with provisioned capacity and auto scaling. Create a DynamoDB table in provisioned capacity mode, and configure it as a global table. ✨ 关键词：unpredictable traffic、cost optimization 1️⃣ ✅ 💡 解析：使用 DynamoDB 存储数据，早晨不使用，夜间流量不可预料，流量猛增会非常快。需要最便宜的架构。按需付费的最佳使用场景。 Amazon DynamoDB 定价 按需容量模式的定价 - DynamoDB 按需模式是一种无服务器选项，采用按请求付费定价和自动扩缩，无需规划、预置和管理容量。 预置容量模式的定价 - 使用预置容量模式，必须指定预计您的应用程序需要的每秒读取和写入次数。您需要根据预置的每小时读取和写入容量付费，而不是根据应用程序消耗的容量付费。 现有应用程序具有稳定且可预测的吞吐量模式 可以预测容量要求以控制成本 👨‍👨‍👦‍👦 社区讨论：On-demand mode isa good option if any of the following are true: You create new tables with unknown workloads. You have unpredictable application traffic. You prefer the ease of paying for only what you use. C - provisioned capacity is recommended for known patterns. Not the case here. 十五、AMI Share and KMS ShareA company recently signed a contract with an AWS Managed Service Provider (MSP) Partner for help with an application migration initiative. A solutions architect needs to share an Amazon Machine Image (AMI) from an existing AWS account with the MSP Partner’s AWS account. The AMI is backed by Amazon Elastic Block Store (Amazon EBS) and uses an AWS Key Management Service (AWS KMS) customer managed key to encrypt EBS volume snapshots.What is the MOST secure way for the solutions architect to share the AMI with the MSP Partner’s AWS account? Make the encrypted AMI and snapshots publicly available. Modify the key policy to allow the MSP Partner’s AWS account to use the key. ✅ Modify the launchPermission property of the AMI. Share the AMI with the MSP Partner’s AWS account only. Modify the key policy to allow the MSP Partner’s AWS account to use the key. Modify the launchPermission property of the AMI. Share the AMI with the MSP Partner’s AWS account only. Modify the key policy to trust a new KMS key that is owned by the MSP Partner for encryption. Export the AMI from the source account to an Amazon S3 bucket in the MSP Partner’s AWS account, Encrypt the S3 bucket with a new KMS key that is owned by the MSP Partner. Copy and launch the AMI in the MSP Partner’s AWS account. ✨ 关键词：share an Amazon Machine Image from an existing AWS account with the MSP Partner’s AWS account 2️⃣ ✅ 💡 解析：需要共享一个 AMI 给第三方的 AWS 账号，这个 AMI 有一个用 KMS 的密钥加密了 EBS。问该怎么共享这个 AMI。首先需要共享这个 AMI 本身，之后参照最小权限原则只将这个密钥共享给第三方 AWS 账户，选 2️⃣。 Allowing users in other accounts to use a KMS key Allowing use of external KMS keys with AWS servicesYou can give a user in a different account permission to use your KMS key with a service that is integrated with AWS KMS. For example, a user in an external account can use your KMS key to encrypt the objects in an Amazon S3 bucket or to encrypt the secrets they store in AWS Secrets Manager. The key policy must give the external user or the external user’s account permission to use the KMS key. In addition, you need to attach IAM policies to the identity that gives the user permission to use the AWS service. The service might also require that users have additional permissions in the key policy or IAM policy. For a list of permissions that the AWS service requires on a customer managed key, see the Data Protection topic in the Security chapter of the user guide or developer guide for the service. 没有实操过，对于 Key 的共享和解密 EBS 流程有点云里雾里的，不过总归是可以共享 Key 就是了。 👨‍👨‍👦‍👦 社区讨论：Share the existing KMS key with the MSP external account because it hasalready been used to encrypt the AMI snapshot.https://docs.aws.amazon.com/kms/latest/developerguide/key-policy-modifying-external-accounts.html","link":"/2024/11/26/saa_test_daily_20241126/"},{"title":"SAA 考试每日练习 - 2024&#x2F;11&#x2F;24","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam7 题 (No.51 ~ No.57)，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： retrievaln. 取回，索回，数据检索 statisticsn. 统计数据 extractv. （费力）取出，拔出；提取，提炼；榨取；摘录；设法得到；开方，求根 | n. 提取物；萃取物；精，汁；摘录；选段；引文 low-confidence低信心 predictionn. 预言；预测；预报，预告 一、Send formatted data by emailA company is developing an application that provides order shipping statistics统计数据 for retrieval by a REST API. The company wants to extract提炼 the shipping statistics, organize the data into an easy-to-read HTML format, and send the report to several email addresses at the same time every morning.Which combination of steps should a solutions architect take to meet these requirements? (Choose two.) Configure the application to send the data to Amazon Kinesis Data Firehose. ✅ Use Amazon Simple Email Service (Amazon SES) to format the data and to send the report by email. Create an Amazon EventBridge (Amazon CloudWatch Events) scheduled event that invokes an AWS Glue job to query the application’s API for the data. ✅ Create an Amazon EventBridge (Amazon CloudWatch Events) scheduled event that invokes an AWS Lambda function to query the application’s API for the data. Store the application data in Amazon S3. Create an Amazon Simple Notification Service (Amazon SNS) topicas an S3 event destination to send the report by email. ✨ 关键词：the same time every morning、organize the data into HTML format、send email 2️⃣ 4️⃣ ✅ 💡 解析：应用程序能通过 REST API 获取船运统计数据，公司希望提炼数据并将其组织成 HTML 格式，然后每天早上发送给多个邮箱。答案中能够实现定时任务的只有 Amazon CloudWatch Events，然后调用 Lambda 结构化数据，之后通过 SES 发出。 什么是亚马逊 EventBridge？ EventBridge 是一项无服务器服务，它使用事件将应用程序组件连接在一起，使您可以更轻松地构建可扩展的事件驱动应用程序。事件驱动型架构 (event-driven applications) 是一种构建松耦合软件系统的风格，这些系统通过发出和响应事件来协同工作。事件驱动型架构可以帮助您提高敏捷性，并构建可靠、可扩展的应用程序。 创建在 Amazon 中按计划运行的规则 EventBridge 规则可以响应事件运行，也可以按特定的时间间隔运行。例如，要定期运行 AWS Lambda 函数，可以创建按计划运行的规则 👨‍👨‍👦‍👦 社区讨论：B&amp;D are the only 2 correct options. If you are choosing option E then you missed the daily morning schedule requirement mentioned in the question which cant be achieved with S3 events forSNS.Event Bridge can used to configure scheduled events (every morning in this case). Option B fulfills the email in HTML format requirement (bySES) and D fulfillsevery morning schedule event requirement (by EventBridge) EventBridge can be used to schedule regular invocations of a Lambda function that retrieves the required data from the application’s API.This step sets up the process to collect the data at the specified time every morning. 二、Standard file system structureA company wants to migrate its on-premises application to AWS. The application produces output files that vary in size from tens of gigabytes to hundreds of terabytes. The application data must be stored in a standard file system structure. The company wants a solution that scales automatically. is highly available, and requires minimum operational overhead.Which solution will meet these requirements? Migrate the application to run as containers on Amazon Elastic Container Service (Amazon ECS). Use Amazon S3 for storage. Migrate the application to run as containers on Amazon Elastic Kubernetes Service (Amazon EKS). Use Amazon Elastic Block Store (Amazon EBS) for storage. ✅ Migrate the application to Amazon EC2 instances in a Multi-AZ Auto Scaling group. Use Amazon ElasticFile System (Amazon EFS) for storage. Migrate the application to Amazon EC2 instances in a Multi-AZ Auto Scaling group. Use Amazon Elastic Block Store (Amazon EBS) for storage. ✨ 关键词：10 GB 到 100 TB 的文件、standard file system structure、scales automatically、ha、minimum operational overhead 3️⃣ ✅ 💡 解析：私有云迁移到 AWS，应用程序会产生 10 GB 到 100 TB 的文件，需要部署在独立文件系统架构上，并且易于扩展、高可用、操作低延迟。S3 的最大文件大小限制为 5 TB，因此需要选择 EFS。 不过社区讨论中指出了 EFS 最大也仅支持 47.9 TB 的文件，可能题目的重点在 a standard file system structure，S3 是对象存储，EBS 是块存储，都不是文件存储系统。 👨‍👨‍👦‍👦 社区讨论： S3, 5TiB is per object but you can have more than one object in a bucket, meaning infinity https://aws.amazon.com/fr/blogs/aws/amazon-s3-object-size-limit/ EBS 64 Tib is per block of storage https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/volume_constraints.html EFS 47.9 TiB per file and in the questions its says Files the ‘s’ https://docs.aws.amazon.com/efs/latest/ug/limits.html 三、S3 Object LockA company needs to store its accounting records in Amazon S3. The records must be immediately accessible for 1 year and then must be archived for an additional 9 years. No one at the company, including administrative users and root users, can be able to delete the records during the entire 10-year period. The records must be stored with maximum resiliency弹性（恢复能力）.Which solution will meet these requirements? Store the records in S3 Glacier for the entire 10-year period. Use an access control policy to deny deletion of the records for a period of 10 years. Store the records by using S3 Intelligent-Tiering. Use an IAM policy to deny deletion of the records. After 10 years, change the IAM policy to allow deletion. ✅ Use an S3 Lifecycle policy to transition the records from S3 Standard to S3 Glacier Deep Archive after 1 year. Use S3 Object Lock in compliance mode for a period of 10 years. Use an S3 Lifecycle policy to transition the records from S3 Standard to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 1 year. Use S3 Object Lock in governance mode for a period of 10 years. ✨ 关键词：be immediately accessible for 1 year、archived for an additional 9 years、no one can delete 3️⃣ ✅ 💡 解析：账号记录存储在 S3 中，第 1 年需要立即可用，之后再归档 9 年，不允许删除。需要使用 S3 生命周期策略来完成标准和归档间的迁移，并使用锁来禁止删除。 使用对象锁定以锁定对象 ​S3 对象锁定可以协助在固定的时间长度内或无限期地阻止删除或覆盖 Amazon S3 对象。对象锁定使用一次写入多次读取（WORM）模式存储对象。您可以使用对象锁定来协助满足需要 WORM 存储的法规要求，或用于添加额外的保护层来防止对象被更改和删除。 👨‍👨‍👦‍👦 社区讨论：Only CD provides Object Lock options which is required for stopping admin/root users from deleting.D is governance mode which is like government, payenough moneyand you can do anything.This is not what we want so compliance is the option.C is right choice. For future, remember S3 Lock Governance = corrupt government official（腐败的政府官员） 在管理模式下，除非用户拥有特殊权限，否则无法覆盖或删除对象版本或更改其锁定设置。使用管理模式，可以防止大多数用户删除对象，但仍可授予某些用户更改保留设置或在必要时删除对象的权限。在创建合规模式保留期之前，还可以使用管理模式测试保留期设置。 S3 Lock Compliance = honest solution architect!（诚实的解决方案架构师！） 在合规模式下，受保护对象版本不能被任何用户覆盖或删除，包括 AWS 账户中的根用户。在合规模式下锁定对象时，不能更改保留模式，也不能缩短保留期。合规模式有助于确保对象版本在保留期内无法被覆盖或删除。 S3 Object Lock 已通过 Cohasset Associates 的评估，符合 SEC 规则 17a-4(f)、FINRA 规则 4511 和 CFTC 条例 1.31。 四、Windows File ServerA company runs multiple Windows workloads on AWS. The company’s employees use Windows file shares that are hosted on two Amazon EC2 instances. The file shares synchronize data between themselves and maintain duplicate copies. The company wants a highly available and durable storage solution that preserves how users currently access the files.What should a solutions architect do to meet these requirements? Migrate all the data to Amazon S3. Set up IAM authentication for users to access files. Set up an Amazon S3 File Gateway. Mount the S3 File Gateway on the existing EC2 instances. ✅ Extend the file share environment to Amazon FSx for Windows File Server with a Multi-AZ configuration. Migrate all the data to FSx for Windows File Server. Extend the file share environment to Amazon ElasticFile System (Amazon EFS) with a Multi-AZ configuration. Migrate all the data to Amazon EFS. ✨ 关键词：Windows workloads、HA、durable 3️⃣ ✅ 💡 解析：有工作负载运行在两台 Windows 实例上，之前使用 Windows 文件共享来同步文件并保留两份备份，希望迁移到高可用持久的存储上。因为使用了 Windows 因此 EFS 不适用，需要选择 Amazon FSx for Windows File Server。 👨‍👨‍👦‍👦 社区讨论：EFS is not supported on Windows instanceshttps://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/AmazonEFS.htmlAmazon FSx for Windows File Server provides fully managed Microsoft Windows file servers, backed bya fully native Windows file system.https://docs.aws.amazon.com/fsx/latest/WindowsGuide/what-is.html 五、Security GroupA solutions architect is developing a VPC architecture that includes multiple subnets. The architecture will host applications that use Amazon EC2 instances and Amazon RDS DB instances. The architecture consists of six subnets in two Availability Zones. Each Availability Zone includes a public subnet, a private subnet, and a dedicated subnet for databases. Only EC2 instances that run in the private subnets can have access to the RDS databases.Which solution will meet these requirements? Create a new route table that excludes the route to the public subnets’ CIDR blocks. Associate the route table with the database subnets. Create a security group that denies inbound traffic from the security group that is assigned to instances in the public subnets. Attach the security group to the DB instances. ✅ Create a security group that allows inbound traffic from the security group that is assigned to instances in the private subnets. Attach the security group to the DB instances. Create a new peering connection between the public subnets and the private subnets. Create a different peering connection between the private subnets and the database subnets. ✨ 关键词：six subnets in two Availability Zones、Each Availability Zone includes a public subnet and a private subnet and a dedicated subnet for databases 3️⃣ ✅ 💡 解析：EC2 和 RDS 分布于总计 2 个可用区 6 个子网，每个可用区有 1 个公有子网、1 个私有子网和 1 个运行数据库的专有子网，只有在私有子网中的 EC2 实例才能访问数据库。问怎样解决这个需求。 首先明确 VPC 是区域级别的，可以跨可用区，而 子网 则无法跨可用区。1️⃣ 创建一个包含前往公有子网 CIDR 块记录的路由表，将这个路由表附加在数据库子网。2️⃣ 创建一个安全组，阻止来自公有子网实例的入站流量，将这个安全组附加在 DB 实例上。3️⃣ 创建一个安全组，允许来自私有子网实例的入站流量，将这个安全组附加在 DB 实例上。4️⃣ 创建一个连接公有子网和私有子网的对等连接，再创建一个对等连接连接私有子网和数据库子网。 1️⃣ 没有意义，数据库子网不需要访问公有子网实例；2️⃣ 错在安全组没有拒绝规则；3️⃣ 更贴合题意，允许来自私有子网实例的连接；4️⃣ 对等连接是 VPC 级别的。 👨‍👨‍👦‍👦 社区讨论：A: doesn’t fully configure the traffic flowB: security groups don’t have deny rulesD: peering is mostly between VPCs, doesn’t really help here 六、API Gateway with doamin and SSLA company has registered its domain name with Amazon Route 53. The company uses Amazon API Gateway in the ca-central-1 Region as a public interface for its backend microservice APIs. Third-party services consume the APIs securely. The company wants to design its API Gateway URL with the company’s domain name and corresponding certificate so that the third-party services can use HTTPS.Which solution will meet these requirements? Create stage variables in API Gateway with Name=”Endpoint-URL” and Value=”Company Domain Name” to overwrite the default URL. Import the public certificate associated with the company’s domain name into AWS Certificate Manager (ACM). ❌ Create Route 53 DNS records with the company’s domain name. Point the alias record to the Regional API Gateway stage endpoint. Import the public certificate associated with the company’s domain name into AWS Certificate Manager (ACM) in the us-east-1 Region. ✅ Create a Regional API Gateway endpoint. Associate the API Gateway endpoint with the company’s domain name. Import the public certificate associated with the company’s domain name into AWS Certificate Manager (ACM) in the same Region. Attach the certificate to the API Gateway endpoint. Configure Route 53 to route traffic to the API Gateway endpoint. Create a Regional API Gateway endpoint. Associate the API Gateway endpoint with the company’s domain name. Import the public certificate associated with the company’s domain name into AWS Certificate Manager (ACM) in the us-east-1 Region. Attach the certificate to the API Gateway APIs. Create Route 53 DNS records with the company’s domain name. Point an A record to the company’s domain name. ✨ 关键词：domain on Amazon Route 53、design its API Gateway URL with the company’s domain name、corresponding certificate 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：让 API Gateway 上的接口使用 Route 53 上的域名，并配置证书开启 HTTPS。这里需要注意 ACM 中的证书是区域级的资源，因此需要首先将 API Gateway 限制在一个区域（或者就是每个区域都配置 SSL 证书）。 什么是 AWS Certificate Manager？ ACM 中的证书属于区域性资源。若要为多个AWS区域中相同的完全限定域名 (FQDN) 或 FQDN 组将证书用于 Elastic Load Balancing，您必须为每个区域请求或导入一个证书。对于 ACM 提供的证书，这意味着您必须重新验证每个区域的证书中的每个域名。您不能在各区域之间复制证书。 在 API Gateway 中设置区域自定义域名 使用区域自定义域名创建用户友好的 API 基本 URL。利用区域自定义域名，您可以将 HTTP 和 REST API 阶段映射到相同的自定义域名并使用双向 TLS 身份验证。 注意事项 您必须提供特定于区域的 ACM 证书。该证书必须与您的 API 位于同一区域。有关创建或上传自定义域名证书的更多信息，请参阅在 AWS Certificate Manager 中准备好证书。 在您创建（或迁移）包含 ACM 证书的区域自定义域名时，API Gateway 会在您的账户中创建一个服务相关角色。需要使用服务相关角色，才能将 ACM 证书附加到您的区域端点。该角色名为 AWSServiceRoleForAPIGateway，将对其附加 APIGatewayServiceRolePolicy 托管策略。有关使用服务相关角色的更多信息，请参阅使用服务相关角色。 创建区域自定义域名后，您必须创建将该自定义域名指向区域域名的“A”型 DNS 记录。这使绑定到自定义域名的流量可以路由到 API 的区域主机名。 👨‍👨‍👦‍👦 社区讨论：The correct solution to meet these requirements is option C.To design the API Gateway URL with the company’s domain name and corresponding certificate, the company needs to do the following: Create a Regional API Gatewayendpoint:This will allow the company to create an endpoint that is specific to a region. Associate the API Gatewayendpoint with the company’s domain name:This will allow the company to use its own domain name for the API Gateway URL. Import the public certificate associated with the company’s domain name into AWS Certificate Manager (ACM) in the same Region:This will allow the company to use HTTPS for secure communication with its APIs. Attach the certificate to the API Gatewayendpoint:This will allow the company to use the certificate for securing the API Gateway URL. Configure Route 53 to route traffic to the API Gatewayendpoint:This will allow the company to use Route 53 to route traffic to the API Gateway URL using the company’s domain name. 七、Amazon Rekognition &amp; Ground TruthA company is running a popular social media website. The website gives users the ability to upload images to share with other users. The company wants to make sure that the images do not contain inappropriate content. The company needs a solution that minimizes development effort.What should a solutions architect do to meet these requirements? Use Amazon Comprehend to detect inappropriate content. Use human review for low-confidence低信心 predictions预测. ✅ Use Amazon Rekognition to detect inappropriate content. Use human review for low-confidence predictions. Use Amazon SageMaker to detect inappropriate content. Use ground truth to label low-confidence predictions. ❌ Use AWS Fargate to deploy a custom machine learning model to detect inappropriate content. Use ground truth to label low-confidence predictions. ✨ 关键词：do not contain inappropriate content、AI 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：社交媒体应用需要确保用户上传的图片不包含隐私信息。使用 AI 进行筛选，之后结合人工进行核实。考点就是各 AWS AI 产品的特性和使用场景。 使用 Amazon G SageMaker round Truth 使用人类训练数据标签 要训练机器学习模型，您需要一个大型、高质量的标注数据集。Ground Truth 有助于您为机器学习模型构建高质量的训练数据集。借助 Ground Truth，您可以将来自 Amazon Mechanical Turk、您选择的供应商公司或内部私有人力资源的工作人员与机器学习相结合，以便创建已标注的数据集。您可以使用从 Ground Truth 输出的已标注数据集来训练自己的模型。您也可以将输出用作 Amazon SageMaker 模型的训练数据集。 Amazon Comprehend（理解）自然语言处理（NLP）服务 Amazon Comprehend使用自然语言处理 (NLP) 来提取有关文档内容的见解。它可以通过识别文档中的实体、关键短语、语言、情绪和其他常见元素生成见解。 Amazon Rekognition 图像识别 Amazon Rekognition 是一项基于云的图像和视频分析服务，可以轻松地向应用程序添加高级计算机视觉功能。 Amazon SageMaker 机器学习面向每位开发人员和数据科学家 Amazon SageMaker 是一项完全托管的服务，可以帮助开发人员和数据科学家快速构建、训练和部署机器学习 (ML) 模型。SageMaker 完全消除了机器学习过程中每个步骤的繁重工作，让开发高质量模型变得更加轻松。 AWS Fargate 适用于容器的无服务器计算 AWS Fargate 是一种无服务器、随用随付的计算引擎，可让您专注于构建应用程序，而无需管理服务器。 👨‍👨‍👦‍👦 社区讨论：The best solution to meet these requirements would be option B: Use Amazon Rekognition to detect inappropriate content, and use human review for low-confidence predictions.Amazon Rekognition isa cloud-based image and video analysis service that can detect inappropriate content in images using its pre-trained label detection model. It can identifya wide range of inappropriate content, including explicit or suggestive adult content, violent content,and offensive language.The service provides high accuracyand low latency, making it a good choice for this use case.","link":"/2024/11/24/saa_test_daily_20241124/"},{"title":"SAA 考试每日练习 - 2024&#x2F;11&#x2F;28","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam15 题 (No.101 ~ No.115)，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： retrievev. 重新得到，收回，取回；检索；挽回，补救｜n. 恢复，取回；检索 indicatev. 显示，表明；暗示；是……的标志，象征 一、Private subnet connect internetA solutions architect is designing a VPC with public and private subnets. The VPC and subnets use IPv4 CIDR blocks. There is one public subnet and one private subnet in each of three Availability Zones (AZs) for high availability. An internet gateway is used to provide internet access for the public subnets. The private subnets require access to the internet to allow Amazon EC2 instances to download software updates.What should the solutions architect do to enable Internet access for the private subnets? ✅ Create three NAT gateways, one for each public subnet in each AZ. Create a private route table for each AZ that forwards non-VPC traffic to the NAT gateway in its AZ. Create three NAT instances, one for each private subnet in each AZ. Create a private route table for each AZ that forwards non-VPC traffic to the NAT instance in its AZ. Create a second internet gateway on one of the private subnets. Update the route table for the private subnets that forward non-VPC traffic to the private internet gateway. Create an egress-only internet gateway on one of the public subnets. Update the route table for the private subnets that forward non-VPC traffic to the egress-only Internet gateway. ✨ 关键词：private subnets require access to the internet 1️⃣ ✅ 💡 解析：同一 VPC 的三个 可用区 中，每个都有一个 公有子网 和一个 私有子网，现在想私有子网的 EC2 实例能够访问互联网进行软件更新。使用 NAT 网关或者 NAT 实例都能解决。NAT 网关和 NAT 实例都需要部署在公有子网中，并在私有子网将流量路由到对应网关或实例。 👨‍👨‍👦‍👦 社区讨论：NAT Instances - OUTDATED BUT CAN STILL APPEAR IN THE EXAM!However, given that A provides the newer option of NAT Gateway, then A is the correct answer.B would be correct if NAT Gateway wasn’t an option. （这里答主就犯了错误，2️⃣ 错在 NAT instances 需要建立在公有子网中）🙋‍♂️ 回复：NAT instance or NAT Gateway always created in public subnet to provide internet access to private subnet. In option B. they are creating NAT Instance in private subnet which is not correct. 二、DataSyncA company wants to migrate an on-premises data center to AWS. The data center hosts an SFTP server that stores its data on an NFS-based file system. The server holds 200 GB of data that needs to be transferred. The server must be hosted on an Amazon EC2 instance that uses an Amazon Elastic File System (Amazon EFS) file system.Which combination of steps should a solutions architect take to automate this task? (Choose two.) Launch the EC2 instance into the same Availability Zone as the EFS file system. ✅ Install an AWS DataSync agent in the on-premises data center. Create a secondary Amazon Elastic Block Store (Amazon EBS) volume on the EC2 instance for the data. Manually use an operating system copy command to push the data to the EC2 instance. ✅ Use AWS DataSync to create a suitable location configuration for the on-premises SFTP server. ✨ 关键词：automate 2️⃣ 5️⃣ ✅ 💡 解析：200 GB 文件存储在基于 NFS 的文件系统上，并通过 SFTP 提供访问。数据需要传输到 AWS，要求最终服务部署在 EC2 实例上并使用 EFS。问如何实现自动化。EFS 是天生跨可用区高可用的，1️⃣ 存在错误（可以选单可用区部署，因此不存在逻辑错误，）。不过这个操作没有那么有必要，多做和少做仅可能对文件传输的速度和质量有些微影响。数据的传输需要使用到 DataSync，2️⃣ 不存在问题。3️⃣ 提到创建一个新的 EBS 卷挂载到 EC2 实例上，没有意义。4️⃣ 手动执行命令将数据推送到 EC2 实例，而 5️⃣ 则在本地 SFTP 服务上配置 DataSync，显然 5️⃣ 可行且更优雅。 确认下 EFS 的知识点：什么是 Amazon Elastic File System？ 这项服务在可扩展性、可用性和持久性方面都十分出众。Amazon EFS 提供以下文件系统类型以满足您的可用性和持久性需求： 区域（推荐）— 区域文件系统（推荐）将数据冗余存储在同一区域内的多个地理位置分开的可用区。 AWS 区域跨多个可用区存储数据可为数据提供持续可用性，即使其中一个或多个可用区不可用 AWS 区域 也是如此。 一个可用区 — 一个区域文件系统将数据存储在单个可用区内。将数据存储在单个可用区可为数据提供持续可用性。但是，在不太可能发生的全部或部分可用区丢失或损坏的情况下，存储在这些类型的文件系统中的数据可能会丢失。 比较令人意外的是 EFS 其实也是可以选单可用区的，那么 1️⃣ 其实就不存在逻辑错误了。 什么是 AWS DataSync？ 以下是 DataSync 的主要使用案例：…… 迁移数据 - 通过网络将活动数据集快速移动到AWS存储服务中。DataSync包括自动加密和数据完整性验证，以帮助确保您的数据安全、完好无损地到达并随时可用。 复制数据 - 将数据复制到任何 Amazon S3 存储类中，根据您的需求选择最具成本效益的存储类别。您还可以将数据发送到亚马逊 EFS、FSx for Windows File Server、适用于 Lustre 的 FsX 或备用文件系统的适用于 OpenZFS 的 FsX。 通过使用 DataSync，您可以获得以下好处：…… 自动移动数据 - DataSync 使通过网络在存储系统和服务之间移动数据变得更加容易。DataSync自动管理数据传输过程和高性能和安全数据传输所需的基础架构。 👨‍👨‍👦‍👦 社区讨论：nswer and HOW-TOB. Install an AWS DataSync agent in the on-premises data center.E. Use AWS DataSync to create a suitable location configuration for the on-premises SFTP server. To automate the process of transferring the data from the on-premises SFTP server to an EC2 instance with an EFS file system, you can use AWS DataSync. AWS DataSync is a fully managed data transfer service that simplifies, automates, and accelerates transferring data between on-premises storage systems and Amazon S3, Amazon EFS, or Amazon FSx for Windows File Server.To use AWS DataSync for this task, you should first install an AWS DataSync agent in the on-premises data center. This agent is a lightweight software application that you install on your on-premises data source. The agent communicates with the AWS DataSync service to transfer data between the data source and target locations. 三、AWS GlueA company has an AWS Glue extract, transform, and load (ETL) job that runs every day at the same time. The job processes XML data that is in an Amazon S3 bucket. New data is added to the S3 bucket every day. A solutions architect notices that AWS Glue is processing all the data during each run.What should the solutions architect do to prevent AWS Glue from reprocessing old data? ✅ Edit the job to use job bookmarks. ❌ Edit the job to delete data after the data is processed. Edit the job by setting the NumberOfWorkers field to 1. Use a FindMatches machine learning (ML) transform. ✨ 关键词：Glue is processing all the data during each run. 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：公司有个 Glue 应用在每天的同一时间进行转换和数据处理工作。处理 S3 存储桶内的 XML 文件并添加回 S3。架构师发现每次 Glue 都处理所有数据，需要做什么来让 Glue 不二次处理旧数据。删除已经处理过的数据似乎是个不错的主意。但是针对 Glue 官方提供了作业书签 (job bookmarks) 来维护状态信息，防止重新处理旧数据。 什么是 AWS Glue？ AWS Glue 是一项无服务器数据集成服务，可让使用分析功能的用户轻松发现、准备、移动和集成来自多个来源的数据。您可以将其用于分析、机器学习和应用程序开发。它还包括用于编写、运行任务和实施业务工作流程的额外生产力和数据操作工具。 通过使用 AWS Glue，您可以发现并连接到 70 多个不同的数据来源，并在集中式数据目录中管理您的数据。您可以直观地创建、运行和监控“提取、转换、加载（ETL）”管道，以将数据加载到数据湖中。此外，您可以使用 Amazon Athena、Amazon EMR 和 Amazon Redshift Spectrum 立即搜索和查询已编目数据。 使用作业书签 (job bookmarks) 跟踪已处理的数据 AWS Glue 通过保存作业运行的状态信息来跟踪上次运行 ETL 作业期间已处理的数据。此持久状态信息称为作业书签。作业书签可帮助 AWS Glue 维护状态信息，并可防止重新处理旧数据。有了作业书签，您可以在按照计划的时间间隔重新运行时处理新数据。作业书签包含作业的各种元素的状态，如源、转换和目标。例如，您的 ETL 任务可能会读取 Amazon S3 文件中的新分区。AWS Glue 跟踪任务已成功处理哪些分区，以防止任务的目标数据存储中出现重复处理和重复数据。 👨‍👨‍👦‍👦 社区讨论：his is the purpose of bookmarks: “AWS Glue tracks data that has already been processed during a previous run of an ETL job by persisting state information from the job run. This persisted state information is called a job bookmark. Job bookmarks help AWS Glue maintain state information and prevent the reprocessing of old data.”https://docs.aws.amazon.com/glue/latest/dg/monitor-continuations.html 四、DDoS attackA solutions architect must design a highly available infrastructure for a website. The website is powered by Windows web servers that run on Amazon EC2 instances. The solutions architect must implement a solution that can mitigate a large-scale DDoS attack that originates from thousands of IP addresses. Downtime is not acceptable for the website.Which actions should the solutions architect take to protect the website from such an attack? (Choose two.) ✅ Use AWS Shield Advanced to stop the DDoS attack. Configure Amazon GuardDuty to automatically block the attackers. ✅ Configure the website to use Amazon CloudFront for both static and dynamic content. Use an AWS Lambda function to automatically add attacker IP addresses to VPC network ACLs. Use EC2 Spot Instances in an Auto Scaling group with a target tracking scaling policy that is set to 80% CPU utilization. ✨ 关键词：HA、Windows web servers、DDoS attack from thousands of IP addresses、Downtime is not acceptable 1️⃣ 3️⃣ ✅ 💡 解析：网页允许在 Windows 服务器上，在来自数千个 IP 发起的 DDoS 攻击下需要不离线。首先使用 Shield Advanced 进行 DDoS 防护是必选项。同时使用 CloudFront 来保护源站 IP 不泄漏也是个不错的选择。社区还有人提到了使用 CloudFront 后流量会被分流到各个地区的边缘节点上，缓解了 DDoS 攻击的压力。 Amazon GuardDuty 通过智能威胁检测，保护您的 AWS 账户、工作负载和数据 Amazon GuardDuty 将 ML 与来自 AWS 和领先第三方的集成威胁情报相结合，帮助保护您的 AWS 账户、工作负载和数据免受威胁侵害。 Amazon GuardDuty 只是威胁检测工具，无法抵御攻击。 👨‍👨‍👦‍👦 社区讨论：I think it is AC, reason is they require a solution that is highly available. AWS Shield can handle the DDoS attacks. To make the solution HA you can use cloud front. AC seems to be the best answer imo.AB seem like redundant answers. How do those answers make the solution HA? CloudFront is a content delivery network (CDN) that integrates with other Amazon Web Services products, such as Amazon S3 and Amazon EC2, to deliver content to users with low latency and high data transfer speeds. By using CloudFront, the solutions architect can distribute the website’s content across multiple edge locations, which can help absorb the impact of a DDoS attack and reduce the risk of downtime for the website. 五、Lambda policyA company is preparing to deploy a new serverless workload. A solutions architect must use the principle of least privilege to configure permissions that will be used to run an AWS Lambda function. An Amazon EventBridge (Amazon CloudWatch Events) rule will invoke the function.Which solution meets these requirements? Add an execution role to the function with lambda:InvokeFunction as the action and * as the principal. Add an execution role to the function with lambda:InvokeFunction as the action and Service: lambda.amazonaws.com as the principal. Add a resource-based policy to the function with lambda:* as the action and Service: events.amazonaws.com as the principal. ✅ Add a resource-based policy to the function with lambda:InvokeFunction as the action and Service: events.amazonaws.com as the principal. ✨ 关键词：PoLP for AWS Lambda function、EventBridge 4️⃣ ✅ 💡 解析：需要在 Lambda 方法上实施最小权限原则，让 EventBridge 能调用它。1️⃣ 是创建角色权限，将动作设置为 lambda:InvokeFunction，主体设置为 。结果是所有人都能调用。2️⃣ 是创建角色权限，将动作设置为 lambda:InvokeFunction，主体设置为 Service: lambda.amazonaws.com。结果是让 lambda 服务自己能调用方法。3️⃣ 是创建资源策略，将动作设置为 lambda:，主体设置为 Service: events.amazonaws.com。让事件对 Lambda 做任何操作。4️⃣ 是创建资源策略，将动作设置为 lambda:InvokeFunction，主体设置为 Service: events.amazonaws.com。让事件能调用方法。显然答案是 4️⃣。 官方给了个一幕一样的样例：AWS Lambda 权限 要使用 EventBridge 规则调用您的 AWS Lambda 函数，请在 Lambda 函数的策略中添加以下权限。 1234567891011121314{ &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: &quot;lambda:InvokeFunction&quot;, &quot;Resource&quot;: &quot;arn:aws:lambda:region:account-id:function:function-name&quot;, &quot;Principal&quot;: { &quot;Service&quot;: &quot;events.amazonaws.com&quot; }, &quot;Condition&quot;: { &quot;ArnLike&quot;: { &quot;AWS:SourceArn&quot;: &quot;arn:aws:events:region:account-id:rule/rule-name&quot; } }, &quot;Sid&quot;: &quot;InvokeLambdaFunction&quot;} 👨‍👨‍👦‍👦 社区讨论：Best way to check it… The question is taken from the example shown here in the documentation:https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-use-resource-based.html#eb-lambda-permissions Why other options are wrongOption A is incorrect because it grants the lambda:InvokeFunction action to any principal (), which would allow any entity to invoke the function and goes beyond the minimum permissions needed.Option B is incorrect because it grants the lambda:InvokeFunction action to the Service: lambda.amazonaws.com principal, which would allow any Lambda function to invoke the function and goes beyond the minimum permissions needed.Option C is incorrect because it grants the lambda: action to the Service: events.amazonaws.com principal, which would allow Amazon EventBridge to perform any action on the function and goes beyond the minimum permissions needed. 六、KMSA company is preparing to store confidential data in Amazon S3. For compliance reasons, the data must be encrypted at rest.Encryption key usage must be logged for auditing purposes. Keys must be rotated every year.Which solution meets these requirements and is the MOST operationally efficient? Server-side encryption with customer-provided keys (SSE-C) Server-side encryption with Amazon S3 managed keys (SSE-S3) Server-side encryption with AWS KMS keys (SSE-KMS) with manual rotation ✅ Server-side encryption with AWS KMS keys (SSE-KMS) with automatic rotation ✨ 关键词：Encryption key usage must be logged 4️⃣ ✅ 💡 解析：重要数据需要加密存储在 S3 上，且加密密钥的使用记录需要被保存，密钥还需要每年轮转。需要效率最高的解决方法。需要引入 KMS 进行密钥轮转和使用记录，然后开启自动轮转。 👨‍👨‍👦‍👦 社区讨论：The MOST operationally efficient one is D.Automating the key rotation is the most efficient.Just to confirm, the A and B options don’t allow automate the rotation as explained here:https://aws.amazon.com/kms/faqs/#:~:text=You%20can%20choose%20to%20have%20AWS%20KMS%20automatically%20rotate%20KMS,KMS%20custom%20key%20store%20feature 七、Data storing and retrievingA bicycle sharing company is developing a multi-tier architecture to track the location of its bicycles during peak operating hours. The company wants to use these data points in its existing analytics platform. A solutions architect must determine the most viable multi-tier option to support this architecture. The data points must be accessible from the REST API.Which action meets these requirements for storing and retrieving检索 location data? Use Amazon Athena with Amazon S3. Use Amazon API Gateway with AWS Lambda. ❌ Use Amazon QuickSight with Amazon Redshift. ✅ Use Amazon API Gateway with Amazon Kinesis Data Analytics. ✨ 关键词：existing analytics platform、data points must be accessible from the REST API 3️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：多层架构跟踪自行车的坐标数据，并使用现有的分析平台进行分析。数据需要能通过 REST API 进行操作。需要兼顾保存和检索的方案。QuickSight 是商业分析服务，Redshift 是数据湖，如果 Redshift 支持 REST API 操作的话，看起来就是四个选项中最优的解决方案。Amazon Kinesis Data Analytics 也是用于数据流分析的，但是和题目中要求的使用现有分析平台冲突了。但是社区的投票比例是 B 为 48%、D 为 45%、A 为 7%，我没法理解。 看起来 API Gateway 在出现 REST API 字眼后就是必须的了，因此可以排除 A 和 C。而再根据要使用现有的分析平台所以可以排除 4️⃣。最终只能选 2️⃣。 争议其实就在数据的存储上，4️⃣ 的支持者倾向于表示 Lambda 不具有数据存储功能。我觉得 4️⃣ 更合理，因为官方明确表示了 Amazon Kinesis Data Analytics 支持数据读取、处理和存储功能：什么是适用于 SQL 应用程序的 Amazon Kinesis Data Analytics？ 通过使用 Amazon Kinesis Data Analytics，您可以快速编写 SQL 代码以使用近乎实时的方式持续读取、处理和存储数据。通过对流数据采用标准 SQL 查询，您可以构建转换数据并深入了解这些数据的应用程序。下面提供了一些使用 Kinesis Data Analytics 的示例方案： 它是在必须使用 API Gateway 情况下的唯一解。 使用 Amazon Redshift 数据 API Amazon Redshift 数据 API 消除了管理数据库驱动程序、连接、网络配置、数据缓冲、凭证等的需求，从而简化了对 Amazon Redshift 数据仓库的访问。您可以通过 AWS SDK，使用数据 API 操作来运行 SQL 语句。 题目归题目，真实场景下我依然会选择使用 Amazon Redshift。 👨‍👨‍👦‍👦 社区讨论：API Gateway is needed to get the data so option A and C are out.“The company wants to use these data points in its existing analytics platform” so there is no need to add Kynesis. Option D is also out.This leaves us with option B as the correct one. 🙅 反对：I dont understand why you will vote B?how are you going to store data with just lambda? Which action meets these requirements for storing and retrieving location data In this use case there will obviously be a ton of data and you want to get real-time location data of the bicycles, and to analyze all these info kinesis is the one that makes most sense here. 八、RDS update and notificationA company has an automobile sales website that stores its listings in a database on Amazon RDS. When an automobile is sold, the listing needs to be removed from the website and the data must be sent to multiple target systems.Which design should a solutions architect recommend? ✅ Create an AWS Lambda function triggered when the database on Amazon RDS is updated to send the information to an Amazon Simple Queue Service (Amazon SQS) queue for the targets to consume. Create an AWS Lambda function triggered when the database on Amazon RDS is updated to send the information to an Amazon Simple Queue Service (Amazon SQS) FIFO queue for the targets to consume. Subscribe to an RDS event notification and send an Amazon Simple Queue Service (Amazon SQS) queue fanned out to multiple Amazon Simple Notification Service (Amazon SNS) topics. Use AWS Lambda functions to update the targets. ❌ Subscribe to an RDS event notification and send an Amazon Simple Notification Service (Amazon SNS) topic fanned out to multiple Amazon Simple Queue Service (Amazon SQS) queues. Use AWS Lambda functions to update the targets. ✨ 关键词：RDS、notification 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：汽车销售数据存在 RDS 中，汽车销售后需要在页面上移除对应条目并将信息发送给多个系统。通知功能符合发布订阅模型，需要使用 SNS。3️⃣ 和 4️⃣ 区别于 SQS 与 SNS 的位置，标准的 Fan Out 是先 SNS 再 SQS，因此选 4️⃣。 社区 2/3 选 1️⃣ 而 1/3 选 4️⃣，争论的重心在 RDS 是否支持数据条目更新的事件类型。列出 Amazon RDS 事件通知类型AWS RDS notification when record is added to a table参照了现有的文档和讨论，官方确实不支持针对数据条目操作的通知事件，因此只能选 1️⃣。不过可以使用 stackoverflow 中评论提到的，监控 RDS 日志的方式来监控数据条目的操作事件。 👨‍👨‍👦‍👦 社区讨论：Interesting point that Amazon RDS event notification doesn’t support any notification when data inside DB is updated.https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Events.overview.html So subscription to RDS events doesn’t give any value for Fanout = SNS =&gt; SQSB is out because FIFO is not required here.A is left as correct answer 九、S3 Legal holdsA company needs to store data in Amazon S3 and must prevent the data from being changed. The company wants new objects that are uploaded to Amazon S3 to remain unchangeable for a nonspecific amount of time until the company decides to modify the objects. Only specific users in the company’s AWS account can have the ability to delete the objects.What should a solutions architect do to meet these requirements? Create an S3 Glacier vault. Apply a write-once, read-many (WORM) vault lock policy to the objects. ❌ Create an S3 bucket with S3 Object Lock enabled. Enable versioning. Set a retention period of 100 years. Use governance mode as the S3 bucket’s default retention mode for new objects. Create an S3 bucket. Use AWS CloudTrail to track any S3 API events that modify the objects. Upon notification, restore the modified objects from any backup versions that the company has. ✅ Create an S3 bucket with S3 Object Lock enabled. Enable versioning. Add a legal hold to the objects. Add the s3:PutObjectLegalHold permission to the IAM policies of users who need to delete the objects. ✨ 关键词：S3、prevent the data from being changed、have the ability to delete the objects 2️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：文件上传到 S3 后需要确保一段时间不能被修改。之后有权限的用户可以删除。使用 S3 Object Lock 的 governance 模式（贪腐的政府官员 - 有权限就能修改文件）可以解决这个问题。 社区在 2️⃣ 和 4️⃣ 间存在争议，4️⃣ 选择人更多。这里涉及到 S3 Object Lock 和 IAM 策略优先级的问题：S3 对象锁定依法保留 您可以将 S3 分批操作与对象锁定一起使用，以便同时添加对很多 Amazon S3 对象的依法保留。为此，请在清单中指定目标对象的列表，并将该列表提交给批量操作。S3 批量操作对象锁定法定保留任务将持续运行，直至完成、取消或达到失败状态。 在处理清单中的任何对象之前，S3 批量操作会验证是否已在您的 S3 存储桶上启用对象锁定。要执行对象操作和存储桶级别验证，S3 批量操作需要 AWS Identity and Access Management（IAM）角色中的 s3:PutObjectLegalHold 和 s3:GetBucketObjectLockConfiguration。这些权限可让 S3 批量操作代表您调用 S3 对象锁定。 上面的文章有点绕，来看下更直接的：使用对象锁定以锁定对象 依法保留 (Legal holds)使用对象锁定，您还可以在对象版本上实施依法保留。与保留期限相似，依法保留可防止对象版本被覆盖或删除。但是，依法保留没有关联的固定时间长度，会一直有效，直至删除。拥有 s3:PutObjectLegalHold 权限的任何用户均可自由实施和删除依法保留。 可以看到依法保留 (Legal holds) 完美符合题目要求：不定时的永久锁定存储、拥有权限的用户可以自由删除。 👨‍👨‍👦‍👦 社区讨论：A - No as “specific users can delete”B - No as “nonspecific amount of time”C - No as “prevent the data from being change”D - The answer: “The Object Lock legal hold operation enables you to place a legal hold on an object version. Like setting a retention period, a legal hold prevents an object version from being overwritten or deleted. However, a legal hold doesn’t have an associated retention period and remains in effect until removed.”https://docs.aws.amazon.com/AmazonS3/latest/userguide/batch-ops-legal-hold.html 十、Reduce couplingA social media company allows users to upload images to its website. The website runs on Amazon EC2 instances. During upload requests, the website resizes the images to a standard size and stores the resized images in Amazon S3. Users are experiencing slow upload requests to the website.The company needs to reduce coupling within the application and improve website performance. A solutions architect must design the most operationally efficient process for image uploads.Which combination of actions should the solutions architect take to meet these requirements? (Choose two.) Configure the application to upload images to S3 Glacier. ✅ Configure the web server to upload the original images to Amazon S3. Configure the application to upload images directly from each user’s browser to Amazon S3 through the use of apresigned URL ✅ Configure S3 Event Notifications to invoke an AWS Lambda function when an image is uploaded. Use the function to resize the image. Create an Amazon EventBridge (Amazon CloudWatch Events) rule that invokes an AWS Lambda function on a schedule to resize uploaded images. ✨ 关键词：reduce coupling 2️⃣ 4️⃣ ✅ 💡 解析：用户将图片上传至社交媒体网站，针对这个上传请求，应用程序重新设置大小然后存到 S3 中。用户上传很慢，公司需要解耦。首先考虑使用 SQS 异步处理图片上传和处理工作，但是没有这个选项。有一个先存储原始图片，再通过事件通知调用 Lambda 函数处理图片的方法，看上去也可行。 社区中选 3️⃣ 的很多：通过预签名 URL 让用户之间把文件上传到 S3 存储桶中绕过后端。但是预签名 URL 的使用场景是临时：使用预签名 URL 下载和上传对象 您可以使用预签名 URL 授予对 Amazon S3 中对象的限时访问权限，而不更新存储桶策略。可以在浏览器中输入预签名 URL，或者程序使用预签名 URL 来下载对象。预签名 URL 使用的凭证是生成该 URL 的 AWS 用户的凭证。 在公开的网页上提供自动生成的 S3 存储桶预签名 URL 供客户使用，在安全方面绝对不是一个好主意。 👨‍👨‍👦‍👦 社区讨论：To meet the requirements of reducing coupling within the application and improving website performance, the solutions architect should consider taking the following actions:C. Configure the application to upload images directly from each user’s browser to Amazon S3 through the use of a pre-signed URL. This will allow the application to upload images directly to S3 without having to go through the web server, which can reduce the load on the web server and improve performance.D. Configure S3 Event Notifications to invoke an AWS Lambda function when an image is uploaded. Use the function to resize the image. This will allow the application to resize images asynchronously, rather than having to do it synchronously during the the image. This will allow the application to resize images asynchronously, rather than having to do it synchronously during the upload request, which can improve performance. 十一、HA for MQ applicationA company recently migrated a message processing system to AWS. The system receives messages into an ActiveMQ queue running on an Amazon EC2 instance. Messages are processed by a consumer application running on Amazon EC2. The consumer application processes the messages and writes results to a MySQL database running on Amazon EC2. The company wants this application to be highly available with low operational complexity.Which architecture offers the HIGHEST availability? Add a second ActiveMQ server to another Availability Zone. Add an additional consumer EC2 instance in another Availability Zone. Replicate the MySQL database to another Availability Zone. Use Amazon MQ with active/standby brokers configured across two Availability Zones. Add an additional consumer EC2 instance in another Availability Zone. Replicate the MySQL database to another Availability Zone. Use Amazon MQ with active/standby brokers configured across two Availability Zones. Add an additional consumer EC2 instance in another Availability Zone. Use Amazon RDS for MySQL with Multi-AZ enabled. ✅ Use Amazon MQ with active/standby brokers configured across two Availability Zones. Add an Auto Scaling group for the consumer EC2 instances across two Availability Zones. Use Amazon RDS for MySQL with Multi-AZ enabled. ✨ 关键词：ActiveMQ、MySQL database running on Amazon EC2、HA 4️⃣ ✅ 💡 解析：现有架构是自建的 MQ 和自建的数据库，消费者也运行在 EC2 上。公司希望新架构高可用且更少操作。使用 AWS 提供的 Amazon MQ 和 RDS 可以解决问题，4️⃣ 还部署了弹性 EC2 组，更全面。 Amazon MQ 面向开源消息代理的完全托管式服务 消息代理允许软件系统（通常在各种平台上使用不同编程语言）进行通信和交换信息。Amazon MQ 是一种适用于 Apache ActiveMQ 和 RabbitMQ 的托管式消息代理服务，可简化 AWS 上消息代理的设置、操作和管理。只需几个步骤，Amazon MQ 便可为您的消息代理预置软件版本升级支持。 👨‍👨‍👦‍👦 社区讨论：Answer is D as the “HIGHEST available” and less “operational complex”The “Amazon RDS for MySQL with Multi-AZ enabled” option excludes A and BThe “Auto Scaling group” is more available and reduces operational complexity in case of incidents (as remediation it is automated) than just adding one more instance. This excludes C.C and D to choose from based onD over C since is configured 十二、Container Auto SaclingA company hosts a containerized web application on a fleet of on-premises servers that process incoming requests. The number of requests is growing quickly. The on-premises servers cannot handle the increased number of requests. The company wants to move the application to AWS with minimum code changes and minimum development effort.Which solution will meet these requirements with the LEAST operational overhead? ✅ Use AWS Fargate on Amazon Elastic Container Service (Amazon ECS) to run the containerized web application with Service Auto Scaling. Use an Application Load Balancer to distribute the incoming requests. Use two Amazon EC2 instances to host the containerized web application. Use an Application Load Balancer to distribute the incoming requests. Use AWS Lambda with a new code that uses one of the supported languages. Create multiple Lambda functions to support the load. Use Amazon API Gateway as an entry point to the Lambda functions. Use a high performance computing (HPC) solution such as AWS ParallelCluster to establish an HPC cluster that can process the incoming requests at the appropriate scale. ✨ 关键词：containerized 1️⃣ ✅ 💡 解析：容器化的 Web 应用访问量激增且需要迁移到 AWS。最少的代码改修和开发影响。还需要支持弹性扩容。既然已经容器化了，那么迁移就和 ECS 或 EKS 有关了，需要弹性扩容的话 AWS Fargate 就能简单实现。 👨‍👨‍👦‍👦 社区讨论：Less operational overhead means A: Fargate (no EC2), move the containers on ECS, autoscaling for growth and ALB to balance consumption.B - requires configure EC2C - requires add code (developpers)D - seems like the most complex approach, like re-architecting the app to take advantage of an HPC platform. 十三、AWS Snow Family and GlueA company uses 50 TB of data for reporting. The company wants to move this data from on premises to AWS. A custom application in the company’s data center runs a weekly data transformation job. The company plans to pause the application until the data transfer is complete and needs to begin the transfer process as soon as possible.The data center does not have any available network bandwidth for additional workloads. A solutions architect must transfer the data and must configure the transformation job to continue to run in the AWS Cloud.Which solution will meet these requirements with the LEAST operational overhead? Use AWS DataSync to move the data. Create a custom transformation job by using AWS Glue. Order an AWS Snowcone device to move the data. Deploy the transformation application to the device. ✅ Order an AWS Snowball Edge Storage Optimized device. Copy the data to the device. Create a custom transformation job by using AWS Glue. ❌ Order an AWS Snowball Edge Storage Optimized device that includes Amazon EC2 compute. Copy the data to the device. Create a new EC2 instance on AWS to run the transformation application. ✨ 关键词：50 TB of data、not have any available network bandwidth for additional workloads、transformation job to continue to run in the AWS Cloud 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：50 TB 的本地数据需要传输到 AWS。本地还有一个每周运行到任务需要使用到这些数据，公司计划暂停这个应用直到数据传输完成。之后这个处理程序也要部署到 AWS。需要最简单的解决方案。网络不好不使用 DataSync。Snowcone 最大只支持 14 TB 不够容量。50 TB 的数据使用一台 Snowball Edge 设备就够了。3️⃣ 和 4️⃣ 对数据的处理方式不同。3️⃣ 选择使用 AWS Glue 数据集成（收集和移动）工具，并不支持数据转换支持数据转换。4️⃣ 将应用程序部署到 EC2 上，合理但是操作更多。 什么是 AWS Glue？ AWS Glue 是一项无服务器数据集成服务，可让使用分析功能的用户轻松发现、准备、移动和集成来自多个来源的数据。您可以将其用于分析、机器学习和应用程序开发。它还包括用于编写、运行任务和实施业务工作流程的额外生产力和数据操作工具。 With AWS Glue, you can discover and connect to more than 70 diverse data sources and manage your data in a centralized data catalog. You can visually create, run, and monitor extract, transform, and load (ETL) pipelines to load data into your data lakes. Also, you can immediately search and query cataloged data using Amazon Athena, Amazon EMR, and Amazon Redshift Spectrum. 什么是 ETL（提取、转换、加载）？ 提取 (Extract)、转换 (Transform)、加载 (Load) 过程将多个来源的数据组合到称为数据仓库的大型中央存储库中。ETL 使用一组业务规则来清理和组织原始数据，并为存储、数据分析和机器学习（ML）做好准备。您可以通过数据分析满足特定的商业智能需求（例如预测业务决策的结果、生成报告和控制面板、减少无效运营等）。 👨‍👨‍👦‍👦 社区讨论：A. Use AWS DataSync to move the data. Create a custom transformation job by using AWS Glue. - No BW available for DataSync, so “asap” will be weeks/months (?)B. Order an AWS Snowcone device to move the data. Deploy the transformation application to the device. - Snowcone will just store 14TB (SSD configuration).C. Order an AWS Snowball Edge Storage Optimized device. Copy the data to the device. Create a custom transformation job by using AWS Glue. - SnowBall can store 80TB (ok), takes around 1 week to move the device (faster than A), and AWS Glue allows to do ETL jobs. This is the answer.D. Order an AWS Snowball Edge Storage Optimized device that includes Amazon EC2 compute. Copy the data to the device. Create a new EC2 instance on AWS to run the transformation application. - Same as C, but the ETL job requires the deployment/configuration/maintenance of an EC2 instance, while Glue is serverless. This means D has more operational overhead than C. 十四、ScaleA company has created an image analysis application in which users can upload photos and add photo frames to their images.The users upload images and metadata to indicate显示 which photo frames they want to add to their images. The application uses a single Amazon EC2 instance and Amazon DynamoDB to store the metadata.The application is becoming more popular, and the number of users is increasing. The company expects the number of concurrent users to vary significantly depending on the time of day and day of week. The company must ensure that the application can scale to meet the needs of the growing user base.Which solution meats these requirements? Use AWS Lambda to process the photos. Store the photos and metadata in DynamoDB. Use Amazon Kinesis Data Firehose to process the photos and to store the photos and metadata. ✅ Use AWS Lambda to process the photos. Store the photos in Amazon S3. Retain DynamoDB to store the metadata. Increase the number of EC2 instances to three. Use Provisioned IOPS SSD (io2) Amazon Elastic Block Store (Amazon EBS) volumes to store the photos and metadata. ✨ 关键词：scale 3️⃣ ✅ 💡 解析：处理图片的应用程序由 EC2 + DynamoDB 构成，用户数量开始增多，需要弹性的解决方案。可以使用 Lambda 完成图片处理，然后由 S3 存储，元数据保存在 DynamoDB 中。 👨‍👨‍👦‍👦 社区讨论：Solution C offloads the photo processing to Lambda. Storing the photos in S3 ensures scalability and durability, while keeping the metadata in DynamoDB allows for efficient querying of the associated information.Option A does not provide an appropriate solution for storing the photos, as DynamoDB is not suitable for storing large binary data like images.Option B is more focused on real-time streaming data processing and is not the ideal service for processing and storing photos and metadata in this use case.Option D involves manual scaling and management of EC2 instances, which is less flexible and more labor-intensive compared to the serverless nature of Lambda. It may not efficiently handle the varying number of concurrent users and can introduce higher operational overhead. In conclusion, option C provides the best solution for scaling the application to meet the needs of the growing user base by leveraging the scalability and durability of Lambda, S3, and DynamoDB. 十五、Gateway endpointA medical records company is hosting an application on Amazon EC2 instances. The application processes customer data files that are stored on Amazon S3. The EC2 instances are hosted in public subnets. The EC2 instances access Amazon S3 over the internet, but they do not require any other network access.A new requirement mandates that the network traffic for file transfers take a private route and not be sent over the internet.Which change to the network architecture should a solutions architect recommend to meet this requirement? Create a NAT gateway. Configure the route table for the public subnets to send traffic to Amazon S3 through the NAT gateway. Configure the security group for the EC2 instances to restrict outbound traffic so that only traffic to the S3 prefix list is permitted. ✅ Move the EC2 instances to private subnets. Create a VPC endpoint for Amazon S3, and link the endpoint to the route table for the private subnets. Remove the internet gateway from the VPC. Set up an AWS Direct Connect connection, and route traffic to Amazon S3 over the Direct Connect connection. ✨ 关键词：private route to S3 3️⃣ ✅ 💡 解析：目前 EC2 不需要联网，但是 EC2 和 S3 通过公有网络进行连接，现在要求改走内网。先把 EC2 移动到私有子网或者移除当前子网路由表中对公网的路由记录，然后再在 VPC 级别部署网关终端节点使实例能够访问 S3。 👨‍👨‍👦‍👦 社区讨论：Option A (creating a NAT gateway) would not meet the requirement since it still involves sending traffic to S3 over the internet.NAT gateway is used for outbound internet connectivity from private subnets, but it doesn’t provide a private route for accessing S3. Option B (configuring security groups) focuses on controlling outbound traffic using security groups. While it can restrict outbound traffic, it doesn’t provide a private route for accessing S3. Option D (setting up Direct Connect) involves establishing a dedicated private network connection between the on-premises environment and AWS. While it offers private connectivity, it is more suitable for hybrid scenarios and not necessary for achieving private access to S3 within the VPC. In summary, option C provides a straightforward solution by moving the EC2 instances to private subnets, creating a VPC endpoint for S3, and linking the endpoint to the route table for private subnets. This ensures that file transfer traffic between the EC2 instances and S3 remains within the private network without going over the internet.","link":"/2024/11/28/saa_test_daily_20241128/"},{"title":"SAA 考试每日练习 - 2024&#x2F;11&#x2F;29","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam65 题 (No.116 ~ No.180) 只记录了 16 道错题，仅供自己复习使用。与正式考试题量一样，总共耗时 92/(130+30) 分钟，正确率为 49/65。如果侵权请联系删除。 🌟 单词： associatev. 联系，联想 | n. 同事；合作人；伙伴 | adj. （等级或头衔）副的；准的 stagen. 阶段；舞台；步，步骤；驿站 | v. 举行，上演，举办，组织 moving forward前进，推动 underlyingadj. 根本的，潜在的，隐含的，表面下的 monolithicadj. 庞大的, 巨石的, 整体(式)的, 铁板一块的 moderateadj. 适度的；温和的；中等的 | v. 变缓和；变弱；节制；减轻；主持（讨论、辩论等） | n. 持温和政见者 steadyadj. 稳定的，稳固的，沉稳的，可靠的；持续的，规则的 | v. （使）稳固，（使）稳定 metricadj. 米制的，公制的，按公制制作的，用公制测量的 | n. 衡量标准；度量；米制单位 compositen. 合成物；混合物；复合材料 | adj. 合成的；混成的；复合的 thresholdn. 门槛，门口；阈，界；起点，临界点 employeesn. 雇员，受雇者，雇工 compliancen. 遵从，顺从，服从 detectv. 测出；发现，查明 gainv. 获得，增加，赢得，取得 | n. 增加，利益，好处，利润 consolidatev. 巩固，加强；联合，统一 paralleladj. 平行的，并列的 | v. 与……同时发生；与……相似；与…媲美；比得上 | n. 平行线，极其相似的人（或情况、事件等） 一、WAF across multiple accountsA global company is using Amazon API Gateway to design REST APIs for its loyalty club users in the us-east-1 Region and the ap-southeast-2 Region. A solutions architect must design a solution to protect these API Gateway managed REST APIs across multiple accounts from SQL injection and cross-site scripting attacks.Which solution will meet these requirements with the LEAST amount of administrative effort? ❌ Set up AWS WAF in both Regions. Associate Regional web ACLs with an API stage. ✅ Set up AWS Firewall Manager in both Regions. Centrally configure AWS WAF rules. Set up AWS Shield in bath Regions. Associate Regional web ACLs with an API stage. Set up AWS Shield in one of the Regions. Associate Regional web ACLs with an API stage. ✨ 关键词：across multiple accounts、SQL injection、cross-site scripting attacks 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：使用 API Gateway 部署了 REST API 提供给两个区域，需要保护 API 不被 SQL 注入和跨站访问攻击。针对攻击 WAF 是肯定需要使用的，而 1️⃣ 和 2️⃣ 的差异在于：跨区域是通过手动联系还是通过 AWS Firewall Manager。 先看下 AWS Firewall Manager：AWS Firewall Manager 什么是 AWS Firewall Manager？AWS Firewall Manager 简化了多个账户和资源的管理和维护任务，包括 AWS WAF、AWS Shield Advanced、Amazon VPC 安全组和网络 ACL、AWS Network Firewall 和 Amazon Route 53 Resolver DNS Firewall，以提供各种保护。使用 Firewall Manager 一次设置好保护措施，该服务就会自动将其应用于您的账户和资源，即使添加新资源和账户时也是如此。 Firewall Manager 提供了以下优势： 有助于跨账户保护资源 有助于保护某个特定类型的所有资源，如所有 Amazon CloudFront 分配 有助于保护带特定标签的所有资源 自动向已添加到您账户的资源添加防护 允许您让 AWS Organizations 组织中的所有成员账户订阅 AWS Shield Advanced，并自动让新加入组织的范围内账户进行订阅 允许您将安全组规则应用到 AWS Organizations 组织中的所有成员账户或特定账户子集，并自动将这些规则应用到新加入组织的范围内账户 允许您使用自己的规则，或者从 AWS Marketplace 购买托管规则 如果要保护整个组织而不是少数特定账户和资源，或者经常添加要保护的新资源，Firewall Manager 尤其有用。Firewall Manager 还可对整个组织的 DDoS 攻击进行集中监控。 看上去 AWS Firewall Manager 就是这题的考点，“跨账号”、“保护某个特定类型的所有资源（跨区域）”。 👨‍👨‍👦‍👦 社区讨论：If you want to use AWS WAF acrossaccounts,accelerate WAF configuration, automate the protection of new resources, use Firewall Manager with AWS WAF Using AWS WAF has several benefits. Additional protection against web attacks using criteria that you specify. You can define criteria using characteristics of web requests such as the following: Presence of SQL code that is likely to be malicious (known asSQL injection). Presence of a script that is likely to be malicious (known as cross-site scripting). AWS Firewall Manager simplifies your administration and maintenance tasksacross multiple accountsand resources for a variety of protections.https://docs.aws.amazon.com/waf/latest/developerguide/what-is-aws-waf.html 二、DNSA company has implemented a self-managed DNS solution on three Amazon EC2 instances behind a Network Load Balancer (NLB) in the us-west-2 Region. Most of the company’s users are located in the United States and Europe. The company wants to improve the performance and availability of the solution. The company launches and configures three EC2 instances in the eu-west-1 Region and adds the EC2 instances as targets for a new NLB.Which solution can the company use to route traffic to all the EC2 instances? ❌ Create an Amazon Route 53 geolocation routing policy to route requests to one of the two NLBs. Create an Amazon CloudFront distribution. Use the Route 53 record as the distribution’s origin. ✅ Create a standard accelerator in AWS Global Accelerator. Create endpoint groups in us-west-2 and eu-west-1. Add the two NLBs as endpoints for the endpoint groups. Attach Elastic IP addresses to the six EC2 instances. Create an Amazon Route 53 geolocation routing policy to route requests to one of the six EC2 instances. Create an Amazon CloudFront distribution. Use the Route 53 record as the distribution’s origin. Replace the two NLBs with two Application Load Balancers (ALBs). Create an Amazon Route 53 latency routing policy to route requests to one of the two ALBs. Create an Amazon CloudFront distribution. Use the Route 53 record as the distribution’s origin. ✨ 关键词：DNS、two regions 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：NLB 后多台实例上运行着 DNS 应用，公司用户在美国和欧洲。现在为了改善性能和可用性，在 eu-west-1 区域新增了 3 台实例，并且要为它们配置新的 NLB。问怎么路由流量到两个区域。首先明确 DNS 是既使用 TCP 也使用 UDP 协议的，不过在这其中，使用最多的 DNS 的 A 记录、CNAME 记录查询都是用的是 UDP 协议。为什么 DNS 使用 UDP 协议 实际上，DNS 不仅使用了 UDP 协议，也使用了 TCP 协议，不过在具体介绍今天的问题之前，我们还是要对 DNS 协议进行简单的介绍：DNS 查询的类型不止包含 A 记录、CNAME 记录等常见查询，还包含 AXFR 类型的特殊查询，这种特殊查询主要用于 DNS 区域传输，它的作用就是在多个命名服务器之间快速迁移记录，由于查询返回的响应比较大，所以会使用 TCP 协议来传输数据包。 但是 CloudFront 只能对 HTTP 和 HTTPS 协议的请求进行处理：协议 CloudFront 基于以下将 HTTP 或 HTTPS 请求转发到源服务器： 查看器发送到 CloudFront 的请求的协议（HTTP 或 HTTPS）。 CloudFront 控制台中源协议策略的值，或者，如果您使用 CloudFront API，则为 OriginProtocolPolicy复杂型中的 DistributionConfig 元素。在 CloudFront 控制台中，选项包括仅 HTTP、仅 HTTPS 和匹配查看器。如果您指定仅 HTTP 或仅 HTTPS，则 CloudFront 仅使用指定的协议将请求转发到源服务器，而不考虑查看器请求中的协议。 如果您指定匹配查看器，则 CloudFront 将使用查看器请求中的协议将请求转发到源服务器。请注意，CloudFront 仅缓存对象一次，即使查看器使用 HTTP 和 HTTPS 协议发出请求。 因此 1️⃣ 存在错误。而 AWS Global Accelerator 则明确支持 DNS 的协议并且拥有路由用户到最近区域终端节点的功能：什么是 AWS Global Accelerator？ AWS Global Accelerator 是一项服务，您可以在其中创建加速器，以提高本地和 Global 用户的应用程序的性能。根据您选择的加速器的类型，您可以获得额外的好处。 通过使用标准加速器，您可以提高全球受众使用的 Internet 应用程序的可用性。使用标准加速器，全球加速器将 AWS 全球网络的流量引导到离客户端最近的区域中的终端节点。 通过使用自定义路由加速器，您可以将一个或多个用户映射到多个目标之间的特定目标。 AWS Global Accelerator 支持哪些协议？ AWS Global Accelerator 支持 TCP 和 UDP 协议。 同时在官方的文档中，AWS Global Accelerator 也是推荐的 DNS 寻址解决方案：Support for DNS addressing in AWS Global Accelerator，因此选 2️⃣。 👨‍👨‍👦‍👦 社区讨论：B is the correct one for seld manage DNSIf need to use Route53, ALB (layar 7 ) needs to be used asend points for 2 reginal x 3 EC2s, if it the case answer would be the option 4 三、Encrypt RDS DB instanceA company is running an online transaction processing (OLTP) workload on AWS. This workload uses an unencrypted Amazon RDS DB instance in a Multi-AZ deployment. Daily database snapshots are taken from this instance.What should a solutions architect do to ensure the database and snapshots are always encrypted moving forward推动? ✅ Encrypt a copy of the latest DB snapshot. Replace existing DB instance by restoring the encrypted snapshot. Create a new encrypted Amazon Elastic Block Store (Amazon EBS) volume and copy the snapshots to it. Enable encryption on the DB instance. ❌ Copy the snapshots and enable encryption using AWS Key Management Service (AWS KMS) Restore encrypted snapshot to an existing DB instance. Copy the snapshots to an Amazon S3 bucket that is encrypted using server-side encryption with AWS Key Management Service (AWS KMS) managed keys (SSE-KMS). ✨ 关键词：database and snapshots are always encrypted moving forward 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：目前 RDS 数据库实例未加密。需要数据库和快照加密。首选 RDS 数据库在创建的时候是可以选择加密选项的：加密 Amazon RDS 资源 Amazon RDS 可以加密您的 Amazon RDS 数据库实例。静态加密的数据包括数据库实例的基础存储、其自动化备份、只读副本和快照。 加密数据库实例要加密新数据库实例，请在 Amazon RDS 控制台上，选择 Enable encryption（启用加密）。想要了解有关创建数据库实例的信息，请参阅创建 Amazon RDS 数据库实例。创建加密的数据库实例后，您无法更改该数据库实例使用的 KMS 密钥。因此，请确保先确定您的 KMS 密钥要求，然后再创建加密的数据库实例。 Amazon RDS 加密的数据库实例的限制 您只能在创建 Amazon RDS 数据库实例时而不是创建该数据库实例之后加密该数据库实例。 不过，由于您可以加密未加密快照的副本，因此，您可以高效地为未加密的数据库实例添加加密。也就是说，您可以创建数据库实例快照，然后创建该快照的加密副本。然后，您可以从加密快照还原数据库实例，从而获得原始数据库实例的加密副本。有关更多信息，请参阅 复制 Amazon RDS 的数据库快照。 您无法在加密的数据库实例上关闭加密。 您无法创建未加密数据库实例的加密快照。 您不能将未加密的备份或快照还原到加密的数据库实例。 …… 但是就和文档描述的一样，不支持在数据库创建后再进行加密、解密或者密钥更改等操作。只有创建数据库快照后，加密快照，再重建数据库来替换当前数据库这一条路可以走。3️⃣ 错在不能将快照恢复到现有的数据库中。 👨‍👨‍👦‍👦 社区讨论：”You can enable encryption for an Amazon RDS DB instance when you create it, but not after it’s created. However, you can add encryption to an unencrypted DB instance by creating a snapshot of your DB instance,and then creating an encrypted copy of that snapshot. You can then restore a DB instance from the encrypted snapshot to get an encrypted copy of your original DBinstance.”https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/encrypt-an-existing-amazon-rds-for-postgresql-db-instance.html 四、Amazon RDS Custom for OracleA company runs an Oracle database on premises. As part of the company’s migration to AWS, the company wants to upgrade the database to the most recent available version. The company also wants to set up disaster recovery (DR) for the database.The company needs to minimize the operational overhead for normal operations and DR setup. The company also needs to maintain维护 access to the database’s underlying潜在的，根本的 operating system.Which solution will meet these requirements? Migrate the Oracle database to an Amazon EC2 instance. Set up database replication to a different AWS Region. ❌ Migrate the Oracle database to Amazon RDS for Oracle. Activate Cross-Region automated backups to replicate the snapshots to another AWS Region. ✅ Migrate the Oracle database to Amazon RDS Custom for Oracle. Create a read replica for the database in another AWS Region. Migrate the Oracle database to Amazon RDS for Oracle. Create a standby database in another Availability Zone. ✨ 关键词：can access to the database’s underlying operating system 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：自建 Oracle 数据库要迁移到 AWS，要求能控制数据库底层的操作系统。那能操作底层操作系统的话，托管的 Amazon RDS for Oracle 就不适用了，只能将现有的 Oracle 迁移到 EC2 实例中或使用 Amazon RDS Custom for Oracle。 宣告 Amazon RDS Custom for Oracle Amazon Relational Database Service (Amazon RDS) Custom 是一个托管式数据库服务，用于需要访问底层操作系统和数据库环境的旧式、自定义和打包应用程序。Amazon RDS Custom 当前可用于 Oracle 数据库引擎。Amazon RDS Custom for Oracle 可在云中自动设置、操作和扩缩数据库，同时授予对数据库和底层操作系统的访问权限，以配置设置、安装补丁和启用本机功能以满足相关应用程序的要求。 显然考点就是这个服务。同时它在迁移方面似乎也有一定优势：RDS Custom 的主要益处 在将本地数据库移动到完全托管式服务之前，将其暂存。 如果您管理自己的本地数据库，则可以按原样将数据库暂存到 RDS Custom。熟悉云环境后，您可以将数据库迁移到完全托管式 Amazon RDS 数据库实例。 并且 Amazon RDS for Oracle 的副本操作与 Amazon RDS 相似，这意味着它也是支持只读副本和升级的：Working with Oracle replicas for RDS Custom for Oracle You can create Oracle replicas for RDS Custom for Oracle DB instances that run Oracle Enterprise Edition. Both container databases (CDBs) and non-CDBs are supported. Standard Edition 2 doesn’t support Oracle Data Guard. Creating an RDS Custom for Oracle replica is similar to creating an RDS for Oracle replica, but with important differences. For general information about creating and managing Oracle replicas, see Working with DB instance read replicas and Working with read replicas for Amazon RDS for Oracle. 👨‍👨‍👦‍👦 社区讨论：Option C since RDS Custom hasaccess to the underlying OS and it provides less operational overhead. Also,a read replica in another Region can be used for DR activities.https://aws.amazon.com/blogs/database/implementing-a-disaster-recovery-strategy-with-amazon-rds/ 五、S3 encryption and Cross-Region ReplicationA company wants to move its application to a serverless solution. The serverless solution needs to analyze existing and new data by using SL. The company stores the data in an Amazon S3 bucket. The data requires encryption and must be replicated to a different AWS Region.Which solution will meet these requirements with the LEAST operational overhead? ✅ Create a new S3 bucket. Load the data into the new S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with AWS KMS multi-Region keys (SSE-KMS). Use Amazon Athena to query the data. Create a new S3 bucket. Load the data into the new S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with AWS KMS multi-Region keys (SSE-KMS). Use Amazon RDS to query the data. ❌ Load the data into the existing S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Use Amazon Athena to query the data. Load the data into the existing S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Use Amazon RDS to query the data. ✨ 关键词： 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：新的架构需要通过 SL (Security Lake)（或 ML 机器学习）分析既存的和新的数据。数据存储在 S3 中。数据需要加密并备份到另一个区域。要求最少操作。直接来看争议较大的 1️⃣ 和 3️⃣ 的区别吧： 1️⃣ 选择新建存储桶，并且加密使用 AWS KMS multi-Region keys (SSE-KMS) 3️⃣ 将数据加载到现有存储桶中，并且加密采用 Amazon S3 managed encryption keys (SSE-S3) 首先确认下 KMS 是否支持跨区域的密钥：AWS KMS 中的多区域密钥 AWS KMS 支持多区域密钥，它们不同 AWS 区域 中可以互换使用的 AWS KMS keys，就好像您在多个区域中拥有相同的密钥一样。每组相关多区域密钥均具有相同的密钥材料和密钥 ID，因此您可以在一个 AWS 区域 中将数据加密并将其解密到不同 AWS 区域 中，而无需重新加密或跨区域调用 AWS KMS。 显然是支持的，这使得再多个可用区用同一份密钥加密 S3 存储桶成为了可能。 对 Amazon S3 managed encryption keys 是否支持跨区域密钥我并没有找到详细资料，如果之后再碰到会考虑做下实践。但是将数据加载到现有存储桶再开启 S3 加密的方式总是错误的，这会导致当前已经在存储桶中文件处于不加密状态，在现实操作中不会采取 3️⃣ 这种方案。 👨‍👨‍👦‍👦 社区讨论：SSE-KMS vsSSE-S3 - The last seems to have less overhead (as the keysare automatically generated byS3 and applied on data at upload,and don’t require further actions. KMS provides more flexibility, but in turn involvesa different service, which finally is more “complex” than just managing one (S3).So A and B are excluded. If you are in doubt, you are having 2 buckets in A and B, while just keeping one in C and D.https://s3browser.com/server-side-encryption-types.aspx 🙅 反对：Amazon S3 Bucket Keys reduce the cost of Amazon S3 server-side encryption using AWS Key ManagementService (SSE-KMS).This new bucket-level key forSSE can reduce AWS KMS request costs by up to 99 percent by decreasing the request traffic from Amazon S3 to AWS KMS. With a few clicks in the AWS Management Console,and without any changes to your client applications, you can configure your bucket to use an S3 Bucket Key for AWS KMS-based encryption on new objects.The Existing S3 bucket might have uncrypted data - encryption will apply new data received after the applying of encryption on the new bucket. 六、AWS PrivateLinkA company runs workloads on AWS. The company needs to connect to a service from an external provider. The service is hosted in the provider’s VPC. According to the company’s security team, the connectivity must be private and must be restricted to the target service. The connection must be initiated only from the company’s VPC.Which solution will mast these requirements? ❌ Create a VPC peering connection between the company’s VPC and the provider’s VPC. Update the route table to connect to the target service. Ask the provider to create a virtual private gateway in its VPC. Use AWS PrivateLink to connect to the target service. Create a NAT gateway in a public subnet of the company’s VPUpdate the route table to connect to the target service. ✅ Ask the provider to create a VPC endpoint for the target service. Use AWS PrivateLink to connect to the target service. ✨ 关键词：connectivity must be private、connection must be initiated only from the company’s VPC 1️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：公司的工作负载部署在 AWS 上。公司现在需要连接到外部提供者的服务，服务部署在提供者的 VPC 中。根据公司安全要求，连接必须是私有的且被直接连接到对应的服务。连接必须只从公司的 VPC 中创建。 什么是 AWS PrivateLink？ AWS PrivateLink 是一项高度可用的可扩展技术，可用于将 VPC 私密地连接到服务，如同这些服务就在您自己的 VPC 中一样。您无需使用互联网网关、NAT 设备、公有 IP 地址、AWS Direct Connect 连接或 AWS Site-to-Site VPN 连接来允许与私有子网中的服务进行通信。因此，您可以控制可从 VPC 访问的特定 API 端点、站点和服务。 PrivateLink 不需要通过虚拟私有网关，直接连接到对应的服务即可。 1️⃣ 错在建立对等连接后，两边 VPC 内的实例都可以互相访问了，这并不符合题目中描述的连接只能由一边建立的需求。 👨‍👨‍👦‍👦 社区讨论：AWS PrivateLink provides private connectivity between VPCs, AWS services,and your on-premises networks, without exposing your traffic to the public internet. AWS PrivateLink makes it easy to connect servicesacross different accountsand VPCs to significantly simplify your networkarchitecture.Interface VPC endpoints, powered by AWS PrivateLink, connect you to services hosted by AWS Partnersand supported solutionsavailable in AWS Marketplace.https://aws.amazon.com/privatelink/ Option A VPC peering connection may not meet security requirement as it can allow communication between all resources in both VPCs.Option B,asking the provider to create a virtual private gateway in its VPC and use AWS PrivateLinkto connect to the target service is not the optimal solution because it may require the provider to make changesand also you may face security issues.Option C, creating a NAT gateway in a public subnet of the company’s VPC can expose the target service to the internet, which would not meet the security requirements. 七、Database migrating and ongoing replication taskA company is migrating its on-premises PostgreSQL database to Amazon Aurora PostgreSQL. The on-premises database must remain online and accessible during the migration. The Aurora database must remain synchronized with the on-premises database.Which combination of actions must a solutions architect take to meet these requirements? (Choose two.) ✅ Create an ongoing replication task. Create a database backup of the on-premises database. ✅ Create an AWS Database Migration Service (AWS DMS) replication server. ❌ Convert the database schema by using the AWS Schema Conversion Tool (AWS SCT). Create an Amazon EventBridge (Amazon CloudWatch Events) rule to monitor the database synchronization. ✨ 关键词：the on-premises database must remain online and accessible during the migration 3️⃣ 4️⃣ ❌ -&gt; 1️⃣ 3️⃣ ✅ 💡 解析：自建的 PostgreSQL 数据库要迁移到 AWS，迁移过程中自建数据库依然要在线且能被访问，而新的 Amazon Aurora PostgreSQL 要能被同步数据。来看下 AWS Schema Conversion Tool 是什么：那是什么 AWS Schema Conversion Tool？ 您可以使用 AWS Schema Conversion Tool (AWS SCT) 将现有数据库架构从一个数据库引擎转换为另一个数据库引擎。您可以转换关系OLTP架构或数据仓库架构。转换后的架构适用于亚马逊关系数据库服务（亚马逊RDS）My SQL、MariaDB、Oracle、SQL服务器、Postgre 数据库、亚马逊 Aurora SQL 数据库集群或亚马逊 Redshift 集群。转换后的架构也可以与 Amazon EC2 实例上的数据库一起使用，或者作为数据存储在 Amazon S3 存储桶中。 由于迁移源和迁移目的数据库都是 PostgreSQL，因此 AWS Schema Conversion Tool 并不适用。再来看下 1️⃣ 选项提供的 ongoing replication task（持续复制创建任务）：使用 AWS DMS 为持续复制创建任务 您可以创建一个 AWS DMS 任务来捕获源数据存储的持续更改。您可以在迁移数据时执行此捕获。您还可以创建一个任务，以便在初始（完全加载）迁移到支持的目标数据存储完成后捕获持续更改。此过程称为持续复制或更改数据捕获 (CDC)。AWS DMS 在从源数据存储复制持续更改时使用此过程。此过程的工作方式是使用数据库引擎的原生 API 来收集对数据库日志的更改。 它是 AWS Database Migration Service (AWS DMS) 所提供的任务，因此 1️⃣ 和 3️⃣ 一起选是刚好能完成需求的方案。 👨‍👨‍👦‍👦 社区讨论：AWS Database Migration Service (AWS DMS) helps you migrate databases to AWS quicklyand securely.The source database remains fully operational during the migration, minimizing downtime to applications that rely on the database.… With AWS Database Migration Service, you can also continuously replicate data with low latency from any supported source to any supported target.https://aws.amazon.com/dms/ 八、Monolithic application migrate and breakA company wants to migrate its existing on-premises monolithic庞大的 application to AWS. The company wants to keep as much of the front-end code and the backend code as possible. However, the company wants to break the application into smaller applications. A different team will manage each application. The company needs a highly scalable solution that minimizes operational overhead.Which solution will meet these requirements? Host the application on AWS Lambda. Integrate the application with Amazon API Gateway. Host the application with AWS Amplify. Connect the application to an Amazon API Gateway API that is integrated with AWS Lambda. Host the application on Amazon EC2 instances. Set up an Application Load Balancer with EC2 instances in an Auto Scaling group as targets. Host the application on Amazon Elastic Container Service (Amazon ECS). Set up an Application Load Balancer with Amazon ECS as the target. ✨ 关键词：microservices 2️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：公司要迁移一个大型应用到 AWS，需要尽可能保持前端和后端代码。但是同时又希望进行微服务化，不同的团队将会管理每个微服务。要求高可用的最少操作的解决方案。 AWS Amplify 全栈 TypeScript。适用于 AWS 的前端 DX AWS Amplify 可以满足构建 Web 和移动应用程序的一切需求。易于使用，轻松扩展。 显然它没法覆盖题目中要求的后端代码运行需求。大型应用拆成微服务并容器化，是非常合理的解决方案，也是大家都在采用的，4️⃣ 没有疑问。3️⃣ 不存在措施，只是相比 4️⃣ 更多。 👨‍👨‍👦‍👦 社区讨论：I thinkthe answer here is “D” because usually when you see terms like “monolithic” the answer will likely refer to microservices. 九、Reserved InstancesA company runs a stateless web application in production on a group of Amazon EC2 On-Demand Instances behind an Application Load Balancer. The application experiences heavy usage during an 8-hour period each business day. Application usage is moderate温和的 and steady稳定的 overnight. Application usage is low during weekends.The company wants to minimize its EC2 costs without affecting the availability of the application.Which solution will meet these requirements? Use Spot Instances for the entire workload. Use Reserved Instances for the baseline level of usage. Use Spot instances for any additional capacity that the application needs. Use On-Demand Instances for the baseline level of usage. Use Spot Instances for any additional capacity that the application needs. Use Dedicated Instances for the baseline level of usage. Use On-Demand Instances for any additional capacity that the application needs. ✨ 关键词：minimize its EC2 costs without affecting the availability of the application 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：程序运行在弹性、按需 EC2 实例组上，并且前置 ALB。工作日的 8 小时负载高，晚上则是温和稳定的；休息日低负载。需要在不影响可用性的前提下控制支出。预留实例类型当然更省钱，但是问题是如何配置让他根据工作日和时间不同来缩扩容呢？Amazon EC2 的预留实例概览 期限承诺您可以承诺购买一年或三年的 Reserved Instance，三年承诺可以获得更大的折扣。 唯一的方法似乎就是将实例组中固定要运行的实例（最小运行实例个数）转为预留实例。由于 AWS 目前在推荐使用可以更改实例配置的 Savings Plans，因此扩展了解下：什么是节省计划？ Savings Plans 提供灵活的定价模式，可节省 AWS 使用量。您可以节省高达 72% 的 AWS 计算工作负载。无论EC2实例系列、大小、操作系统、租赁或 AWS 地区如何，Compute Savings Plans 都提供更低的亚马逊实例使用价格。这也适用于 AWS Fargate 和 AWS Lambda 用法。 👨‍👨‍👦‍👦 社区讨论：In the Question is mentioned that it has on Demand instances…so I thinkis more cheapest reserved and spot 十、CloudWatch composite alarmsA company is migrating an application from on-premises servers to Amazon EC2 instances. As part of the migration design requirements, a solutions architect must implement infrastructure metric指标 alarms. The company does not need to take action if CPU utilization increases to more than 50% for a short burst of time. However, if the CPU utilization increases to more than 50% and read IOPS on the disk are high at the same time, the company needs to act as soon as possible. The solutions architect also must reduce false alarms.What should the solutions architect do to meet these requirements? ✅ Create Amazon CloudWatch composite复合 alarms where possible. Create Amazon CloudWatch dashboards to visualize the metrics and react to issues quickly. Create Amazon CloudWatch Synthetics canaries to monitor the application and raise an alarm. ❌ Create single Amazon CloudWatch metric alarms with multiple metric thresholds阈值 where possible. ✨ 关键词：metric alarms 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：需要对运行程序的 EC2 实例们进行监控，CPU 短时间超过 50% 无需报警，但是如果既超过 50% 同读 IOPS 也很高，则需要报警。同时还需要减少错误报警。只知道要使用 CloudWatch……1️⃣ 所描述的符合警报：创建复合告警 在导航窗格中，选择 Alarms（告警），然后选择 All alarms（所有告警）。 在告警列表中，选中要在规则表达式中引用的每个现有告警旁边的复选框，然后选择 Create composite alarm（创建复合告警）。 在 Specify composite alarm conditions（指定复合告警条件）中，指定新复合告警的规则表达式。 您可以使用以下子步骤修改规则表达式： 您可以将每个告警的所需状态从 ALARM 更改为 OK 或 INSUFFICENT_DATA。 您可以将规则表达式中的逻辑运算符从 OR 更改为 AND 或 NOT，并且您可以添加括号来对函数进行分组。 您可以在规则表达式中包含其他告警，也可以从规则表达式中删除告警。 看上去完美符合题目需求。而 Amazon CloudWatch Synthetics 则是一项综合监控服务：新增功能 – 使用 CloudWatch Synthetics 监控站点、API 终端节点、Web 工作流等 可以监控站点、API 终端节点、Web 工作流等。您将获得一个由外而内的视图，更好地了解性能和可用性，从而比以往更快地发现和解决所有问题。您可以提高客户满意度，并对应用程序达到性能目标更有信心。 👨‍👨‍👦‍👦 社区讨论：Composite alarms determine their states by monitoring the states of other alarms. You can use composite alarms to reduce alarm noise. Forexample, you can create a composite alarm where the underlying metric alarms go into ALARM when they meet specific conditions. You then can set up your composite alarm to go into ALARM and send you notifications when the underlying metric alarms go into ALARM by configuring the underlying metric alarms never to take actions. Currently, composite alarms can take the following actions: https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Create_Composite_Alarm.html 十一、AWS Control Tower and SCPSA company wants to migrate its on-premises data center to AWS. According to the company’s compliance遵从 requirements, the company can use only the ap-northeast-3 Region. Company administrators are not permitted to connect VPCs to the internet.Which solutions will meet these requirements? (Choose two.) Use AWS Control Tower to implement data residency guardrails to deny internet access and deny access to all AWS Regions except ap-northeast-3. Use rules in AWS WAF to prevent internet access. Deny access to all AWS Regions except ap-northeast-3 in the AWS account settings. Use AWS Organizations to configure service control policies (SCPS) that prevent VPCs from gaining获得 internet access. Deny access to all AWS Regions except ap-northeast-3. Create an outbound rule for the network ACL in each VPC to deny all traffic from 0.0.0.0/0. Create an IAM policy for each user to prevent the use of any AWS Region other than ap-northeast-3. Use AWS Config to activate managed rules to detect侦测 and alert for internet gateways and to detect and alert for new resources deployed outside of ap-northeast-3. ✨ 关键词：can use only the ap-northeast-3 Region、not permitted to connect VPCs to the internet 4️⃣ 5️⃣ ❌ -&gt; 1️⃣ 3️⃣ ✅ 💡 解析：只能使用 ap-northeast-3 且 VPC 不能连接到互联网。2️⃣ 错在防火墙只能防御来自外部的访问，禁止账号连接到除了 ap-northeast-3 以外的区域也很奇怪。4️⃣ 创建一个禁止所有来自 0.0.0.0/0 的出站请求，确实是防止实例连接到互联网了，不过没有控制入站请求。而创建 IAM 策略来禁止用户对 ap-northeast-3 以外的区域资源的使用看上去是对的。5️⃣ 使用 AWS Config 添加规则来侦测和警告互联网连接以及对 ap-northeast-3 以外的区域的部署，也没有起到禁止功能。 3️⃣ 使用 SCPS 来阻止 VPC 连接到互联网，并且禁止创建 ap-northeast-3 区域以外的资源。服务控制策略 (SCPs) 服务控制策略 (SCPs) 是一种组织策略，可用于管理组织中的权限。SCPs为组织中的IAM用户和IAM角色提供对最大可用权限的集中控制。SCPs帮助您确保您的帐户符合组织的访问控制准则。SCPs仅在启用了所有功能的组织中可用。SCPs如果您的组织仅启用了整合账单功能，则不可用。有关启用的说明SCPs，请参阅启用策略类型。 显然它可以完成对资源创建的限制。但是 VPC 联网它并不能拒绝，它只能拒绝用户修改 VPC 的联网状态：阻止还没有 Internet 访问权的任何 VPC 获取它 此 SCP 阻止任何受影响账户中的用户或角色更改 Amazon EC2 Virtual Private Cloud（VPC）的配置以允许他们直接访问 Internet。它不会阻止现有直接访问或通过您的本地网络环境路由的任何访问。 而 VPC 的联网是由 Control Tower 控制的，令人意外。首先重新认识下 AWS Control Tower：集成服务 AWS Control Tower 是一项建立在其他 AWS 服务之上的服务，可帮助您设置架构良好的环境。本章简要概述了这些服务，包括有关底层服务的配置信息以及它们在 AWS Control Tower 中的工作方式。 在 AWS Control Tower 中联网 AWS Control Tower 为通过 VPC 进行联网提供基本支持。 其他信息和链接 联网为中的 AWS网络设置可重复且易于管理的模式。详细了解客户常用的设计、自动化和设备。 AWS 快速入门 VPC 架构 — 本快速入门指南根据您的 AWS 云基础架构 AWS 的最佳实践提供了网络基础。它构建了一个包含公有和私有子网的 AWS Virtual Private Network 环境，您可以在其中启动 AWS 服务和其他资源。 因此我们可以通过 AWS Control Tower 来初始化一个没有互联网连接的 VPC。同时还能通过 AWS Control Tower 来控制组织的 OU 实现对资源区域的限制：Region deny control applied to the OU 此控制禁止访问组织单位 (OU) 指定区域之外的全球和区域 AWS 服务中的未列名操作。您可以将此控制应用于 AWS 控制塔着陆区所管辖区域的任何子集。 👨‍👨‍👦‍👦 社区讨论：A. By using Control Tower, the company can enforce data residency guardrailsand restrict internet access for VPCsand denies access to all Regionsexcept the required ap-northeast-3 Region.C. With Organizations, the company can configure SCPs to prevent VPCs from gaining internet access. By denying access to all Regionsexcept ap-northeast-3, the companyensures that VPCs can only be deployed in the specified Region. Option B is incorrect because using rules in AWS WAFalone does not address the requirement of denying access to all AWS Regionsexcept ap-northeast-3.Option D is incorrect because configuring outbound rules in network ACLsand IAM policies for users can help restrict traffic and access, but it does not enforce the company’s requirement of denying access to all Regionsexcept ap-northeast-3.Option E is incorrect because using AWS Config and managed rules can help detect and alert for specific resourcesand configurations, but it does not directlyenforce the restriction of internet access or denyaccess to specific Regions. 十二、RDS automatic stopA company uses a three-tier web application to provide training to new employees雇员. The application is accessed for only 12 hours every day. The company is using an Amazon RDS for MySQL DB instance to store information and wants to minimize costs.What should a solutions architect do to meet these requirements? Configure an IAM policy for AWS Systems Manager Session Manager. Create an IAM role for the policy. Update the trust relationship of the role. Set up automatic start and stop for the DB instance. Create an Amazon ElastiCache for Redis cache cluster that gives users the ability to access the data from the cache when the DB instance is stopped. Invalidate the cache after the DB instance is started. Launch an Amazon EC2 instance. Create an IAM role that grants access to Amazon RDS. Attach the role to the EC2 instance. Configure a cron job to start and stop the EC2 instance on the desired schedule. Create AWS Lambda functions to start and stop the DB instance. Create Amazon EventBridge (Amazon CloudWatch Events) scheduled rules to invoke the Lambda functions. Configure the Lambda functions as event targets for the rules. ✨ 关键词： 3️⃣ ❌ -&gt; 4️⃣ 💡 解析：公司有个三层网页应用，每天只使用 12 小时，后端使用 RDS for MySQL 数据库。希望最小化费用。首先明确 RDS 是支持按使用量（时间）付费的：Amazon RDS 按需型实例，那么题目的焦点就在于如何定时停止和启动 RDS 实例了。在官方的博客中有现成的案例：Schedule Amazon RDS stop and start using AWS Lambda This post presents a solution using AWS Lambda and Amazon EventBridge that allows you to schedule a Lambda function to stop and start the idle databases with specific tags to save on compute costs. The second post presents a solution that accomplishes stop and start of the idle Amazon RDS databases using AWS Systems Manager. 这和 4️⃣ 完美符合。顺便提一下，数据库实例停止后，仍然需要为存储的数据付费：Amazon RDS 的按需数据库实例 当数据库实例停止时，您将为预配置存储付费，包括预置 IOPS。您还将为备份存储付费，包括在指定保留时间内用于手动快照和自动备份的存储。您无需为数据库实例小时数付费。 我选 3️⃣ 是以为程序已经运行在 EC2 实例上了。而 1️⃣ 错在 AWS Systems Manager Session Manager 是用来连接 EC2 的：AWS Systems Manager Session Manager Session Manager 是 AWS Systems Manager 的一项完全托管式功能。借助 Session Manager，您可以管理 Amazon Elastic Compute Cloud（Amazon EC2）实例、边缘设备、本地服务器和虚拟机（VM）。您可使用基于浏览器的一键式交互 Shell 或 AWS Command Line Interface (AWS CLI)。Session Manager 提供安全且可审计的节点管理，而无需打开入站端口、维护堡垒主机或管理 SSH 密钥。 社区有人提到了这篇文章：Schedule Amazon RDS stop and start using AWS Systems Manager This post presents a solution using AWS Systems Manager State Manager that automates the process of keeping RDS instances in a start or stop state. 但是文章中其实使用的是：AWS Systems Manager State Manager State Manager（AWS Systems Manager 的一种功能）是一项安全并且可扩展的配置管理服务，可以自动将您的托管式节点和其他 AWS 资源保持在定义的状态。要开始使用 State Manager，请打开 Systems Manager 控制台。在导航窗格中，选择 State Manager。 👨‍👨‍👦‍👦 社区讨论：https://aws.amazon.com/blogs/database/schedule-amazon-rds-stop-and-start-using-aws-lambda/It is option D. Option A could have been applicable had it been AWS Systems ManagerState Manager &amp; not AWS Systems ManagerSession Manager 十三、S3 Lifecycle policy or S3 Intelligent-TieringA company sells ringtones created from clips of popular songs. The files containing the ringtones are stored in Amazon S3 Standard and are at least 128 KB in size. The company has millions of files, but downloads are infrequent for ringtones older than 90 days. The company needs to save money on storage while keeping the most accessed files readily available for its users.Which action should the company take to meet these requirements MOST cost-effectively? Configure S3 Standard-Infrequent Access (S3 Standard-IA) storage for the initial storage tier of the objects. Move the files to S3 Intelligent-Tiering and configure it to move objects to a less expensive storage tier after 90 days. Configure S3 inventory to manage objects and move them to S3 Standard-Infrequent Access (S3 Standard-IA) after 90 days. Implement an S3 Lifecycle policy that moves the objects from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) after 90 days. ✨ 关键词： 2️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：由百万个、最小 128 KB 的文件存储在 S3 中。对 90 天以上的文件访问不频繁，公司需要保证对常用文件的快速访问。最便宜的方案。S3 Intelligent-Tiering 和 S3 Lifecycle policy 每次选起来都很困难。来再看下 S3 Intelligent-Tiering：S3 Intelligent-Tiering 工作原理 对于每月较低的对象监视和自动化收费，S3 Intelligent-Tiering 监控访问模式，并在连续 30 天未访问对象时自动将对象移动到非频繁访问层 (Infrequent Access)。在不访问 90 天后，对象将移动到存档即时访问层 (Archive)，而不会影响性能或运营开销。 2/3 选了 4️⃣，1/3 选了 2️⃣。2️⃣ 如果归档后肯定做不到立即访问，因此选 4️⃣ 肯定没错。 👨‍👨‍👦‍👦 社区讨论：Answer DWhy Optoin D ?The Question talksabout downloadsare infrequent older than 90 days which means files less than 90 daysare accessed frequently.Standard-Infrequent Access (S3 Standard-IA) needsa minimum 30 days if accessed before, it costs more.So to access the files frequently you need a S3 Standard . After 90 days you can move it to Standard-Infrequent Access (S3 Standard-IA) as its going to be less frequentlyaccessed 十四、AWS Lake Formation and GlueA company produces batch data that comes from different databases. The company also produces live stream data from network sensors and application APIs. The company needs to consolidate统一 all the data into one place for business analytics.The company needs to process the incoming data and then stage the data in different Amazon S3 buckets. Teams will later run one-time queries and import the data into a business intelligence tool to show key performance indicators (KPIs).Which combination of steps will meet these requirements with the LEAST operational overhead? (Choose two.) ✅ Use Amazon Athena for one-time queries. Use Amazon QuickSight to create dashboards for KPIs. Use Amazon Kinesis Data Analytics for one-time queries. Use Amazon QuickSight to create dashboards for KPIs. Create custom AWS Lambda functions to move the individual records from the databases to an Amazon Redshift cluster. ❌ Use an AWS Glue extract, transform, and load (ETL) job to convert the data into JSON format. Load the data into multiple Amazon OpenSearch Service (Amazon Elasticsearch Service) clusters. ✅ Use blueprints蓝图 in AWS Lake Formation to identify the data that can be ingested into a data lake. Use AWS Glue to crawl the source, extract the data, and load the data into Amazon S3 in Apache Parquet format. ✨ 关键词： 1️⃣ 4️⃣ ❌ -&gt; 1️⃣ 5️⃣ ✅ 💡 解析：需要处理来自多个数据库的数据，同时还要处理来自网络哨兵和应用程序 API 的数据流，要统一所有数据到一个地方进行商业分析。需要将接收的数据分别存储到不同的 S3 存储桶中，之后进行一次性检索并导入商业分析工具生成 KPI。要求最少操作的解决方案。使用 Amazon Athena 对 S3 存储桶进行检索和使用 QuickSight 进行商业化分析不存在争议。4️⃣ 通过 AWS Glue 将数据提取转换并加载为 JSON 格式，然后导入到 ES 集群中。5️⃣ 则使用 AWS Lake Formation 辨别能被加载到数据湖中的数据，并使用 AWS Glue 爬取来源、转换数据并以 Apache Parquet 格式加载到 S3 存储桶中（供后续检索）。 什么是 AWS Lake Formation？ AWS Lake Formation 帮助您集中管理、保护和全球共享用于分析和机器学习的数据。您可以对 Amazon Simple Storage Service (Amazon S3) 上的数据湖数据及其在 AWS Glue Data Catalog中的元数据进行精细访问控制。 Lake Formation 中的蓝图和工作流 工作流程封装了复杂的多任务提取、转换和加载 () 活动。ETL工作流生成 AWS Glue 爬虫、作业和触发器，以协调数据的加载和更新。Lake Formation 将工作流作为单个实体来执行和跟踪。您可以将工作流配置为按需或按计划运行。 你在 Lake Formation 中创建的工作流程可以在 AWS Glue 控制台作为有向无环图 (DAG)。每个DAG节点都是一个作业、爬虫或触发器。要监控进度并进行故障排除，您可以跟踪工作流中每个节点的状态。 官方推荐将 Lake Formation 与 AWS Glue 组合使用，显然这也是本题的考点。 👨‍👨‍👦‍👦 社区讨论：AWS Lake Formation and Glue provide automated data lake creation with minimal coding. Glue crawlers identify sources and ETL jobs load to S3.Athena allows ad-hoc queries directly on S3 data with no infrastructure to manage.QuickSight provides easy cloud BI for dashboards.Options C and D require significant custom coding for ETL and queries.Redshift and OpenSearch would require additional setup and management overhead. 十五、Global streamingA solutions architect is optimizing a website for an upcoming musical event. Videos of the performances will be streamed in real time and then will be available on demand. The event is expected to attract a global online audience.Which service will improve the performance of both the real-time and on-demand streaming? ✅ Amazon CloudFront ❌ AWS Global Accelerator Amazon Route 53 Amazon S3 Transfer Acceleration ✨ 关键词：Video streaming 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：音乐活动在准备全球网页应用，视频将被实时按需串流。如何解决实时和按需串流。CloudFront 可以用来加速 HTTP 协议的视频流。 👨‍👨‍👦‍👦 社区讨论：A is rightYou can use CloudFront to deliver video on demand (VOD) or live streaming video using any HTTP originGlobal Accelerator isa good fit for non-HTTP use cases, such as gaming (UDP), IoT (MQTT), or Voice over IP,as well as for HTTP use cases that specifically require static IP addresses website = http = cloudfront, if it is UDP, then global accelerator 十六、Application without any downtimeA company runs a production application on a fleet of Amazon EC2 instances. The application reads the data from an Amazon SQS queue and processes the messages in parallel并行. The message volume is unpredictable and often has intermittent traffic.This application should continually process messages without any downtime.Which solution meets these requirements MOST cost-effectively? Use Spot Instances exclusively to handle the maximum capacity required. Use Reserved Instances exclusively to handle the maximum capacity required. ❌ Use Reserved Instances for the baseline capacity and use Spot Instances to handle additional capacity. ✅ Use Reserved Instances for the baseline capacity and use On-Demand Instances to handle additional capacity. ✨ 关键词： 3️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：一组 EC2 实例持续消费 SQS 中的消息，消息无法预测且断断续续，但是需要确保应用程序不中断。最便宜的方案。3️⃣ 确实合理，预留实例保证最低容量，抢占实例来处理额外消息。但是 4️⃣ 更能覆盖题目中没有任何停工的需求。最具成本效益是建立在满足所有需求的基础上的。 👨‍👨‍👦‍👦 社区讨论：”without any downtime” - Reserved Instances for the baseline capacity“MOST cost-effectively” - Spot Instances to handle additional capacity 🙅 反对：cost-effectively means, Cheapest solution (cost) that achieve all the requirements (effectively). Its not cost-effectively if is just cheapest solution that fail to addressall the requirements, in this case. (Thisapplication should continually process messages without any downtime) no matter the volume, since it is unpredictable. B forexample,address the requirement but not the cheapest solution that achieve it. D is the cheaper choice that address the requirement (without any downtime).and C is cheaper than D but do not garantee that you wont have downtime since it isSPOT instances.","link":"/2024/11/29/saa_test_daily_20241129/"},{"title":"SAA 考试每日练习 - 2024&#x2F;11&#x2F;30","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam10 题 (No.181 ~ No.190) 只记录了 2 道首次碰到的、错误的或有疑问的题目，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： destinationn. 目的地，终点 一、Connect to on-premises databaseA company has an AWS account used for software engineering. The AWS account has access to the company’s on-premises data center through a pair of AWS Direct Connect connections. All non-VPC traffic routes to the virtual private gateway.A development team recently created an AWS Lambda function through the console. The development team needs to allow the function to access a database that runs in a private subnet in the company’s data center.Which solution will meet these requirements? ✅ Configure the Lambda function to run in the VPC with the appropriate security group. Set up a VPN connection from AWS to the data center. Route the traffic from the Lambda function through the VPN. Update the route tables in the VPC to allow the Lambda function to access the on-premises data center through Direct Connect. ❌ Create an Elastic IP address. Configure the Lambda function to send traffic through the Elastic IP address without an elastic network interface. ✨ 关键词：all Lambda function access on-premises database、AWS Direct Connect 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：公司的自建数据中心和 AWS 同通过 AWS Direct Connect 建立了连接，现在需要 Lambda 函数能够访问本地数据库。首先需要确定 Lambda 创建后默认是不属于任何 VPC，且可以访问互联网的： 之后通过配置可以将其放入 VPC 内，获取与 VPC 内其他实例相同的网络访问权限： 官方的文档描述 Lambda 总是运行在 VPC 内，这并不准确：Networking and VPC configurations Lambda functions always run inside VPCs owned by the Lambda service. As with customer-owned VPCs, this allows the service to apply network access and security rules to everything within the VPC. These VPCs are not visible to customers, the configurations are maintained automatically, and monitoring is managed by the service. 回到题目，1️⃣ 是必须要做的事情，选择没有问题。而争议比较大的 3️⃣ 则是配置路由表让 VPC 内的 Lambda 函数能够访问本地网络，即使要做也是在 1️⃣ 之后。 👨‍👨‍👦‍👦 社区讨论：To configure a VPC for an existing function: Open the Functions page of the Lambda console. Choose a function. Choose Configuration and then choose VPC. Under VPC, choose Edit. Choose a VPC, subnets,and security groups. &lt;– That’s why I believe the answer is A. Note: If your function needs internet access, use networkaddress translation (NAT). Connecting a function to a public subnet doesn’t give it internet access or a public IP address. 二、S3 SFTP uploadA company uses Amazon S3 as its data lake. The company has a new partner that must use SFTP to upload data files. A solutions architect needs to implement a highly available SFTP solution that minimizes operational overhead.Which solution will meet these requirements? ✅ Use AWS Transfer Family to configure an SFTP-enabled server with a publicly accessible endpoint. Choose the S3 data lake as the destination. Use Amazon S3 File Gateway as an SFTP server. Expose the S3 File Gateway endpoint URL to the new partner. Share the S3 File Gateway endpoint with the new partner. Launch an Amazon EC2 instance in a private subnet in a VPInstruct the new partner to upload files to the EC2 instance by using a VPN. Run a cron job script, on the EC2 instance to upload files to the S3 data lake. Launch Amazon EC2 instances in a private subnet in a VPC. Place a Network Load Balancer (NLB) in front of the EC2 instances. Create an SFTP listener port for the NLB. Share the NLB hostname with the new partner. Run a cron job script on the EC2 instances to upload files to the S3 data lake. ✨ 关键词：S3、SFTP solution 1️⃣ ✅ 💡 解析：使用 S3 作为数据湖，新的合作方一定要使用 SFTP 上传文件。需要高可用的 SFTP 方案。AWS Transfer Family 提供了多种协议与 AWS 存储服务交互的服务。 什么是 AWS Transfer Family？ AWS Transfer Family 是一种安全的传输服务，使您能够将文件传入和传出 AWS 存储服务。Transfer Family 是该 AWS Cloud 平台的一部分。 AWS Transfer Family 为通过SFTP、、AS2、FTPS以及FTP直接传入和传出 Amazon S3 或 Amazon 的文件提供完全托管的支持EFS。通过维护现有的客户端身份验证、访问和防火墙配置，您可以无缝迁移、自动化和监控文件传输工作流程，因此您的客户、合作伙伴和内部团队或其应用程序不会发生任何变化。 👨‍👨‍👦‍👦 社区讨论：For Exam :Whenever you see SFTP , FTP lookfor “Transfer” in optionsavailable","link":"/2024/11/30/saa_test_daily_20241130/"},{"title":"SAA 考试每日练习 - 2024&#x2F;12&#x2F;02","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam15 题 (No.221 ~ No.235) 只记录了 4 道首次碰到的、错误的或有疑问的题目，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： demonstrationn. 示范，演示，证明；表示，表露；示威游行；示威集会 isolatedadj. 偏远的，孤立的，孤独的 | v. 分离 一、Amazon Route 53 routing policyA company recently migrated its web application to AWS by rehosting the application on Amazon EC2 instances in a single AWS Region. The company wants to redesign its application architecture to be highly available and fault tolerant. Traffic must reach all running EC2 instances randomly.Which combination of steps should the company take to meet these requirements? (Choose two.) ❌ Create an Amazon Route 53 failover routing policy. Create an Amazon Route 53 weighted routing policy. ✅ Create an Amazon Route 53 multivalue answer routing policy. Launch three EC2 instances: two instances in one Availability Zone and one instance in another Availability Zone. ✅ Launch four EC2 instances: two instances in one Availability Zone and two instances in another Availability Zone. ✨ 关键词：Traffic must reach all running EC2 instances randomly 1️⃣ 5️⃣ ❌ -&gt; 3️⃣ 5️⃣ ✅ 💡 解析：应用要高可用和容灾，同时流量随机到每个 EC2 实例。5️⃣ 肯定是对的，但是要来过一下路由策略：选择路由策略 简单路由策略 (Simple routing policy) 故障转移路由策略 (Failover routing policy) - 主动-被动 (active-passive) 故障转移的情况下使用。 故障转移路由允许您将流量路由到某个资源 (如果该资源正常) 或路由到其他资源 (如果第一个资源不正常)。主和辅助记录可以将流量路由到从配置为网站的 Amazon S3 存储桶到复杂记录树的任何目的地 地理位置路由策略 (Geolocation routing policy) 地理位置临近度路由策略 (Geoproximity routing policy) 延迟路由策略 (Latency routing policy) 基于 IP 的路由策略 (IP-based routing policy) 多值应答路由策略 (Multivalue answer routing policy) - 如果您想要让 Route 53 用随机选择的正常记录（最多八条）响应 DNS 查询，则可以使用该策略。在私有托管区域中，可以使用多值应答路由创建记录。 加权路由策略 (Weighted routing policy) 当前场景下是由 3️⃣ 正确。 👨‍👨‍👦‍👦 社区讨论：C. A multivalue answer routing policy in Route 53 allows you to configure multiple values for a DNS record,and Route 53 responds to DNS queries with multiple random values.Thisenables the distribution of traffic randomlyamong the available EC2 instances.E. By launching EC2 instances in different AZs, you achieve high availabilityand fault tolerance. Launching four instances (two in each AZ) ensures that there are enough resources to handle the traffic load and maintain the desired level of availability. A. Failover routing is designed to direct traffic to a backup resource or secondary location only when the primary resource or location is unavailable.B. Although a weighted routing policyallows you to distribute traffic across multiple EC2 instances, it does not ensure random distribution.D. While launching instances in multiple AZs is important for fault tolerance, having only three instances does not provide an even distribution of traffic. With only three instances, the traffic may not be evenly distributed, potentially leading to imbalanced resource utilization. 二、Petabytes size of dataA media company collects and analyzes user activity data on premises. The company wants to migrate this capability to AWS.The user activity data store will continue to grow and will be petabytes in size. The company needs to build a highly available data ingestion solution that facilitates on-demand analytics of existing data and new data with SQL.Which solution will meet these requirements with the LEAST operational overhead? ❌ Send activity data to an Amazon Kinesis data stream. Configure the stream to deliver the data to an Amazon S3 bucket. ✅ Send activity data to an Amazon Kinesis Data Firehose delivery stream. Configure the stream to deliver the data to an Amazon Redshift cluster. Place activity data in an Amazon S3 bucket. Configure Amazon S3 to run an AWS Lambda function on the data as the data arrives in the S3 bucket. Create an ingestion service on Amazon EC2 instances that are spread across multiple Availability Zones. Configure the service to forward data to an Amazon RDS Multi-AZ database. ✨ 关键词：petabytes、data storage、analytics with SQL 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：PB 级别的数据存储与分析。S3 当然是能存储 PB 级别的数据的，但是存储加分析显然使用 Redshift 更合适：Amazon Redshift 定价 使用 Amazon Redshift 时，您可以从小规模开始（每小时 0.25 美元），逐渐扩展到 PB 级数据和数千个并发用户。 社区讨论中提到了 Kinesis Data Stream 存储数据使用分片，数据增多时需要手动增加分片，这并不准确：容量模式 若采用按需模式，Kinesis Data Streams 会自动管理分片来提供必要的吞吐量。您只需为实际使用的吞吐量付费，Kinesis Data Streams 会在工作负载增加或减少时自动适应吞吐量需求。 若采用预置模式，您必须为数据流指定分片数。数据流的总容量是其分片容量的总和。您可以根据需要增加或减少数据流中的分片数，并且按小时费率支付分片数的费用。 Amazon 总是推荐选择集成度更高、且能符合题目需求的服务。 👨‍👨‍👦‍👦 社区讨论：Petabyte scale- Redshift 1 - Kinesis Data Stream providesa fully managed platform for custom data processing and analysis. Or we can say that used for custom data processing and analysis which required more manual intervention.2 - Kinesis Data Firehose simplifies the delivery of streaming data to various destinations without the need for complex transformations.Option B is more suitable for the given scenario. 三、Notify RDP or SSH accessA company runs demonstration演示 environments for its customers on Amazon EC2 instances. Each environment is isolated孤立的 in its own VPC. The company’s operations team needs to be notified when RDP or SSH access to an environment has been established. ❌ Configure Amazon CloudWatch Application Insights to create AWS Systems Manager OpsItems when RDP or SSH access is detected. Configure the EC2 instances with an IAM instance profile that has an IAM role with the AmazonSSMManagedInstanceCore policy attached. ✅ Publish VPC flow logs to Amazon CloudWatch Logs. Create required metric filters. Create an Amazon CloudWatch metric alarm with a notification action for when the alarm is in the ALARM state. Configure an Amazon EventBridge rule to listen for events of type EC2 Instance State-change Notification. Configure an Amazon Simple Notification Service (Amazon SNS) topicas a target. Subscribe the operations team to the topic. ✨ 关键词： 1️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：需要监控对 EC2 实例的 SSH 和 RDP 连接。我并不了解 CloudWatch Application Insights（见解） 实际上能完成哪些工作，来看下：Amazon CloudWatch Application Insights 是什么？ CloudWatch Application Insights 可帮助您监控使用 Amazon EC2 实例以及其他应用程序资源的应用程序。它可在应用程序资源和技术堆栈（例如，Microsoft SQL Server 数据库、Web (IIS) 和应用程序服务器、操作系统、负载均衡器和队列）中识别和设置关键指标、日志和警报。它会持续监控指标和日志，以检测异常情况和错误并将它们关联起来。 看上去它是用以监控警告和错误信息，并将其关联起来的。并不适用于当前的 SSH 和 RDP 登录场景。而 4️⃣ 错在 EC2 的实例中不会反映登录状态：Amazon EC2 实例的状态更改事件 state 可使用的值为： pending running stopping stopped shutting-down terminated 当您启用或启动实例时，它会进入 pending 状态，然后进入 running 状态。当您停止实例时，它会进入 stopping 状态，然后进入 stopped 状态。当您终止实例时，它会进入 shutting-down 状态，然后进入 terminated 状态。 最终答案只剩 3️⃣ 了：How to Monitor and Visualize Failed SSH Access Attempts to Amazon EC2 Linux Instances 👨‍👨‍👦‍👦 社区讨论：By publishing VPC flow logs to CloudWatch Logsand creating metric filters to detect RDP orSSH access, the operations team can configure an CloudWatch metric alarm to notify them when the alarm is triggered.This will provide the desired notification when RDP orSSH access to an environment isestablished. Option A is incorrect because CloudWatch Application Insights is not designed for detecting RDP or SSH access.Option B isalso incorrect because configuring an IAM instance profile with the AmazonSSMManagedInstanceCore policy does not directlyaddress the requirement of notifying the operations team when RDP orSSH access occurs.Option D is wrong beacuse configuring an EventBridge rule to listen for EC2 Instance State-change Notification eventsand using an SNS topic asa target will notify the operations team about changes in the instance state, such as starting or stopping instances. However, it does not specifically detect or notify when RDP orSSH access isestablished, which is the requirement stated in the question. 四、Database migrationA company is moving its on-premises Oracle database to Amazon Aurora PostgreSQL. The database has several applications that write to the same tables. The applications need to be migrated one by one with a month in between each migration.Management has expressed concerns that the database has a high number of reads and writes. The data must be kept in sync across both databases throughout the migration.What should a solutions architect recommend? Use AWS DataSync for the initial migration. Use AWS Database Migration Service (AWS DMS) to create a change data capture (CDC) replication task and a table mapping to select all tables. Use AWS DataSync for the initial migration. Use AWS Database Migration Service (AWS DMS) to create a full load plus change data capture (CDC) replication task and a table mapping to select all tables. ✅ Use the AWS Schema Conversion Tool with AWS Database Migration Service (AWS DMS) using a memory optimized replication instance. Create a full load plus change data capture (CDC) replication task and a table mapping to select all tables. Use the AWS Schema Conversion Tool with AWS Database Migration Service (AWS DMS) using a compute optimized replication instance. Create a full load plus change data capture (CDC) replication task and a table mapping to select the largest tables. ✨ 关键词：Oracle database to Amazon Aurora PostgreSQL、high number of reads and writes 3️⃣ ✅ 💡 解析：要将数据库从本地 Oracle 迁移到云上的 PostgreSQL，并且需要改善性能。需要适用 AWS Schema Conversion Tool 来处理数据库类型的转换。我比较好奇 change data capture (CDC) 是什么：什么是变更数据捕获（CDC）？ 变更数据捕获是一种经过验证的数据集成模式，用于跟踪数据更改，并向必须响应这些更改的其他系统和服务发出警报。变更数据捕获有助于确保所有依赖数据的系统数据同步，功能正常。 它在 DMS 中的使用：使用 AWS DMS 为持续复制创建任务 您可以创建一个 AWS DMS 任务来捕获源数据存储的持续更改。您可以在迁移数据时执行此捕获。您还可以创建一个任务，以便在初始（完全加载）迁移到支持的目标数据存储完成后捕获持续更改。此过程称为持续复制或更改数据捕获 (CDC)。AWS DMS 在从源数据存储复制持续更改时使用此过程。此过程的工作方式是使用数据库引擎的原生 API 来收集对数据库日志的更改。 有两种类型的持续复制任务： Full load plus CDC – The task migrates existing data and then updates the target database based on changes to the source database. CDC only – The task migrates ongoing changes after you have data on your target database. 我认为这是代表着：Full load plus CDC 包含初始化行为，CDC only 不包含。也能与题目中的操作对应。 👨‍👨‍👦‍👦 社区讨论：C : because we need SCT to convert from Oracle to PostgreSQL,and we need memory optimized machine for databases not compute optimized.","link":"/2024/12/02/saa_test_daily_20241202/"},{"title":"SAA 考试每日练习 - 2024&#x2F;12&#x2F;04","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam50 题 (No.286 ~ No.335) 只记录了 11 道首次碰到的、错误的或有疑问的题目，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： legacyn. 遗产，遗赠财物，遗留问题，后遗症 | adj. （计算机系统或产品）已停产的 fully managed全托管 thumbnailadj. 极小的, 简短的(论文等) | n. 拇指甲, 索引图像, （打印预览）略图 一、S3 share urlA media company uses Amazon CloudFront for its publicly available streaming video content. The company wants to secure the video content that is hosted in Amazon S3 by controlling who has access. Some of the company’s users are using a custom HTTP client that does not support cookies. Some of the company’s users are unable to change the hardcoded URLs that they are using for access.Which services or methods will meet these requirements with the LEAST impact to the users? (Choose two.) ✅ Signed cookies ✅ Signed URLs AWS AppSync JSON Web Token (JWT) AWS Secrets Manager ✨ 关键词：a custom HTTP client that does not support cookies、unable to change the hardcoded URLs 1️⃣ 2️⃣ ✅ 💡 解析：要将 S3 存储桶中的文件分享给外部用户，有的用户使用着不支持 Cookies 的 HTTP 客户端，另一些无法改变硬编码后的访问 URL（例如写死在代码中）。对于使用不支持 Cookies 客户端的用户，使用预签名 URL 和公开 URL 明显都可以。而对于硬编码了的用户，明显也是公开 URL。这里单纯选 2️⃣ 就行了。 Amazon AppSync 利用全球范围内一个或多个数据源的适当数据为您的应用程序提供技术支持 借助 AppSync，您可以在 NoSQL 数据存储、关系数据库、HTTP API 等一系列数据源和您使用 Amazon Lambda 自定义的数据源上构建可扩展的应用程序，包括需要实时更新的应用程序。对于移动和 Web 应用程序，AppSync 会在设备离线时额外提供本地数据访问，并在设备重新上线时提供数据与可自定义冲突解决的同步。 👨‍👨‍👦‍👦 社区讨论：I thought that option A was totally wrong, because the question mentions “HTTP client does not support cookies”. However it is right,along with option B. Checkthe link bellow, first paragraph.https://aws.amazon.com/blogs/media/secure-content-using-cloudfront-functions/ 二、Data Stream ETL and saveA company is preparing a new data platform that will ingest real-time streaming data from multiple sources. The company needs to transform the data before writing the data to Amazon S3. The company needs the ability to use SQL to query the transformed data.Which solutions will meet these requirements? (Choose two.) ✅ Use Amazon Kinesis Data Streams to stream the data. Use Amazon Kinesis Data Analytics to transform the data. Use Amazon Kinesis Data Firehose to write the data to Amazon S3. Use Amazon Athena to query the transformed data from Amazon S3. ✅ Use Amazon Managed Streaming for Apache Kafka (Amazon MSK) to stream the data. Use AWS Glue to transform the data and to write the data to Amazon S3. Use Amazon Athena to query the transformed data from Amazon S3. Use AWS Database Migration Service (AWS DMS) to ingest the data. Use Amazon EMR to transform the data and to write the data to Amazon S3. Use Amazon Athena to query the transformed data from Amazon S3. Use Amazon Managed Streaming for Apache Kafka (Amazon MSK) to stream the data. Use Amazon Kinesis Data Analytics to transform the data and to write the data to Amazon S3. Use the Amazon RDS query editor to query the transformed data from Amazon S3. Use Amazon Kinesis Data Streams to stream the data. Use AWS Glue to transform the data. Use Amazon Kinesis Data Firehose to write the data to Amazon S3. Use the Amazon RDS query editor to query the transformed data from Amazon S3. ✨ 关键词：real-time streaming data、multiple sources、ETL、S3 1️⃣ 2️⃣ ✅ 💡 解析：来自多个源的近实时数据流，需要转换后写入 S3 中。之后能够通过 SQL 进行查询。首先 S3 使用 SQL 查询只能使用 Amazon Athena 实现，这样排除后只有 1️⃣ 2️⃣ 3️⃣ 可以选了。2️⃣ 的操作非常标准，通过 Amazon Managed Streaming 将数据流式传输，使用 Glue 进行 ETL 操作之后存入 S3 中。而 1️⃣ 的有些繁琐，其中对 Amazon Kinesis Data Analytics 能否转换数据：Examples: Transforming String Values Amazon Kinesis Data Analytics supports formats such as JSON and CSV for records on a streaming source. 是可以的，那么 1️⃣ 也就不存在问题了。3️⃣ 的 DMS 是用来迁移数据库的，明显不对。 Amazon Managed Streaming for Apache Kafka (MSK) 利用完全托管、高度可用的 Apache Kafka 服务安全地流式传输数据 Amazon Managed Streaming for Apache Kafka（Amazon MSK）是一项流式传输数据服务，可以管理 Apache Kafka 基础设施和运营。 Apache Kafka 是一个开源、高性能、可容错且可扩展的平台，用于构建实时流式传输数据管道和应用程序。Apache Kafka 是一个流数据存储，它将生成流数据的应用程序（生产者）与从其数据存储中使用流数据的应用程序（使用者）分离到其数据存储中。各个组织将 Apache Kafka 用作持续分析和响应流式传输数据的应用程序的数据来源。 👨‍👨‍👦‍👦 社区讨论：OK, for B I did some research, https://docs.aws.amazon.com/glue/latest/dg/add-job-streaming.html“You can create streaming extract, transform,and load (ETL) jobs that run continuously, consume data from streaming sources like Amazon Kinesis Data Streams, Apache Kafka,and Amazon Managed Streaming for Apache Kafka (Amazon MSK).The jobs cleanse and transform the data,and then load the results into Amazon S3 data lakes or JDBC data stores.” 三、High performance file systemA research laboratory needs to process approximately 8 TB of data. The laboratory requires sub-millisecond latencies and a minimum throughput of 6 GBps for the storage subsystem. Hundreds of Amazon EC2 instances that run Amazon Linux will distribute and process the data.Which solution will meet the performance requirements? Create an Amazon FSx for NetApp ONTAP file system. Sat each volume’ tiering policy to ALL. Import the raw data into the file system. Mount the fila system on the EC2 instances. ✅ Create an Amazon S3 bucket to store the raw data. Create an Amazon FSx for Lustre file system that uses persistent SSD storage. Select the option to import data from and export data to Amazon S3. Mount the file system on the EC2 instances. Create an Amazon S3 bucket to store the raw data. Create an Amazon FSx for Lustre file system that uses persistent HDD storage. Select the option to import data from and export data to Amazon S3. Mount the file system on the EC2 instances. ❌ Create an Amazon FSx for NetApp ONTAP file system. Set each volume’s tiering policy to NONE. Import the raw data into the file system. Mount the file system on the EC2 instances. ✨ 关键词：8 TB、sub-millisecond latencies、6 GBps 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：8 TB 的数据需要存储在亚毫秒级读取、6Gbps 速率的文件系统上。 Amazon for FSx Lustre 是什么？ FSxfor Lustre 可以轻松且经济高效地启动和运行流行的高性能 Lustre 文件系统。您可以将 Lustre 用于速度至关重要的工作负载，例如机器学习、高性能计算 (HPC)、视频处理和财务建模。 开源 Lustre 文件系统专为需要快速存储的应用程序而设计，即希望存储能跟上计算速度。Lustre 的构建是为了解决既快又省地处理全球不断增长的数据集的问题。它是一个广泛使用的文件系统，专为世界上速度最快的计算机而设计。它提供亚毫秒级的延迟、高达数百的吞吐量和高达数百万GBps的吞吐量。 什么是 Amazon FSx for NetApp ONTAP 通过符合行业标准的 NFS、SMB、iSCSI 和 NVMe-over-TCP 协议向广泛的工作负载和用户提供您的数据。 Volume tiering policies Auto（自动）- 该策略将所有冷数据（用户数据和快照）移至容量池层。数据的冷却速度由策略的冷却期决定，默认为 31 天，可配置值在 2-183 天之间。 Snapshot Only（仅快照）- 此策略仅将快照数据移动到容量池存储层。快照分层到容量池的速度由策略的冷却期决定，默认设置为 2 天，可配置值在 2-183 天之间。 All（全部）- 此策略将所有用户数据和快照数据标记为冷数据，并将其存储在容量池层中。 None - 该策略可将卷的所有数据保留在主存储层上，并防止其转移到容量池存储。 👨‍👨‍👦‍👦 社区讨论：Keyword here isa minimum throughput of 6 GBps. Only the FSx for Lustre with SSD option gives the sub-milli response and throughput of 6 GBps or more.B. Create an Amazon S3 bucket to store the raw data. Create an Amazon FSx for Lustre file system that uses persistentSSD storage.Select the option to import data from and export data to Amazon S3. Mount the file system on the EC2 instances.Refrences:https://aws.amazon.com/fsx/when-to-choose-fsx/ 四、Data TransferA university research laboratory needs to migrate 30 TB of data from an on-premises Windows file server to Amazon FSx for Windows File Server. The laboratory has a 1 Gbps network link that many other departments in the university share.The laboratory wants to implement a data migration service that will maximize the performance of the data transfer. However, the laboratory needs to be able to control the amount of bandwidth that the service uses to minimize the impact on other departments. The data migration must take place within the next 5 days.Which AWS solution will meet these requirements? ❌ AWS Snowcone Amazon FSx File Gateway ✅ AWS DataSync AWS Transfer Family ✨ 关键词：30 TB、5 TB 1️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：有 30 TB 的数据需要在 5 天迁移到 AWS。有 1 Gbsp 的网络连接并希望最大化网络使用，但还能保留对带宽的控制。如果是 1 Gbps 的话每天能传输 (1000 / 8) * 3600 * 24 / 1024 / 1024 = 10.3 TB，这意味着 5 天理论可以传输 51.5 TB，完全能满足文件传输的总大小要求。选 3️⃣ 没有问题。并且 Snowcone 也无法在 5 天内寄到并传输完数据发送回 AWS。 什么是 AWS Transfer Family？ AWS Transfer Family 是一种安全的传输服务，使您能够将文件传入和传出 AWS 存储服务。Transfer Family 是该 AWS Cloud 平台的一部分。 AWS Transfer Family 为通过SFTP、AS2、FTPS以及FTP直接传入和传出 Amazon S3 或 Amazon 的文件提供完全托管的支持EFS。通过维护现有的客户端身份验证、访问和防火墙配置，您可以无缝迁移、自动化和监控文件传输工作流程，因此您的客户、合作伙伴和内部团队或其应用程序不会发生任何变化。 AWS Transfer Family 主要功能是使用其他协议将文件传入传出到 S3 和 EFS。 👨‍👨‍👦‍👦 社区讨论：AWS DataSync isa data transfer service that can copy large amounts of data between on-premises storage and Amazon FSx for Windows File Server at high speeds. It allows you to control the amount of bandwidth used during data transfer. DataSync usesagentsat the source and destination to automatically copy filesand file metadata over the network.This optimizes the data transfer and minimizes the impact on your network bandwidth. DataSync allows you to schedule data transfersand configure transfer rates to suit your needs. You can transfer 30 TB within 5 days while controlling bandwidth usage. DataSync can resume interrupted transfersand validate data to ensure integrity. It provides detailed monitoring and reporting on the progressand performance of data transfers. 五、Auto ScalingA company is launching a new application deployed on an Amazon Elastic Container Service (Amazon ECS) cluster and is using the Fargate launch type for ECS tasks. The company is monitoring CPU and memory usage because it is expecting high traffic to the application upon its launch. However, the company wants to reduce costs when utilization decreases.What should a solutions architect recommend? Use Amazon EC2 Auto Scaling to scale at certain periods based on previous traffic patterns. Use an AWS Lambda function to scale Amazon ECS based on metric breaches that trigger an Amazon CloudWatch alarm. Use Amazon EC2 Auto Scaling with simple scaling policies to scale when ECS metric breaches trigger an Amazon CloudWatch alarm. ✅ Use AWS Application Auto Scaling with target tracking policies to scale when ECS metric breaches trigger an Amazon CloudWatch alarm. ✨ 关键词：ECS、Auto Scaling 4️⃣ ✅ 💡 解析：部署在 ECS 和 Fargate 平台上的应用需要准备弹性扩容措施。看看 AWS Application Auto Scaling 是什么：什么是 Application Auto Scaling？ Application Auto Scaling 是一项网络服务，适用于需要一种解决方案来自动扩展其可扩展资源以用于亚马逊以外的各项 AWS 服务的开发人员和系统管理员EC2。使用 Application Auto Scaling，您可以为以下资源配置自动缩放： DynamoDB 表和全局二级索引 亚马逊 ECS 服务 Lambda 函数预置并发 ……等等大量服务 👨‍👨‍👦‍👦 社区讨论：Answer is D - Auto-scaling with target tracking 六、Bill and costA company has multiple AWS accounts that use consolidated billing. The company runs several active high performance Amazon RDS for Oracle On-Demand DB instances for 90 days. The company’s finance team has access to AWS Trusted Advisor in the consolidated billing account and all other AWS accounts.The finance team needs to use the appropriate AWS account to access the Trusted Advisor check recommendations for RDS.The finance team must review the appropriate Trusted Advisor check to reduce RDS costs.Which combination of steps should the finance team take to meet these requirements? (Choose two.) Use the Trusted Advisor recommendations from the account where the RDS instances are running. ✅ Use the Trusted Advisor recommendations from the consolidated billing account to see all RDS instance checks at the same time. Review the Trusted Advisor check for Amazon RDS Reserved Instance Optimization. ✅ Review the Trusted Advisor check for Amazon RDS Idle DB Instances. Review the Trusted Advisor check for Amazon Redshift Reserved Node Optimization. ✨ 关键词：reduce RDS costs 2️⃣ 4️⃣ ✅ 💡 解析：公司最近运行了 90 天的 RDS。财务团等需要使用 AWS Trusted Advisor 查看建议并减少费用。AWS Trusted Advisor 优化成本、提高性能并解决安全漏洞 AWS Trusted Advisor 可以帮助您优化成本、提升性能、提高安全性和韧性，并在云中大规模运营。Trusted Advisor 使用云成本优化、性能、韧性、安全性、卓越运营和服务限制等类别的最佳实践检查来持续评估您的 AWS 环境，并对任何偏离最佳实践的情况提出补救措施建议。 如何使用 AWS Trusted Advisor 优化成本？ 对未充分利用的资源进行的成本优化检查 适用于预留的成本优化检查 其他成本优化检查 👨‍👨‍👦‍👦 社区讨论：B &amp; Dhttps://aws.amazon.com/premiumsupport/knowledge-center/trusted-advisor-cost-optimization/ 七、Static file transferA company sells datasets to customers who do research in artificial intelligence and machine learning (AI/ML). The datasets are large, formatted files that are stored in an Amazon S3 bucket in the us-east-1 Region. The company hosts a web application that the customers use to purchase access to a given dataset. The web application is deployed on multiple Amazon EC2 instances behind an Application Load Balancer. After a purchase is made, customers receive an S3 signed URL that allows access to the files.The customers are distributed across North America and Europe. The company wants to reduce the cost that is associated with data transfers and wants to maintain or improve performance.What should a solutions architect do to meet these requirements? Configure S3 Transfer Acceleration on the existing S3 bucket. Direct customer requests to the S3 Transfer Acceleration endpoint. Continue to use S3 signed URLs for access control. ✅ Deploy an Amazon CloudFront distribution with the existing S3 bucket as the origin. Direct customer requests to the CloudFront URL. Switch to CloudFront signed URLs for access control. ❌ Set up a second S3 bucket in the eu-central-1 Region with S3 Cross-Region Replication between the buckets. Direct customer requests to the closest Region. Continue to use S3 signed URLs for access control. Modify the web application to enable streaming of the datasets to end users. Configure the web application to read the data from the existing S3 bucket. Implement access control directly in the application. ✨ 关键词： 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：大的数据集需要分发给北美和欧洲的用户，S3 存储桶位于 us-east-1。看下 2️⃣ 提到的 CloudFront signed URLs：使用签名 URL 签名 URL 包括额外的信息，例如，过期日期和时间，为您提供内容访问方面的更多控制权。该额外信息出现在策略声明中，且是基于标准策略或自定义策略。标准策略和自定义策略之间的差别将在接下来的两节中予以说明。 那么显然是 2️⃣ 更好。 👨‍👨‍👦‍👦 社区讨论：To reduce the cost associated with data transfersand maintain or improve performance,a solutionsarchitect should use Amazon CloudFront,a content delivery network(CDN) service that securely delivers data, videos,applications,and APIs to customers globally with low latencyand high transfer speeds.Deploying a CloudFront distribution with the existing S3 bucket as the origin will allow the company to serve the data to customers from edge locations that are closer to them, reducing data transfer costsand improving performance.Directing customer requests to the CloudFront URL and switching to CloudFront signed URLs for access control will enable customers to access the data securelyand efficiently. 八、VulnerabilitiesA company experienced a breach that affected several applications in its on-premises data center. The attacker took advantage of vulnerabilities in the custom applications that were running on the servers. The company is now migrating its applications to run on Amazon EC2 instances. The company wants to implement a solution that actively scans for vulnerabilities on the EC2 instances and sends a report that details the findings.Which solution will meet these requirements? Deploy AWS Shield to scan the EC2 instances for vulnerabilities. Create an AWS Lambda function to log any findings to AWS CloudTrail. Deploy Amazon Macie and AWS Lambda functions to scan the EC2 instances for vulnerabilities. Log any findings to AWS CloudTrail. ❌ Turn on Amazon GuardDuty. Deploy the GuardDuty agents to the EC2 instances. Configure an AWS Lambda function to automate the generation and distribution of reports that detail the findings. ✅ Turn on Amazon Inspector. Deploy the Amazon Inspector agent to the EC2 instances. Configure an AWS Lambda function to automate the generation and distribution of reports that detail the findings. ✨ 关键词：vulnerabilities 3️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：应用存在漏洞，需要进行防护。AWS Shield 是防 DDoS 的。Amazon Macie 是用来甄别敏感信息的。Amazon GuardDuty 是以 AWS 账号为对象的安全检测服务。 GuardDuty 为您提供准确的账户盗用威胁检测，如果您没有以近乎实时的方式持续监控相关因素，可能难以快速发现这种情况。GuardDuty 可检测出账户盗用的迹象，例如在一天之中的非典型时间从异常地理位置访问 AWS 资源。对于编程 AWS 账户，GuardDuty 能够检查异常 API 调用，例如试图通过禁用 CloudTrail 日志记录或从恶意 IP 地址创建数据库快照掩盖账户活动。 Amazon Inspector 是漏洞检测服务：Amazon Inspector 是什么？ Amazon Inspector 是一项漏洞管理服务，可自动发现工作负载并持续扫描工作负载以查找软件漏洞和意外网络泄露。 👨‍👨‍👦‍👦 社区讨论：AWS Shield for DDOSAmazon Macie for discover and protect sensitive dateAmazon GuardDuty for intelligent thread discovery to protect AWS accountAmazon Inspector for automated securityassessment. like known Vulnerability 九、Safe movement on AWS resourcesA company recently migrated its entire IT environment to the AWS Cloud. The company discovers that users are provisioning oversized Amazon EC2 instances and modifying security group rules without using the appropriate change control process. A solutions architect must devise a strategy to track and audit these inventory and configuration changes.Which actions should the solutions architect take to meet these requirements? (Choose two.) ✅ Enable AWS CloudTrail and use it for auditing. Use data lifecycle policies for the Amazon EC2 instances. Enable AWS Trusted Advisor and reference the security dashboard. ✅ Enable AWS Config and create rules for auditing and compliance purposes. Restore previous resource configurations with an AWS CloudFormation template. ✨ 关键词：without using the appropriate change control process 1️⃣ 4️⃣ ✅ 💡 解析：用户对 AWS 资源的操作没有参照流程，安全问题。CloudTrail 会记录对 AWS 资源的操作历史，可以用来审计，没有疑问。而 AWS Config 对用户操作的限制：使用 AWS Config 规则评估资源 AWS Config 用于评估 AWS 资源的配置设置。为此，您可以创建 AWS Config 规则，这些规则代表您的理想配置设置。 AWS Config 提供名为托管规则的可自定义预定义规则，以帮助您入门。 AWS Config 规则是如何运作的在 AWS Config 持续跟踪您的资源中出现的配置更改时，它会检查这些更改是否不符合规则中的任何条件。如果资源不符合规则，则会将该资源和规则 AWS Config 标记为不合规。 👨‍👨‍👦‍👦 社区讨论：A.Enable AWS CloudTrail and use it for auditing. CloudTrail providesevent history of your AWS account activity, including actions taken through the AWS Management Console, AWS Command Line Interface (CLI),and AWS SDKsand APIs. By enabling CloudTrail, the company can track user activityand changes to AWS resources,and monitor compliance with internal policiesand external regulations. D.Enable AWS Config and create rules for auditing and compliance purposes. AWS Config providesa detailed inventory of the AWS resources in your account,and continuously records changes to the configurations of those resources. By creating rules in AWS Config, the company can automate the evaluation of resource configurationsagainst desired state,and receive alerts when configurations drift from compliance. Options B, C,and E are not directly relevant to the requirement of tracking and auditing inventoryand configuration changes. 十、Amazon Cognito identity poolA company is hosting a web application from an Amazon S3 bucket. The application uses Amazon Cognito as an identity provider to authenticate users and return a JSON Web Token (JWT) that provides access to protected resources that are stored in another S3 bucket.Upon deployment of the application, users report errors and are unable to access the protected content. A solutions architect must resolve this issue by providing proper permissions so that users can access the protected content.Which solution meets these requirements? ✅ Update the Amazon Cognito identity pool to assume the proper IAM role for access to the protected content. Update the S3 ACL to allow the application to access the protected content. Redeploy the application to Amazon S3 to prevent eventually consistent reads in the S3 bucket from affecting the ability of users to access the protected content. ❌ Update the Amazon Cognito pool to use custom attribute mappings within the identity pool and grant users the properpermissions to access the protected content. ✨ 关键词： 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：应用使用 Amazon Cognito 作为认证提供者，生成 JWT 供用户访问 S3 存储桶内的数据。部署应用后收到用户的信息说无法访问受保护的文件。1️⃣ 的操作是更新 Amazon Cognito 的认证池赋予合适的 IAM 用户使其能够访问 S3 内受保护的文件。4️⃣ 则是更新自定义的属性映射来赋予用户适当的权限访问受保护文件。 身份池 (identity pool) 控制台概述 Amazon Cognito 身份池为访客用户（未经身份验证）和已通过身份验证并收到令牌的用户提供临时 AWS 证书。身份池是指与您的外部身份提供商关联的用户标识符的存储。 1️⃣ 中更具体的、与 IAM 角色相关的描述：IAM角色 创建身份池时，系统会提示您更新用户所IAM扮演的角色。IAM角色的工作原理如下：当用户登录您的应用程序时，Amazon Cognito 会为该用户生成临时 AWS 证书。这些临时证书与特定IAM角色关联。使用该IAM角色，您可以定义一组访问 AWS 资源的权限。 您可以为经过身份验证和未经身份验证的用户指定默认IAM角色。 来看下 4️⃣ 描述的属性指的是什么：将属性用于访问控制 访问控制属性是 Amazon Cognito 身份池对基于属性的访问控制 (ABAC) 的实现。您可以使用 IAM 策略，根据用户属性通过 Amazon Cognito 身份池控制对 AWS 资源的访问。这些属性可以来自社会和企业身份提供商。您可以将提供商的访问和 ID 标记或 SAML 断言中的属性映射到可在 IAM 权限策略中引用的标记。 例如，假设您拥有一个具有免费和付费会员资格的媒体流式传输服务。您可以将媒体文件存储在 Amazon S3 中，并使用免费或高级标签对其贴标签。您可以将属性用于访问控制，以允许访问基于用户会员级别（这是用户配置文件的一部分）的免费和付费内容。您可以将成员资格属性映射到标签密钥，以便委托人传递给IAM权限策略。通过这种方式，您可以创建单个权限策略，并根据会员级别的值和内容文件上的标签有条件地允许对高级内容的访问。 看上去它只是一种身份的标签，用以区分不同用户的不同权限组。 👨‍👨‍👦‍👦 社区讨论：To resolve the issue and provide proper permissions for users to access the protected content, the recommended solution is:A. Update the Amazon Cognito identity pool to assume the proper IAM role for access to the protected content. Explanation:Amazon Cognito providesauthentication and user management services for web and mobile applications.In this scenario, the application is using Amazon Cognito asan identity provider to authenticate usersand obtain JSON Web Tokens (JWTs).The JWTs are used to access protected resources stored in anotherS3 bucket.To grant users access to the protected content, the proper IAM role needs to be assumed by the identity pool in Amazon Cognito.By updating the Amazon Cognito identity pool with the appropriate IAM role, users will be authorized to access the protected content in the S3 bucket. Option D is incorrect because updating custom attribute mappings in Amazon Cognito will not directly grant users the properpermissions to access the protected content. 十一、ASG restoreA company is experiencing sudden increases in demand. The company needs to provision large Amazon EC2 instances from an Amazon Machine Image (AMI). The instances will run in an Auto Scaling group. The company needs a solution that provides minimum initialization latency to meet the demand.Which solution meets these requirements? ❌ Use the aws ec2 register-image command to create an AMI from a snapshot. Use AWS Step Functions to replace the AMI in the Auto Scaling group. ✅ Enable Amazon Elastic Block Store (Amazon EBS) fast snapshot restore on a snapshot. Provision an AMI by using the snapshot. Replace the AMI in the Auto Scaling group with the new AMI. Enable AMI creation and define lifecycle rules in Amazon Data Lifecycle Manager (Amazon DLM). Create an AWS Lambda function that modifies the AMI in the Auto Scaling group. Use Amazon EventBridge to invoke AWS Backup lifecycle policies that provision AMIs. Configure Auto Scaling group capacity limits as an event source in EventBridge. ✨ 关键词： 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：需要为 ASG 准备 AMI。最快的启动方式。没有读懂题目。但是明确下可以从 EC2 实例的根卷快照创建 AMI（之后用于 ASG 等）：创建 Amazon EBS-backed AMI 可以从 Amazon EC2 实例或从 Amazon EC2 实例的根设备快照创建自己的 Amazon EBS-backed AMI。 要从实例创建 Amazon EBS-backed AMI，请先使用现有的 Amazon EBS-backed AMI 启动一个实例。此 AMI 可以是从 AWS Marketplace 获得的 AMI，可以是使用 VM Import/Export 创建的 AMI，也可以是能够访问的任何其他 AMI。自定义满足特定要求的实例后，创建新的 AMI 并加以注册。然后，即可使用新的 AMI 启动具有自定义项的新实例。 下述过程适用于由加密的 Amazon Elastic Block Store (Amazon EBS) 卷（包括根卷）支持的 Amazon EC2 实例，也适用于未加密卷。 👨‍👨‍👦‍👦 社区讨论：readed the question 5 times, didn’t understood a thing :( Enabling Amazon Elastic BlockStore (Amazon EBS) fast snapshot restore on a snapshot allows you to quickly create a new Amazon Machine Image (AMI) from a snapshot, which can help reduce the initialization latency when provisioning new instances. Once the AMI is provisioned, you can replace the AMI in the Auto Scaling group with the new AMI.This will ensure that new instancesare launched from the updated AMI and are able to meet the increased demand quickly. The question wording is pretty weird but the only thing of value is latency during initialisation which makes B the correct option.https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-fast-snapshot-restore.html A only helps with creating the AMIC and D will probably work(ambiguous language) but won’t handle initialising latency issues.","link":"/2024/12/04/saa_test_daily_20241204/"},{"title":"SAA 考试每日练习 - 2024&#x2F;12&#x2F;05","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam50 题 (No.336 ~ No.385) 只记录了 11 道首次碰到的、错误的或有疑问的题目，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： embeddedadj. 植入的, 内含的, 深入的 | v. 埋入, 植入, 深入 | vbl. 埋入, 植入, 深入 overalladj. 全面的；综合的；总体的 | adv. 全部；总计；一般来说；大致上 | n. 外套；罩衣；工装服；连身工作服 一、Aurora cross regionA solutions architect must create a disaster recovery (DR) plan for a high-volume software as a service (SaaS) platform. All data for the platform is stored in an Amazon Aurora MySQL DB cluster.The DR plan must replicate data to a secondary AWS Region.Which solution will meet these requirements MOST cost-effectively? Use MySQL binary log replication to an Aurora cluster in the secondary Region. Provision one DB instance for the Aurora cluster in the secondary Region. ✅ Set up an Aurora global database for the DB cluster. When setup is complete, remove the DB instance from the secondary Region. Use AWS Database Migration Service (AWS DMS) to continuously replicate data to an Aurora cluster in the secondary Region. Remove the DB instance from the secondary Region. ❌ Set up an Aurora global database for the DB cluster. Specify a minimum of one DB instance in the secondary Region. ✨ 关键词：Aurora MySQL DB cluster、secondary AWS Region 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：现在已经有了一个 Aurora MySQL DB 集群，现在因为灾备需要将数据复制到另一个区域中。只使用 Aurora global database 就能解决问题了：Amazon Aurora 全球数据库 Amazon Aurora Global Database 针对全球分布式应用程序而设计，允许单个 Amazon Aurora 数据库跨越多个 AWS 区域。它在不影响数据库性能的情况下复制您的数据，在每个区域中实现低延迟的快速本地读取，并且在发生区域级的中断时提供灾难恢复能力。 2️⃣ 和 4️⃣ 的区别在于，2️⃣ 将 DB 实例从第二个区域中移除，而 4️⃣ 则在其他区域指定了一个最小的 DB 实例。首先看下 Aurora global database DB cluster 的概念：Using Amazon Aurora Global Database In the following diagram, you can find an example Aurora global database that spans two AWS Regions. 它可以在一个区域中部署主集群，然后在其他地方自动部署只读集群。而衍生出的一个概念就是 headless cluster：Achieve cost-effective multi-Region resiliency with Amazon Aurora Global Database headless clusters Headless Secondary Amazon Aurora 数据库集群是指没有数据库实例的集群。这种配置可以降低 Aurora 全局数据库的费用。在 Aurora 数据库集群中，计算和存储是分离的。没有数据库实例，就不收取计算费用。您可以在二级区域中为 Aurora 集群添加实例，以便向您的用户和应用程序提供。 没有实例的第二区域的数据库集群，显然它是本题的考点。 👨‍👨‍👦‍👦 社区讨论：I originally went for D but now I think B is correct. D isactive-active cluster so whereas B isactive-passive (headless cluster) so it is cheaper than D.https://aws.amazon.com/blogs/database/achieve-cost-effective-multi-region-resiliency-with-amazon-aurora-global-database-headless-clusters/ 二、SQS message size limitA company has a Java application that uses Amazon Simple Queue Service (Amazon SQS) to parse messages. The application cannot parse messages that are larger than 256 KB in size. The company wants to implement a solution to give the application the ability to parse messages as large as 50 MB.Which solution will meet these requirements with the FEWEST changes to the code? ✅ Use the Amazon SQS Extended Client Library for Java to host messages that are larger than 256 KB in Amazon S3. Use Amazon EventBridge to post large messages from the application instead of Amazon SQS. Change the limit in Amazon SQS to handle messages that are larger than 256 KB. Store messages that are larger than 256 KB in Amazon ElasticFile System (Amazon EFS). Configure Amazon SQS to reference this location in the messages. ✨ 关键词：SQS、256 KB 1️⃣ ✅ 💡 解析：连接到 SQS 的 Java 应用无法消费超过 256 KB 的消息。SQS 本身不支持超过 256 KB 大小的消息：Configuring queue parameters using the Amazon SQS console For Maximum message size, enter a value. The range is 1 KB to 256 KB. The default value is 256 KB. 使用 Amazon SQS Extended Client Library for Java 后可以处理超过 2 GB 大小的消息：Managing large Amazon SQS messages using Java and Amazon S3 You can use the Amazon SQS Extended Client Library for Java and Amazon Simple Storage Service (Amazon S3) to manage large Amazon Simple Queue Service (Amazon SQS) messages. This is especially useful for consuming large message payloads, from 256 KB and up to 2 GB. The library saves the message payload to an Amazon S3 bucket and sends a message containing a reference of the stored Amazon S3 object to an Amazon SQS queue. 👨‍👨‍👦‍👦 社区讨论：A. Use the Amazon SQS Extended Client Library for Java to host messages that are larger than 256 KB in Amazon S3.Amazon SQS hasa limit of 256 KB for the size of messages.To handle messages larger than 256 KB, the Amazon SQS Extended Client Library for Java can be used.This libraryallows messages larger than 256 KB to be stored in Amazon S3 and providesa way to retrieve and process them. Using this solution, the application code can remain largely unchanged while still being able to process messages up to 50 MB in size. 三、Saving plansA company has an application that is running on Amazon EC2 instances. A solutions architect has standardized the company on a particular instance family and various instance sizes based on the current needs of the company.The company wants to maximize cost savings for the application over the next 3 years. The company needs to be able to change the instance family and sizes in the next 6 months based on application popularity and usage.Which solution will meet these requirements MOST cost-effectively? ✅ Compute Savings Plan ❌ EC2 Instance Savings Plan Zonal Reserved Instances Standard Reserved Instances ✨ 关键词：maximize cost savings 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：有固定的 EC2 架构，且需要最大化降低费用。不使用 Reserved Instances 是因为它不能更改实例类型：Amazon EC2 的预留实例概览 使用预留实例时，您将承诺使用特定的实例配置。 而节省计划还分 Compute Savings Plan 和 EC2 Instance Savings Plan 两种：Savings Plans Compute Savings Plans：Compute Savings Plans 的灵活性最高，最高可帮助您节省 66% 的费用。这些计划会自动应用于 EC2 实例用量，不分实例系列、大小、可用区、区域、操作系统或租期，并且还适用于 Fargate 和 Lambda 的使用。 例如，注册 Compute Savings Plans 后，您可以随时从 C4 实例更改为 M5 实例，将工作负载从欧洲（爱尔兰）区域转移到欧洲（伦敦）区域，或者将工作负载从 EC2 迁移到 Fargate 或 Lambda，并继续自动支付 Savings Plans 价格。 EC2 Instance Savings Plans：EC2 Instance Savings Plans 可提供最低的价格，最高可提供 72% 的折扣，以换取在单个区域内使用单个实例系列的承诺（例如在弗吉尼亚北部区域使用 M5 实例）。这会自动降低您在该区域的选定实例系列成本，不分可用区、实例大小、操作系统或租期。借助 EC2 Instance Savings Plans，您可以灵活地在该区域的一个实例系列中更改实例的使用情况。 例如，您可以从运行 Windows 的 c5.xlarge 实例迁移到运行 Linux 的 c5.2xlarge 实例，并自动享受 Savings Plan 价格。 社区支持 EC2 Instance Savings Plans 虽然省的更多，不支持实例类型家族的转换，因此选 1️⃣。 顺便过一下各类型的 EC2 实例：Amazon EC2 实例类型 M 系列（通用型实例） C 系列（计算优化型实例） R 系列（内存优化型实例） 👨‍👨‍👦‍👦 社区讨论：Read Carefully guys ,They need to be able to change FAMILY ,and although EC2 Savings hasa higher discount , its clearly documented as not allowed &gt;EC2 Instance Savings Plans provide savings up to 72 percent off On-Demand, in exchange for a commitment to a specific instance family in a chosen AWS Region (forexample, M5 in Virginia).These plansautomaticallyapply to usage regardless of size (forexample, m5.xlarge, m5.2xlarge,etc.), OS (forexample, Windows, Linux,etc.),and tenancy (Host, Dedicated, Default) within the specified family in a Region. 四、Batch jobA company is migrating an old application to AWS. The application runs a batch job every hour and is CPU intensive. The batch job takes 15 minutes on average with an on-premises server. The server has 64 virtual CPU (vCPU) and 512 GiB of memory.Which solution will run the batch job within 15 minutes with the LEAST operational overhead? Use AWS Lambda with functional scaling. Use Amazon Elastic Container Service (Amazon ECS) with AWS Fargate. Use Amazon Lightsail with AWS Auto Scaling. ✅ Use AWS Batch on Amazon EC2. ✨ 关键词：batch job、takes 15 minutes on average 4️⃣ ✅ 💡 解析：有平均运行 15 分钟、需要 64 核心 512 内存的批处理任务要迁移到 AWS。Lambda 不能运行超过 15 分钟：Configure Lambda function timeout Lambda runs your code for a set amount of time before timing out. Timeout is the maximum amount of time in seconds that a Lambda function can run. The default value for this setting is 3 seconds, but you can adjust this in increments of 1 second up to a maximum value of 900 seconds (15 minutes). 再看下 AWS Batch 是什么：什么是 AWS Batch？ 借助 AWS Batch，您可以在 AWS Cloud上运行批处理计算工作负载。批量计算是开发人员、科学家和工程师用来访问大量计算资源的常见方法。AWS Batch 可根据提交的批处理作业的卷和特定资源需求动态预置最佳的计算资源（如 CPU 或内存优化计算资源）数量和类型。借助 AWS Batch，您无需安装和管理批处理计算软件或服务器集群，从而使您能够集中精力分析结果和解决问题。AWS Batch 使用 Amazon ECS、Amazon EKS 和 AWS Fargate 计划、安排和执行您的批处理计算工作负载，并可选择使用竞价型实例。 毫无疑问它很适合这个场景。 👨‍👨‍👦‍👦 社区讨论：The amount of CPU and memory resources required by the batch job exceeds the capabilities of AWS Lambda and Amazon Lightsail with AWS Auto Scaling, which offer limited compute resources. AWS Fargate offers containerized application orchestration and scalable infrastructure, but may require additional operational overhead to configure and manage the environment. AWS Batch isa fully managed service that automatically provisions the required infrastructure for batch jobs, with options to use different instance typesand launch modes.Therefore, the solution that will run the batch job within 15 minutes with the LEAST operational overhead is D. Use AWS Batch on Amazon EC2. AWS Batch can handle all the operational aspects of job scheduling, instance management,and scaling while using Amazon EC2 injavascript:void(0)stances with the right amount of CPU and memory resources to meet the job’s requirements. 五、FIFO queueA company uses a payment processing system that requires messages for a particular payment ID to be received in the same order that they were sent. Otherwise, the payments might be processed incorrectly.Which actions should a solutions architect take to meet this requirement? (Choose two.) Write the messages to an Amazon DynamoDB table with the payment ID as the partition key. ✅ Write the messages to an Amazon Kinesis data stream with the payment ID as the partition key. Write the messages to an Amazon ElastiCache for Memcached cluster with the payment ID as the key. Write the messages to an Amazon Simple Queue Service (Amazon SQS) queue. Set the message attribute to use the payment ID. ✅ Write the messages to an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Set the message group to use the payment ID. ✨ 关键词：received in the same order that they were sent 2️⃣ 5️⃣ ✅ 💡 解析：需要按照发送顺序接收带有支付 ID 的消息。5️⃣ 先进先出队列是一定正确的。看下官方描述的对 2️⃣ Amazon Kinesis data stream 的使用场景：https://www.amazonaws.cn/en/kinesis/data-streams/faqs/ Q: When should I use Amazon Kinesis Data Streams, and when should I use Amazon SQS?We recommend Amazon Kinesis Data Streams for use cases with requirements that are similar to the following: Ordering of records. For example, you want to transfer log data from the application host to the processing/archival host while maintaining the order of log statements. 它适用于对顺序有要求的数据流，因此它是支持先进先出的。社区里有人提到了 Amazon Kinesis Data Streams Terminology and concepts 这篇文章，但是我并没有在其中找到明确的写明 Amazon Kinesis data stream 遵循先进先出的相关信息。 👨‍👨‍👦‍👦 社区讨论：Option B is preferred over A because Amazon Kinesis Data Streams inherently maintain the order of records within a shard, which is crucial for the given requirement of preserving the order of messages for a particular payment ID. When you use the payment ID as the partition key,all messages for that payment ID will be sent to the same shard,ensuring that the order of messages is maintained. 选项 B 比选项 A 更可取，因为 Amazon Kinesis 数据流本质上保持了碎片内记录的顺序，这对于保存特定支付 ID 的消息顺序的给定要求是至关重要的。当您使用支付 ID 作为分区密钥时，该支付 ID 的所有消息将被发送到同一碎片，以确保保持消息的顺序。 On the other hand, Amazon DynamoDB isa NoSQL database service that provides fast and predictable performance with seamless scalability. While it can store data with partition keys, it does not guarantee the order of records within a partition, which isessential for the given use case. Hence, using Kinesis Data Streams is more suitable for this requirement.As DynamoDB does not keep the order, I think BE is the correct answer here. 六、SNS FIFOA company is building a game system that needs to send unique events to separate leaderboard, matchmaking, and authentication services concurrently. The company needs an AWS event-driven system that guarantees the order of the events.Which solution will meet these requirements? Amazon EventBridge event bus ✅ Amazon Simple Notification Service (Amazon SNS) FIFO topics ❌ Amazon Simple Notification Service (Amazon SNS) standard topics Amazon Simple Queue Service (Amazon SQS) FIFO queues ✨ 关键词：guarantees the order of the events 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：游戏公司需要按顺序发送一系列的事件。由于消费者不同，这里更适合发布-订阅模型，因此选用 SNS，而 SNS 也是支持 FIFO（先进先出）模式的，因此选 2️⃣：Message ordering and deduplication strategies using Amazon SNS FIFO topics 👨‍👨‍👦‍👦 社区讨论：The answer is B la.SNS FIFO topics queue should be used combined with SQS FIFO queue in this case.The question asked for correct order to different event, so asking forSNS fan out here to send to individual SQS.https://docs.aws.amazon.com/sns/latest/dg/fifo-example-use-case.html 七、SNS and SQS encryptionA hospital is designing a new application that gathers symptoms from patients. The hospital has decided to use Amazon Simple Queue Service (Amazon SQS) and Amazon Simple Notification Service (Amazon SNS) in the architecture.A solutions architect is reviewing the infrastructure design. Data must be encrypted at rest and in transit. Only authorized personnel of the hospital should be able to access the data.Which combination of steps should the solutions architect take to meet these requirements? (Choose two.) Turn on server-side encryption on the SQS components. Update the default key policy to restrict key usage to a set of authorized principals. ✅ Turn on server-side encryption on the SNS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply a key policy to restrict key usage to a set of authorized principals. ❌ Turn on encryption on the SNS components. Update the default key policy to restrict key usage to a set of authorized principals. Set a condition in the topic policy to allow only encrypted connections over TLS. ✅ Turn on server-side encryption on the SQS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply a key policy to restrict key usage to a set of authorized principals. Set a condition in the queue policy to allow only encrypted connections over TLS. Turn on server-side encryption on the SQS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply an IAM policy to restrict key usage to a set of authorized principals. Set a condition in the queue policy to allow only encrypted connections over TLS. ✨ 关键词：SQS、SNS、data must be encrypted at rest and in transit 3️⃣ 4️⃣ ❌ -&gt; 2️⃣ 4️⃣ ✅ 💡 解析：SNS 和 SQS 作为数据的传输过程需要加密。SQS 和 SNS 都默认提供传输中加密，因此不需要再手动配置 HTTPS。对于 SQS 队列的静态加密：Encryption at rest in Amazon SQS Server-side encryption (SSE) lets you transmit sensitive data in encrypted queues. SSE protects the contents of messages in queues using SQS-managed encryption keys (SSE-SQS) or keys managed in the AWS Key Management Service (SSE-KMS). 和 S3 一样不仅可以使用 SQS 管理的密钥，还能使用 KMS 的。当然权限也需要使用 Key Policy。而针对 SNS 的静态加密：Securing Amazon SNS data with server-side encryption Server-side encryption (SSE) lets you store sensitive data in encrypted topics by protecting the contents of messages in Amazon SNS topics using keys managed in AWS Key Management Service (AWS KMS).SSE encrypts messages as soon as Amazon SNS receives them. The messages are stored in encrypted form, and only decrypted when they are sent. 同样也是支持两种，而密钥的管理也采用 Key Policy。回到题目，3️⃣ 对 SNS 的加密使用默认加密方式，然后更新密钥的策略允许其他人使用。我并没找到详细的文章说明 SNS 管理的密钥不能共享给别人，但是我实操了下发现并没有 SSE 的选项了： 总之有 KMS 尽量就选 KMS 吧。3️⃣ 重复设置 HTTPS 其实本身也错了。 👨‍👨‍👦‍👦 社区讨论：read this:https://docs.aws.amazon.com/sns/latest/dg/sns-server-side-encryption.htmlhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-server-side-encryption.html 八、AWS account password policyA solutions architect wants all new users to have specific complexity requirements and mandatory rotation periods for IAM user passwords.What should the solutions architect do to accomplish this? ✅ Set an overall password policy for the entire AWS account. Set a password policy for each IAM user in the AWS account. Use third-party vendor software to set password requirements. ❌ Attach an Amazon CloudWatch rule to the Create_newuser event to set the password with the appropriate requirements. ✨ 关键词：specific complexity requirements、mandatory rotation periods 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：要让所有（新）用户的密码具有强制的复杂性和定期轮换要求。Set an account password policy for IAM users Rules for setting a password policyIAM 密码策略不适用于 AWS 账户根用户密码或 IAM 用户访问密钥。如果密码过期，IAM 用户将无法登录 AWS 管理控制台，但可以继续使用其访问密钥。创建或更改密码策略时，大部分密码策略设置会在用户下次更改密码时执行。不过，有些设置会立即执行。例如： 当最小长度和字符类型要求发生变化时，这些设置会在用户下一次更改密码时强制执行。即使现有密码不符合更新后的密码策略，也不会强制用户更改现有密码。 设置密码失效期后，失效期将立即生效。例如，假设你设置的密码过期时间为 90 天。在这种情况下，现有密码超过 90 天的所有 IAM 用户的密码都会过期。这些用户下次登录时必须更改密码。 👨‍👨‍👦‍👦 社区讨论：You can set a custom password policy on your AWS account to specify complexity requirementsand mandatory rotation periods for your IAM users’ passwords. When you create or change a password policy, most of the password policy settingsare enforced the next time your users change their passwords. However, some of the settingsare enforced immediately.https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords_account-policy.html#:~:text=Setting%20an%20account-,password%20policy,-for%20IAM%20users 九、HA DB and stroageA company wants to migrate an Oracle database to AWS. The database consists of a single table that contains millions of geographic information systems (GIS) images that are high resolution and are identified by a geographic code.When a natural disaster occurs, tens of thousands of images get updated every few minutes. Each geographic code has a single image or row that is associated with it. The company wants a solution that is highly available and scalable during such events.Which solution meets these requirements MOST cost-effectively? Store the images and geographic codes in a database table. Use Oracle running on an Amazon RDS Multi-AZ DB instance. ✅ Store the images in Amazon S3 buckets. Use Amazon DynamoDB with the geographic code as the key and the image S3 URL as the value. ❌ Store the images and geographic codes in an Amazon DynamoDB table. Configure DynamoDB Accelerator (DAX) during times of high load. Store the images in Amazon S3 buckets. Store geographic codes and image S3 URLs in a database table. Use Oracle running on an Amazon RDS Multi-AZ DB instance. ✨ 关键词：high resolution images 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：数分钟内会有万级的图片上传，需要插入表中。这里需要注意的是 DynamoDB 有单条数据大小限制：Data types String - The length of a String is constrained by the maximum item size of 400 KB. Binary - The length of a Binary is constrained by the maximum item size of 400 KB. 这和题目中的高分辨率图像存储需求冲突，因此需要使用到 S3。 👨‍👨‍👦‍👦 社区讨论：Amazon prefers people to move from Oracle to its own services like DynamoDB and S3. 十、Dedicated Hosts and InstancesA company is planning to migrate a commercial off-the-shelf application from its on-premises data center to AWS. The software has a software licensing model using sockets and cores with predictable capacity and uptime requirements. The company wants to use its existing licenses, which were purchased earlier this year.Which Amazon EC2 pricing option is the MOST cost-effective? ✅ Dedicated Reserved Hosts Dedicated On-Demand Hosts ❌ Dedicated Reserved Instances Dedicated On-Demand Instances ✨ 关键词：software licensing model using sockets and cores with predictable capacity and uptime requirements 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：软件授权限制核心数和时长。独立服务器 + 预留实例最具性价比。Amazon EC2 专用主机 (Dedicated Hosts) 专门用于支持现有软件许可证和改善合规性的硬件 借助 Amazon EC2 专用主机，您可以在 Amazon EC2 上使用 Microsoft 和 Oracle 等供应商提供的合格软件许可证，从而既能享受使用自己的许可证带来的灵活性与经济性，又能享受 AWS 带来的简便性与弹性。Amazon EC2 专用主机是完全专门供您使用的物理服务器，有助于您满足企业合规性要求。 Amazon EC2 专用实例 (Dedicated Instances) 专用实例是在单一客户专用硬件上的 VPC 中运行的 Amazon EC2 实例。您的专用实例在主机硬件级别与属于其他 AWS 账户的实例进行物理隔离。专用实例可与来自同一 AWS 账户中属于非专用实例的其他实例共享硬件。 专用主机强调对许可证合规性的配合；而专用实例更多强调物理级别与其他 AWS 账号隔离，可以确保更进一步的数据安全。 👨‍👨‍👦‍👦 社区讨论：”predictable capacityand uptime requirements” means “Reserved”“socketsand cores” means “dedicated host” 十一、POSIX-compliant stroageA company runs an application on Amazon EC2 Linux instances across multiple Availability Zones. The application needs a storage layer that is highly available and Portable Operating System Interface (POSIX)-compliant. The storage layer must provide maximum data durability and must be shareable across the EC2 instances. The data in the storage layer will be accessed frequently for the first 30 days and will be accessed infrequently after that time.Which solution will meet these requirements MOST cost-effectively? ❌ Use the Amazon S3 Standard storage class. Create an S3 Lifecycle policy to move infrequently accessed data to S3 Glacier. Use the Amazon S3 Standard storage class. Create an S3 Lifecycle policy to move infrequently accessed data to S3 Standard-Infrequent Access (S3 Standard-IA). ✅ Use the Amazon ElasticFile System (Amazon EFS) Standard storage class. Create a lifecycle management policy to move infrequently accessed data to EFS Standard-Infrequent Access (EFS Standard-IA). Use the Amazon ElasticFile System (Amazon EFS) One Zone storage class. Create a lifecycle management policy to move infrequently accessed data to EFS One Zone-Infrequent Access (EFS One Zone-IA). ✨ 关键词：POSIX、be accessed frequently for the first 30 days and will be accessed infrequently after that time 1️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：该应用程序需要一个高度可用性和便携式操作系统接口（POSIX）兼容的存储层。同时数据只在前 30 天访问频繁，之后偶尔访问。重点在于如何兼容 POSIX 协议：可移植操作系统接口 可移植操作系统接口（英语：Portable Operating System Interface，缩写为POSIX）是IEEE为要在各种UNIX操作系统上运行软件。 看下 EFS 的文档：创建和管理EFS资源 Amazon EFS 提供POSIX符合要求的弹性共享文件存储。您创建的文件系统支持来自多个 Amazon EC2 实例的并发读写权限。也可以从文件系统的创建地的所有可用区访问 AWS 区域 该文件系统。 由于 4️⃣ 使用了单区存储与高可用需求冲突，因此选 3️⃣ 。 👨‍👨‍👦‍👦 社区讨论：Multi AZ = both EFS and S3 supportStorage classes = both EFS and S3 supportPOSIX file system access = only Amazon EFS supports","link":"/2024/12/05/saa_test_daily_20241205/"},{"title":"SAA 考试每日练习 - 2024&#x2F;11&#x2F;27","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam20 题 (No.81 ~ No.100)，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： gatherv. 聚集，集合，搜集，积聚，增加（力量，速度等），收割，收获 | n. 聚集，收缩，衣褶 confidentialadj. 秘密的，机密的；委以机密的；获信任的 auditn. 审计，（地主与佃户间的）决算 | v. 审计，检查，〔美国〕（大学生）旁听（课程） staging暂存 一、Auto Sacling Group and SQSA solutions architect is designing the cloud architecture for a new application being deployed on AWS. The process should run in parallel while adding and removing application nodes as needed based on the number of jobs to be processed. The processor application is stateless. The solutions architect must ensure that the application is loosely coupled and the job items are durably stored.Which design should the solutions architect use? Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch configuration that uses the AMI. Create an Auto Scaling group using the launch configuration. Set the scaling policy for the Auto Scaling group to add and remove nodes based on CPU usage. Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch configuration that uses the AMI. Create an Auto Scaling group using the launch configuration. Set the scaling policy for the Auto Scaling group to add and remove nodes based on network usage. ✅ Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of items in the SQS queue. Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of messages published to the SNS topic. ✨ 关键词：based on the number of jobs to be processed、processor application is stateless、the job items are durably stored 3️⃣ ✅ 💡 解析：应用程序无状态，且需要按照任务数量动态扩展。任务需要持久保存。SQS + 弹性扩展 EC2 实例的最佳使用场景，但是 3️⃣ 和 4️⃣ 存在使用 launch configuration 还是 launch template 的区别。 Auto Scaling launch configurations You can not call CreateLaunchConfiguration with new Amazon EC2 instance types that are released after December 31, 2022. In addition, any new accounts created on or after June 1, 2023 will not have the option to create new launch configurations through the console. Starting on October 1, 2024, new accounts will not be able to create new launch configurations by using the console, API, CLI, and CloudFormation. Migrate to launch templates to ensure that you don’t need to create new launch configurations now or in the future. For information about migrating your Auto Scaling groups to launch templates, see Migrate your Auto Scaling groups to launch templates. Auto Scaling launch templates A launch template is similar to a launch configuration, in that it specifies instance configuration information. It includes the ID of the Amazon Machine Image (AMI), the instance type, a key pair, security groups, and other parameters used to launch EC2 instances. However, defining a launch template instead of a launch configuration allows you to have multiple versions of a launch template. launch configurations 可以指定的属性较少，并且已经不再更新了，之后都选 launch templates 即可。 👨‍👨‍👦‍👦 社区讨论：decoupled = SQSLaunch template = AMILaunch configuration = EC2 二、Certificates expirationA company hosts its web applications in the AWS Cloud. The company configures Elastic Load Balancers to use certificates that are imported into AWS Certificate Manager (ACM). The company’s security team must be notified 30 days before the expiration of each certificate.What should a solutions architect recommend to meet this requirement? Add a rule in ACM to publish a custom message to an Amazon Simple Notification Service (Amazon SNS) topic every day, beginning 30 days before any certificate will expire. ✅ Create an AWS Config rule that checks for certificates that will expire within 30 days. Configure Amazon EventBridge (Amazon CloudWatch Events) to invoke a custom alert by way of Amazon Simple Notification Service (Amazon SNS) when AWS Config reports a noncompliant resource. Use AWS Trusted Advisor to check for certificates that will expire within 30 days. Create an Amazon CloudWatch alarm that is based on Trusted Advisor metrics for check status changes. Configure the alarm to send a custom alert by way of Amazon Simple Notification Service (Amazon SNS). Create an Amazon EventBridge (Amazon CloudWatch Events) rule to detect any certificates that will expire within 30 days. Configure the rule to invoke an AWS Lambda function. Configure the Lambda function to send a custom alert by way of Amazon Simple Notification Service (Amazon SNS). ✨ 关键词：ELB with ACM、must notified 30 days before the expiration of each certificate 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：应用程序部署在 ELB 后，同时使用了导入到 ACM 中的证书，需要在证书过期前 30 天进行提醒。本来认为如果 ACM 自己拥有检测证书过期功能的话，1️⃣ 就是最佳选择，否则就得选 4️⃣ 了。但是社区的投票 2️⃣ 却占多数。 首先，根据官方的问答 当 ACM 导入的证书即将到期时，如何收到通知？，很显然 ACM 是并没有集成证书过期触发事件的功能的，需要通过 Amazon EventBridge 中的 ACM API 配置 ACM 证书即将到期事件： 在 EventBridge 中配置“ACM 证书即将到期”事件对于接近到期日期的事件，ACM 会通过 CloudWatch 发送通知。默认情况下，ACM 证书即将到期事件会在活动到期前 45 天发送通知。要配置此通知的计时，请首先在 EventBridge 中将该事件添加为规则。 这个事件是必不可少的，这些选 4️⃣ 的学友占了 47%。而选 2️⃣ 的则是因为在上述的问答中，提到了： 创建 AWS Conﬁg 规则……4. 对于 AWS 托管规则，选择 acm-certificate-expiration-check，然后选择下一步。5. 在参数页上，对于值，在 daysToExpiration 键中输入希望规则调用的天数。**注意：**对于接近所输入的天数的到期日期的证书，acm-certificate-expiration-check AWS Config 规则会被标记为 Noncompliant。 如果需要像题目中一样指定 30 天的过期事件，需要修改 acm-certificate-expiration-check 的配置。只能说 2️⃣ 更有必要，题目的考点似乎是针对过期时间的修改的。 最后来看下文档：acm-certificate-expiration-check 检查账户中的 AWS Certificate Manager 证书是否标记为在指定天数内到期。ACM 提供的证书会自动更新。ACM 不会自动更新您导入的证书。如果您的证书即将过期，则规则为 NON_COMPLIANT。 👨‍👨‍👦‍👦 社区讨论：AWS Config hasa managed rulenamed acm-certificate-expiration-checkto checkforexpiring certificates(configurable number of days) 三、Optimize site loading timeA company’s dynamic website is hosted using on-premises servers in the United States. The company is launching its product in Europe, and it wants to optimize site loading times for new European users. The site’s backend must remain in the United States. The product is being launched in a few days, and an immediate solution is needed.What should the solutions architect recommend? Launch an Amazon EC2 instance in us-east-1 and migrate the site to it. Move the website to Amazon S3. Use Cross-Region Replication between Regions. ✅ Use Amazon CloudFront with a custom origin pointing to the on-premises servers. Use an Amazon Route 53 geoproximity routing policy pointing to on-premises servers. ✨ 关键词：dynamic website in US、launching its product in Europe、optimize site loading times for new European users、site’s backend must remain in the United States 3️⃣ ✅ 💡 解析：动态网站的后端在美国，需要优化欧洲用户的访问，时间紧急。使用 3️⃣ 可以优化，请求在达到欧洲的边缘节点后，就会通过 AWS 的网络达到美国的网站后端。 👨‍👨‍👦‍👦 社区讨论：C. Use Amazon CloudFront with a custom origin pointing to the on-premises servers.Amazon CloudFront isa content delivery network(CDN) that speeds up the delivery of static and dynamic web content, such as HTML, CSS, JavaScript, images,and videos. By using CloudFront, the company can distribute the content of their website from edge locations that are closer to the users in Europe, reducing the loading times for these users.To use CloudFront, the company can set up a custom origin pointing to their on-premises servers in the United States. CloudFront will then cache the content of the website at edge locationsaround the world and serve the content to users from the location that is closest to them.This will allow the company to optimize the loading times for their European users without having to move the backend of the website to a different region. 四、EC2 Billing MethodA company wants to reduce the cost of its existing three-tier web architecture. The web, application, and database servers are running on Amazon EC2 instances for the development, test, and production environments. The EC2 instances average 30% CPU utilization during peak巅峰 hours and 10% CPU utilization during non-peak hours.The production EC2 instances run 24 hours a day. The development and test EC2 instances run for at least 8 hours each day. The company plans to implement automation to stop the development and test EC2 instances when they are not in use.Which EC2 instance purchasing solution will meet the company’s requirements MOST cost-effectively? Use Spot Instances for the production EC2 instances. Use Reserved Instances for the development and test EC2 instances. ✅ Use Reserved Instances for the production EC2 instances. Use On-Demand Instances for the development and test EC2 instances. Use Spot blocks for the production EC2 instances. Use Reserved Instances for the development and test EC2 instances. Use On-Demand Instances for the production EC2 instances. Use Spot blocks for the development and test EC2 instances. ✨ 关键词：reduce the cost、30% CPU utilization during peak hours、production EC2 instances run 24 hours a day、development and test EC2 instances run for at least 8 hours each day、automation development and test EC2 instances 2️⃣ ✅ 💡 解析：公司希望节省开销，EC2 实例巅峰占用为 30%，平常为 10%，生产环境机器 24 小时运行，开发测试环境每天至少 8 小时，计划不使用时自动停止开发和测试环境的 EC2 实例。生产环境使用预留实例计费模式，开发测试使用按需，选 2️⃣。 👨‍👨‍👦‍👦 社区讨论：Option B, would indeed be the most cost-effective solution. Reserved Instances provide cost savings for instances that run consistently, such as the production environment in this case, while On-Demand Instances offer flexibilityand are suitable for instances with variable usage patterns like the development and test environments.This combination ensures cost optimization based on the specific requirementsand usage patterns described in the question. Spot blocksare not longer available,and you can’t use spot instances on Prod machines 24x7, so option B should be valid. 五、S3 Object LockA company has a production web application in which users upload documents through a web interface or a mobile app.According to a new regulatory requirement. new documents cannot be modified or deleted after they are stored.What should a solutions architect do to meet this requirement? ✅ Store the uploaded documents in an Amazon S3 bucket with S3 Versioning and S3 Object Lock enabled. Store the uploaded documents in an Amazon S3 bucket. Configure an S3 Lifecycle policy to archive the documents periodically. Store the uploaded documents in an Amazon S3 bucket with S3 Versioning enabled. Configure an ACL to restrict all access to read-only. Store the uploaded documents on an Amazon ElasticFile System (Amazon EFS) volume. Access the data by mounting the volume in read-only mode. ✨ 关键词：cannot be modified or deleted after they are stored 1️⃣ ✅ 💡 解析：用户通过 API 上传文档，受限于新的审计要求，新的文档保存后就无法修改和删除。使用 S3 Object Lock 可以解决问题。 S3 对象锁定的工作原理 保留期限 - 保留期限可在固定时间内保护对象版本。当您对对象版本施加保留期限时，Amazon S3 会在该对象版本的元数据中存储时间戳，以指示保留期限的到期时间。在保留期限到期后，便可覆盖或删除对象版本。 保留模式 合规性模式 (Compliance mode) - 完全没法修改 监管模式 (Governance mode) - 有权限的特别用户可以修改 依法保留 (Legal holds) - 使用对象锁定，您还可以在对象版本上实施依法保留。与保留期限相似，依法保留可防止对象版本被覆盖或删除。但是，依法保留没有关联的固定时间长度，会一直有效，直至删除。拥有 s3:PutObjectLegalHold 权限的任何用户均可自由实施和删除依法保留。 S3 Object Lock 在官方文档中，提到了很多次与 Versioning 的结合使用，之后的题目中需要注意。 👨‍👨‍👦‍👦 社区讨论：You can use S3 Object Lockto store objects using a write-once-read-many (WORM) model. Object Lockcan help prevent objects from being deleted or overwritten for a fixed amount of time or indefinitely. You can use S3 Object Lockto meet regulatory requirements that require WORM storage, or add an extra layer of protection against object changesand deletion.Versioning is required and automaticallyactivated as Object Lockisenabled.https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock-overview.html 六、AWS Secrets ManagerA company has several web servers that need to frequently access a common Amazon RDS MySQL Multi-AZ DB instance. The company wants a secure method for the web servers to connect to the database while meeting a security requirement to rotate user credentials frequently.Which solution meets these requirements? ✅ Store the database user credentials in AWS Secrets Manager. Grant the necessary IAM permissions to allow the web servers to access AWS Secrets Manager. Store the database user credentials in AWS Systems Manager OpsCenter. Grant the necessary IAM permissions to allow the web servers to access OpsCenter. Store the database user credentials in a secure Amazon S3 bucket. Grant the necessary IAM permissions to allow the web servers to retrieve credentials and access the database. Store the database user credentials in files encrypted with AWS Key Management Service (AWS KMS) on the web server file system. The web server should be able to decrypt the files and access the database. ✨ 关键词：several web servers connect a common Amazon RDS MySQL Multi-AZ DB instance、rotate user credentials frequently 1️⃣ ✅ 💡 解析：多个应用程序连接到同一个 RDS MySQL 多可用区数据库实例，需要能够自动流转用户认证信息。数据库凭证、自动流转都是 AWS Secrets Manager 的使用场景，遇到非常多次了。 在 AWS Secrets Manager 中存储数据库凭证 在调用数据 API 时，您可以使用 AWS Secrets Manager 中的密钥传递集群或无服务器工作组的凭证。要通过此方式传递凭证，您需要指定密钥的名称或密钥的 Amazon 资源名称（ARN）。 👨‍👨‍👦‍👦 社区讨论：Secrets Managerenables you to replace hardcoded credentials in your code, including passwords, with an API call to Secrets Manager to retrieve the secret programmatically.This helpsensure the secret can’t be compromised by someone examining your code, because the secret no longerexists in the code. Also, you can configure Secrets Manager to automatically rotate the secret for you according to a specified schedule.Thisenables you to replace long-term secrets with short-term ones, significantly reducing the risk of compromise.https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html 七、Database Upgrade and DecoupleA company hosts an application on AWS Lambda functions that are invoked by an Amazon API Gateway API. The Lambda functions save customer data to an Amazon Aurora MySQL database. Whenever the company upgrades the database, the Lambda functions fail to establish database connections until the upgrade is complete. The result is that customer data is not recorded for some of the event.A solutions architect needs to design a solution that stores customer data that is created during database upgrades.Which solution will meet these requirements? Provision an Amazon RDS proxy to sit between the Lambda functions and the database. Configure the Lambda functions to connect to the RDS proxy. Increase the run time of the Lambda functions to the maximum. Create a retry mechanism in the code that stores the customer data in the database. Persist the customer data to Lambda local storage. Configure new Lambda functions to scan the local storage to save the customer data to the database. ✅ Store the customer data in an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Create a new Lambda function that polls the queue and stores the customer data in the database. ✨ 关键词：save customer data to an Amazon Aurora MySQL database、that customer data is not recorded because of the db upgrade 4️⃣ ✅ 💡 解析：用户信息经由 Lambda 后保存到 Amazon Aurora MySQL 数据库中，但是数据库升级时相应的处理数据丢失了。问如何设计一个新的解决方案。使用 SQS 解耦并设立一个新的 Lambda 函数处理保存数据的操作可以解决。 社区有 40% 的学友选了 1️⃣ 使用 Amazon RDS proxy，似乎是针对单台实例升级或故障的场景。提一下 Amazon Aurora MySQL 是支持多主数据库实例的，这意味着可以多写。Amazon Aurora Multi-Master is Now Generally Available Amazon Aurora Multi-Master 现已全面上市，允许您在多个可用区为 Aurora 数据库创建多个读写实例，从而使对正常运行时间敏感的应用程序能够在实例发生故障时实现持续的写入可用性。在实例或可用区发生故障的情况下，Aurora Multi-Master可使Aurora数据库保持读写可用性，应用程序停机时间为零。有了Aurora Multi-Master，数据库无需进行故障切换即可恢复写操作。查看本博客，了解如何使用Aurora Multi-Master构建高可用性的MySQL应用程序。 并且关于 Amazon RDS proxy 的介绍 RDS Proxy 概念和术语也明确了它在数据库故障时进行转移： 故障转移故障转移是一项高可用性功能，可在原始实例变得不可用时将数据库实例替换为另一个数据库实例。可能会因为数据库实例出现问题而发生故障转移。故障转移也可能是正常维护程序的一部分，例如在数据库升级期间。故障转移适用于多可用区配置中的 RDS 数据库实例。 但我认为升级 Amazon Aurora MySQL 总需要你手动执行：Aurora MySQL 主要版本就地升级的工作原理。并且升级是以集群为单位的，单台升级的场景就站不住脚了。 ……2. Aurora 使您的集群离线。然后，Aurora 执行与上一阶段类似的一组测试，以确认关机过程中没有产生新问题。如果此时 Aurora 检测到任何会阻止升级的情况，Aurora 会取消升级并使集群恢复联机。在这种情况下，请确认条件何时不再适用，然后再次开始升级。…… 这个题目场景更多是手动升级，而非灾难情况。4️⃣ 的方法可以一劳永逸解决问题，且符合题目需要的新架构需求。 👨‍👨‍👦‍👦 社区讨论：https://aws.amazon.com/rds/proxy/RDS Proxy minimizesapplication disruption from outagesaffecting the availability of your database byautomatically connecting to a new database instance while preserving application connections. When failovers occur, RDS Proxy routes requests directly to the new database instance.This reduces failover times for Aurora and RDS databases by up to 66%. 🙅：The original question wasabout handling a situation where the database is unavailable due to an upgrade, not a failover situation. During a database upgrade, the database instance is not available,and RDS Proxy would not be able to connect to a new database instance because there isn’t one.In this specific scenario, using Amazon SQS as described in option D providesa buffer for the incoming data during the period when the database is unavailable.Thisensures that no data is lost,and it can be written to the database once the upgrade is complete. 八、S3 Cross-Region ReplicationA survey company has gathered收集 data for several years from areas in the United States. The company hosts the data in an Amazon S3 bucket that is 3 TB in size and growing. The company has started to share the data with a European marketing firm that has S3 buckets. The company wants to ensure that its data transfer costs remain as low as possible.Which solution will meet these requirements? ✅ Configure the Requester Pays feature on the company’s S3 bucket. ❌ Configure S3 Cross-Region Replication from the company’s S3 bucket to one of the marketing firm’s S3 buckets. Configure cross-account access for the marketing firm so that the marketing firm has access to the company’s S3 bucket. Configure the company’s S3 bucket to use S3 Intelligent-Tiering. Sync the S3 bucket to one of the marketing firm’s S3 buckets. ✨ 关键词：United States S3 share with European S3、low cost 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：公司在美国的 S3 存储桶中存了 3 TB 数据，要分享给欧洲其他 AWS 账户的 S3 存储桶。需要最便宜的方案。使用跨区域副本功能将 S3 存储桶备份给对方。 我在进行选择的适合犹豫了下 S3 Cross-Region Replication 是否可以跨 AWS 账户，确认了是支持的。Workload requirements and live replication Workload requirement S3 RTC (15-minute SLA) Cross-Region Replication (CRR) Same-Region Replication (SRR) Replicate objects between different AWS accounts Yes Yes Yes 社区投票 1️⃣ 和 2️⃣ 一半一半，有人提到了 S3 Cross-Region Replication 不支持现有数据，查了下是真的：在区域内和跨区域复制对象 实时复制 (Live replication)：想要在向源存储桶写入新的和更新的对象的同时，自动复制这些对象，请使用实时复制。实时复制不会复制在设置复制之前就存在于存储桶中的任何对象。想要复制在设置复制之前就存在的对象，请使用按需复制。 跨区域复制（CRR）– 可以使用 CRR 跨不同 AWS 区域中的 S3 存储桶复制对象。有关 CRR 的更多信息，请参阅何时使用跨区域复制。 同区域复制（SRR）– 可以使用 SRR 跨同一 AWS 区域中的 Amazon S3 存储桶复制对象。有关 SRR 的更多信息，请参阅何时使用同区域复制。 按需复制 (On-demand replication)：想要按需从源存储桶中复制现有对象到一个或多个目标存储桶，请使用 S3 批量复制。有关复制现有对象的更多信息，请参阅 何时使用 S3 分批复制。 根据这点 2️⃣ 就是错误的了，因此选 1️⃣。 👨‍👨‍👦‍👦 社区讨论：this question is too vague imhoif the question is looking for a way to incur charges to the European company instead of the US company, then requester pay makes sense.if theyare looking to reduce overall data transfer cost, then B makes sense because the data does not leave the AWS network, thus data transfer cost should be lower technically?A. makes sense because the US company saves money, but the European company is paying for the charges so there is no overall saving in cost when you lookat the big pictureI will go for B because theyare not explicitly stating that they want the other company to pay for the charges 🙅：”Typically, you configure buckets to be Requester Pays buckets when you want to share data but not incur chargesassociated with othersaccessing the data. Forexample, you might use Requester Pays buckets when making available large datasets, such as zip code directories, reference data, geospatial information, or web crawling data.”https://docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysBuckets.html 🙅：B) Cross Region Replication: $0.02/GBA) over the internet it is $0.09/GB 九、Amazon S3 accidental deletionA company uses Amazon S3 to store its confidential机密的 audit审计 documents. The S3 bucket uses bucket policies to restrict access to audit team IAM user credentials according to the principle of least privilege. Company managers are worried about accidental deletion of documents in the S3 bucket and want a more secure solution.What should a solutions architect do to secure the audit documents? ✅ Enable the versioning and MFA Delete features on the S3 bucket. Enable multi-factor authentication (MFA) on the IAM user credentials for each audit team IAM user account. Add an S3 Lifecycle policy to the audit team’s IAM user accounts to deny the s3:DeleteObject action during audit dates. Use AWS Key Management Service (AWS KMS) to encrypt the S3 bucket and restrict audit team IAM user accounts from accessing the KMS key. ✨ 关键词：confidential audit documents、IAM user、accidental deletion 1️⃣ ✅ 💡 解析：在 S3 上存储了机密的审计文档，已经按照最少权限原则创建了 IAM 用户，公司管理层还是担心意外删除并想要一个另外的保障措施。开启版本、删除操作时的二步确认都能解决这个问题。 👨‍👨‍👦‍👦 社区讨论：Same as Question #44 #44 一样的场景，两个正确选项： Enable versioning on the S3 bucket. Enable MFA Delete on the S3 bucket. 十、Read replica for RDSA company is using a SQL database to store movie data that is publicly accessible. The database runs on an Amazon RDS Single-AZ DB instance. A script runs queries at random intervals each day to record the number of new movies that have been added to the database. The script must report a final total during business hours.The company’s development team notices that the database performance is inadequate for development tasks when the script is running. A solutions architect must recommend a solution to resolve this issue.Which solution will meet this requirement with the LEAST operational overhead? Modify the DB instance to be a Multi-AZ deployment. ✅ Create a read replica of the database. Configure the script to query only the read replica. Instruct the development team to manually export the entries in the database at the end of each day. Use Amazon ElastiCache to cache the common queries that the script runs against the database. ✨ 关键词：Single-AZ、database performance is inadequate 2️⃣ ✅ 💡 解析：有一个公开的存放影视数据的单区 RDS 数据库，有一个每天随机运行的统计新电影条数的脚本。发现脚本运行的时候数据库性能下降。最简单的架构解决问题。新增只读副本供脚本查询可以解决。 👨‍👨‍👦‍👦 社区讨论：Elasti Cache if for reading common results.The script is looking for new moviesadded. Read replica would be the best choice. 十一、VPC gateway endpointA company has applications that run on Amazon EC2 instances in a VPC. One of the applications needs to call the Amazon S3 API to store and read objects. According to the company’s security regulations, no traffic from the applications is allowed to travel across the internet.Which solution will meet these requirements? ✅ Configure an S3 gateway endpoint. Create an S3 bucket in a private subnet. Create an S3 bucket in the same AWS Region as the EC2 instances. Configure a NAT gateway in the same subnet as the EC2 instances. ✨ 关键词：EC2 in VPC needs to call the Amazon S3 API、private subnet、 1️⃣ ✅ 💡 解析：私有子网的 EC2 需要访问 S3。网关终端节点（连接 S3 或 DynamoDB）的使用场景。需要注意的是，终端节点是 VPC 级别的。 👨‍👨‍👦‍👦 社区讨论：Gateway endpoints provide reliable connectivity to Amazon S3 and DynamoDB without requiring an internet gateway or a NAT device for your VPC. It should be option A.https://docs.aws.amazon.com/vpc/latest/privatelink/gateway-endpoints.html 十二、S3 bucket policyA company is storing sensitive user information in an Amazon S3 bucket. The company wants to provide secure access to this bucket from the application tier running on Amazon EC2 instances inside a VPC.Which combination of steps should a solutions architect take to accomplish this? (Choose two.) ✅ Configure a VPC gateway endpoint for Amazon S3 within the VPC. Create a bucket policy to make the objects in the S3 bucket public. ✅ Create a bucket policy that limits access to only the application tier running in the VPC. Create an IAM user with an S3 access policy and copy the IAM credentials to the EC2 instance. Create a NAT instance and have the EC2 instances use the NAT instance to access the S3 bucket. ✨ 关键词：provide secure access to this bucket 1️⃣ 3️⃣ ✅ 💡 解析：有敏感的用户信息存放在 S3 存储桶中，需要让运行在 VPC 中 EC2 上的应用程序对其安全访问。IAM 角色权限或存储桶权限都能解决权限问题。2️⃣ 错在不应该公开存储桶，4️⃣ 错在不是 IAM 用户而应该是 IAM 角色 (Role)。而访问 S3 应该使用 网关终端节点。因此选 1️⃣ 3️⃣。 Amazon S3 存储桶策略的示例 向公共匿名用户授予只读权限 需要加密 使用标准 ACL 管理存储桶 使用对象标记管理对象访问权限 使用全局条件键管理对象访问权限 管理基于 HTTP 或 HTTPS 请求的访问权限 管理用户对特定文件夹的访问权限 管理访问日志的访问权限 管理对 Amazon CloudFront OAI 的访问 管理 Amazon S3 Storage Lens 存储统计管理工具的访问权限 管理 S3 清单、S3 分析和 S3 清单报告的权限 需要 MFA 防止用户删除对象 有多种方式实现只让应用程序能够安全访问 S3 存储桶。 👨‍👨‍👦‍👦 社区讨论：A: VPC S3 gateway for direct connection (no public internet) to access S3C: Bucket policy to secure access and only allow the VPC application tier to access it B: Opens up to publicD: Not secure to copy credentialsE: NAT instance (obsolete now) is not useful for limiting resource access, it’s for subnet connections 十三、Amazon Aurora MySQL database cloningA company runs an on-premises application that is powered by a MySQL database. The company is migrating the application to AWS to increase the application’s elasticity and availability.The current architecture shows heavy read activity on the database during times of normal operation. Every 4 hours, the company’s development team pulls a full export of the production database to populate填充 a database in the staging暂存 environment. During this period, users experience unacceptable application latency. The development team is unable to use the staging environment until the procedure completes.A solutions architect must recommend replacement architecture that alleviates the application latency issue. The replacement architecture also must give the development team the ability to continue using the staging environment without delay.Which solution meets these requirements? Use Amazon Aurora MySQL with Multi-AZ Aurora Replicas for production. Populate the staging database by implementing a backup and restore process that uses the mysqldump utility. ✅ Use Amazon Aurora MySQL with Multi-AZ Aurora Replicas for production. Use database cloning to create the staging database on-demand. Use Amazon RDS for MySQL with a Multi-AZ deployment and read replicas for production. Use the standby instance for the staging database. Use Amazon RDS for MySQL with a Multi-AZ deployment and read replicas for production. Populate the staging database by implementing a backup and restore process that uses the mysqldump utility. ✨ 关键词：database full export、latency 2️⃣ ✅ 💡 解析：公司本地运行的数据库，每 4 小时做一次全量导出到暂存环境，导致用户感受到延迟、开发者暂时也无法使用暂存环境。迁移到新架构需要解决延迟问题，并确保暂存环境实时可用。数据库环境要分开，因此不能使用集群而要使用副本，3️⃣ 排除。而解决暂存环境实时可用使用 Aurora MySQL 数据库的复制功能即可。 Aurora 克隆 (Aurora cloning) 概述 Aurora 使用写入时复制协议创建克隆。此机制占用最少的额外空间来创建初始克隆。首次创建克隆时，Aurora 会保留源 Aurora 数据库集群和新（克隆的）Aurora 数据库集群使用的数据的单个副本。只有当源 Aurora 数据库集群或 Aurora 数据库集群克隆对数据（在 Aurora 存储卷上）进行更改时，才会分配额外的存储空间。 Aurora 克隆非常适合使用您的生产数据快速设置测试环境，且不会有损坏数据的风险。您可以将克隆用于多种类型的应用程序，例如： 对潜在的变化（例如模式变化和参数组变化）进行试验，以评估所有影响。 执行工作负载密集型操作，例如导出数据或在克隆上运行分析查询。 为开发、测试或其他用途创建生产数据库集群的副本。 虽然这里我也不知道有 Aurora cloning 这个功能，但是和手动的数据库备份相比，既然 AWS 在选项中提供了更优雅的解决方式，那它应该是有自信自己拥有的 🤦 👨‍👨‍👦‍👦 社区讨论：The recommended solution is Option B: Use Amazon Aurora MySQL with Multi-AZ Aurora Replicas for production. Use database cloning to create the staging database on-demand.To alleviate the application latency issue, the recommended solution is to use Amazon Aurora MySQL with Multi-AZ Aurora Replicas for production, and use database cloning to create the staging database on-demand. This allows the development Replicas for production, and use database cloning to create the staging database on-demand. This allows the development team to continue using the staging environment without delay, while also providing elasticity and availability for the production application.Therefore, Options A, C, and D are not recommended 十四、LambdaA company is designing an application where users upload small files into Amazon S3. After a user uploads a file, the file requires one-time simple processing to transform the data and save the data in JSON format for later analysis.Each file must be processed as quickly as possible after it is uploaded. Demand will vary. On some days, users will upload a high number of files. On other days, users will upload a few files or no files.Which solution meets these requirements with the LEAST operational overhead? Configure Amazon EMR to read text files from Amazon S3. Run processing scripts to transform the data. Store the resulting JSON file in an Amazon Aurora DB cluster. Configure Amazon S3 to send an event notification to an Amazon Simple Queue Service (Amazon SQS) queue. Use Amazon EC2 instances to read from the queue and process the data. Store the resulting JSON file in Amazon DynamoDB. ✅ Configure Amazon S3 to send an event notification to an Amazon Simple Queue Service (Amazon SQS) queue. Use an AWS Lambda function to read from the queue and process the data. Store the resulting JSON file in Amazon DynamoDB. Configure Amazon EventBridge (Amazon CloudWatch Events) to send an event to Amazon Kinesis Data Streams when a new file is uploaded. Use an AWS Lambda function to consume the event from the stream and process the data. Store the resulting JSON file in an Amazon Aurora DB cluster. ✨ 关键词：save the data in JSON format、Demand will vary 3️⃣ ✅ 💡 解析：用户上传到 S3 存储桶的文件需要立即进行处理并保存数据为 JSON 格式。处理需求无法预测且波动剧烈。要求最简单的架构。Lambda 足够简单 (Serverless)，且自带弹性扩容属性非常适合这个场景，3️⃣ 中提到了，并且还使用了 SQS 进行解耦，DynamoDB 也符合 JSON 数据存储需求。 👨‍👨‍👦‍👦 社区讨论：A. Configuring EMR and an Aurora DB cluster for this use case would introduce unnecessary complexity and operational overhead. EMR is typically used for processing large datasets and running big data frameworks like Apache Spark or Hadoop.B. While using S3 event notifications and SQS for decoupling is a good approach, using EC2 to process the data would introduce operational overhead in terms of managing and scaling the EC2.D. Using EventBridge and Kinesis Data Streams for this use case would introduce additional complexity and operational overhead compared to the other options. EventBridge and Kinesis are typically used for real-time streaming and processing of large volumes of data. In summary, option C is the recommended solution as it provides a serverless and scalable approach for processing uploaded files using S3 event notifications, SQS, and Lambda. It offers low operational overhead, automatic scaling, and efficient handling of varying demand. Storing the resulting JSON file in DynamoDB aligns with the requirement of saving the data for later analysis. 十五、Database read replicasAn application allows users at a company’s headquarters to access product data. The product data is stored in an Amazon RDS MySQL DB instance. The operations team has isolated an application performance slowdown and wants to separate read traffic from write traffic. A solutions architect needs to optimize the application’s performance quickly.What should the solutions architect recommend? Change the existing database to a Multi-AZ deployment. Serve the read requests from the primary Availability Zone. Change the existing database to a Multi-AZ deployment. Serve the read requests from the secondary Availability Zone. Create read replicas for the database. Configure the read replicas with half of the compute and storage resources as the source database. ✅ Create read replicas for the database. Configure the read replicas with the same compute and storage resources as the source database. ✨ 关键词：separate read traffic from write traffic 4️⃣ ✅ 💡 解析：应用程序处理存储在 Amazon RDS MySQL 中的数据，操作团队发现性能缓慢并希望读写分离。架构师需要迅速解决问题。读写分离需要创建只读副本，副本最少需要和主数据库保持一样的配置，选 4️⃣。 👨‍👨‍👦‍👦 社区讨论：The solutions architect should recommend option D: Create read replicas for the database. Configure the read replicas with the same compute and storage resources as the source database.Creating read replicas allows the application to offload read traffic from the source database, improving its performance. The read replicas should be configured with the same compute and storage resources as the source database to ensure that they can handle the read workload effectively. 十六、IAM policyAn Amazon EC2 administrator created the following policy associated with an IAM group containing several users:What is the effect of this policy? Users can terminate an EC2 instance in any AWS Region except us-east-1. Users can terminate an EC2 instance with the IP address 10.100.100.1 in the us-east-1 Region. ✅ Users can terminate an EC2 instance in the us-east-1 Region when the user’s source IP is 10.100.100.254. Users cannot terminate an EC2 instance in the us-east-1 Region when the user’s source IP is 10.100.100.254. ✨ 关键词：IAM policy 3️⃣ ✅ 💡 解析：第一段意为允许所有来源 IP 属于 10.100.100.0/24 的执行 ec2:TerminateInstances 命令；第二段意为禁止对所有不属于 us-east-1 区域的 EC2 实例进行操作。这意味着要登陆 EC2 实例，需要用户 IP 属于 10.100.100.0/24 段，同时实例属于 us-east-1 区域。 👨‍👨‍👦‍👦 社区讨论：What the policy means: Allow termination of any instance if user’s source IP address is 100.100.254. Deny termination of instances that are not in the us-east-1 Combining this two, you get: “Allow instance termination in the us-east-1 region if the user’s source IP address is 10.100.100.254. Deny termination operationon other regions.” 十七、Windows File Server and ADA company has a large Microsoft SharePoint deployment running on-premises that requires Microsoft Windows shared file storage. The company wants to migrate this workload to the AWS Cloud and is considering various storage options. The storage solution must be highly available and integrated with Active Directory for access control.Which solution will satisfy these requirements? Configure Amazon EFS storage and set the Active Directory domain for authentication. Create an SMB file share on an AWS Storage Gateway file gateway in two Availability Zones. Create an Amazon S3 bucket and configure Microsoft Windows Server to mount it as a volume. ✅ Create an Amazon FSx for Windows File Server file system on AWS and set the Active Directory domain for authentication. ✨ 关键词：Windows shared file storage、highly available、integrated with Active Directory for access control 4️⃣ ✅ 💡 解析：公司在本地部署有 Windwos 文件存储分享系统，想迁移到 AWS 并使用 AD 控制访问权限。Windows 存储使用 FSx for Windows File Server 没有疑问，AD 使用三种方案都能解决： AWS Managed Microsoft AD - 在 AWS 中建立新的 AD 并与本地 AD 建立信任关系 AD Connector - 代理，AD 认证请求到 AWS 后发回本地认证 Simple AD - 功能简单的 AD 👨‍👨‍👦‍👦 社区讨论：D. Create an Amazon FSx for Windows File Server file system on AWS and set the Active Directory domain for authentication.Amazon FSx for Windows File Server is a fully managed file storage service that is designed to be used with Microsoft Windows workloads. It is integrated with Active Directory for access control and is highly available, as it stores data across multiple availability zones. Additionally, FSx can be used to migrate data from on-premises Microsoft Windows file servers to the AWS Cloud. This makes it a good fit for the requirements described in the question. 十八、SQS message multiple consumedAn image-processing company has a web application that users use to upload images. The application uploads the images into an Amazon S3 bucket. The company has set up S3 event notifications to publish the object creation events to an Amazon Simple Queue Service (Amazon SQS) standard queue. The SQS queue serves as the event source for an AWS Lambda function that processes the images and sends the results to users through email.Users report that they are receiving multiple email messages for every uploaded image. A solutions architect determines that SQS messages are invoking the Lambda function more than once, resulting in multiple email messages.What should the solutions architect do to resolve this issue with the LEAST operational overhead? Set up long polling in the SQS queue by increasing the ReceiveMessage wait time to 30 seconds. Change the SQS standard queue to an SQS FIFO queue. Use the message deduplication ID to discard duplicate messages. ✅ Increase the visibility timeout in the SQS queue to a value that is greater than the total of the function timeout and the batch window timeout. ❌ Modify the Lambda function to delete each message from the SQS queue immediately after the message is read before processing. ✨ 关键词：multiple email messages、SQS messages are invoking the Lambda function more than once 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：SQS 队列后到 Lambda 多次消费同一条消息。要求最简单的解决方式。第一时间觉得需要通过 ChangeMessageVisibility 在第一次消费消息时，将消息设置为隐藏（不可见），但是没有这个选项。 1️⃣ 增加对 SQS 轮训的时间，没有用；2️⃣ 通过 FIFO 队列和去重 ID 保证消息不重复；3️⃣ 将 SQS 中的消息的可见性超时增加到大于函数超时和批处理窗口超时之和的值；4️⃣ 将 Lambda 方法设置为读取到消息就立即删除，即使还没有处理。 如果是消息重复的场景应该选 2️⃣，但是这里明显 S3 存储桶的通知不会出现消息发送重复的低级问题。4️⃣ 它存在函数失败后消息丢失的可能性。 而要选出 3️⃣，需要你了解 SQS 中消息的生命周期：Amazon SQS 可见性超时 当消费者收到来自 Amazon SQS 队列的消息时，该消息会保留在队列中，但其他消费者暂时看不见。这种暂时的隐身性由可见性超时控制，这是一种防止其他使用者在处理同一消息时处理该消息的机制。Amazon SQS 不会自动删除该消息；相反，消费者必须在消息成功处理后使用DeleteMessage操作将其明确删除。 设置可见性超时当一条消息返回给消费者时，Amazon 中的可见性超时就SQS开始了。在这段时间内，消费者需要处理和删除消息。但是，如果消费者未能在可见性超时到期之前删除消息，则该消息将在队列中再次可见，并且可以由其他使用者检索。每个 Amazon SQS 队列的默认可见性超时为 30 秒，但您可以根据应用程序的需求调整此设置。通常，最好将可见性超时设置为与应用程序处理和删除消息所需的最长时间相匹配。您也可以为单个消息配置特定的可见性超时，而无需更改队列的总体超时设置。 那么很显然题目场景就是 Lambda 函数和批处理的总执行时间超过了默认可见性超时的 30 秒，导致消息被重复消费了。我在过往的 RabbitMQ 使用过程中，竟然从来没让消息超时过，以至于一时忽视了这个默认超时机制 🤦 👨‍👨‍👦‍👦 社区讨论：answer should be C,users get duplicated messages because -&gt; lambda polls the message, and starts processing the message.However, before the first lambda can finish processing the message, the visibility timeout runs out on SQS, and SQS returns the message to the poll, causing another Lambda node to process that same message.By increasing the visibility timeout, it should prevent SQS from returning a message back to the poll before Lambda can finish processing the message. this is important part:Immediately after a message is received, it remains in the queue. To prevent other consumers from processing the message again, Amazon SQS sets a visibility timeout, a period of time during which Amazon SQS prevents other consumers from receiving and processing the message. The default visibility timeout for a message is 30 seconds. The minimum is 0 seconds.The maximum is 12 hours. 十九、Lustre storageA company is implementing a shared storage solution for a gaming application that is hosted in an on-premises data center.The company needs the ability to use Lustre clients to access data. The solution must be fully managed.Which solution meets these requirements? Create an AWS Storage Gateway file gateway. Create a file share that uses the required client protocol. Connect the application server to the file share. Create an Amazon EC2 Windows instance. Install and configure a Windows file share role on the instance. Connect the application server to the file share. Create an Amazon Elastic File System (Amazon EFS) file system, and configure it to support Lustre. Attach the file system to the origin server. Connect the application server to the file system. ✅ Create an Amazon FSx for Lustre file system. Attach the file system to the origin server. Connect the application server to the file system. ✨ 关键词：shared storage solution、use Lustre clients to access data 4️⃣ ✅ 💡 解析：需要能让 Lustre 客户端访问的共享存储空间。Amazon FSx for Lustre 可以解决。 Amazon for FSx Lustre 是什么？ FSxfor Lustre 可以轻松且经济高效地启动和运行流行的高性能 Lustre 文件系统。您可以将 Lustre 用于速度至关重要的工作负载，例如机器学习、高性能计算 (HPC)、视频处理和财务建模。 浅谈HPC中的Lustre Lustre 体系结构是一个为集群设计的存储体系结构。 其核心组件是运行在 Linux 操作系统上、 支持标准的 POSIX* UNIX 文件系统接口、 并遵循 GPL2.0 许可的 Lustre 文件系统。 据 IDC 的统计， Lustre 是在 HPC 领域应用最广的文件系统， 世界上最快的 50 个超算网站有 60%都使用 Lustre。 👨‍👨‍👦‍👦 社区讨论：Lustre in the question is only available as FSxhttps://aws.amazon.com/fsx/lustre/ 二十、Certificates encryption and data encryptionA company’s containerized application runs on an Amazon EC2 instance. The application needs to download security certificates before it can communicate with other business applications. The company wants a highly secure solution to encrypt and decrypt the certificates in near real time. The solution also needs to store data in highly available storage after the data is encrypted.Which solution will meet these requirements with the LEAST operational overhead? Create AWS Secrets Manager secrets for encrypted certificates. Manually update the certificates as needed. Control access to the data by using fine-grained IAM access. Create an AWS Lambda function that uses the Python cryptography library to receive and perform encryption operations. Store the function in an Amazon S3 bucket. ✅ Create an AWS Key Management Service (AWS KMS) customer managed key. Allow the EC2 role to use the KMS key for encryption operations. Store the encrypted data on Amazon S3. Create an AWS Key Management Service (AWS KMS) customer managed key. Allow the EC2 role to use the KMS key for encryption operations. Store the encrypted data on Amazon Elastic Block Store (Amazon EBS) volumes. ✨ 关键词：encrypt and decrypt the certificates in near real time、highly available storage、data is encrypted 3️⃣ ✅ 💡 解析：应用程序与其他商业营销交互前需要下载密钥凭证，需要高度安全的解决方案去近实时地加密解密凭证，还需要将数据保密并存于高可用的存储上。最简单的架构。加密解密需要使用到 KMS，高可用且可以加密的存储使用 S3。 这里看上去还是 S3 的客户端加密 (SSE-C) 场景。使用服务器端加密保护数据 具有 Amazon S3 托管密钥的服务器端加密（SSE-S3） 具有 AWS Key Management Service（AWS KMS）密钥的服务器端加密（SSE-KMS） 具有 AWS Key Management Service（AWS KMS）密钥的双层服务器端加密（DSSE-KMS） 具有客户提供密钥的服务器端加密（SSE-C） 👨‍👨‍👦‍👦 社区讨论：C makes a better sense. Between C (S3) and D (EBS), S3 is highly available with LEAST operational overhead.","link":"/2024/11/27/saa_test_daily_20241127/"},{"title":"SAA 考试每日练习 - 2024&#x2F;12&#x2F;07","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam20 题 (No.451 ~ No.470) 只记录了 4 道首次碰到的、错误的或有疑问的题目，仅供自己复习使用。如果侵权请联系删除。 一、Budgets createA company uses AWS Organizations. The company wants to operate some of its AWS accounts with different budgets. The company wants to receive alerts and automatically prevent provisioning of additional resources on AWS accounts when the allocated budget threshold is met during a specific period.Which combination of solutions will meet these requirements? (Choose three.) ❌ Use AWS Budgets to create a budget. Set the budget amount under the Cost and Usage Reports section of the required AWS accounts. ✅ Use AWS Budgets to create a budget. Set the budget amount under the Billing dashboards of the required AWS accounts. Create an IAM user for AWS Budgets to run budget actions with the required permissions. ✅ Create an IAM role for AWS Budgets to run budget actions with the required permissions. Add an alert to notify the company when each account meets its budget threshold. Add a budget action that selects the IAM identity created with the appropriate config rule to prevent provisioning of additional resources. ✅ Add an alert to notify the company when each account meets its budget threshold. Add a budget action that selects the IAM identity created with the appropriate service control policy (SCP) to prevent provisioning of additional resources. ✨ 关键词： 1️⃣ 4️⃣ 6️⃣ ❌ -&gt; 2️⃣ 4️⃣ 6️⃣ ✅ 💡 解析：AWS 的预算在 账单控制台 - 预算和规划 - 预算 处创建： 👨‍👨‍👦‍👦 社区讨论：”Create an AWS Budget: Go to the AWS Billing Dashboard”https://awslabs.github.io/scale-out-computing-on-aws/workshops/TKO-Scale-Out-Computing/modules/071-budgets/ 二、AWS Transfer FamilyA company that uses AWS is building an application to transfer data to a product manufacturer. The company has its own identity provider (IdP). The company wants the IdP to authenticate application users while the users use the application to transfer data. The company must use Applicability Statement 2 (AS2) protocol.Which solution will meet these requirements? Use AWS DataSync to transfer the data. Create an AWS Lambda function for IdP authentication. Use Amazon AppFlow flows to transfer the data. Create an Amazon Elastic Container Service (Amazon ECS) task for IdP authentication. ✅ Use AWS Transfer Family to transfer the data. Create an AWS Lambda function for IdP authentication. ❌ Use AWS Storage Gateway to transfer the data. Create an Amazon Cognito identity pool for IdP authentication. ✨ 关键词： 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：公司希望 IdP 在用户使用应用程序传输数据时对应用程序用户进行身份验证。相当于要将 IdP 功能置放在数据传输的应用程序中。 什么是 AWS Transfer Family？ AWS Transfer Family 是一种安全的传输服务，使您能够将文件传入和传出 AWS 存储服务。Transfer Family 是该 AWS Cloud 平台的一部分。 AWS Transfer Family 为通过SFTP、、AS2、FTPS以及FTP直接传入和传出 Amazon S3 或 Amazon 的文件提供完全托管的支持EFS。过维护现有的客户端身份验证、访问和防火墙配置，您可以无缝迁移、自动化和监控文件传输工作流程，因此您的客户、合作伙伴和内部团队或其应用程序不会发生任何变化。 使用自定义身份提供程序 要对用户进行身份验证，您可以使用现有的身份提供商 AWS Transfer Family。您可以使用功能集成您的身份提供商，该 AWS Lambda 功能对您的用户进行身份验证和授权，使其能够访问 Amazon S3 或 Amazon Elastic File System (Ama EFS zon)。 👨‍👨‍👦‍👦 社区讨论：Option C stands out stronger because AWS Transfer Family securely scales your recurring business-to-business file transfers to AWS Storage services using SFTP, FTPS, FTP, and AS2 protocols.And AWS Lambda can be used to authenticate users with the company’s IdP. 三、LambdaAn IoT company is releasing a mattress that has sensors to collect data about a user’s sleep. The sensors will send data to an Amazon S3 bucket. The sensors collect approximately 2 MB of data every night for each mattress. The company must process and summarize the data for each mattress. The results need to be available as soon as possible. Data processing will require 1 GB of memory and will finish within 30 seconds.Which solution will meet these requirements MOST cost-effectively? Use AWS Glue with a Scala job Use Amazon EMR with an Apache Spark script ✅ Use AWS Lambda with a Python script ❌ Use AWS Glue with a PySpark job ✨ 关键词： 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：这里由于 EMR 和 Glue 都会留存数据，不够便宜因此不选。 Scala 是一门多范式的编程语言，设计初衷是要集成面向对象编程和函数式编程的各种特性。 什么是 Apache Spark？ Apache Spark 是一种用于大数据工作负载的分布式开源处理系统。 一起揭开 PySpark 编程的神秘面纱 Spark支持很多语言的调用，包括了Java、Scala、Python等，其中用Python语言编写的Spark API就是PySpark。 👨‍👨‍👦‍👦 社区讨论：That’s the point here, technically all the options are good and will work, but since we are on a small amount of data Lambda will be the cheapest one, usually Glue or EMR will be kept for a big amount of data.Here is a topic where people did a comparison in comments:https://www.reddit.com/r/aws/comments/9umxv1/aws 四、Multi-AttachA company is developing an application to support customer demands. The company wants to deploy the application on multiple Amazon EC2 Nitro-based instances within the same Availability Zone. The company also wants to give the application the ability to write to multiple block storage volumes in multiple EC2 Nitro-based instances simultaneously to achieve higher application availability. Use General Purpose SSD (gp3) EBS volumes with Amazon Elastic Block Store (Amazon EBS) Multi-Attach Use Throughput Optimized HDD (st1) EBS volumes with Amazon Elastic Block Store (Amazon EBS) Multi-Attach ✅ Use Provisioned IOPS SSD (io2) EBS volumes with Amazon Elastic Block Store (Amazon EBS) Multi-Attach Use General Purpose SSD (gp2) EBS volumes with Amazon Elastic Block Store (Amazon EBS) Multi-Attach ✨ 关键词： 3️⃣ ✅ 💡 解析：使用多重挂载将 EBS 卷挂载到多个 EC2 实例 通过 Amazon EBS 多重挂载，您可以将单个预置 IOPS SSD（io1 或 io2）卷挂载到位于同一可用区中的多个实例。您可以将多个启用多重挂载的卷附加到一个实例或一组实例。卷附加到的每个实例都对共享卷拥有完全读取和写入权限。通过多重挂载，您可以更轻松地在管理并发写入操作的应用程序中实现更高的应用程序可用性。 👨‍👨‍👦‍👦 社区讨论：Multi-Attach is supported exclusively on Provisioned IOPS SSD (io1 and io2) volumes.","link":"/2024/12/07/saa_test_daily_20241207/"},{"title":"SAA 考试每日练习 - 2024&#x2F;12&#x2F;08","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam30 题 (No.471 ~ No.500) 只记录了 8 道首次碰到的、错误的或有疑问的题目，仅供自己复习使用。如果侵权请联系删除。 一、AWS Lambda function with .NET 6A company containerized a Windows job that runs on .NET 6 Framework under a Windows container. The company wants to runthis job in the AWS Cloud. The job runs every 10 minutes. The job’s runtime varies between 1 minute and 3 minutes.Which solution will meet these requirements MOST cost-effectively? ✅ Create an AWS Lambda function based on the container image of the job. Configure Amazon EventBridge to invoke the function every 10 minutes. ❌ Use AWS Batch to create a job that uses AWS Fargate resources. Configure the job scheduling to run every 10 minutes. Use Amazon Elastic Container Service (Amazon ECS) on AWS Fargate to run the job. Create a scheduled task based on the container image of the job to run every 10 minutes. Use Amazon Elastic Container Service (Amazon ECS) on AWS Fargate to run the job. Create a standalone task based on the container image of the job. Use Windows task scheduler to run the job every 10 minutes. ✨ 关键词：containerized 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：Introducing the .NET 6 runtime for AWS Lambda You can now use the .NET 6 runtime to build AWS Lambda functions. The new managed runtime supports both x86 and Arm/Graviton2 processors. Lambda 在 2022 年已经支持了 .NET 6，因此 1️⃣ 没问题。 AWS Batch 常见问题 AWS Batch 是一系列批处理管理功能，能够让开发人员、科学家和工程师轻松高效地在 AWS 上运行成千上万个批处理计算作业。AWS Batch 可根据提交的批处理作业的卷和特定资源需求动态预置最佳的计算资源（如 CPU 或内存优化计算资源）数量和类型。借助 AWS Batch，您无需安装和管理批处理计算软件或服务器集群，从而使您能够集中精力分析结果和解决问题。AWS Batch 使用 Amazon ECS、Amazon EKS 和 AWS Fargate 计划、安排和执行您的批处理计算工作负载，并可选择使用竞价型实例。 2️⃣ 也不存在问题，3️⃣ 也不存在问题。 👨‍👨‍👦‍👦 社区讨论：selected answer : AAWS Lambda now supports .NET 6 as both a managed runtime and a container base image 二、Centralized corporate directory serviceA company wants to move from many standalone AWS accounts to a consolidated, multi-account architecture. The company plans to create many new AWS accounts for different business units. The company needs to authenticate access to these AWS accounts by using a centralized corporate directory service.Which combination of actions should a solutions architect recommend to meet these requirements? (Choose two.) ✅ Create a new organization in AWS Organizations with all features turned on. Create the new AWS accounts in the organization. Set up an Amazon Cognito identity pool. Configure AWS IAM Identity Center (AWS Single Sign-On) to accept Amazon Cognito authentication. ❌ Configure a service control policy (SCP) to manage the AWS accounts. Add AWS IAM Identity Center (AWS Single Sign-On) to AWS Directory Service. Create a new organization in AWS Organizations. Configure the organization’s authentication mechanism to use AWS Directory Service directly. ✅ Set up AWS IAM Identity Center (AWS Single Sign-On) in the organization. Configure IAM Identity Center, and integrate it with the company’s corporate directory service. ✨ 关键词： 1️⃣ 3️⃣ ❌ -&gt; 1️⃣ 5️⃣ ✅ 💡 解析：题干中已经提到了 centralized corporate directory service（集中式的公司目录服务），因此选 5️⃣。通过 5️⃣ 的 AWS Single Sign-On 并使用公司目录服务，就不用再创建一堆 AWS 账户了。 👨‍👨‍👦‍👦 社区讨论：A. By creating a new organization in AWS Organizations, you can establish a consolidated multi-account architecture.This allows you to create and manage multiple AWS accounts for different business units under a single organization.E.Setting up AWS IAM Identity Center (AWS Single Sign-On) within the organization enables you to integrate it with the company’s corporate directory service. This integration allows for centralized authentication, where users can sign in using their corporate credentialsand access the AWS accounts within the organization. Together, these actions create a centralized, multi-account architecture that leverages AWS Organizations for account management and AWS IAM Identity Center (AWS Single Sign-On) for authentication and access control. 三、Expedited retrievalsA company is looking for a solution that can store video archives in AWS from old news footage. The company needs to minimize costs and will rarely need to restore these files. When the files are needed, they must be available in a maximum of five minutes.What is the MOST cost-effective solution? ✅ Store the video archives in Amazon S3 Glacier and use Expedited retrievals. Store the video archives in Amazon S3 Glacier and use Standard retrievals. ❌ Store the video archives in Amazon S3 Standard-Infrequent Access (S3 Standard-IA). Store the video archives in Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA). ✨ 关键词：5 min 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：了解归档检索选项 加速 - 快速访问存储在 S3 Glacier Flexible Retrieval 存储类或 S3 Intelligent-Tiering 归档访问层中的数据。可以在偶尔需要紧急请求归档子集时使用此选项。对于除最大归档对象（250MB+）之外的所有其他归档对象，使用加速检索访问的数据通常在 1 到 5 分钟内可用。 标准 - 在数小时内访问您的任意归档对象。“标准”是未指定检索选项的检索请求的原定设置选项。对于存储在 S3 Glacier Flexible Retrieval 存储类或 S3 Intelligent-Tiering 归档访问层中的对象，标准检索通常在 3-5 小时内完成。对于存储在 S3 Glacier Deep Archive 存储类或 S3 Intelligent-Tiering 深度归档访问层中的对象，这些检索通常会在 12 小时内完成。对于存储在 S3 Intelligent-Tiering 中的对象，标准检索是免费的。 👨‍👨‍👦‍👦 社区讨论：By choosing Expedited retrievals in Amazon S3 Glacier, you can reduce the retrieval time to minutes, making it suitable for scenarios where quickaccess is required.Expedited retrievals come with a higher cost per retrieval compared to standard retrievals but provide faster access to your archived data. 四、SNS dead letter queueAn ecommerce company runs an application in the AWS Cloud that is integrated with an on-premises warehouse solution. The company uses Amazon Simple Notification Service (Amazon SNS) to send order messages to an on-premises HTTPS endpoint so the warehouse application can process the orders. The local data center team has detected that some of the order messages were not received.A solutions architect needs to retain messages that are not delivered and analyze the messages for up to 14 days.Which solution will meet these requirements with the LEAST development effort? Configure an Amazon SNS dead letter queue that has an Amazon Kinesis Data Stream target with a retention period of 14 days. Add an Amazon Simple Queue Service (Amazon SQS) queue with a retention period of 14 days between the application and Amazon SNS. Configure an Amazon SNS dead letter queue that has an Amazon Simple Queue Service (Amazon SQS) target with a retention period of 14 days. Configure an Amazon SNS dead letter queue that has an Amazon DynamoDB target with a TTL attribute set for a retention period of 14 days. ✨ 关键词： 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：解决方案架构师需要保留未传递的消息，并分析消息长多 14 天。Amazon SNS dead-letter queues A dead-letter queue is an Amazon SQS queue that an Amazon SNS subscription can target for messages that can’t be delivered to subscribers successfully. Messages that can’t be delivered due to client errors or server errors are held in the dead-letter queue for further analysis or reprocessing. For more information, see Configuring an Amazon SNS dead-letter queue for a subscription and Amazon SNS message delivery retries. 死信队列是一个 Amazon SQS 队列，Amazon SNS 订阅可将其作为无法成功交付给订阅者的消息的目标。由于客户端错误或服务器错误而无法交付的消息会保留在死信队列中，以便进一步分析或重新处理。有关详细信息，请参阅为订阅配置 Amazon SNS 死信队列和 Amazon SNS 消息传递重试。 👨‍👨‍👦‍👦 社区讨论：A dead-letter queue isan Amazon SQS queue that an Amazon SNS subscription can target for messages that can’t be delivered to subscribers successfully.https://docs.aws.amazon.com/sns/latest/dg/sns-dead-letter-queues.html 五、SQSA solutions architect is designing an asynchronous application to process credit card data validation requests for a bank. The application must be secure and be able to process each request at least once.Which solution will meet these requirements MOST cost-effectively? ✅ Use AWS Lambda event source mapping. Set Amazon Simple Queue Service (Amazon SQS) standard queues as the event source. Use AWS Key Management Service (SSE-KMS) for encryption. Add the kms:Decrypt permission for the Lambda execution role. Use AWS Lambda event source mapping. Use Amazon Simple Queue Service (Amazon SQS) FIFO queues as the event source. Use SQS managed encryption keys (SSE-SQS) for encryption. Add the encryption key invocation permission for the Lambda function. ❌ Use the AWS Lambda event source mapping. Set Amazon Simple Queue Service (Amazon SQS) FIFO queues as the event source. Use AWS KMS keys (SSE-KMS). Add the kms:Decrypt permission for the Lambda execution role. Use the AWS Lambda event source mapping. Set Amazon Simple Queue Service (Amazon SQS) standard queues as the event source. Use AWS KMS keys (SSE-KMS) for encryption. Add the encryption key invocation permission for the Lambda function. ✨ 关键词： 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：SQS 普通队列不会丢信，只会有可能一份信发多次。 👨‍👨‍👦‍👦 社区讨论：SQS FIFO is slightly more expensive than standard queuehttps://calculator.aws/#/addService/SQSI would still go with the standard because of the keyword “at least once” because FIFO process “exactly once”.That leaves us with A and D, I believe that lambda function only needs to decrypt so I would choose A 六、AIA company wants to use artificial intelligence (AI) to determine the quality of its customer service calls. The company currently manages calls in four different languages, including English. The company will offer new languages in the future. The company does not have the resources to regularly maintain machine learning (ML) models.The company needs to create written sentiment analysis reports from the customer service call recordings. The customer service call recording text must be translated into English.Which combination of steps will meet these requirements? (Choose three.) Use Amazon Comprehend to translate the audio recordings into English. Use Amazon Lex to create the written sentiment analysis reports. Use Amazon Polly to convert the audio recordings into text. ✅ Use Amazon Transcribe to convert the audio recordings in any language into text. ✅ Use Amazon Translate to translate text in any language to English. ✅ Use Amazon Comprehend to create the sentiment analysis reports. ✨ 关键词： 4️⃣ 5️⃣ 6️⃣ ✅ 💡 解析：看下 Lex 和 Polly 这两个 AI 服务是干什么的。什么是 Amazon Lex？ Amazon Lex 是一款 AI 聊天构建器，采用与 Alexa 相同的技术，使用户能够使用自然语言语音或聊天与任何应用程序进行交互。使用 Amazon Lex 为任何应用程序构建和部署对话式 AI 界面。将 AI 聊天集成到现有的业务流程和用例中，可以为用户提供更多灵活性和支持，使他们能够以自然的方式完成工作。 什么是 Amazon Polly？ Amazon Polly 云服务可以将文本转化为逼真的语音。可以使用 Amazon Polly 开发能提高参与度和可用性的应用程序。Amazon Polly 支持多种语言，并包含各种逼真的语音。借助 Amazon Polly，您可以构建支持语音的应用程序，这些应用程序可在多个位置运行，并为客户使用理想的语音。此外，您只需为合成文本付费。您也可以免费缓存和重放 Amazon Polly 生成的语音。 👨‍👨‍👦‍👦 社区讨论：A: Comprehend cannot translateB: Lex is like a chatbot so not usefulC: Polly converts text to audio (polly the parrot!) so this is wrongD: Can convert audio to textE: Can translateF: Can do sentiment analysis reports 七、Direct Connect and Hosted connectionA company needs to minimize the cost of its 1 Gbps AWS Direct Connect connection. The company’s average connection utilization is less than 10%. A solutions architect must recommend a solution that will reduce the cost without compromising security.Which solution will meet these requirements? Set up a new 1 Gbps Direct Connect connection. Share the connection with another AWS account. Set up a new 200 Mbps Direct Connect connection in the AWS Management Console. Contact an AWS Direct Connect Partner to order a 1 Gbps connection. Share the connection with another AWS account. ✅ Contact an AWS Direct Connect Partner to order a 200 Mbps hosted connection for an existing AWS account. ✨ 关键词： 4️⃣ ✅ 💡 解析：托管连接在 50 Mbps ~ 200 Mbps，专用连接在 1 Gbps 以上： 👨‍👨‍👦‍👦 社区讨论：Hosted Connection 50 Mbps, 100 Mbps, 200 Mbps,Dedicated Connection 1 Gbps, 10 Gbps,and 100 Gbps 八、File permissionsA company has multiple Windows file servers on premises. The company wants to migrate and consolidate its files into an Amazon FSx for Windows File Server file system. File permissions must be preserved to ensure that access rights do not change.Which solutions will meet these requirements? (Choose two.) ✅ Deploy AWS DataSyncagents on premises. Schedule DataSync tasks to transfer the data to the FSx for Windows File Server file system. ❌ Copy the shares on each file server into Amazon S3 buckets by using the AWS CLI. Schedule AWS DataSync tasks to transfer the data to the FSx for Windows File Server file system. Remove the drives from each file server. Ship the drives to AWS for import into Amazon S3. Schedule AWS DataSync tasks to transfer the data to the FSx for Windows File Server file system. ✅ Order an AWS Snowcone device. Connect the device to the on-premises network. Launch AWS DataSyncagents on the device. Schedule DataSync tasks to transfer the data to the FSx for Windows File Server file system. Order an AWS Snowball Edge Storage Optimized device. Connect the device to the on-premises network. Copy data to the device by using the AWS CLI. Ship the device back to AWS for import into Amazon S3. Schedule AWS DataSync tasks to transfer the data to the FSx for Windows File Server file system. ✨ 关键词： 1️⃣ 2️⃣ ❌ -&gt; 1️⃣ 4️⃣ ✅ 💡 解析：1️⃣ 是肯定正确的，而 4️⃣ 是完全独立的另一个可行方案，之前都是互补着选的 🤦‍ 还是确认下 DataSync 对文件权限的保留吧：Understanding how DataSync handles file and object metadata 没怎么看懂，但是部分情况下是可以通过保留文件的元数据来保留权限的。 👨‍👨‍👦‍👦 社区讨论：A - This option involves deploying DataSync agents on your on-premises file serversand using DataSync to transfer the data directly to the FSx for Windows File Server. DataSync ensures that file permissionsare preserved during the migration process.D - This option involves using an AWS Snowcone device,a portable data transfer device. You would connect the Snowcone device to your on-premises network, launch DataSync agents on the device, and schedule DataSync tasks to transfer the data to FSx for Windows File Server. DataSync handles the migration process while preserving file permissions. B, C and E would copy the files to S3 first where permissions would be lost","link":"/2024/12/08/saa_test_daily_20241208/"},{"title":"SAA 考试每日练习 - 2024&#x2F;12&#x2F;06","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam65 题 (No.386 ~ No.450) 只记录了 21 道首次碰到的、错误的或有疑问的题目，仅供自己复习使用。与正式考试题量一样，总共耗时 98/(130+30) 分钟，正确率为 49/65。如果侵权请联系删除。 一、PoLP with CloudFormation stackA new employee has joined a company as a deployment engineer. The deployment engineer will be using AWS CloudFormation templates to create multiple AWS resources. A solutions architect wants the deployment engineer to perform job activities while following the principle of least privilege.Which combination of actions should the solutions architect take to accomplish this goal? (Choose two.) Have the deployment engineer use AWS account root user credentials for performing AWS CloudFormation stack operations. Create a new IAM user for the deployment engineer and add the IAM user to a group that has the PowerUsers IAM policy attached. Create a new IAM user for the deployment engineer and add the IAM user to a group that has the AdministratorAccess IAM policy attached. ✅ Create a new IAM user for the deployment engineer and add the IAM user to a group that has an IAM policy that allows AWS CloudFormation actions only. ✅ Create an IAM role for the deployment engineer to explicitly define the permissions specific to the AWS CloudFormation stack and launch stacks using that IAM role. ✨ 关键词： 4️⃣ 5️⃣ ✅ 💡 解析：这里的操作时只赋予开发者操作 CloudFormation 的权限，然后再创建一个拥有 CloudFormation 堆栈操作权限的角色并允许用户代入角色。CloudFormation 堆栈策略 堆栈策略可以帮助防止堆栈资源在堆栈更新期间被意外更新或删除。堆栈策略是一个 JSON 文档，用于定义可在指定资源上执行的更新操作。默认情况下，任何具有cloudformation:UpdateStack权限的 IAM 委托人都可以更新 AWS CloudFormation 堆栈中的所有资源。 👨‍👨‍👦‍👦 社区讨论：Option D, creating a new IAM user and adding them to a group with an IAM policy that allows AWS CloudFormation actions only, ensures that the deployment engineer has the necessary permissions to perform AWS CloudFormation operations while limiting access to other resources and actions. This aligns with the principle of least privilege by providing the minimum required permissions for their job activities. Option E, creating an IAM role with specific permissions for AWS CloudFormation stack operations and allowing the deployment engineer to assume that role, is another valid approach. By using an IAM role, the deployment engineer can assume the role when necessary, granting them temporary permissions to perform CloudFormation actions. This provides a level of separation and limits the permissions granted to the engineer to only the required CloudFormation operations. 二、User session saveA company hosts a three-tier ecommerce application on a fleet of Amazon EC2 instances. The instances run in an Auto Scaling group behind an Application Load Balancer (ALB). All ecommerce data is stored in an Amazon RDS for MariaDB Multi-AZ DB instance.The company wants to optimize customer session management during transactions. The application must store session data durably.Which solutions will meet these requirements? (Choose two.) ✅ Turn on the sticky sessions feature (session affinity) on the ALB. ❌ Use an Amazon DynamoDB table to store customer session information. Deploy an Amazon Cognito user pool to manage user session information. ✅ Deploy an Amazon ElastiCache for Redis cluster to store customer session information. Use AWS Systems Manager Application Manager in the application to manage user session information. ✨ 关键词： 1️⃣ 2️⃣ ❌ -&gt; 1️⃣ 4️⃣ ✅ 💡 解析：重点在于使用什么服务保存用户 Session 使用户在多个运行在不同 EC2 实例的节点中保持登陆状态。用 DynamoDB 当时是可以实现的，但是官方给了更好的方案：会话管理 使用像 Amazon ElastiCache 这样的完全托管服务在云中进行缓存，可以很轻松上手。它消除了设置、管理和实施缓存的复杂性，使您能够专注于能为组织创造价值的任务。立即注册 Amazon ElastiCache。 👨‍👨‍👦‍👦 社区讨论：It is A and D. Proof is in link below.https://aws.amazon.com/caching/session-management/ 三、RPOA company needs a backup strategy for its three-tier stateless web application. The web application runs on Amazon EC2 instances in an Auto Scaling group with a dynamic scaling policy that is configured to respond to scaling events. The database tier runs on Amazon RDS for PostgreSQL. The web application does not require temporary local storage on the EC2 instances. The company’s recovery point objective (RPO) is 2 hours.The backup strategy must maximize scalability and optimize resource utilization for this environment.Which solution will meet these requirements? Take snapshots of Amazon Elastic Block Store (Amazon EBS) volumes of the EC2 instances and database every 2 hours to meet the RPO. Configure a snapshot lifecycle policy to take Amazon Elastic Block Store (Amazon EBS) snapshots. Enable automated backups in Amazon RDS to meet the RPO. ✅ Retain the latest Amazon Machine Images (AMIs) of the web and application tiers. Enable automated backups in Amazon RDS and use point-in-time recovery to meet the RPO. ❌ Take snapshots of Amazon Elastic Block Store (Amazon EBS) volumes of the EC2 instances every 2 hours. Enable automated backups in Amazon RDS and use point-in-time recovery to meet the RPO. ✨ 关键词：2 hours 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：运行在 RDS 上的数据库只能丢 2 小时的数据，意味着最少 2 小时也要备份一下。需要明确的是 RDS 是支持 point-in-time 恢复的：Point-in-time recovery and continuous backup for Amazon RDS with AWS Backup，但是没有必要对 EBS 卷进行备份，因为数据不存在 EC2 本地。3️⃣ 创建 AMI 用以恢复是更合理的。在需要对 EC2 进行灾备的场景下，使用 AMI 是更好的选择。 👨‍👨‍👦‍👦 社区讨论：that if there is no temporary local storage on the EC2 instances, then snapshots of EBS volumes are not necessary. Therefore, if your application does not require temporary storage on EC2 instances, using AMIs to back up the web and application tiers is sufficient to restore the system after a failure.Snapshots of EBS volumes would be necessary if you want to back up the entire EC2 instance, including any applications and temporary data stored on the EBS volumes attached to the instances. When you take a snapshot of an EBS volume, it backs up the entire contents of that volume. This ensures that you can restore the entire EC2 instance to a specific point in time more quickly. However, if there is no temporary data stored on the EBS volumes, then snapshots of EBS volumes are not necessary. 四、20,000 IOPSA company is running a multi-tier ecommerce web application in the AWS Cloud. The application runs on Amazon EC2 instances with an Amazon RDS for MySQL Multi-AZ DB instance. Amazon RDS is configured with the latest generation DB instance with 2,000 GB of storage in a General Purpose SSD (gp3) Amazon Elastic Block Store (Amazon EBS) volume. The database performance affects the application during periods of high demand.A database administrator analyzes the logs in Amazon CloudWatch Logs and discovers that the application performance always degrades when the number of read and write IOPS is higher than 20,000.What should a solutions architect do to improve the application performance? Replace the volume with a magnetic volume. Increase the number of IOPS on the gp3 volume. ✅ Replace the volume with a Provisioned IOPS SSD (io2) volume. Replace the 2,000 GB gp3 volume with two 1,000 GB gp3 volumes. ✨ 关键词：2,000 GB of storage、read and write IOPS is higher than 20,000 3️⃣ ✅ 💡 解析：总共 2 TB 的存储，需要将 IOPS 提升到 20,000。在 2024 年 RDS 已经支持了 io2 类型的卷：Amazon RDS now supports io2 Block Express volumes for mission-critical database workloads Amazon RDS 数据库实例存储 Amazon RDS 提供三种存储类型：预调配 IOPS SSD（也称为 io1 和 io2 Block Express）、通用型 SSD（也称为 gp2 和 gp3）和磁性存储（也称为标准存储）。 👨‍👨‍👦‍👦 社区讨论：Answer is C, io2 volumes are supportedhttps://aws.amazon.com/blogs/aws/amazon-rds-now-supports-io2-block-express-volumes-for-mission-critical-database-workloads/ 五、An hour jobAn ecommerce company needs to run a scheduled daily job to aggregate and filter sales records for analytics. The company stores the sales records in an Amazon S3 bucket. Each object can be up to 10 GB in size. Based on the number of sales events, the job can take up to an hour to complete. The CPU and memory usage of the job are constant and are known in advance.A solutions architect needs to minimize the amount of operational effort that is needed for the job to run.Which solution meets these requirements? ❌ Create an AWS Lambda function that has an Amazon EventBridge notification. Schedule the EventBridge event to run once a day. Create an AWS Lambda function. Create an Amazon API Gateway HTTP API, and integrate the API with the function. Create an Amazon EventBridge scheduled event that calls the API and invokes the function. ✅ Create an Amazon Elastic Container Service (Amazon ECS) cluster with an AWS Fargate launch type. Create an Amazon EventBridge scheduled event that launches an ECS task on the cluster to run the job. Create an Amazon Elastic Container Service (Amazon ECS) cluster with an Amazon EC2 launch type and an Auto Scaling group with at least one EC2 instance. Create an Amazon EventBridge scheduled event that launches an ECS task on the cluster to run the job. ✨ 关键词：an hour 1️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：Lambda 函数最大运行时间为 15 分钟。 👨‍👨‍👦‍👦 社区讨论：The requirement is to run a daily scheduled job to aggregate and filter sales records for analytics in the most efficient way possible. Based on the requirement, we can eliminate option A and B since they use AWS Lambda which has a limit of 15 minutes of execution time, which may not be sufficient for a job that can take up to an hour to complete.Between options C and D, option C is the better choice since it uses AWS Fargate which is a serverless compute engine for containers that eliminates the need to manage the underlying EC2 instances, making it a low operational effort solution.Additionally, Fargate also provides instant scale-up and scale-down capabilities to run the scheduled job as per the requirement. Therefore, the correct answer is:C. Create an Amazon Elastic Container Service (Amazon ECS) cluster with an AWS Fargate launch type. Create an Amazon EventBridge scheduled event that launches an ECS task on the cluster to run the job. 六、Auto ScalingA solutions architect is designing the architecture for a software demonstration environment. The environment will run on Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer (ALB). The system will experience significant increases in traffic during working hours but is not required to operate on weekends.Which combination of actions should the solutions architect take to ensure that the system can scale to meet demand? (Choose two.) ❌ Use AWS Auto Scaling to adjust the ALB capacity based on request rate. Use AWS Auto Scaling to scale the capacity of the VPC internet gateway. Launch the EC2 instances in multiple AWS Regions to distribute the load across Regions. ✅ Use a target tracking scaling policy to scale the Auto Scaling group based on instance CPU utilization. ✅ Use scheduled scaling to change the Auto Scaling group minimum, maximum, and desired capacity to zero for weekends. Revert to the default values at the start of the week. ✨ 关键词： 1️⃣ 5️⃣ ❌ -&gt; 4️⃣ 5️⃣ ✅ 💡 解析：选择指标中提到了有 ALB 相关的指标： ASGAverageCPUUtilization — Auto Scaling 组的平均CPU利用率。 ASGAverageNetworkIn – 单个实例在所有网络接口上收到的平均字节数。 ASGAverageNetworkOut – 单个实例在所有网络接口上发送的平均字节数 ALBRequestCountPerTarget – 每目标的应用程序负载均衡器请求计数。 这意味着虽然不直接支持 1️⃣ 提到的 ALB 容量，但是支持基于每个目标均衡后的请求数进行扩展，1️⃣ 是相对合理的。但是 4️⃣ 更正确吧，毕竟 ASG 明确了支持 CPU 相关指标。 👨‍👨‍👦‍👦 社区讨论：Not A - “AWS Auto Scaling” cannot adjust “ALB capacity” (https://aws.amazon.com/autoscaling/faqs/)Not B - VPC internet gateway has nothing to do with thisNot C - Regions have nothing to do with scaling 七、Network shareA company has a business system that generates hundreds of reports each day. The business system saves the reports to a network share in CSV format. The company needs to store this data in the AWS Cloud in near-real time for analysis.Which solution will meet these requirements with the LEAST administrative overhead? Use AWS DataSync to transfer the files to Amazon S3. Create a scheduled task that runs at the end of each day. ✅ Create an Amazon S3 File Gateway. Update the business system to use a new network share from the S3 File Gateway. ❌ Use AWS DataSync to transfer the files to Amazon S3. Create an application that uses the DataSync API in the automation workflow. Deploy an AWS Transfer for SFTP endpoint. Create a script that checks for new files on the network share and uploads the new files by using SFTP. ✨ 关键词： 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：系统将 .csv 文件保存给网络共享存储。2️⃣ 的操作更简单些。 👨‍👨‍👦‍👦 社区讨论：Both Amazon S3 File Gateway and AWS DataSync are suitable for this scenario.But there is a requirement for ‘LEAST administrative overhead’.Option C involves the creation of an entirely new application to consume the DataSync API, this rules out this option. 八、OLTPA rapidly growing global ecommerce company is hosting its web application on AWS. The web application includes static content and dynamic content. The website stores online transaction processing (OLTP) data in an Amazon RDS database The website’s users are experiencing slow page loads.Which combination of actions should a solutions architect take to resolve this issue? (Choose two.) Configure an Amazon Redshift cluster. ✅ Set up an Amazon CloudFront distribution. Host the dynamic web content in Amazon S3. ✅ Create a read replica for the RDS DB instance. ❌ Configure a Multi-AZ deployment for the RDS DB instance. ✨ 关键词： 2️⃣ 5️⃣ ❌ -&gt; 2️⃣ 4️⃣ ✅ 💡 解析：需要解决 OLTP 带来的数据库负载升高而影响用户加载页面。OLAP 与 OLTP 有何区别？ 联机分析处理 (OLAP) 系统和联机事务处理 (OLTP) 系统都是帮助您存储和分析业务数据的数据处理系统。您可以收集和存储来自多个来源的数据，例如网站、应用程序、智能电表和内部系统。 OLAP 对数据进行合并和分组，因此您可以从不同的角度对其进行分析。 OLTP 能够可靠、高效地存储和更新大量事务数据 OLTP 数据库可以成为 OLAP 系统的多个数据来源之一。 OLTP 确实是非只读操作的。但是考试的侧重点是：只读副本重点提高性能，跨区域部署强调高可用和容灾。因此 4️⃣ 和 5️⃣ 中选 4️⃣。 👨‍👨‍👦‍👦 社区讨论：To resolve the issue of slow page loads for a rapidly growing e-commerce website hosted on AWS, a solutions architect can take the following two actions: Set up an Amazon CloudFront distribution Create a read replica for the RDS DB instance Configuring an Amazon Redshift cluster is not relevant to this issue since Redshift is a data warehousing service and is typically used for the analytical processing of large amounts of data.Hosting the dynamic web content in Amazon S3 may not necessarily improve performance since S3 is an object storage service, not a web application server. While S3 can be used to host static web content, it may not be suitable for hosting dynamic web content since S3 doesn’t support server-side scripting or processing.Configuring a Multi-AZ deployment for the RDS DB instance will improve high availability but may not necessarily improve performance. 十、Savings PlanA company uses Amazon EC2 instances and AWS Lambda functions to run its application. The company has VPCs with public subnets and private subnets in its AWS account. The EC2 instances run in a private subnet in one of the VPCs. The Lambda functions need direct network access to the EC2 instances for the application to work.The application will run for at least 1 year. The company expects the number of Lambda functions that the application uses to increase during that time. The company wants to maximize its savings on all application resources and to keep network latency between the services low.Which solution will meet these requirements? Purchase an EC2 Instance Savings Plan Optimize the Lambda functions’ duration and memory usage and the number of invocations. Connect the Lambda functions to the private subnet that contains the EC2 instances. Purchase an EC2 Instance Savings Plan Optimize the Lambda functions’ duration and memory usage, the number of invocations, and the amount of data that is transferred. Connect the Lambda functions to a public subnet in the same VPC where the EC2 instances run. ✅ Purchase a Compute Savings Plan. Optimize the Lambda functions’ duration and memory usage, the number of invocations, and the amount of data that is transferred. Connect the Lambda functions to the private subnet that contains the EC2 instances. Purchase a Compute Savings Plan. Optimize the Lambda functions’ duration and memory usage, the number of invocations, and the amount of data that is transferred. Keep the Lambda functions in the Lambda service VPC. ✨ 关键词： 3️⃣ ✅ 💡 解析：Savings Plans Compute Savings Plans 的灵活性最高，最高可帮助您节省 66% 的费用。这些计划会自动应用于 EC2 实例用量，不分实例系列、大小、可用区、区域、操作系统或租期，并且还适用于 Fargate 和 Lambda 的使用。 例如，注册 Compute Savings Plans 后，您可以随时从 C4 实例更改为 M5 实例，将工作负载从欧洲（爱尔兰）区域转移到欧洲（伦敦）区域，或者将工作负载从 EC2 迁移到 Fargate 或 Lambda，并继续自动支付 Savings Plans 价格。 EC2 Instance Savings Plans 可提供最低的价格，最高可提供 72% 的折扣，以换取在单个区域内使用单个实例系列的承诺（例如在弗吉尼亚北部区域使用 M5 实例）。这会自动降低您在该区域的选定实例系列成本，不分可用区、实例大小、操作系统或租期。借助 EC2 Instance Savings Plans，您可以灵活地在该区域的一个实例系列中更改实例的使用情况。例如，您可以从运行 Windows 的 c5.xlarge 实例迁移到运行 Linux 的 c5.2xlarge 实例，并自动享受 Savings Plan 价格。 Compute Savings Plans 可以更改实例类型，更灵活；EC2 Instance Savings Plans 不能更改实例类型，但是更便宜。但是由于 Compute Savings Plans 还适用于 Lambda 函数和 Fargate，因此在这个场景下更省钱，选 3️⃣。 👨‍👨‍👦‍👦 社区讨论：Answer C is the best solution that meets the company’s requirements.By purchasing a Compute Savings Plan, the company can save on the costs of running both EC2 instances and Lambda functions. The Lambda functions can be connected to the private subnet that contains the EC2 instances through a VPC endpoint for AWS services or a VPC peering connection. This provides direct network access to the EC2 instances while keeping the traffic within the private network, which helps to minimize network latency.Optimizing the Lambda functions’ duration, memory usage, number of invocations, and amount of data transferred can help to further minimize costs and improve performance. Additionally, using a private subnet helps to ensure that the EC2 instances are not directly accessible from the public internet, which is a security best practice. 十一、Policy PrincipalA solutions architect needs to allow team members to access Amazon S3 buckets in two different AWS accounts: a development account and a production account. The team currently has access to S3 buckets in the development account by using unique IAM users that are assigned to an IAM group that has appropriate permissions in the account.The solutions architect has created an IAM role in the production account. The role has a policy that grants access to an S3 bucket in the production account.Which solution will meet these requirements while complying with the principle of least privilege? Attach the Administrator Access policy to the development account users. ✅ Add the development account as a principal in the trust policy of the role in the production account. Turn off the S3 Block Public Access feature on the S3 bucket in the production account. ❌ Create a user in the production account with unique credentials for each team member. ✨ 关键词： 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：AWS JSON 策略元素：Principal 在基于资源的 JSON 策略中使用 Principal 元素指定允许或拒绝访问资源的主体。 您必须使用基于资源的策略中的 Principal 元素。包括 IAM 在内的多项服务支持基于资源的策略。IAM 中唯一基于资源的策略类型是角色信任策略。在 IAM 角色中，在角色的信任策略中使用 Principal 元素来指定可担任该角色的对象。对于跨账户存取，您必须指定受信任账户的 12 位标识符。 在基于资源的策略中，将指定账户添加到 Principal 中可以授权其访问资源。 👨‍👨‍👦‍👦 社区讨论：By adding the development account as a principal in the trust policy of the IAM role in the production account, you are allowing users from the development account to assume the role in the production account. This allows the team members to access the S3 bucket in the production account without granting them unnecessary privileges. 十二、Amazon RDS Multi-AZ DB cluster DRA company wants to use an Amazon RDS for PostgreSQL DB cluster to simplify time-consuming database administrative tasks for production database workloads. The company wants to ensure that its database is highly available and will provide automatic failover support in most scenarios in less than 40 seconds. The company wants to offload reads off of the primary instance and keep costs as low as possible.Which solution will meet these requirements? ❌ Use an Amazon RDS Multi-AZ DB instance deployment. Create one read replica and point the read workload to the read replica. Use an Amazon RDS Multi-AZ DB duster deployment Create two read replicas and point the read workload to the read replicas. Use an Amazon RDS Multi-AZ DB instance deployment. Point the read workload to the secondary instances in the Multi-AZ pair. ✅ Use an Amazon RDS Multi-AZ DB cluster deployment Point the read workload to the reader endpoint. ✨ 关键词： 1️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：根据 Choose the right Amazon RDS deployment option: Single-AZ instance, Multi-AZ instance, or Multi-AZ database cluster： Single-AZ Instance - The RPO with an Amazon RDS Single-AZ instance is typically 5 minutes. Multi-AZ instance - The amount of time it takes for failover is usually 1–2 minutes. Multi-AZ DB cluster - The Multi-AZ DB cluster combines automatic failover with two readable standby instances and provides up to 2x faster commit latencies and automated failovers, typically under 35 seconds. 4️⃣ 集群只需要最长 35 的灾难恢复时间，因此最符合。 👨‍👨‍👦‍👦 社区讨论：A - multi-az instance : failover takes between 60-120 secD - multi-az cluster: failover around 35 sec 十三、SFTP serviceA company runs a highly available SFTP service. The SFTP service uses two Amazon EC2 Linux instances that run with elastic IP addresses to accept traffic from trusted IP sources on the internet. The SFTP service is backed by shared storage that is attached to the instances. User accounts are created and managed as Linux users in the SFTP servers.The company wants a serverless option that provides high IOPS performance and highly configurable security. The company also wants to maintain control over user permissions.Which solution will meet these requirements? Create an encrypted Amazon Elastic Block Store (Amazon EBS) volume. Create an AWS Transfer Family SFTP service with a public endpoint that allows only trusted IP addresses. Attach the EBS volume to the SFTP service endpoint. Grant users access to the SFTP service. ✅ Create an encrypted Amazon Elastic File System (Amazon EFS) volume. Create an AWS Transfer Family SFTP service with elastic IP addresses and a VPC endpoint that has internet-facing access. Attach a security group to the endpoint that allows only trusted IP addresses. Attach the EFS volume to the SFTP service endpoint. Grant users access to the SFTP service. Create an Amazon S3 bucket with default encryption enabled. Create an AWS Transfer Family SFTP service with a public endpoint that allows only trusted IP addresses. Attach the S3 bucket to the SFTP service endpoint. Grant users access to the SFTP service. ❌ Create an Amazon S3 bucket with default encryption enabled. Create an AWS Transfer Family SFTP service with a VPC endpoint that has internal access in a private subnet. Attach a security group that allows only trusted IP addresses. Attach the S3 bucket to the SFTP service endpoint. Grant users access to the SFTP service. ✨ 关键词： 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：替换共享存储方案，同时保留对用户权限的控制。这里理解错了，以为是需要找到可以挂载到 EC2 上的存储方案，其实要求的是替换掉通过 EC2 实现的 SFTP 服务。由于 4️⃣ 的配置会导致其只能在内网访问，因此选 2️⃣。 👨‍👨‍👦‍👦 社区讨论：Not A - Transfer Family canj’t use EBSB - Possible and meets requirementNot C - S3 doesn’t guarantee “high IOPS performance”; also there is no “public endpoint that allows only trusted IP addresses” (you can assign a Security Group to a public endpoint but that is not mentioned here)Not D - Endpoint would be in private subnet, not accessible from Internet at all 十四、Identity-based PolicyA solutions architect wants to use the following JSON text as an identity-based policy to grant specific permissions:Which IAM principals can the solutions architect attach this policy to? (Choose two.) ✅ Role ✅ Group Organization ❌ Amazon Elastic Container Service (Amazon ECS) resource ❌ Amazon EC2 resource ✨ 关键词：identity-based 4️⃣ 5️⃣ ❌ -&gt; 1️⃣ 2️⃣ ✅ 💡 解析：题目总已经明确了是基于身份的策略，因此选 1️⃣ 和 2️⃣。 👨‍👨‍👦‍👦 社区讨论：identity-based policy used for role and group 十五、15,000 IOPS stroageA company uses high block storage capacity to runs its workloads on premises. The company’s daily peak input and output transactions per second are not more than 15,000 IOPS. The company wants to migrate the workloads to Amazon EC2 and to provision disk performance independent of storage capacity.Which Amazon Elastic Block Store (Amazon EBS) volume type will meet these requirements MOST cost-effectively? GP2 volume type ❌ io2 volume type ✅ GP3 volume type io1 volume type ✨ 关键词： 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：看下答案中各存储的 IOPS 和价格：Migrate your Amazon EBS volumes from gp2 to gp3 and save up to 20% on costs 类型 Max IOPS/volume Price gp3 16,000 $0.08/GiB-month gp2 16,000 $0.10/GiB-month io1 64,000 $0.125/GiB-month io2 256,000 $0.125/GiB-month gp 系列已经能达到 IOPS 需求，选 gp3 更便宜。 👨‍👨‍👦‍👦 社区讨论：Both GP2 and GP3 has max IOPS 16000 but GP3 is cost effective.https://aws.amazon.com/blogs/storage/migrate-your-amazon-ebs-volumes-from-gp2-to-gp3-and-save-up-to-20-on-costs/ 十六、Scoreboard in near-real timeA company has developed a new video game as a web application. The application is in a three-tier architecture in a VPC with Amazon RDS for MySQL in the database layer. Several players will compete concurrently online. The game’s developers want to display a top-10 scoreboard in near-real time and offer the ability to stop and restore the game while preserving the current scores.What should a solutions architect do to meet these requirements? Set up an Amazon ElastiCache for Memcached cluster to cache the scores for the web application to display. ✅ Set up an Amazon ElastiCache for Redis cluster to compute and cache the scores for the web application to display. Place an Amazon CloudFront distribution in front of the web application to cache the scoreboard in a section of the application. Create a read replica on Amazon RDS for MySQL to run queries to compute the scoreboard and serve the read traffic to the web application. ✨ 关键词：top-10 scoreboard in near-real time 2️⃣ ✅ 💡 解析：希望能够近乎实时地显示前10名的计分板，并提供在保留当前分数的情况下停止和恢复游戏的功能。1️⃣ 和 2️⃣ 理论上都能解决问题，但是 Amazon ElastiCache for Redis 是官方推荐的解决方案：Build a real-time gaming leaderboard with Amazon ElastiCache for RedisAmazon ElastiCache for Redis 更强调拥有排序的特性，适合该场景：与 Redis OSS 兼容的 Amazon ElastiCache 游戏排行榜借助 Amazon ElastiCache，用户可以轻松创建实时游戏排行榜。可直接使用 Redis OSS 有序集数据结构，此结构实现了元素的唯一性，同时又可维护按元素分数排序的列表。创建实时排序表像用户分数在每次更改后进行更新一样简单。您也可以使用时间戳作为分数，使用有序集处理时间序列数据。 社区还有人提到了 ElastiCache for Memcached 不是持久的，没有备份和还原功能，这是真的，并且也应该是本题不选它的原因之一。 👨‍👨‍👦‍👦 社区讨论：Real-time gaming leaderboards are easy to create with Amazon ElastiCache for Redis. Just use the Redis Sorted Set data structure, which provides uniqueness of elements while maintaining the list sorted by their scores. Creating a real-time ranked list is as simple as updating a user’s score each time it changes. You can also use Sorted Sets to handle time series data by using timestamps as the score.https://aws.amazon.com/cn/elasticache/redis/#:~:text=ElastiCache%20for%20Redis.-,Gaming,-Leaderboards 十七、DR in another regionA company hosts its application in the AWS Cloud. The application runs on Amazon EC2 instances behind an Elastic Load Balancer in an Auto Scaling group and with an Amazon DynamoDB table. The company wants to ensure the application can be made available in anotherAWS Region with minimal downtime.What should a solutions architect do to meet these requirements with the LEAST amount of downtime? ✅ Create an Auto Scaling group and a load balancer in the disaster recovery Region. Configure the DynamoDB table as a global table. Configure DNS failover to point to the new disaster recovery Region’s load balancer. Create an AWS CloudFormation template to create EC2 instances, load balancers, and DynamoDB tables to be launched when needed Configure DNS failover to point to the new disaster recovery Region’s load balancer. ❌ Create an AWS CloudFormation template to create EC2 instances and a load balancer to be launched when needed. Configure the DynamoDB table as a global table. Configure DNS failover to point to the new disaster recovery Region’s load balancer. Create an Auto Scaling group and load balancer in the disaster recovery Region. Configure the DynamoDB table as a global table. Create an Amazon CloudWatch alarm to trigger an AWS Lambda function that updates Amazon Route 53 pointing to the disaster recovery load balancer. ✨ 关键词：minimal downtime 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：3️⃣ 创建了一个 CloudFormation 模板用以容灾，理论上也可以实现短时内在另一个区域启动相同的架构。但是没有 1️⃣ 一直启动着相同架构来的快。 👨‍👨‍👦‍👦 社区讨论：With the LEAST amount of downtime = ACost effective = C , but risky some of EC2 types/capacity not available in Region at the time, when need to switch to DR 十八、Reserved DB instanceA company moved its on-premises PostgreSQL database to an Amazon RDS for PostgreSQL DB instance. The company successfully launched a new product. The workload on the database has increased. The company wants to accommodate the larger workload without adding infrastructure.Which solution will meet these requirements MOST cost-effectively? ✅ Buy reserved DB instances for the total workload. Make the Amazon RDS for PostgreSQL DB instance larger. Make the Amazon RDS for PostgreSQL DB instance a Multi-AZ DB instance. Buy reserved DB instances for the total workload. Add another Amazon RDS for PostgreSQL DB instance. ❌ Make the Amazon RDS for PostgreSQL DB instance an on-demand DB instance. ✨ 关键词： 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：工作负载已经增加了 (increased)，并且之后架构不再增加了，可以使用预留实例了。 👨‍👨‍👦‍👦 社区讨论：”without adding infrastructure” means scaling vertically and choosing larger instance.“MOST cost-effectively” reserved instances 十九、Add CIDR block to VPCA solutions architect configured a VPC that has a small range of IP addresses. The number of Amazon EC2 instances that are in the VPC is increasing, and there is an insufficient number of IP addresses for future workloads.Which solution resolves this issue with the LEAST operational overhead? ✅ Add an additional IPv4 CIDR block to increase the number of IP addresses and create additional subnets in the VPC. Create new resources in the new subnets by using the new CIDR. ❌ Create a second VPC with additional subnets. Use a peering connection to connect the second VPC with the first VPC Update the routes and create new resources in the subnets of the second VPC. Use AWS Transit Gateway to add a transit gateway and connect a second VPC with the first VPUpdate the routes of the transit gateway and VPCs. Create new resources in the subnets of the second VPC. Create a second VPC. Create a Site-to-Site VPN connection between the first VPC and the second VPC by using a VPN-hosted solution on Amazon EC2 and a virtual private gateway. Update the route between VPCs to the traffic through the VPN. Create new resources in the subnets of the second VPC. ✨ 关键词： 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：将 CIDR 块添加到 VPC 或从中删除 默认情况下，您的 VPC 可以最多有 5 个 IPv4 CIDR 块和 5 个 IPv6 CIDR 块，但此限额可调整。 如果您的 VPC 关联了多个 IPv4 CIDR 块，则可以取消一个 IPv4 CIDR 块与 VPC 的关联。您不能将主 IPv4 CIDR 块取消关联。您只能将整个 CIDR 块取消关联；不能将 CIDR 块的子集或 CIDR 块的合并范围取消关联。必须首先删除 CIDR 块中的所有子网。 拓展下子网的 CIDR 也支持修改： 👨‍👨‍👦‍👦 社区讨论：A is correct: You assign a single CIDR IP address range as the primary CIDR block when you create a VPC and can add up to four secondary CIDR blocks after creation of the VPC. 二十、Rebuild DB instanceA company used an Amazon RDS for MySQL DB instance during application testing. Before terminating the DB instance at the end of the test cycle, a solutions architect created two backups. The solutions architect created the first backup by using the mysqldump utility to create a database dump. The solutions architect created the second backup by enabling the final DB snapshot option on RDS termination.The company is now planning for a new test cycle and wants to create a new DB instance from the most recent backup. The company has chosen a MySQL-compatible edition of Amazon Aurora to host the DB instance.Which solutions will create the new DB instance? (Choose two.) ✅ Import the RDS snapshot directly into Aurora. Upload the RDS snapshot to Amazon S3. Then import the RDS snapshot into Aurora. ✅ Upload the database dump to Amazon S3. Then import the database dump into Aurora. Use AWS Database Migration Service (AWS DMS) to import the RDS snapshot into Aurora. ❌ Upload the database dump to Amazon S3. Then use AWS Database Migration Service (AWS DMS) to import the database dump into Aurora. ✨ 关键词： 1️⃣ 5️⃣ ❌ -&gt; 1️⃣ 3️⃣ ✅ 💡 解析：将数据从外部 MySQL 数据库迁移到 Amazon Aurora MySQL 数据库集群 如果数据库支持 InnoDB 或 MyISAM 表空间，则可以使用以下选项将数据迁移到 Amazon Aurora MySQL 数据库集群： 您可以使用 mysqldump 实用程序创建数据的转储，然后将该数据导入现有的 Amazon Aurora MySQL 数据库集群。 您可以将完整备份文件和增量备份文件从数据库复制到 Amazon S3 桶，然后从这些文件还原到 Amazon Aurora MySQL 数据库集群。该选项可能比使用 mysqldump 迁移数据要快得多。 👨‍👨‍👦‍👦 社区讨论：A because the snapshot is already stored in AWS.C because you dont need a migration tool going from MySQL to MySQL. You would use the MySQL utility. 二十一、Connect from local to AWSA company has two VPCs named Management and Production. The Management VPC uses VPNs through a customer gateway to connect to a single device in the data center. The Production VPC uses a virtual private gateway with two attached AWS Direct Connect connections. The Management and Production VPCs both use a single VPC peering connection to allow communication between the applications.What should a solutions architect do to mitigate any single point of failure in this architecture? Add a set of VPNs between the Management and Production VPCs. ❌ Add a second virtual private gateway and attach it to the Management VPC. ✅ Add a second set of VPNs to the Management VPC from a second customer gateway device. Add a second VPC peering connection between the Management VPC and the Production VPC. ✨ 关键词： 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：一个公司有两个 VPC，分别是 Management 和 Production。管理 VPC 通过客户网关使用 VPN 连接到数据中心的单个设备。生产 VPC 使用一个附加了 2 个 AWS Direct Connect 连接的虚拟私有网关。管理 VPC 和生产 VPC 都使用单个 VPC 对等连接，实现应用之间的通信。需要防止单点故障。首先 VPC 对等连接不会出问题，然后 2 条 AWS Direct Connect 连接也保证了高可用，只有与管理 VPC 间的连接存在风险。 如何 AWS Site-to-Site VPN 运作 虚拟专用网关 (virtual private gateway) 是在 AWS 侧的，而客户网关是在本地的，两者通过 VPN 或者基于 AWS Direct Connect 的 VPN 隧道进行连接。所以在本题场景下，2️⃣ 的操作（在管理 VPC 新增一个虚拟专用网关）是没法让连接更加高可用的，只有增加一条本地到管理 VPC 的连接才行，只能选 3️⃣。 👨‍👨‍👦‍👦 社区讨论：C is the correct option to mitigate the single point of failure.The Management VPC currently has a single VPN connection through one customer gateway device. This is a single point of failure.Adding a second set of VPN connections from the Management VPC to a second customer gateway device provides redundancy and eliminates this single point of failure.","link":"/2024/12/06/saa_test_daily_20241206/"},{"title":"SAA 考试每日练习 - 2024&#x2F;12&#x2F;10","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam100 题 (No.601 ~ No.700) 只记录了 24 道首次碰到的、错误的或有疑问的题目，仅供自己复习使用。其中后 65 题与正式考试题量一样，总共耗时 81/(130+30) 分钟，正确率为 47/65。如果侵权请联系删除。 一、AWS Step Functions MapA company recently migrated to the AWS Cloud. The company wants a serverless solution for large-scale parallel on-demand processing of a semistructured dataset. The data consists of logs, media files, sales transactions, and IoT sensor data that is stored in Amazon S3. The company wants the solution to process thousands of items in the dataset in parallel.Which solution will meet these requirements with the MOST operational efficiency? Use the AWS Step Functions Map state in Inline mode to process the data in parallel. ✅ Use the AWS Step Functions Map state in Distributed mode to process the data in parallel. ❌ Use AWS Glue to process the data in parallel. Use several AWS Lambda functions to process the data in parallel. ✨ 关键词： 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：在 Step Functions 中为大规模并行工作负载在分布模式下使用 Map 状态 借助 Step Functions，您可以编排大规模的并行工作负载来执行任务，例如按需处理半结构化数据。这些并行工作负载允许您同时处理存储在 Amazon S3 中的大规模数据来源。例如，您可以处理包含大量数据的单个CSV文件JSON或文件。或者，您也可以处理一大组 Amazon S3 对象。 如果您未指定，Step Functions 将并行运行 1 万个并行子工作流执行。 在 Step Functions 工作流程中以内联模式使用 Map 状态 默认情况下，Map 状态以内联模式运行。在内联模式下，Map 状态仅接受JSON数组作为输入。它接收来自工作流中上一步的数组。在此模式下，Map 状态的每次迭代都在包含 Map 状态的工作流的上下文中运行。Step Functions 会将这些迭代的执行历史记录添加到父工作流的执行历史记录中。 在此模式下，Map 状态最多支持 40 次并发迭代。 1️⃣ 选项是流水线类型（串联），而 2️⃣ 是并行。 。。 👨‍👨‍👦‍👦 社区讨论：AWS Step Functions allows you to orchestrate and scale distributed processing using the Map state. The Map state can process items in a large dataset in parallel by distributing the work across multiple resources.Using the Map state in Distributed mode will automatically handle the parallel processing and scaling. Step Functions will add more workers to process the data as needed.Step Functions is serverless so there are no servers to manage. It will scale up and down automatically based on demand. 二、AWS WAFA company has an application that serves clients that are deployed in more than 20.000 retail storefront locations around the world. The application consists of backend web services that are exposed over HTTPS on port 443. The application is hosted on Amazon EC2 instances behind an Application Load Balancer (ALB). The retail locations communicate with the web application over the public internet. The company allows each retail location to register the IP address that the retail location has been allocated by its local ISP.The company’s security team recommends to increase the security of the application endpoint by restricting access to only the IP addresses registered by the retail locations.What should a solutions architect do to meet these requirements? ✅ Associate an AWS WAF web ACL with the ALB. Use IP rule sets on the ALB to filter traffic. Update the IP addresses in the rule to include the registered IP addresses. ❌ Deploy AWS Firewall Manager to manage the ALConfigure firewall rules to restrict traffic to the ALModify the firewall rules to include the registered IP addresses. Store the IP addresses in an Amazon DynamoDB table. Configure an AWS Lambda authorization function on the ALB to validate that incoming requests are from the registered IP addresses. Configure the network ACL on the subnet that contains the public interface of the ALB. Update the ingress rules on the network ACL with entries for each of the registered IP addresses. ✨ 关键词： 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：AWS Firewall Manager 和 AWS Organizations AWS Firewall Manager 是一项安全管理服务，您可以使用它集中配置和管理组织中AWS 账户和应用程序的防火墙规则。使用 Firewall Manager，您可以轻松地推行 AWS WAF 规则，创建 AWS Shield Advanced 保护、配置和审计 Amazon Virtual Private Cloud（Amazon VPC）安全组，并部署 AWS Network Firewall。使用 Firewall Manager 一次设置好保护措施，并让它们跨组织中的所有账户和资源自动应用，即使添加新资源和账户时也是如此。 AWS Firewall Manager AWS Firewall Manager 是一种安全性管理工具，可跨帐户和应用程序集中设定和管理 AWS WAF 规则。使用 Firewall Manager，您可一次性的向 Application Load Balancer 和 Amazon CloudFront 分配推送 WAF 规则，且可确保新应用程序和资源从一开始就符合通用的安全性规则集。 使用 AWS Firewall Manager 当然也能够解决问题，但是这里 2️⃣ 说的不清不楚的。1️⃣ 就很具体：在 AWS WAF 中使用 Web ACL Web ACL 可让您对受保护资源响应的所有 HTTP(S) Web 请求进行精细控制。您可以保护 Amazon CloudFront、Amazon API Gateway、应用程序负载均衡器 AWS AppSync、Amazon Cognito AWS App Runner 和 AWS Verified Access 资源。 您可以使用如下条件来允许或阻止请求： 请求的 IP 地址源 请求的源国家/地区 部分请求中的字符串匹配或正则表达式匹配 请求特定部分的大小 检测恶意 SQL 代码或脚本 并且它总共支持 100 条规则，每个可以包含 10,000 个 IP 地址源，符合题目需求。 👨‍👨‍👦‍👦 社区讨论：WAF, you can have 100 “rule sets” per account, each with up to 10,000 IP addresses.https://docs.aws.amazon.com/waf/latest/developerguide/limits.html 三、AWS Lake FormationA company is building a data analysis platform on AWS by using AWS Lake Formation. The platform will ingest data from different sources such as Amazon S3 and Amazon RDS. The company needs a secure solution to prevent access to portions of the data that contain sensitive information.Which solution will meet these requirements with the LEAST operational overhead? Create an IAM role that includes permissions to access Lake Formation tables. ✅ Create data filters to implement row-level security and cell-level security. Create an AWS Lambda function that removes sensitive information before Lake Formation ingests the data. Create an AWS Lambda function that periodically queries and removes sensitive information from Lake Formationtables. ✨ 关键词： 2️⃣ ✅ 💡 解析：什么是 AWS Lake Formation？ AWS Lake Formation 帮助您集中管理、保护和全球共享用于分析和机器学习的数据。您可以对 Amazon Simple Storage Service (Amazon S3) 上的数据湖数据及其在 AWS Glue Data Catalog 中的元数据进行精细访问控制 (fine-grained access control)。 安全管理 定义和管理访问控制 混合访问模式 实施审计日志记录 行和单元格级别安全功能 基于标签的访问控制 跨账户访问 👨‍👨‍👦‍👦 社区讨论：The key reasons are:Lake Formation data filters allow restricting access to rows or cells in data tables based on conditions. This allows preventing access to sensitive data.Data filters are implemented within Lake Formation and do not require additional coding or Lambda functions.Lambda functions to pre-process data or purge tables would require ongoing development and maintenance.IAM roles only provide user-level permissions, not row or cell level security.Data filters give granular access control over Lake Formation data with minimal configuration, avoiding complex custom code. 四、EKS secretsA company uses Amazon Elastic Kubernetes Service (Amazon EKS) to run a container application. The EKS cluster stores sensitive information in the Kubernetes secrets object. The company wants to ensure that the information is encrypted.Which solution will meet these requirements with the LEAST operational overhead? Use the container application to encrypt the information by using AWS Key Management Service (AWS KMS). ✅ Enable secrets encryption in the EKS cluster by using AWS Key Management Service (AWS KMS). Implement an AWS Lambda function to encrypt the information by using AWS Key Management Service (AWS KMS). ❌ Use AWS Systems Manager Parameter Store to encrypt the information by using AWS Key Management Service (AWS KMS). ✨ 关键词： 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：在现有集群上使用 AWS KMS 加密 Kubernetes 密钥 如果启用密钥加密，将使用您选择的 AWS KMS 对 Kubernetes 密钥加密。KMS 密钥必须符合以下条件： 对称 可以加密和解密数据 在与集群相同的 AWS 区域中创建 如果 KMS 密钥是在其他账户中创建的，则 IAM 主体必须拥有对 KMS 密钥的访问权限。 👨‍👨‍👦‍👦 社区讨论：EKS supports encrypting Kubernetes secrets at the cluster level using AWS KMS keys. This provides an automated way to encrypt secrets.Enabling this feature requires minimal configuration changes to the EKS cluster and no code changes.Other options like using Lambda functions or modifying the application code to encrypt secrets require additional development effort and overhead.Systems Manager Parameter Store could store encrypted parameters but does not natively integrate with EKS to encrypt Kubernetes secrets.The EKS secrets encryption feature leverages AWS KMS without the need to directly call KMS APIs from the application. 五、CloudWatch and EKSA company runs a critical, customer-facing application on Amazon Elastic Kubernetes Service (Amazon EKS). The application has a microservices architecture. The company needs to implement a solution that collects, aggregates, and summarizes metrics and logs from the application in a centralized location.Which solution meets these requirements? ❌ Run the Amazon CloudWatch agent in the existing EKS cluster. View the metrics and logs in the CloudWatch console. Run AWS App Mesh in the existing EKS cluster. View the metrics and logs in the App Mesh console. Configure AWS CloudTrail to capture data events. Query CloudTrail by using Amazon OpenSearch Service. ✅ Configure Amazon CloudWatch Container Insights in the existing EKS cluster. View the metrics and logs in the CloudWatch console. ✨ 关键词： 1️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：安装 CloudWatch 代理 CloudWatch 代理在 Amazon Linux 2023 和 Amazon Linux 2 中，可作为软件包使用。如果您使用其中一个操作系统，则可以通过输入以下命令来安装该软件包。 Container Insights 使用 CloudWatch Container Insights 可以从容器化应用程序和微服务中收集、聚合和汇总指标与日志。Container Insights 可用于 Amazon EC2 上的 Amazon Elastic Container Service (Amazon ECS)、Amazon Elastic Kubernetes Service (Amazon EKS) 和 Kubernetes 平台。Container Insights 支持从部署在 AWS Fargate 上的集群中收集针对 Amazon ECS 和 Amazon EKS 的指标。 Agent 是部署在实例上的，Container Insights 是部署在容器和集群中的。 👨‍👨‍👦‍👦 社区讨论：Use CloudWatch Container Insights to collect, aggregate, and summarize metrics and logs from your containerized applications and microservices. Container Insights is available for Amazon Elastic Container Service (Amazon ECS), Amazon Elastic Kubernetes Service (Amazon EKS), and Kubernetes platforms on Amazon EC2. Container Insights supports collecting metrics from clusters deployed on AWS Fargate for both Amazon ECS and Amazon EKS. 六、SecurityA company has deployed its newest product on AWS. The product runs in an Auto Scaling group behind a Network Load Balancer. The company stores the product’s objects in an Amazon S3 bucket.The company recently experienced malicious attacks against its systems. The company needs a solution that continuously monitors for malicious activity in the AWS account, workloads, and access patterns to the S3 bucket. The solution must also report suspicious activity and display the information on a dashboard.Which solution will meet these requirements? Configure Amazon Macie to monitor and report findings to AWS Config. ❌ Configure Amazon Inspector to monitor and report findings to AWS CloudTrail. ✅ Configure Amazon GuardDuty to monitor and report findings to AWS Security Hub. Configure AWS Config to monitor and report findings to Amazon EventBridge. ✨ 关键词： 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：什么是 Amazon Inspector？ - 针对 AWS 服务的漏洞扫描 Amazon Inspector 是一项自动化漏洞管理服务，可近乎实时地持续扫描 Amazon Elastic Compute Cloud（EC2）、Amazon Lambda 函数以及 Amazon ECR 中的容器映像以及持续集成和持续交付（CI/CD）工具中的软件漏洞和意外网络暴露。 什么是 AWS CloudTrail？ - 记录 AWS 账号操作 AWS CloudTrail 是一项 AWS 服务，可帮助您实现 AWS 账户 的运营和风险审计、治理和合规性。用户、角色或 AWS 服务执行的操作将记录为 CloudTrail 中的事件。事件包括在 AWS Management Console、AWS Command Line Interface 和 AWS 开发工具包和 API 中执行的操作。 什么是 Amazon GuardDuty？ - 监控恶意活动，保护账号、工作负载和数据 Amazon GuardDuty 是一项威胁检测服务，用于持续监控、分析和处理 AWS 环境中的 AWS 数据来源和日志。GuardDuty 使用恶意 IP 地址和域列表、文件哈希值和机器学习（ML）模型等威胁情报源，来识别 AWS 环境中的可疑和潜在有恶意的活动。 什么是 AWS Security Hub？ - 安全状态大屏 AWS Security Hub 为您提供了 AWS 中安全状态的全面视图，可帮助您评测您的 AWS 环境是否符合安全行业标准和最佳实践。 Security Hub 可跨 AWS 账户、AWS 服务、和受支持的第三方产品收集安全数据，并可帮助您分析安全趋势，以及确定最高优先级的安全问题。 👨‍👨‍👦‍👦 社区讨论：- Amazon Inspector = automated vulnerability management service Amazon GuardDuty = threat detection service that monitors for malicious activity and anomalous behavior to protect AWS accounts, workloads, and data. 七、Amazon Route 53A company is hosting a website behind multiple Application Load Balancers. The company has different distribution rights for its content around the world. A solutions architect needs to ensure that users are served the correct content without violating distribution rights.Which configuration should the solutions architect choose to meet these requirements? Configure Amazon CloudFront with AWS WAF. Configure Application Load Balancers with AWS WAF ✅ Configure Amazon Route 53 with a geolocation policy ❌ Configure Amazon Route 53 with a geoproximity routing policy ✨ 关键词： 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：选择路由策略 地理位置路由策略 (Geolocation routing policy) - 如果您想要根据用户的位置来路由流量，则可以使用该策略。在私有托管区域中，可以使用地理位置路由创建记录。 地理位置临近度路由策略 (Geoproximity routing policy) - 用于根据资源的位置来路由流量，以及（可选）将流量从一个位置中的资源转移到另一个位置中的资源。在私有托管区中，可以使用地理位置临近度路由创建记录。 👨‍👨‍👦‍👦 社区讨论：Geolocation routing policy — Use when you want to route traffic based on the location of usersGeo-proximity routing policy — Use when you want to route traffic based on the location of your resourcesand optionally switch resource traffic at one location to resourceselsewhere. 八、S3 Storage LensA global company runs its applications in multiple AWS accounts in AWS Organizations. The company’s applications use multipart uploads to upload data to multiple Amazon S3 buckets across AWS Regions. The company wants to report on incomplete multipart uploads for cost compliance purposes.Which solution will meet these requirements with the LEAST operational overhead? Configure AWS Config with a rule to report the incomplete multipart upload object count. ❌ Create a service control policy (SCP) to report the incomplete multipart upload object count. ✅ Configure S3 Storage Lens to report the incomplete multipart upload object count. Create an S3 Multi-Region Access Point to report the incomplete multipart upload object count. ✨ 关键词： 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：了解 Amazon S3 Storage Lens 存储统计管理工具 Amazon S3 Storage Lens 存储统计管理工具是一项云存储分析功能，您可以使用它在整个组织范围内了解对象存储的使用情况和活动。 您可以使用 S3 Storage Lens 存储统计管理工具指标生成摘要见解，例如，了解整个组织中有多少存储空间，或增长最快的桶和前缀是哪些。 您还可以使用 S3 Storage Lens 存储统计管理工具指标来识别成本优化机会，实施数据保护和安全最佳实践，并提高应用程序工作负载的性能。例如，您可以识别没有 S3 生命周期规则的桶，使超过 7 天的未完成分段上传过期。 您还可以识别未遵循数据保护最佳实践（例如使用 S3 复制或 S3 版本控制）的桶。S3 Storage Lens 存储统计管理工具还分析指标以提供上下文建议，您可以使用这些建议来优化存储成本并应用最佳实践来保护数据。 👨‍👨‍👦‍👦 社区讨论：S3 storage lenses can be used to find incomplete multipart uploads:https://aws.amazon.com/blogs/aws-cloud-financial-management/discovering-and-deleting-incomplete-multipart-uploads-to-lower-amazon-s3-costs/ 九、Amazon Neptune and Amazon Quantum Ledger DatabaseA social media company wants to store its database of user profiles, relationships, and interactions in the AWS Cloud. The company needs an application to monitor any changes in the database. The application needs to analyze the relationships between the data entities and to provide recommendations to users.Which solution will meet these requirements with the LEAST operational overhead? Use Amazon Neptune to store the information. Use Amazon Kinesis Data Streams to process changes in the database. ✅ Use Amazon Neptune to store the information. Use Neptune Streams to process changes in the database. Use Amazon Quantum Ledger Database (Amazon QLDB) to store the information. Use Amazon Kinesis Data Streams to process changes in the database. ❌ Use Amazon Quantum Ledger Database (Amazon QLDB) to store the information. Use Neptune Streams to process changes in the database. ✨ 关键词： 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：什么是 Amazon Neptune？ Amazon Neptune 是一项快速、可靠且完全托管式的图数据库服务，可帮助您轻松构建和运行适用于高度互连数据集的应用程序。Neptune 的核心是一个专门打造的高性能图形数据库引擎。该引擎经过优化，可存储数十亿个关系并能以毫秒级延迟进行图形查询。Neptune 支持流行的属性图查询语言 Apache TinkerPop Gremlin 和 Neo4j，以及 W3C 的openCypher查询语言。RDF SPARQL这可让您构建能够高效地浏览高度互联的数据集的查询。Neptune 支持图形用例，如建议引擎、欺诈检测、知识图谱、药物开发和网络安全。 使用 Neptune Streams 实时捕获图形更改 Neptune Streams 以完全托管式方式按发生顺序即时记录对图形所做的每一个更改。启用 Streams 后，Neptune 将负责管理可用性、备份、安全性和到期等事宜。 在许多使用案例中，都可能需要即时捕获对图的更改，下面是一些示例： 您可能希望在发生某些更改时应用程序能够自动通知用户。 您可能还想在其他数据存储中维护图表数据的最新版本，例如亚马逊 OpenSearch 服务、亚马逊或亚马逊 ElastiCache简单存储服务 (Amazon S3)。 什么是 Amazon QLDB？ 终止支持通知：现有客户可以在2025年7月31日终止支持QLDB之前使用亚马逊。有关更多详细信息，请参阅将亚马逊QLDB账本迁移到亚马逊 Aurora PostgreSQL。 Amazon Quantum Ledger 数据库 (AmazonQLDB) 是一个完全托管的账本数据库，它提供由中央可信机构拥有的透明、不可变且可加密验证的交易日志。您可以使用 Amazon QLDB 来跟踪所有应用程序数据更改，并维护一段时间内完整且可验证的更改历史记录。 👨‍👨‍👦‍👦 社区讨论：Relationships between entities = Graph data = Neptune 十、FSx for Lustre deployment optionsA weather forecasting company needs to process hundreds of gigabytes of data with sub-millisecond latency. The company has a high performance computing (HPC) environment in its data center and wants to expand its forecasting capabilities.A solutions architect must identify a highly available cloud storage solution that can handle large amounts of sustained throughput. Files that are stored in the solution should be accessible to thousands of compute instances that will simultaneously access and process the entire dataset.What should the solutions architect do to meet these requirements? ❌ Use Amazon FSx for Lustre scratch file systems. ✅ Use Amazon FSx for Lustre persistent file systems. Use Amazon ElasticFile System (Amazon EFS) with Bursting Throughput mode. Use Amazon ElasticFile System (Amazon EFS) with Provisioned Throughput mode. ✨ 关键词：highly available cloud storage solution 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：FSx for Lustre 文件系统的部署选项 Amazon FSx for Lustre 提供两个文件系统部署选项：临时 (scratch) 和持久 (persistent)。 临时 (scratch) 文件系统 - 临时文件系统专为临时存储和短期数据处理而设计。如果文件服务器出现故障，则不会复制数据，也不会持久保留数据。临时文件系统提供高突增吞吐量，高达基准吞吐量（每 TiB 存储容量 200MBps）的六倍 当需要对处理量繁重的短期工作负载使用成本优化的存储时，可以使用临时文件系统。 持久性 (persistent) 文件系统 - 持久性文件系统专为长期存储和工作负载而设计。文件服务器具有高可用性，并且数据在文件系统所在的同一可用区内自动复制。附加到文件服务器的数据卷独立于所附加的文件服务器进行复制。 对于长期存储以及侧重于吞吐量的工作负载，且这些工作负载将长时间运行或无限期运行，并可能对可用性中断很敏感，在这两种情况下，使用持久性文件系统。 👨‍👨‍👦‍👦 社区讨论：HPC + the entire dataset -&gt; FSx Lustre presistence 十一、Tag the resourcesA company maintains an Amazon RDS database that maps users to cost centers. The company has accounts in an organization in AWS Organizations. The company needs a solution that will tag all resources that are created in a specific AWS account in the organization. The solution must tag each resource with the cost center ID of the user who created the resource.Which solution will meet these requirements? Move the specific AWS account to a new organizational unit (OU) in Organizations from the management account. Create a service control policy (SCP) that requires all existing resources to have the correct cost center tag before the resources are created. Apply the SCP to the new OU. ✅ Create an AWS Lambda function to tag the resources after the Lambda function looks up the appropriate cost center from the RDS database. Configure an Amazon EventBridge rule that reacts to AWS CloudTrail events to invoke the Lambda function. ❌ Create an AWS CloudFormation stack to deploy an AWS Lambda function. Configure the Lambda function to look up the appropriate cost center from the RDS database and to tag resources. Create an Amazon EventBridge scheduled rule to invoke the CloudFormation stack. Create an AWS Lambda function to tag the resources with a default value. Configure an Amazon EventBridge rule that reacts to AWS CloudTrail events to invoke the Lambda function when a resource is missing the cost center tag. ✨ 关键词： 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：使用 AWS Organizations 的标签进行基于属性的访问控制 检查附加到请求中指定资源的标签当您使用AWS Management Console、AWS Command Line Interface（AWS CLI）或其中一个 AWS SDK 发出请求时，您可以指定要通过该请求访问的资源。无论您是试图列出给定类型的可用资源、读取资源还是写入、修改或更新资源，都可以将要访问的资源指定为请求中的参数。此类请求由您附加到用户和角色的 IAM 权限策略控制。在这些策略中，您可以比较附加到请求资源的标签，并根据这些标签的键和值选择允许或拒绝访问。 SCP 可以对操作的资源进行标签检查，但是不能为其打上标签，这就是为什么 1️⃣ 是错的。 👨‍👨‍👦‍👦 社区讨论：A policy cannot look up “the cost center ID of the user who created the resource”, we need Lambda to do that.Thus A is out.C would work but runs on a schedule which doesn’t make sense (and we would temporarily have untagged resources).D tags resources “with a default value” which is not what we want. 十二、Customer-managed prefix listsA company has multiple AWS accounts in an organization in AWS Organizations that different business units use. The company has multiple offices around the world. The company needs to update security group rules to allow new office CIDR ranges or to remove old CIDR ranges across the organization. The company wants to centralize the management of security group rules to minimize the administrative overhead that updating CIDR ranges requires.Which solution will meet these requirements MOST cost-effectively? Create VPC security groups in the organization’s management account. Update the security groups when a CIDR range update is necessary. ✅ Create a VPC customer managed prefix list that contains the list of CIDRs. Use AWS Resource Access Manager (AWS RAM) to share the prefix list across the organization. Use the prefix list in the security groups across the organization. Create an AWS managed prefix list. Use an AWS Security Hub policy to enforce the security group update across the organization. Use an AWS Lambda function to update the prefix list automatically when the CIDR ranges change. ❌ Create security groups in a central administrative AWS account. Create an AWS Firewall Manager common security group policy for the whole organization. Select the previously created security groups as primary groups in the policy. ✨ 关键词： 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：使用托管前缀列表 (managed prefix lists) 合并和管理网络 CIDR 块 托管式前缀列表是包含一个或多个 CIDR 块的集合。您可以使用前缀列表更轻松地配置和维护安全组和路由表。您可以根据经常使用的 IP 地址创建前缀列表，并将它们作为安全组规则和路由中的集合引用，而不是单独引用它们。例如，您可以将具有不同 CIDR 块但使用相同端口和协议的安全组规则整合到使用前缀列表的单个规则中。如果您扩展网络并需要允许来自另一个 CIDR 块的流量，则可以更新相关的前缀列表，使用该前缀列表的所有安全组都将更新。您还可以使用资源访问管理器（RAM）与其他 AWS 账户一起使用托管式前缀列表。 前缀列表有两种类型： 客户管理的前缀列表 (Customer-managed prefix lists) — 您定义和管理的 IP 地址范围集。您可以与其他AWS账户共享您的前缀列表，使这些账户能够在自己的资源中引用该前缀列表。 AWS托管前缀列表 (AWS-managed prefix lists) — AWS服务的 IP 地址范围集。您无法创建、修改、共享或删除AWS托管的前缀列表。 👨‍👨‍👦‍👦 社区讨论：A managed prefix list isa set of one or more CIDR blocks. You can use prefix lists to make it easier to configure and maintain your security groupsand route tables. You can create a prefix list from the IP addresses that you frequently use,and reference them asa set in security group rulesand routes instead of referencing them individually. If you scale your networkand need to allow traffic from another CIDR block, you can update the relevant prefix list and all security groups that use the prefix list are updated. You can also use managed prefix lists with other AWS accounts using Resource Access Manager (RAM). 十三、KMSA company is developing a new application on AWS. The application consists of an Amazon Elastic Container Service (Amazon ECS) cluster, an Amazon S3 bucket that contains assets for the application, and an Amazon RDS for MySQL database that contains the dataset for the application. The dataset contains sensitive information. The company wants to ensure that only the ECS cluster can access the data in the RDS for MySQL database and the data in the S3 bucket.Which solution will meet these requirements? ✅ Create a new AWS Key Management Service (AWS KMS) customer managed key to encrypt both the S3 bucket and the RDS for MySQL database. Ensure that the KMS key policy includes encrypt and decrypt permissions for the ECS task execution role. Create an AWS Key Management Service (AWS KMS) AWS managed key to encrypt both the S3 bucket and the RDS for MySQL database. Ensure that the S3 bucket policy specifies the ECS task execution role as a user. ❌ Create an S3 bucket policy that restricts bucket access to the ECS task execution role. Create a VPC endpoint for Amazon RDS for MySQL. Update the RDS for MySQL security group to allow access from only the subnets that the ECS cluster will generate tasks in. Create a VPC endpoint for Amazon RDS for MySQL. Update the RDS for MySQL security group to allow access from only the subnets that the ECS cluster will generate tasks in. Create a VPC endpoint for Amazon S3. Update the S3 bucket policy to allow access from only the S3 VPC endpoint. ✨ 关键词： 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：只有 ECS 集群可以访问 S3 和 RDS 数据库。3️⃣ 和 4️⃣ 的问题都在允许子网或 VPC 内的所有实例访问 S3 或 RDS。2️⃣ 没有限制 RDS。只能选 1️⃣。社区争议很大。 👨‍👨‍👦‍👦 社区讨论：We’re asked to restrict access to both, RDS and S3, to “the ECS cluster” (not to a subnet orendpoint).Not B: Does not restrict RDS at all. Wording aboutS3 is unusual.Not C: Would workforS3, but would allow RDS access from whole subnet which may contain other resources besides the ECS cluster.Not D: Would allow RDS access from whole subnet which may contain other resources besides the ECS cluster. Would allow S3 access from VPC endpoint which might be accessed by other resources besides the ECS cluster. 十四、Elastic BeanstalkA company has a web application that runs on premises. The application experiences latency issues during peak hours. The latency issues occur twice each month. At the start of a latency issue, the application’s CPU utilization immediately increases to 10 times its normal amount.The company wants to migrate the application to AWS to improve latency. The company also wants to scale the application automatically when application demand increases. The company will use AWS Elastic Beanstalk for application deployment. Which solution will meet these requirements? ✅ Configure an Elastic Beanstalk environment to use burstable performance instances in unlimited mode. Configure the environment to scale based on requests. Configure an Elastic Beanstalk environment to use compute optimized instances. Configure the environment to scale based on requests. Configure an Elastic Beanstalk environment to use compute optimized instances. Configure the environment to scale on a schedule. Configure an Elastic Beanstalk environment to use burstable performance instances in unlimited mode. Configure the environment to scale on predictive metrics. ✨ 关键词： 1️⃣ ✅ 💡 解析：实例指标 Web 服务器指标 过去 10 秒内 Web 服务器每秒处理的请求数。 过去 10 秒内导致每种类型的状态代码的请求数。 过去 10 秒内最慢的 x% 的请求的平均延迟，其中 x 是数字与 100 之差。 操作系统指标 自启动实例以来经过的时间量。 （只有 Linux 系统支持）过去一分钟和五分钟时段内的负载平均值。 过去 10 秒内 CPU 在每个状态中耗费的时间的百分比。 👨‍👨‍👦‍👦 社区讨论：”Scale on predictive metrics” does not sound like something that Beanstalkcan do. In EC2 you can create a “predictive scaling policy”, but apparently this is not supported by Beanstalk.That would rule out D.We have no indication that the application is CPU-intensive in general. If CPU utilization “increases to 10 times its normalamount” then the “normal amount” cannot be higher than 10 %.This would rule out B and C. 十五、Gateway endpoints and interface endpointsA company is moving its data and applications to AWS during a multiyear migration project. The company wants to securely access data on Amazon S3 from the company’s AWS Region and from the company’s on-premises location. The data must not traverse the internet. The company has established an AWS Direct Connect connection between its Region and its on-premises location.Which solution will meet these requirements? ❌ Create gateway endpoints for Amazon S3. Use the gateway endpoints to securely access the data from the Region and the on-premises location. Create a gateway in AWS Transit Gateway to access Amazon S3 securely from the Region and the on-premises location. ✅ Create interface endpoints for Amazon S3. Use the interface endpoints to securely access the data from the Region and the on-premises location. Use an AWS Key Management Service (AWS KMS) key to access the data securely from the Region and the on-premises location. ✨ 关键词： 1️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：适用于 Amazon S3 的网关端点 Amazon S3 同时支持网关端点和接口端点。 借助网关端点，您可以从 VPC 访问 Amazon S3，而无需为 VPC 配备互联网网关或 NAT 设备，也无需任何额外费用。 但是，网关端点不允许从本地网络、其他 AWS 区域的对等 VPC 或通过传输网关进行访问。 必须使用接口端点（以允许从本地网络、其他 AWS 区域的对等 VPC 或通过传输网关进行访问），后者需要额外付费。 网关终端节点不支持端到端，接口终端节点支持。 👨‍👨‍👦‍👦 社区讨论：Ans is C: &gt;&gt;You can access Amazon S3 from your VPC using gateway VPC endpoints. After you create the gatewayendpoint, you can add it asa target in your route table for traffic destined from your VPC to Amazon S3.There is no additional charge for using gatewayendpoints. Amazon S3 supports both gatewayendpointsand interface endpoints. With a gatewayendpoint, you can access Amazon S3 from your VPC, without requiring an internet gateway or NAT device for your VPC,and with no additional cost. However, gatewayendpoints do not allow access from on-premises networks, from peered VPCs in other AWS Regions, or through a transit gateway. For those scenarios, you must use an interface endpoint, which isavailable for an additional cost. For more information, see Types of VPC endpoints for Amazon S3 in the Amazon S3 User Guide.https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html 十六、DynamoDB modeA company performs tests on an application that uses an Amazon DynamoDB table. The tests run for 4 hours once a week. The company knows how many read and write operations the application performs to the table each second during the tests. The company does not currently use DynamoDB for any other use case. A solutions architect needs to optimize the costs for the table.Which solution will meet these requirements? ❌ Choose on-demand mode. Update the read and write capacity units appropriately. ✅ Choose provisioned mode. Update the read and write capacity units appropriately. Purchase DynamoDB reserved capacity for a 1-year term. Purchase DynamoDB reserved capacity for a 3-year term. ✨ 关键词： 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：公司对每周运行 4 小时的 DynamoDB 有一定的使用量预测。DynamoDB on-demand and provisioned capacity 在无服务器应用程序中，您通常会使用亚马逊的完全托管 NoSQL 数据库服务 DynamoDB。亚马逊 DynamoDB 有两种定价模式：按需容量模式定价和配置容量模式定价。 使用预配置容量 (on-demand mode)，您需要为 DynamoDB 表的读写容量单位支付费用。而按需使用 DynamoDB 时，您需要为应用程序在表上执行的数据读写按请求付费。在按需容量模式下，DynamoDB 会根据应用程序在表上执行的数据读写来收费。您不需要指定您期望应用程序执行的读写吞吐量，因为 DynamoDB 会根据工作负载的增减即时调整。 在调配容量模式 (provisioned mode) 下，您可以指定应用程序每秒所需的读写量，并据此计费。此外，如果您能预测您的容量需求，您还可以预留一部分 DynamoDB 预配置容量，从而进一步优化您的成本。 通过预留容量，您还可以使用自动缩放功能，根据指定的利用率自动调整表的容量，以确保应用程序的性能，并降低潜在成本。要在 DynamoDB 中配置自动缩放，除了目标利用率百分比外，还要设置读写容量的最小和最大级别。 👨‍👨‍👦‍👦 社区讨论：With provisioned capacity mode, you specify the number of readsand writes per second that you expect your application to require,and you are billed based on that. Furthermore if you can forecast your capacity requirements you can also reserve a portion of DynamoDB provisioned capacityand optimize your costseven further.https://docs.aws.amazon.com/wellarchitected/latest/serverless-applications-lens/capacity.html 十七、AWS Glue crawler and data analyticsA marketing company receives a large amount of new clickstream data in Amazon S3 from a marketing campaign. The company needs to analyze the clickstream data in Amazon S3 quickly. Then the company needs to determine whether to process the data further in the data pipeline.Which solution will meet these requirements with the LEAST operational overhead? Create external tables in a Spark catalog. Configure jobs in AWS Glue to query the data. ✅ Configure an AWS Glue crawler to crawl the data. Configure Amazon Athena to query the data. Create external tables in a Hive metastore. Configure Spark jobs in Amazon EMR to query the data. ❌ Configure an AWS Glue crawler to crawl the data. Configure Amazon Kinesis Data Analytics to use SQL to query the data. ✨ 关键词： 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：Kinesis Data Analytics 是用以处理数据的，并且即将被停用。适用于 SQL 应用程序的 Amazon Kinesis Data Analytics：工作原理 Kinesis Data Analytics 应用程序持续实时读取和处理流数据。您可以使用 SQL 编写应用程序代码来处理传入的流数据并生成输出。然后，Kinesis Data Analytics 会将输出写入到配置的目标中。以下示意图说明典型的应用程序架构。 除了这些基本属性外，每个应用程序还包括： Input - 应用程序的流式传输源。 应用程序代码 - 应用程序的流式传输源。 输出 - 应用程序的流式传输源。 👨‍👨‍👦‍👦 社区讨论：You’ve come a loooong way…keep going…Kinesis Data Analytics applications continuously read and process streaming data in real time.Data is already at rest in S3. So Athena.https://docs.aws.amazon.com/kinesisanalytics/latest/dev/how-it-works.html 十八、RDS auto scaling is not a thingA company runs a web application on Amazon EC2 instances in an Auto Scaling group. The application uses a database that runs on an Amazon RDS for PostgreSQL DB instance. The application performs slowly when traffic increases. The database experiences a heavy read load during periods of high traffic.Which actions should a solutions architect take to resolve these performance issues? (Choose two.) ❌ Turn on auto scaling for the DB instance. ✅ Create a read replica for the DB instance. Configure the application to send read traffic to the read replica. Convert the DB instance to a Multi-AZ DB instance deployment. Configure the application to send read traffic to the standby DB instance. ✅ Create an Amazon ElastiCache cluster. Configure the application to cache query results in the ElastiCache cluster. Configure the Auto Scaling group subnets to ensure that the EC2 instances are provisioned in the same Availability Zone as the DB instance. ✨ 关键词： 1️⃣ 2️⃣ ❌ -&gt; 2️⃣ 4️⃣ ✅ 💡 解析：RDS 的弹性扩展确实是不存在的，只有 Aurora 数据库的读取副本支持弹性扩展。Amazon Aurora Auto Scaling 与 Aurora 副本结合使用 为了满足您的连接和工作负载要求，Aurora Auto Scaling 动态调整为 Aurora 数据库集群预调配的 Aurora 副本数（读取器数据库实例）。Aurora Auto Scaling 适用于 Aurora MySQL 和 Aurora PostgreSQL。通过使用 Aurora Auto Scaling，Aurora 数据库集群可以处理连接或工作负载突然增加的情况。在连接或工作负载减少时，Aurora Auto Scaling 删除不需要的 Aurora 副本，以便您无需为未使用的配置数据库实例付费。 Aurora Auto Scaling 不适用于写入器数据库实例上的工作负载。Aurora Auto Scaling 只能协助处理读取器实例上的工作负载。 👨‍👨‍👦‍👦 社区讨论：A: RDS DB instance Autoscaling is not a thingC: You cannot read from standby even if this was done.E: Does not solve any problem Correct answerB: Read replicas distribute load and help improving performanceD: Caching of any kind will help with performanceRemember: “ The database experiences a heavy read load during periods of high traffic.” 十九、Amazon EBS snapshot lockA company uses Amazon EC2 instances and Amazon Elastic Block Store (Amazon EBS) volumes to run an application. The company creates one snapshot of each EBS volume every day to meet compliance requirements. The company wants to implement an architecture that prevents the accidental deletion of EBS volume snapshots. The solution must not change the administrative rights of the storage administrator user.Which solution will meet these requirements with the LEAST administrative effort? Create an IAM role that has permission to delete snapshots. Attach the role to a new EC2 instance. Use the AWS CLI from the new EC2 instance to delete snapshots. Create an IAM policy that denies snapshot deletion. Attach the policy to the storage administrator user. ❌ Add tags to the snapshots. Create retention rules in Recycle Bin for EBS snapshots that have the tags. ✅ Lock the EBS snapshots to prevent deletion. ✨ 关键词： 3️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：亚马逊EBS快照锁 您可以锁定您的 Amazon EBS 快照以防止意外或恶意删除，或者以 WORM (write-once-read-many) 格式将其存储在特定时间内。当快照处于锁定状态时，任何用户都无法将其删除，无论其IAM权限如何。您可以像使用任何其他快照一样继续使用锁定的快照。 👨‍👨‍👦‍👦 社区讨论：Locking EBS Snapshots (Option D): The “lock” feature in AWS allows you to prevent accidental deletion of resources, including EBS snapshots. This can be set at the snapshot level, providing a straightforward and effective way to meet the requirements without changing the administrative rights of the storage administrator user. 二十、EKS and spot instancesA company is developing an application that will run on a production Amazon Elastic Kubernetes Service (Amazon EKS) cluster. The EKS cluster has managed node groups that are provisioned with On-Demand Instances.The company needs a dedicated EKS cluster for development work. The company will use the development cluster infrequently to test the resiliency of the application. The EKS cluster must manage all the nodes.Which solution will meet these requirements MOST cost-effectively? Create a managed node group that contains only Spot Instances. ✅ Create two managed node groups. Provision one node group with On-Demand Instances. Provision the second node group with Spot Instances. Create an Auto Scaling group that has a launch configuration that uses Spot Instances. Configure the user data to add the nodes to the EKS cluster. ❌ Create a managed node group that contains only On-Demand Instances. ✨ 关键词： 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：社区在 1️⃣ 和 2️⃣ 之间争议较大，但是争议点为题目描述方式，是需要一个“专用以开发环境的集群”还是“一个集群既包含生产节点又包含开发节点”。无论如何将抢占 (Spot) 实例用以开发节点是共识。竞价型实例的工作原理 如果有可用容量，则您的竞价型实例将启动。您的 Spot 实例会一直运行，直到您停止或终止它，或者 Amazon EC2 中断它（称为 Spot 实例中断）。Amazon EC2 可以在中断竞价型实例时使实例停止、终止或休眠。 👨‍👨‍👦‍👦 社区讨论：This question is convoluted and missing some details.We need: control plane running on on-demand EC2s worker nodes running on spot instancesRead this to understand correct solution:https://aws.amazon.com/blogs/containers/amazon-eks-now-supports-provisioning-and-managing-ec2-spot-instances-in-managed-node-groups/ 二十一、EBS auto encryptionA company needs a solution to enforce data encryption at rest on Amazon EC2 instances. The solution must automatically identify noncompliant resources and enforce compliance policies on findings.Which solution will meet these requirements with the LEAST administrative overhead? ✅ Use an IAM policy that allows users to create only encrypted Amazon Elastic Block Store (Amazon EBS) volumes. Use AWS Config and AWS Systems Manager to automate the detection and remediation of unencrypted EBS volumes. Use AWS Key Management Service (AWS KMS) to manage access to encrypted Amazon Elastic Block Store (Amazon EBS) volumes. Use AWS Lambda and Amazon EventBridge to automate the detection and remediation of unencrypted EBS volumes. Use Amazon Macie to detect unencrypted Amazon Elastic Block Store (Amazon EBS) volumes. Use AWS Systems Manager Automation rules to automatically encrypt existing and new EBS volumes. ❌ Use Amazon inspector to detect unencrypted Amazon Elastic Block Store (Amazon EBS) volumes. Use AWS Systems Manager Automation rules to automatically encrypt existing and new EBS volumes. ✨ 关键词： 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：自动加密现有和新的 Amazon EBS 卷 AWS Config 检测到未加密的EBS卷。 管理员使用 AWS Config 向 Systems Manager 发送修复命令。 Systems Manager 会自动拍摄未加密EBS卷的快照。 Systems Manager 自动化用于AWSKMS创建快照的加密副本。 Systems Manager 自动化执行以下操作： 如果受影响的EC2实例正在运行，则将其停止 将卷的新加密副本附加到实EC2例 将EC2实例恢复到其原始状态 示例：创建卷 - 以下策略允许用户使用该CreateVolumeAPI操作。系统只允许用户创建加密且大小不足 20 GiB 的卷 👨‍👨‍👦‍👦 社区讨论：A as exactly described here: https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/automatically-encrypt-existing-and-new-amazon-ebs-volumes.htmlNot B, that could in theory work but would be massive operational overheadNot C, Macie detects PII data, not unencrypted volumesNot D, Inspector detects vulnerabilities, not unencrypted volumes 二十二、Amazon ForecastA company that uses AWS needs a solution to predict the resources needed for manufacturing processes each month. The solution must use historical values that are currently stored in an Amazon S3 bucket. The company has no machine learning (ML) experience and wants to use a managed service for the training and predictions.Which combination of steps will meet these requirements? (Choose two.) Deploy an Amazon SageMaker model. Create a SageMaker endpoint for inference. ❌ Use Amazon SageMaker to train a model by using the historical data in the S3 bucket. ❌ Configure an AWS Lambda function with a function URL that uses Amazon SageMaker endpoints to create predictions based on the inputs. ✅ Configure an AWS Lambda function with a function URL that uses an Amazon Forecast predictor to create a prediction based on the inputs. ✅ Train an Amazon Forsecast predictor by using the historical data in the S3 bucket. ✨ 关键词： 2️⃣ 3️⃣ ❌ -&gt; 4️⃣ 5️⃣ ✅ 💡 解析：什么是 Amazon Forecast？ Amazon Forecast 是一种完全托管式服务，可使用统计和机器学习算法提供高度精确的时间序列预测。Forecast 基于与 Amazon.com 用于时间序列预测的相同技术，提供基于历史数据预测未来时间序列数据的 state-of-the-art 算法，无需任何机器学习经验。时间序列预测适用于多个领域，包括零售、金融、物流和医疗保健。您还可以使用 Forecast 来预测库存、人力、Web 流量、服务器容量和财务状况等特定领域的指标。 Amazon Forecast 不再向新买家开放。Amazon Forecast 的现有客户可以继续照常使用该服务。 什么是 Amazon SageMaker？ Amazon SageMaker 是一项完全托管的服务，可为每位开发人员和数据科学家提供快速构建、训练和部署机器学习 (ML) 模型的能力。SageMaker 消除了机器学习过程中每个步骤的繁重工作，让您能够更轻松地开发高质量模型。 两个也都能读取 S3 内的数据，因此在这里理论上都能选。 👨‍👨‍👦‍👦 社区讨论：Amazon Forecast is no longer available to new customers.https://aws.amazon.com/blogs/machine-learning/transition-your-amazon-forecast-usage-to-amazon-sagemaker-canvas/ 二十三、IAM Identity CenterA company manages AWS accounts in AWS Organizations. AWS IAM Identity Center (AWS Single Sign-On) and AWS Control Tower are configured for the accounts. The company wants to manage multiple user permissions across all the accounts.The permissions will be used by multiple IAM users and must be split between the developer and administrator teams. Each team requires different permissions. The company wants a solution that includes new users that are hired on both teams.Which solution will meet these requirements with the LEAST operational overhead? Create individual users in IAM Identity Center for each account. Create separate developer and administrator groups in IAM Identity Center. Assign the users to the appropriate groups. Create a custom IAM policy for each group to set fine-grained permissions. ❌ Create individual users in IAM Identity Center for each account. Create separate developer and administrator groups in IAM Identity Center. Assign the users to the appropriate groups. Attach AWS managed IAM policies to each user as needed for fine-grained permissions. ✅ Create individual users in IAM Identity Center. Create new developer and administrator groups in IAM Identity Center. Create new permission sets that include the appropriate IAM policies for each group. Assign the new groups to the appropriate accounts. Assign the new permission sets to the new groups. When new users are hired, add them to the appropriate group. 为每个组创建包含适当IAM策略的新权限集。将新组分配给适当的帐户。将新的权限集分配给新的组。雇用新用户时，将其添加到适当的组中。 Create individual users in IAM Identity Center. Create new permission sets that include the appropriate IAM policies for each user. Assign the users to the appropriate accounts. Grant additional IAM permissions to the users from within specific accounts. When new users are hired, add them to IAM Identity Center and assign them to the accounts. ✨ 关键词： 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：与 AWS IAM 身份中心和 AWS Control Tower 合作 在 AWS Control Tower 中，IAM 身份中心允许中央云管理员和最终用户管理对多个 AWS 账户和业务应用程序的访问权限。默认情况下，AWS Control Tower 使用此服务来设置和管理对通过 Account Factory 创建的账户的访问权限，除非您选择了自行管理身份和访问控制的选项。 👨‍👨‍👦‍👦 社区讨论：C is least overhead 二十四、S3A company regularly uploads GB-sized files to Amazon S3. After the company uploads the files, the company uses a fleet of Amazon EC2 Spot Instances to transcode the file format. The company needs to scale throughput when the company uploads data from the on-premises data center to Amazon S3 and when the company downloads data from Amazon S3 to the EC2 instances.Which solutions will meet these requirements? (Choose two.) ❌ Use the S3 bucket access point instead of accessing the S3 bucket directly. Upload the files into multiple S3 buckets. ✅ Use S3 multipart uploads. ✅ Fetch multiple byte-ranges of an object in parallel. Add a random prefix to each object when uploading the files. ✨ 关键词： 1️⃣ 3️⃣ ❌ -&gt; 3️⃣ 4️⃣ ✅ 💡 解析：使用字节范围提取 通过在 GET 对象请求中使用范围 HTTP 标头，您可以从对象中提取字节范围，只传输指定的部分。您可以使用到 Amazon S3 的并行连接，从相同对象中提取不同的字节范围。这有助于您通过单一整个对象请求实现更高的聚合吞吐量。通过提取较小范围的大型对象，您的应用程序还可以在请求中断时改善重试次数。 👨‍👨‍👦‍👦 社区讨论：C: Increase the file upload throughputD: increase the file download throughput","link":"/2024/12/10/saa_test_daily_20241210/"},{"title":"SAA 考试每日练习 - 2024&#x2F;12&#x2F;11","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam100 题 (No.701 ~ No.800) 只记录了 15 道首次碰到的、错误的或有疑问的题目，仅供自己复习使用。其中有 65 题与正式考试题量一样，总共耗时 87/(130+30) 分钟，正确率为 57/65。如果侵权请联系删除。 一、SnowFamily and S3A company copies 200 TB of data from a recent ocean survey onto AWS Snowball Edge Storage Optimized devices. The company has a high performance computing (HPC) cluster that is hosted on AWS to look for oil and gas deposits. A solutions architect must provide the cluster with consistent sub-millisecond latency and high-throughput access to the data on the Snowball Edge Storage Optimized devices. The company is sending the devices back to AWS.Which solution will meet these requirements? Create an Amazon S3 bucket. Import the data into the S3 bucket. Configure an AWS Storage Gateway file gateway to use the S3 bucket. Access the file gateway from the HPC cluster instances. ✅ Create an Amazon S3 bucket. Import the data into the S3 bucket. Configure an Amazon FSx for Lustre file system, and integrate it with the S3 bucket. Access the FSx for Lustre file system from the HPC cluster instances. Create an Amazon S3 bucket and an Amazon ElasticFile System (Amazon EFS) file system. Import the data into the S3 bucket. Copy the data from the S3 bucket to the EFS file system. Access the EFS file system from the HPC cluster instances. ❌ Create an Amazon FSx for Lustre file system. Import the data directly into the FSx for Lustre file system. Access the FSx for Lustre file system from the HPC cluster instances. ✨ 关键词： 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：使用 Amazon S3 适配器传输文件，以便在 Snow Family 设备之间迁移数据 以下是 Amazon S3 适配器的概述，您可以使用该适配器通过 Amazon S3 操作以编程方式将数据传输到设备上已有的 S3 存储桶或从 AWS Snowball Edge 设备上传输数据。REST API此 Amazon S3 REST API 支持仅限于部分操作。您可以将此操作子集与其中一个操作配合使用， AWS SDKs以编程方式传输数据。您还可以对 Amazon S3 使用这一部分受支持的 AWS Command Line Interface （AWS CLI）命令来以编程方式传输数据。 社区选 2️⃣ 的原因是 SnowFamily 只支持 S3 形式的存储，但是我并没有在官方的文档中找到完全一样的描述，只有说支持 S3 的：什么是 AWS Snowball Edge？ 在这些设备上的 Snow Family 设备上使用与 Amazon S3 兼容的存储空间时，可用存储空间会有所不同。请参阅在 Snow Family 设备上在 Snow Family 设备上使用兼容 Amazon S3 的存储，了解在 Sn ow Family 设备上使用兼容 Amazon S3 的存储容量。 姑且暂时这么认为吧：SnowFamily 设备上只能以 S3 形式存储文件。 👨‍👨‍👦‍👦 社区讨论：No direct integration between Snowball and Fsx for Lustre. It must be via S3.Snowball Edge (Storage Optimized) –&gt; S3 –integrate–&gt; FSx for Lustrehttps://docs.aws.amazon.com/fsx/latest/LustreGuide/create-dra-linked-data-repo.htmlhttps://aws.amazon.com/tw/blogs/aws/enhanced-amazon-s3-integration-for-amazon-fsx-for-lustre/ 二、Route 53 ResolverA company is designing a web application on AWS. The application will use a VPN connection between the company’s existing data centers and the company’s VPCs.The company uses Amazon Route 53 as its DNS service. The application must use private DNS records to communicate with the on-premises services from a VPC.Which solution will meet these requirements in the MOST secure manner? ✅ Create a Route 53 Resolver outbound endpoint. Create a resolver rule. Associate the resolver rule with the VPC. Create a Route 53 Resolver inbound endpoint. Create a resolver rule. Associate the resolver rule with the VPC. ❌ Create a Route 53 private hosted zone. Associate the private hosted zone with the VPC. Create a Route 53 publichosted zone. Create a record for each service to allow service communication ✨ 关键词： 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：什么是 Amazon Route 53 Resolver？ Amazon Route 53 Resolver 会递归响应 AWS 资源对公共记录、Amazon VPC 特定 DNS 名称和 Amazon Route 53 私有托管区域的 DNS 查询，默认情况下在所有 VPC 中都可用。 出站（实心箭头 1–5）： 亚马逊EC2实例需要解析对域名internal.example.com的DNS查询。权威DNS服务器位于本地数据中心。此DNS查询被发送到连接VPC到 Route 53 Resolver 的 VPC +2。 Route 53 Resolver 转发规则配置为将查询转发到本地数据中心的 internal.example.com。 查询将被转发到出站端点。 出站终端节点通过与数据中心之间的 AWS 私有连接将查询转发给本地DNS解析器。该连接可以是 AWS Direct Connect 或 AWS Site-to-Site VPN，可以描述为虚拟专用网关。 本地DNS解析器解析对 internal.example.com 的DNS查询，并通过相同的路径反向将答案返回给亚马逊EC2实例。 入站（虚线箭头 a–d）： 本地数据中心的客户端需要解析对域 dev.example.com AWS 资源的DNS查询。它将查询发送到本地解DNS析器。 本地解DNS析器具有转发规则，可将发往 dev.example.com 的查询指向入站终端节点。 查询通过私有连接（例如 AWS Direct Connect 或）到达入站终端节点 AWS Site-to-Site VPN，该连接被描述为虚拟网关。 入站终端节点将查询发送到 Route 53 解析器，Route 53 解析器解析 dev.example.com 的DNS查询，并通过相同的路径反向将答案返回给客户端。 本题中，VPC 内的服务要访问本地托管的服务，因此属于出栈，需要使用 Route 53 Resolver outbound endpoint。 使用公有托管区 公有托管区域是一个容器，其中包含的信息说明您希望如何路由特定域（如 example.com）及其子域（acme.example.com 和 zenith.example.com）的 Internet 流量。 使用私有托管区 私有托管区域是一个容器，其中包含有关您希望 Amazon Route 53 如何响应您使用 Amazon VPC 服务创建的一个或多个VPCs域名及其子域名的DNS查询的信息。 公有托管区面向互联网，私有托管区面向 VPC。 👨‍👨‍👦‍👦 社区讨论：If you have workloads that leverage both VPCsand on-premises resources, you also need to resolve DNS records hosted on-premises.Similarly, these on-premises resources may need to resolve names hosted on AWS.Through Resolver endpoints and conditional forwarding rules, you can resolve DNS queries between your on-premises resourcesand VPCs to create a hybrid cloud setup over VPN or Direct Connect (DX).Specifically:Inbound Resolver endpoints allow DNS queries to your VPC from your on-premises network or another VPC.Outbound Resolver endpoints allow DNS queries from your VPC to your on-premises network or another VPC.Reference: https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resolver.html 三、Saving Plans coverageA company uses Amazon EC2, AWS Fargate, and AWS Lambda to run multiple workloads in the company’s AWS account. The company wants to fully make use of its Compute Savings Plans. The company wants to receive notification when coverage of the Compute Savings Plans drops.Which solution will meet these requirements with the MOST operational efficiency? ✅ Create a daily budget for the Savings Plans by using AWS Budgets. Configure the budget with a coverage threshold to send notifications to the appropriate email message recipients. Create a Lambda function that runs a coverage report against the Savings Plans. Use Amazon Simple Email Service (Amazon SES) to email the report to the appropriate email message recipients. Create an AWS Budgets report for the Savings Plans budget. Set the frequency to daily. ❌ Create a Savings Plans alert subscription. Enable all notification options. Enter an email address to receive notifications. ✨ 关键词： 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：使用 AWS Budgets 管理成本 您可以使用 AWS Budgets 来跟踪 AWS 成本和使用情况并执行操作。您可以使用 AWS Budgets 监控预留实例 (RI) 或 Savings Plans 的聚合利用率和覆盖率指标。 您可以使用 AWS Budgets 启用简单到复杂成本和使用情况跟踪。一些示例包括： 设置每日利用率或覆盖率预算，以跟踪您的 RI 或 Savings Plans。您可以选择在指定日期的利用率降至 80% 以下时通过电子邮件和 Amazon SNS 主题接收通知。 您可创建下列类型的预算： Savings Plans 使用率预算 - 定义使用率阈值，并在 Savings Plans 的使用率低于该阈值时接收提醒。这使您可以查看 Savings Plans 是否未使用或未充分利用。 Savings Plans 覆盖率预算 - 定义覆盖率阈值，并在 Savings Plans 覆盖的 Savings Plans 合格使用量低于该阈值时接收提醒。这使您可以查看 Savings Plans 所覆盖的实例使用量的多少。 这和题目中描述的 Saving Plans 覆盖率下降相符。 👨‍👨‍👦‍👦 社区讨论：My vote is for A : https://docs.aws.amazon.com/savingsplans/latest/userguide/sp-usingBudgets.html 四、Default Host Configuration ManagementA company has applications that run on Amazon EC2 instances. The EC2 instances connect to Amazon RDS databases by using an IAM role that has associated policies. The company wants to use AWS Systems Manager to patch the EC2 instances without disrupting the running applications.Which solution will meet these requirements? ❌ Create a new IAM role. Attach the AmazonSSMManagedInstanceCore policy to the new IAM role. Attach the new IAM role to the EC2 instances and the existing IAM role. Create an IAM user. Attach the AmazonSSMManagedInstanceCore policy to the IAM user. Configure Systems Manager to use the IAM user to manage the EC2 instances. ✅ Enable Default Host Configuration Management in Systems Manager to manage the EC2 instances. Remove the existing policies from the existing IAM role. Add the AmazonSSMManagedInstanceCore policy to the existing IAM role. ✨ 关键词： 1️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：使用默认主机管理配置自动管理 EC2 实例 通过“默认主机管理配置”设置，AWS Systems Manager 可以将 Amazon EC2 实例作为托管式实例自动管理。托管实例是一个配置为与 Systems Manager 一起使用的 EC2 实例。使用 Systems Manager 管理实例的好处包括以下几点： 可以使用 Session Manager 安全地连接到您的 EC2 实例。 可以使用 Patch Manager 执行自动补丁扫描。 可以使用 Systems Manager 清单查看有关您的实例的详细信息。 可以使用 Fleet Manager 追踪和管理实例。 可以自动保持 SSM Agent 处于最新状态。 “默认主机管理配置”使您无需手动创建 AWS Identity and Access Management（IAM）实例配置文件即可管理 EC2 实例。“默认主机管理配置”会创建并应用默认 IAM 角色，确保 Systems Manager 有权管理已激活该设置的 AWS 账户 和 AWS 区域 中的所有实例。 如果提供的权限不足以满足您的应用场景要求，您还可以向“默认主机管理配置”创建的默认 IAM 角色添加策略。或者，如果您不需要默认 IAM 角色提供的所有功能的权限，可以创建自己的自定义角色和策略。对您为“默认主机管理配置”选择的 IAM 角色所做的任何更改，都适用于相应区域和账户中的所有托管 Amazon EC2 实例。 👨‍👨‍👦‍👦 社区讨论：option C….Default Host Management Configuration createsand appliesa default IAM role to ensure thatSystems Manager has permissions to manage all instances in the Region and perform automated patch scans using Patch Manager. 五、AWS Direct Connect GatewayA company has an AWS Direct Connect connection from its corporate data center to its VPC in the us-east-1 Region. The company recently acquired a corporation that has several VPCs and a Direct Connect connection between its on-premises data center and the eu-west-2 Region. The CIDR blocks for the VPCs of the company and the corporation do not overlap. The company requires connectivity between two Regions and the data centers. The company needs a solution that is scalable while reducing operational overhead.What should a solutions architect do to meet these requirements? Set up inter-Region VPC peering between the VPC in us-east-1 and the VPCs in eu-west-2. Create private virtual interfaces from the Direct Connect connection in us-east-1 to the VPCs in eu-west-2. ❌ Establish VPN appliances in a fully meshed VPN network hosted by Amazon EC2. Use AWS VPN CloudHub to send and receive data between the data centers and each VPC. ✅ Connect the existing Direct Connect connection to a Direct Connect gateway. Route traffic from the virtual private gateways of the VPCs in each Region to the Direct Connect gateway. ✨ 关键词： 3️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：AWS Direct Connect 网关 使用 AWS Direct Connect 网关连接您的 VPC。将 AWS Direct Connect 网关与以下任一网关关联： 当您在同一区域有多个 VPC 时的中转网关 虚拟私有网关 您也可以使用虚拟私有网关来扩展本地区域。Direct Connect 网关是全球可用资源。您可以使用 Direct Connect 网关连接到全球任何区域。 你可以通过使用 AWS Direct Connect 连接到 AWS Direct Connect Gateway，之后再连接到其他 区域，因此 4️⃣ 正确。需要注意的是，AWS VPN CloudHub 是使用建立在公网上的 VPN 隧道，并连接 Amazon VPC 虚拟私有网关 和 客户网关 实现的：AWS VPN CloudHub 👨‍👨‍👦‍👦 社区讨论：”If you want to set up a Direct Connect to one or more VPC in many different regions (same account), you must use a Direct Connect Gateway.” 六、S3 Transfer AccelerationA company has a new mobile app. Anywhere in the world, users can see local news on topics they choose. Users also can post photos and videos from inside the app.Users access content often in the first minutes after the content is posted. New content quickly replaces older content, and then the older content disappears. The local nature of the news means that users consume 90% of the content within the AWS Region where it is uploaded.Which solution will optimize the user experience by providing the LOWEST latency for content uploads? Upload and store content in Amazon S3. Use Amazon CloudFront for the uploads. ✅ Upload and store content in Amazon S3. Use S3 Transfer Acceleration for the uploads. Upload content to Amazon EC2 instances in the Region that is closest to the user. Copy the data to Amazon S3. ❌ Upload and store content in Amazon S3 in the Region that is closest to the user. Use multiple distributions of Amazon CloudFront. ✨ 关键词： 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：使用 Amazon S3 Transfer Acceleration 配置快速、安全的文件传输 mazon S3 Transfer Acceleration 是一项存储桶级别功能，可在您的客户端和 S3 存储桶之间实现快速、轻松、安全的远距离文件传输。Transfer Acceleration 旨在优化从世界各地传入 S3 存储桶的传输速度。Transfer Acceleration 利用 Amazon CloudFront 中的全球分布式边缘站点。当数据到达某个边缘站点时，数据会被经过优化的网络路径路由至 Amazon S3。 Amazon S3 Transfer Acceleration 也使用到了 CloudFront 的边缘节点，因此和 4️⃣ 的效果差不多。我依然觉得 4️⃣ 的延迟会更低，毕竟将文件上传到就近的 S3 存储桶了，但是操作会更复杂，实际场景下我也会改用 2️⃣。 👨‍👨‍👦‍👦 社区讨论：Question says - “ LOWEST latency for content uploads”Hence Use S3 Transfer Acceleration for the uploads. 七、S3 Glacier Flexible RetrievalA media company stores movies in Amazon S3. Each movie is stored in a single video file that ranges from 1 GB to 10 GB in size.The company must be able to provide the streaming content of a movie within 5 minutes of a user purchase. There is higher demand for movies that are less than 20 years old than for movies that are more than 20 years old. The company wants to minimize hosting service costs based on demand.Which solution will meet these requirements? Store all media content in Amazon S3. Use S3 Lifecycle policies to move media data into the Infrequent Access tier when the demand for a movie decreases. ✅ Store newer movie video files in S3 Standard. Store older movie video files in S3 Standard-infrequent Access (S3 Standard-IA). When a user orders an older movie, retrieve the video file by using standard retrieval. ❌ Store newer movie video files in S3 Intelligent-Tiering. Store older movie video files in S3 Glacier Flexible Retrieval. When a user orders an older movie, retrieve the video file by using expedited retrieval. Store newer movie video files in S3 Standard. Store older movie video files in S3 Glacier Flexible Retrieval. When a user orders an older movie, retrieve the video file by using bulk retrieval. ✨ 关键词： 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：了解归档检索选项 加速 (Expedited) - 对于除最大归档对象（250MB+）之外的所有其他归档对象，使用加速检索访问的数据通常在 1 到 5 分钟内可用。 加速检索是一项高级特征，按加急请求和检索费率收费。 标准 (Standard) - 对于存储在 S3 Glacier Flexible Retrieval 存储类或 S3 Intelligent-Tiering 归档访问层中的对象，标准检索通常在 3-5 小时内完成。 对于存储在 S3 Glacier Deep Archive 存储类或 S3 Intelligent-Tiering 深度归档访问层中的对象，这些检索通常会在 12 小时内完成。 批量 (Bulk) - 使用 Amazon S3 Glacier 中成本最低的检索选项访问您的数据。通过批量检索，您能够以低廉的成本检索大量数据，甚至达到 PB 级。 对于存储在 S3 Glacier Flexible Retrieval 存储类或 S3 Intelligent-Tiering 存档访问层中的对象，批量检索通常在 5-12 小时内完成。 对于存储在 S3 Glacier Deep Archive 存储类或 S3 Intelligent-Tiering 深度存档访问层中的对象，这些检索通常会在 48 小时内完成。 存储类或层 加速 标准（带批量 Batch 操作） 标准（不带批量 Batch 操作） 批量 S3 Glacier Flexible Retrieval 或 S3 Intelligent-Tiering 归档访问 1 – 5 分钟 数分钟 – 5 小时 3 – 5 小时 5 – 12 小时 S3 Glacier Deep Archive 或 S3 Intelligent-Tiering 深度归档访问 不可用 9 - 12 小时 12 小时内 48 小时内 本题中的文件大小超过 1 GB，因此 3️⃣ 中即使使用加速检索，也无法确保能在 5 分钟内完成。4️⃣ 的批量检索耗时更长，肯定也不对。而 IA 和标准都支持毫秒级访问，因此 2️⃣ 是绝对正确且比 1️⃣ 更便宜的。 👨‍👨‍👦‍👦 社区讨论：Technically,expedited retrieval for files is not guaranteed within 1-5 minutes for files larger than 250 MB+. See:https://docs.aws.amazon.com/AmazonS3/latest/userguide/restoring-objects-retrieval-options.html 八、LDAPA company needs to use its on-premises LDAP directory service to authenticate its users to the AWS Management Console. The directory service is not compatible with Security Assertion Markup Language (SAML).Which solution meets these requirements? ❌ Enable AWS IAM Identity Center (AWS Single Sign-On) between AWS and the on-premises LDAP. Create an IAM policy that uses AWS credentials, and integrate the policy into LDAP. Set up a process that rotates the IAM credentials whenever LDAP credentials are updated. ✅ Develop an on-premises custom identity broker application or process that uses AWS Security Token Service (AWS STS) to get short-lived credentials. ✨ 关键词： 1️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：什么是轻量级目录访问协议（LDAP）身份验证？ LDAP 是微软的 Active Directory（AD）目录服务中使用的核心协议（但并非是其专用）；而 Active Directory 是一个大型目录服务数据库，包含网络中每一用户帐户的信息。更具体地说，LDAP 是目录访问协议（DAP）的轻量级版本，提供一个中央位置来访问和管理在传输控制协议/互联网协议（TCP/IP）上运行的目录服务，其最新版本是 LDAPv3。 题目中提到它于 SAML 并不兼容：为您的 AWS 资源启用 SAML 安全断言标记语言 2.0 (SAML) 是一种开放联合标准，允许身份提供商 (IdP) 对用户进行身份验证，并将有关用户的身份和安全信息传递给服务提供商 (SP)，通常是应用程序或服务。使用 SAML，您可以跨很多启用了 SAML 的应用程序和服务为您的用户启用单点登录体验。用户使用一组凭证通过 IdP 进行一次身份验证，然后无需额外登录即可访问多个应用程序和服务。 由于启用了 SAML 的应用程序将身份验证委托给 IdP，所以当管理员在 IdP 中添加、删除或修改用户信息时，SP 可以自动授予、撤销或更改用户对应用程序和服务的访问范围。AWS 提供不同的 SAML 解决方案来验证员工、承包商和合作伙伴（劳动力）的 AWS 账户和业务应用程序身份，并增加对面向客户的 Web 和移动应用程序的 SAML 支持。 因此这里不能选 1️⃣。 👨‍👨‍👦‍👦 社区讨论：The solution that best meets the requirements.Thisapproach providesa pathway for authenticating LDAP users to AWS without requiring direct LDAP to AWS IAM Identity Center integration orSAML compatibility, offering a flexible and secure method to extend on-premisesauthentication mechanisms to AWS services. 九、AWS Storage GatewayA pharmaceutical company is developing a new drug. The volume of data that the company generates has grown exponentially over the past few months. The company’s researchers regularly require a subset of the entire dataset to be immediately available with minimal lag. However, the entire dataset does not need to be accessed on a daily basis. All the data currently resides in on-premises storage arrays, and the company wants to reduce ongoing capital expenses.Which storage solution should a solutions architect recommend to meet these requirements? Run AWS DataSyncas a scheduled cron job to migrate the data to an Amazon S3 bucket on an ongoing basis. ❌ Deploy an AWS Storage Gateway file gateway with an Amazon S3 bucket as the target storage. Migrate the data to the Storage Gateway appliance. ✅ Deploy an AWS Storage Gateway volume gateway with cached volumes with an Amazon S3 bucket as the target storage. Migrate the data to the Storage Gateway appliance. Configure an AWS Site-to-Site VPN connection from the on-premises environment to AWS. Migrate data to an Amazon ElasticFile System (Amazon EFS) file system. ✨ 关键词： 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：file gateway 和 volume gateway (cached mode) 都支持对频繁访问的文件进行本地缓存： 但是题目中提到了 storage arrays 存储整列，这种情况下 3️⃣ 的卷网关更符合。 👨‍👨‍👦‍👦 社区讨论：Deploying an AWS Storage Gateway file gateway with an Amazon S3 bucket as the target storage would require the entire dataset to be stored in Amazon S3, which might not be cost-effective considering that onlya subset of the data needs to be accessed regularly. Additionally,accessing data directly from S3 might introduce latency. so correct option is C bcz AWS Storage Gateway volume gateway with cached volumesallows the company to keep frequentlyaccessed data locally on-premises while storing the entire dataset in Amazon S3.This solution provides immediate access to the subset of data with minimal lag,as frequentlyaccessed data is cached locally. It also reduces ongoing capital expensesas it leverages Amazon S3 storage, which is cost-effective. 十、AWS ConfigA solutions architect must provide an automated solution for a company’s compliance policy that states security groups cannot include a rule that allows SSH from 0.0.0.0/0. The company needs to be notified if there is any breach in the policy. A solution is needed as soon as possible.What should the solutions architect do to meet these requirements with the LEAST operational overhead? Write an AWS Lambda script that monitors security groups for SSH being open to 0.0.0.0/0 addresses and creates a notification every time it finds one. ✅ Enable the restricted-ssh AWS Config managed rule and generate an Amazon Simple Notification Service (Amazon SNS) notification when a noncompliant rule is created. Create an IAM role with permissions to globally open security groups and network ACLs. Create an Amazon Simple Notification Service (Amazon SNS) topic to generate a notification every time the role is assumed by a user. ❌ Configure a service control policy (SCP) that prevents non-administrative users from creating or editing security groups. Create a notification in the ticketing system when a user requests a rule that needs administrator permissions. ✨ 关键词： 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：AWS Config 中有专门针对 SSH 来源的规则：restricted-ssh 检查安全组的传入SSH流量是否可访问。规则是安全组中传入SSH流量的 IP 地址COMPLIANT是否受到限制（0.0.0.0/0 或:: /0 CIDR 除外）。否则，NON_ COMPLIANT。 标识符：INCOMING_ SSH _ DISABLED 资源类型： AWS::EC2::SecurityGroup 触发器类型：配置更改和定期 AWS 区域: 全部支持 AWS 区域 参数：无 之后一些细节的配置限制可以都考虑选择 AWS Config 进行实现。 👨‍👨‍👦‍👦 社区讨论：Option B 十一、VPC Lattice service networkUse Amazon Elastic Kubernetes Service (Amazon EKS) with Amazon EC2 worker nodes.A company has deployed an application in an AWS account. The application consists of microservices that run on AWS Lambda and Amazon Elastic Kubernetes Service (Amazon EKS). A separate team supports each microservice. The company has multiple AWS accounts and wants to give each team its own account for its microservices.A solutions architect needs to design a solution that will provide service-to-service communication over HTTPS (port 443). The solution also must provide a service registry for service discovery.Which solution will meet these requirements with the LEAST administrative overhead? Create an inspection VPC. Deploy an AWS Network Firewall firewall to the inspection VPC. Attach the inspection VPC to a new transit gateway. Route VPC-to-VPC traffic to the inspection VPC. Apply firewall rules to allow only HTTPS communication. ✅ Create a VPC Lattice service network. Associate the microservices with the service network. Define HTTPS listeners for each service. Register microservice compute resources as targets. Identify VPCs that need to communicate with the services. Associate those VPCs with the service network. Create a Network Load Balancer (NLB) with an HTTPS listener and target groups for each microservice. Create an AWS PrivateLink endpoint service for each microservice. Create an interface VPC endpoint in each VPC that needs to consume that microservice. Create peering connections between VPCs that contain microservices. Create a prefix list for each service that requires a connection to a client. Create route tables to route traffic to the appropriate VPC. Create security groups to allow only HTTPS communication. ✨ 关键词： 2️⃣ ✅ 💡 解析：什么是 Amazon VPC Lattice？ Amazon VPC Lattice 是一项完全托管的应用程序网络服务，用于连接、保护和监控应用程序的服务。您可以将 VPC Lattice 与单个虚拟私有云（VPC）一起使用，也可以从一个或多个账户跨多个 VPC 使用。现代应用程序可以由多个小型模块化服务组成，这些服务通常称为微服务。现代化固然有其优势，但在连接这些微服务时，也可能带来网络复杂性和挑战。例如，如果开发人员分布在不同的团队，他们可能会在多个账户或 VPC 上构建和部署微服务。 👨‍👨‍👦‍👦 社区讨论：VPC Lattice is a completely new way to simplify API communication between services or microservices in one or more AWS accounts. 十二、Amazon ElastiCache for RedisA company has a mobile game that reads most of its metadata from an Amazon RDS DB instance. As the game increased in popularity, developers noticed slowdowns related to the game’s metadata load times. Performance metrics indicate that simply scaling the database will not help. A solutions architect must explore all options that include capabilities for snapshots, replication, and sub-millisecond response times.What should the solutions architect recommend to solve these issues? Migrate the database to Amazon Aurora with Aurora Replicas. Migrate the database to Amazon DynamoDB with global tables. ✅ Add an Amazon ElastiCache for Redis layer in front of the database. ❌ Add an Amazon ElastiCache for Memcached layer in front of the database. ✨ 关键词： 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：Redis 和 Memcached 都支持亚毫秒级延迟，但是只有 Redis 支持快照和复制功能：比较 Redis OSS 与 Memcached 特点 Memcached Redis 亚毫秒级延迟 是 是 开发人员易用性 是 是 数据分区 是 是 支持多种编程语言 是 是 高级数据结构 - 是 多线程架构 是 - 快照 - 是 复制 - 是 事务处理 - 是 发布/订阅 - 是 Lua 脚本编写 - 是 地理空间支持 - 是 👨‍👨‍👦‍👦 社区讨论：Option C is better as we need replication and snapshots 十三、Amazon Quantum Ledger DatabaseA company maintains its accounting records in a custom application that runs on Amazon EC2 instances. The company needs to migrate the data to an AWS managed service for development and maintenance of the application data. The solution must require minimal operational support and provide immutable, cryptographically verifiable logs of data changes.Which solution will meet these requirements MOST cost-effectively? Copy the records from the application into an Amazon Redshift cluster. Copy the records from the application into an Amazon Neptune cluster. Copy the records from the application into an Amazon Timestream database. ✅ Copy the records from the application into an Amazon Quantum Ledger Database (Amazon QLDB) ledger. ✨ 关键词： 4️⃣ ✅ 💡 解析：什么是 Amazon QLDB？ Amazon Quantum Ledger 数据库 (AmazonQLDB) 是一个完全托管的账本数据库，它提供由中央可信机构拥有的透明、不可变且可加密验证的交易日志。您可以使用 Amazon QLDB 来跟踪所有应用程序数据更改，并维护一段时间内完整且可验证的更改历史记录。 什么是 Amazon Neptune？ Amazon Neptune 是一项快速、可靠且完全托管式的图数据库服务，可帮助您轻松构建和运行适用于高度互连数据集的应用程序。Neptune 的核心是一个专门打造的高性能图形数据库引擎。该引擎经过优化，可存储数十亿个关系并能以毫秒级延迟进行图形查询。Neptune 支持流行的属性图查询语言 Apache TinkerPop Gremlin 和 Neo4j，以及 W3C 的openCypher查询语言。RDF SPARQL这可让您构建能够高效地浏览高度互联的数据集的查询。Neptune 支持图形用例，如建议引擎、欺诈检测、知识图谱、药物开发和网络安全。 Amazon Timestream 易于管理的时间序列数据库，针对安全性、性能、可用性和可扩展性进行了优化 Amazon Timestream 为从低延迟查询到大规模数据摄取的工作负载提供完全托管、专门构建的时间序列数据库引擎。借助 Timestream for LiveAnalytics，您可以每分钟摄取数十 GB 以上的时间序列数据，并在几秒钟内对数 TB 的时间序列数据运行 SQL 查询，可用性最高达 99.99%。 👨‍👨‍👦‍👦 社区讨论：Option D 十四、Amazon AthenaA company has stored 10 TB of log files in Apache Parquet format in an Amazon S3 bucket. The company occasionally needs to use SQL to analyze the log files.Which solution will meet these requirements MOST cost-effectively? Create an Amazon Aurora MySQL database. Migrate the data from the S3 bucket into Aurora by using AWS Database Migration Service (AWS DMS). Issue SQL statements to the Aurora database. ❌ Create an Amazon Redshift cluster. Use Redshift Spectrum to run SQL statements directly on the data in the S3 bucket. ✅ Create an AWS Glue crawler to store and retrieve table metadata from the S3 bucket. Use Amazon Athena to run SQL statements directly on the data in the S3 bucket. Create an Amazon EMR cluster. Use Apache Spark SQL to run SQL statements directly on the data in the S3 bucket. ✨ 关键词： 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：Redshift Spectrum 介绍 Redshift Spectrum可以帮助客户通过Redshift直接查询S3中的数据。如同Amazon EMR，通过Redshift Spectrum客户可以方便的使用多种开放数据格式并享有低廉的存储成本，同时还可以轻松扩展到上千个计算节点实现数据的提取、筛选、投影、聚合、group、排序等等操作。Redshift Spectrum采用了无服务器架构，所以客户不需要额外配置或管理任何资源，而只需为Redshift Spectrum的用量付费。 需要注意的是，Athena SQL 可以和 AWS Glue Data Catalog 等进行配合：使用 Athena SQL 您可以使用 Athena SQL，借助 AWS Glue Data Catalog（外部 Hive 元存储）或者通过各种预构建连接器对其他数据来源进行联合查询，从而在 Amazon S3 中就地查询数据。 这就是 3️⃣ 中 Glue 在做的事情。而相关的 Apache Spark：在 Amazon Athena 中使用 Apache Spark Amazon Athena 让您可以轻松使用 Apache Spark 以交互方式运行数据分析和探索，无需规划、配置或管理资源。在 Athena 上运行 Apache Spark 应用程序意味着，无需额外配置即可提交 Spark 代码进行处理和直接接收结果。您可以使用 Amazon Athena 控制台中简化的笔记本体验，以通过 Python 或 Athena notebook API 开发 Apache Spark 应用程序。Amazon Athena 上的 Apache Spark 无服务器，可通过提供即时计算实现自动按需扩展，从而满足不断变化的数据卷和处理要求。 👨‍👨‍👦‍👦 社区讨论：S3 + SQL = Athena 十五、Cross Account LambdaA company needs to create an AWS Lambda function that will run in a VPC in the company’s primary AWS account. The Lambda function needs to access files that the company stores in an Amazon Elastic File System (Amazon EFS) file system. The EFS file system is located in a secondary AWS account. As the company adds files to the file system, the solution must scale to meet the demand.Which solution will meet these requirements MOST cost-effectively? Create a new EFS file system in the primary account. Use AWS DataSync to copy the contents of the original EFS file system to the new EFS file system. ✅ Create a VPC peering connection between the VPCs that are in the primary account and the secondary account. Create a second Lambda function in the secondary account that has a mount that is configured for the file system. Use the primary account’s Lambda function to invoke the secondary account’s Lambda function. ❌ Move the contents of the file system to a Lambda layer. Configure the Lambda layer’s permissions to allow the company’s secondary account to use the Lambda layer. ✨ 关键词： 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：从其他EFS服务器挂载文件系统 AWS 账户 或 VPC 您可以使用挂载帮助程序使用NFS客户端和EFS接入点的IAM授权来EFS挂载您的 Amazon EFS 文件系统。默认情况下，EFS挂载助手使用域名服务 (DNS) 来解析您的EFS挂载目标的 IP 地址。如果要从其他账户或虚拟私有云 (VPC) 挂载文件系统，则需要手动解析EFS挂载目标。 接下来，您可以找到有关确定用于NFS客户端的正确EFS挂载目标 IP 地址的说明。您还可以找到有关将客户机配置为使用该 IP 地址挂载EFS文件系统的说明。 可以提供 EFS 服务给其他 AWS 账号使用，因此这个问题从 Lambda 如何访问其他账号中的 EFS 变为了如何跨 VPC 访问。 顺便看下 Lambda Layer：使用层管理 Lambda 依赖项 Lambda 层是包含补充代码或数据的 .zip 文件存档。层通常包含库依赖项、自定义运行时系统或配置文件。您可能会基于很多原因考虑使用层： 减小部署包的大小。与其将所有函数依赖项和函数代码都包含在部署包中，不如将其放在一个层中。这样可以减小部署包的大小并对其进行组织。 分离核心函数逻辑与依赖项。借助层，您无需使用函数代码即可更新函数依赖项，反之亦然。这有助于将二者分离，并帮助您专注于函数逻辑。 在多个函数之间共享依赖项。创建层后，您可以将其应用到账户中任意数量的函数。如果没有层，则需要在每个单独的部署包中包含相同的依赖项。 使用 Lambda 控制台代码编辑器。代码编辑器是快速测试次要功能代码更新的得力工具。但是，如果部署包过大，则无法使用编辑器。使用层可以减小部署包的大小，并解锁代码编辑器的用法。 👨‍👨‍👦‍👦 社区讨论：B -&gt; VPC peering allows the Lambda access secondary account securely and efficientlyA -&gt; redundancyC -&gt; additional complexityD -&gt; sharing code libraries You can configure a function to mount an Amazon EFS file system in another AWS account. Before you mount the file system, you must ensure the following:VPC peering must be configured, and appropriate routes must be added to the route tables in each VPC.","link":"/2024/12/11/saa_test_daily_20241211/"},{"title":"SAA 考试每日练习 - 2024&#x2F;12&#x2F;01","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam30 题 (No.191 ~ No.220) 只记录了 10 道首次碰到的、错误的或有疑问的题目，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： comprehendv. 理解；领悟；懂 transcribev. 记录，抄录，把…转成（另一种书写形式），用音标标音 一、Medical informationA hospital wants to create digital copies for its large collection of historical written records. The hospital will continue to add hundreds of new documents each day. The hospital’s data team will scan the documents and will upload the documents to the AWS Cloud.A solutions architect must implement a solution to analyze the documents, extract the medical information, and store the documents so that an application can run SQL queries on the data. The solution must maximize scalability and operational efficiency.Which combination of steps should the solutions architect take to meet these requirements? (Choose two.) Write the document information to an Amazon EC2 instance that runs a MySQL database. ✅ Write the document information to an Amazon S3 bucket. Use Amazon Athena to query the data. Create an Auto Scaling group of Amazon EC2 instances to run a custom application that processes the scanned files and extracts the medical information. Create an AWS Lambda function that runs when new documents are uploaded. Use Amazon Rekognition to convert the documents to raw text. Use Amazon Transcribe Medical to detect and extract relevant medical information from the text. ✅ Create an AWS Lambda function that runs when new documents are uploaded. Use Amazon Textract to convert the documents to raw text. Use Amazon Comprehend Medical to detect and extract relevant medical information from the text. ✨ 关键词：documents、SQL queries、medical information 2️⃣ 5️⃣ ✅ 💡 解析：现有大量文档，之后每天还有几百和文件。要能使用 SQL 查询文档数据并提取医学数据。过下涉及到的 AI 工具： Amazon Rekognition - 图像、视频识别 Amazon Transcribe Medical - 医疗语音转文本 Amazon Textract - 文档文本检测和分析、信息提取 Amazon Comprehend Medical - 医疗文本分析和信息提取 什么是 Amazon Rekognition？ Amazon Rekognition 是一项基于云的图像和视频分析服务，可以轻松地向应用程序添加高级计算机视觉功能。该服务由久经考验的深度学习技术提供支持，无需任何机器学习专业知识即可使用。Amazon Rekognition 包含一个 easy-to-use 简单的 API，可以快速分析存储在 Amazon S3 中的任何图像或视频文件。 Amazon Transcribe Medical Amazon Transcribe Medical 是一种自动语音识别 (ASR) 服务，让您能够轻松地为具有语音功能的应用程序添加医疗语音转文本功能。医疗保健提供者和患者之间的对话为患者的诊断和治疗计划以及临床文档工作流程提供了基础。确保这些信息准确无误是至关重要的。然而，准确的医疗转录（如口授记录器和抄写员）价格昂贵、耗时长，而且会破坏患者的体验。某些组织使用现有的医疗转录软件，但发现它们的效率和质量都很低。 什么是 Amazon Textract？ Amazon Textract 让您可以向应用程序轻松添加文档文本检测和分析功能。以下是使用 Amazon Textract 的常见使用案例： 创建智能搜索索引 使用智能文本提取功能进行自然语言处理 (NLP) 加快来自不同来源的数据的捕获和标准化 自动从表单中捕获数据 什么是 Amazon Comprehend Medical？ Amazon Comprehend Medical 可以检测并返回非结构化临床文本中的有用信息，例如医生记录、出院摘要、检验结果、病例记录等。Amazon Comprehend Medical 使用自然语言处理 (NLP) 模型来检测实体，这些实体是对医疗信息 [例如医学状况、药物或受保护的健康信息 (PHI)] 的文本引用。有关检测到的实体的完整列表，请参阅 检测实体（版本 2）。Amazon Comprehend Medical 还允许用户通过本体链接操作将这些检测到的实体与标准化医学知识库（ RxNorm 例如 ICD-10-CM）关联起来。 👨‍👨‍👦‍👦 社区讨论：B and E are correct.Textract to extract text from files. Rekognition can also be used for text detection but after Rekognition - it’s mentioned that Transcribe is used.Transcribe is used forSpeech to Text.So that option D may not be valid. 二、DynamoDB keep data for 30 daysA company runs an application on a large fleet of Amazon EC2 instances. The application reads and writes entries into an Amazon DynamoDB table. The size of the DynamoDB table continuously grows, but the application needs only data from the last 30 days. The company needs a solution that minimizes cost and development effort.Which solution meets these requirements? ❌ Use an AWS CloudFormation template to deploy the complete solution. Redeploy the CloudFormation stack every 30 days, and delete the original stack. Use an EC2 instance that runs a monitoring application from AWS Marketplace. Configure the monitoring application to use Amazon DynamoDB Streams to store the timestamp when a new item is created in the table. Use a script that runs on the EC2 instance to delete items that have a timestamp that is older than 30 days. Configure Amazon DynamoDB Streams to invoke an AWS Lambda function when a new item is created in the table. Configure the Lambda function to delete items in the table that are older than 30 days. ✅ Extend the application to add an attribute that has a value of the current timestamp plus 30 days to each new item that is created in the table. Configure DynamoDB to use the attribute as the TTL attribute. ✨ 关键词：DynamoDB、needs only data from the last 30 days 1️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：DynamoDB 删除 30 天以上的数据。忘记 AWS CloudFormation 是什么了：什么是 AWS CloudFormation？ AWS CloudFormation 是一项服务，可帮助您对 AWS 资源进行建模和设置，以便能花较少的时间管理这些资源，而将更多的时间花在运行于 AWS 中的应用程序上。您创建一个描述您所需的所有 AWS 资源（如 Amazon EC2 实例或 Amazon RDS 数据库实例）的模板，并且 CloudFormation 将负责为您预置和配置这些资源。您无需单独创建和配置 AWS 资源并了解 what; CloudFormation 句柄处理该工作时所依赖的内容。以下方案演示 CloudFormation 如何提供帮助。 它其实就是和 Terraform 一样的 IaC（基础设施即代码）工具，因此这里肯定不选 1️⃣。3️⃣ 其实是我自己项目里的解决方案，新的数据来的时候做一次旧数据的删除。但是存在问题一直不来新数据怎么办。4️⃣ 虽然要改到代码，但是如果 DynamoDB 本身不支持对数据插入时间的判断的话，已经是最优解了。 来看下 DynamoDB TTL 是什么：Using time to live (TTL) in DynamoDB DynamoDB 的 “有效时间”（TTL）是删除不再相关的项目的一种经济有效的方法。TTL 允许你定义每个项目的过期时间戳，以指示何时不再需要项目。DynamoDB 会在过期后几天内自动删除过期项目，而不会消耗写吞吐量。 要使用 TTL，首先要在表上启用它，然后定义一个特定属性来存储 TTL 过期时间戳。时间戳必须以 Unix 时间格式存储，粒度为秒。每次创建或更新项目时，都可以计算过期时间并将其保存在 TTL 属性中。 显然它就是本题的考点。 👨‍👨‍👦‍👦 社区讨论：changing myanswer to D after researching a bit.The DynamoDB TTL feature allows you to define a per-item timestamp to determine when an item is no longer needed.Shortly after the date and time of the specified timestamp, DynamoDB deletes the item from your table without consuming any write throughput. 三、Amazon TranscribeA telemarketing company is designing its customer call center functionality on AWS. The company needs a solution that provides multiple speaker recognition and generates transcript files. The company wants to query the transcript files to analyze the business patterns. The transcript files must be stored for 7 years for auditing purposes.Which solution will meet these requirements? Use Amazon Rekognition for multiple speaker recognition. Store the transcript files in Amazon S3. Use machine learning models for transcript file analysis. ✅ Use Amazon Transcribe for multiple speaker recognition. Use Amazon Athena for transcript file analysis. Use Amazon Translate for multiple speaker recognition. Store the transcript files in Amazon Redshift. Use SQL queries for transcript file analysis. Use Amazon Rekognition for multiple speaker recognition. Store the transcript files in Amazon S3. Use Amazon Textract for transcript file analysis. ✨ 关键词：generates transcript files from voice、file analysis 2️⃣ ✅ 💡 解析：需要语音转文字，并将文本保存和分析。Amazon Rekognition 是语音和图像识别工具，处理类似与打标签或是判断是否存在物体的工作。题目中涉及到的 AI 服务： Amazon Transcribe - 语音转文本 Amazon Translate - 结合机器学习的翻译服务 Amazon Textract - 文档文本检测和分析、信息提取 什么是 Amazon Transcribe？ Amazon Transcribe是一种自动语音识别服务，它使用机器学习模型将音频转换为文本。您可以用Amazon Transcribe作独立的转录服务，也可以向任何应用程序添加speech-to-text功能。 什么是 Amazon Translate？ Amazon Translate 是一种文本翻译服务，它使用先进的机器学习技术，按需提供高质量的翻译。您可以使用 Amazon Translate 来翻译非结构化文本文档或构建使用多种语言的应用程序。 👨‍👨‍👦‍👦 社区讨论：The correct answer is B: Use Amazon Transcribe for multiple speaker recognition. Use Amazon Athena for transcript file analysis.Amazon Transcribe isa service that automatically transcribes spoken language into written text. It can handle multiple speakers and can generate transcript files in real-time or asynchronously.These transcript files can be stored in Amazon S3 for long-term storage.Amazon Athena isa query service that allows you to analyze data stored in Amazon S3 using SQL. You can use it to analyze the transcript filesand identify patterns in the data. Option A is incorrect because Amazon Rekognition isa service for analyzing imagesand videos, not transcribing spoken language.Option C is incorrect because Amazon Translate isa service for translating text from one language to another, not transcribing spoken language.Option D is incorrect because Amazon Textract isa service forextracting text and data from documentsand images, not transcribing spoken language. 四、Amazon Cognito and API accessA company hosts its application on AWS. The company uses Amazon Cognito to manage users. When users log in to the application, the application fetches required data from Amazon DynamoDB by using a REST API that is hosted in Amazon API Gateway. The company wants an AWS managed solution that will control access to the REST API to reduce development efforts.Which solution will meet these requirements with the LEAST operational overhead? Configure an AWS Lambda function to be an authorizer in API Gateway to validate which user made the request. For each user, create and assign an API key that must be sent with each request. Validate the key by using an AWS Lambda function. Send the user’s email address in the header with every request. Invoke an AWS Lambda function to validate that the user with that email address has proper access. ✅ Configure an Amazon Cognito user pool authorizer in API Gateway to allow Amazon Cognito to validate each request. ✨ 关键词：Amazon Cognito、control access to the REST API 4️⃣ ✅ 💡 解析：使用 Amazon Cognito 管理用户，用户登录应用后可以通过 Amazon API Gateway 提供的 API 获取 DynamoDB 的数据。现在希望使用 AWS 的服务来解决 API 权限问题。使用 Amazon Cognito 用户池 (user pool) 控制用户对 REST API 的访问是官方的解决方案。大概分为 3 步： 在 Amazon Cognito 控制台创建用户池 在 API Gateway 控制台选定用户池创建 API Gateway Authorizer（授权方） 在 API Gateway 控制台对指定的 API 启动授权方 什么是 Amazon Cognito？ Amazon Cognito 是 Web 和移动应用程序的身份平台。它是一个用户目录、一个身份验证服务器以及一个用于 OAuth 2.0 访问令牌和 AWS 凭据的授权服务。使用 Amazon Cognito，您可以对内置用户目录、企业目录以及 Google 和 Facebook 等使用者身份提供者中的用户进行身份验证和授权。 使用 Amazon Cognito 用户池作为授权方控制对 REST API 的访问 作为使用 IAM 角色和策略或 Lambda 授权方（以前称为自定义授权方）的替代方案，您可以使用 Amazon Cognito 用户池来控制谁可以在 Amazon API Gateway 中访问您的 API。 要将 Amazon Cognito 用户池与您的 API 一起使用，您必须先创建 COGNITO_USER_POOLS 类型的授权方，然后配置 API 方法以使用该授权方。部署 API 之后，客户端必须先将用户注册到用户池，获取用户的身份令牌或访问令牌，然后使用令牌之一调用 API 方法，这通常设置为请求的 Authorization 标头。只有提供了所需的令牌并且提供的令牌有效时，API 调用才会成功，否则，客户端未获得授权来执行调用，因为客户端没有可用于授权的凭证。 使用身份令牌，基于已登录用户的身份声明来授权 API 调用。使用访问令牌，基于指定访问受保护资源的自定义范围授权 API 调用。 要为 API 创建和配置 Amazon Cognito 用户池，请执行以下任务： 使用 Amazon Cognito 控制台、CLI/开发工具包或 API 创建用户池，或者使用由其他 AWS 账户拥有的用户池。 使用 API Gateway 控制台、CLI/开发工具包或 API 创建具有选定用户池的 API Gateway Authorizer。 使用 API Gateway 控制台、CLI/开发工具包或 API，在所选 API 方法上启用授权方。 👨‍👨‍👦‍👦 社区讨论：KEYWORD: LEAST operational overheadTo control access to the REST API and reduce development efforts, the company can use an Amazon Cognito user pool authorizer in API Gateway.This will allow Amazon Cognito to validate each request and ensure that onlyauthenticated users can access the API.This solution has the LEAST operational overhead,as it does not require the company to develop and maintain anyadditional infrastructure or code.Therefore, Option D is the correct answer.Option D. Configure an Amazon Cognito user pool authorizer in API Gateway to allow Amazon Cognito to validate each request. 五、SMS messagesA company is developing a marketing communications service that targets mobile app users. The company needs to send confirmation messages with Short Message Service (SMS) to its users. The users must be able to reply to the SMS messages.The company must store the responses for a year for analysis.What should a solutions architect do to meet these requirements? ❌ Create an Amazon Connect contact flow to send the SMS messages. Use AWS Lambda to process the responses. ✅ Build an Amazon Pinpoint journey. Configure Amazon Pinpoint to send events to an Amazon Kinesis data stream for analysis and archiving. Use Amazon Simple Queue Service (Amazon SQS) to distribute the SMS messages. Use AWS Lambda to process the responses. Create an Amazon Simple Notification Service (Amazon SNS) FIFO topic. Subscribe an Amazon Kinesis data stream to the SNS topic for analysis and archiving. ✨ 关键词：send SMS and get the reply 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：公司需要发送短信并受到回复，回复需要保存一年用作分析。 什么是 Amazon Pinpoint？ 您可以使用 Amazon Pinpoint 通过多个消息渠道与客户互动。 AWS 服务 您可以使用 Amazon Pinpoint 通过自定义渠道发送推送通知、应用程序内通知、电子邮件、文本消息、语音消息等。它包括客户细分、活动和旅程功能，可帮助您在正确的时间通过正确的渠道向正确的客户发送正确的信息。 显然使用 Amazon Pinpoint 可以实现发送 SMS 这个需求，那么接收响应呢？需要使用到 two-way SMS：在 “AWS 最终用户SMS消息” 中为电话号码设置双向消息 SMS AWS 最终用户消息SMS包括对双向的支持SMS。设置双向时SMS，您可以接收来自客户的传入消息。您还可以将双向消息与 Lambda 和 Amazon Lex 等其他 AWS 服务消息一起使用，以创建交互式短信体验。 当您的一位客户向您的电话号码发送消息时，消息正文将发送到亚马逊SNS主题或 Amazon Connect 实例进行处理。 而关于数据存储一年的需求，Amazon Kinesis Data Stream 足以做到了：更改数据留存期 Amazon Kinesis Data Streams 支持更改数据流的数据记录保留期。Kinesis 数据流是数据记录的有序序列，可用于执行实时写入和读取。因此，数据记录临时存储在您的流的分片中。从添加记录开始，到记录不再可供访问为止的时间段称为保留期。默认情况下，Kinesis 数据流的记录存储时间从 24 小时到 8760 小时（365 天）不等。 👨‍👨‍👦‍👦 社区讨论：By using Pinpoint, the company can effectively send SMS messages to its mobile app users. Additionally, Pinpoint allows the configuration of journeys, which enable the tracking and management of user interactions.The events generated during the journey, including user responses to SMS, can be captured and sent to an Kinesis data stream.This data stream can then be used for analysisand archiving purposes. A. Creating an Amazon Connect contact flow is primarily focused on customer support and engagement,and it lacks the capability to store and processSMS responses for analysis.C. Using SQS isa message queuing service and is not specifically designed for handling SMS responses or capturing them for analysis.D. Creating an SNS FIFO topic and subscribing a Kinesis data stream is not the most appropriate solution for capturing and storing SMS responses,asSNS is primarily used for message publishing and distribution. In summary, option B is the best choice as it leverages Pinpoint to send SMS messagesand captures user responses for analysis and archiving using an Kinesis data stream. 六、Data Lake and fine-grained permissionsAn online retail company has more than 50 million active customers and receives more than 25,000 orders each day. The company collects purchase data for customers and stores this data in Amazon S3. Additional customer data is stored in Amazon RDS.The company wants to make all the data available to various teams so that the teams can perform analytics. The solution must provide the ability to manage fine-grained permissions for the data and must minimize operational overhead.Which solution will meet these requirements? Migrate the purchase data to write directly to Amazon RDS. Use RDS access controls to limit access. Schedule an AWS Lambda function to periodically copy data from Amazon RDS to Amazon S3. Create an AWS Glue crawler. Use Amazon Athena to query the data. Use S3 policies to limit access. ✅ Create a data lake by using AWS Lake Formation. Create an AWS Glue JDBC connection to Amazon RDS. Register the S3 bucket in Lake Formation. Use Lake Formation access controls to limit access. Create an Amazon Redshift cluster. Schedule an AWS Lambda function to periodically copy data from Amazon S3 and Amazon RDS to Amazon Redshift. Use Amazon Redshift access controls to limit access. ✨ 关键词：get data from S3 and RDS、fine-grained permissions 3️⃣ ✅ 💡 解析：需要汇总 S3 和 RDS 中的数据并提供精细的权限控制。显然需要使用到数据湖或者数据仓库。看下 AWS Lake Formation：什么是 AWS Lake Formation？ AWS Lake Formation 帮助您集中管理、保护和全球共享用于分析和机器学习的数据。您可以对 Amazon Simple Storage Service (Amazon S3) 上的数据湖数据及其在 AWS Glue Data Catalog中的元数据进行精细访问控制。 显然完美符合题目需求。再看下同为数据仓库的 Redshift：什么是 Amazon Redshift Amazon Redshift 是云中一种完全托管的 PB 级数据仓库服务。Amazon Redshift Serverless 让您可以访问和分析数据，而无需对预置数据仓库执行任何配置操作。 数据库安全 您可以通过控制哪些用户可以访问哪些数据库对象来管理数据库安全。可以为用户分配角色或组，授予给用户、角色或组的权限决定了他们可以访问哪些数据库对象。 4️⃣ 看上去也能完成任务，但是操作比 3️⃣ 更复杂。 👨‍👨‍👦‍👦 社区讨论：Answer : C keyword “manage-fine-grained”https://aws.amazon.com/blogs/big-data/manage-fine-grained-access-control-using-aws-lake-formation/ Lake Formation enables the creation of a secure and scalable data lake on AWS,allowing centralized access controls for both S3 and RDS data. By using Lake Formation, the company can manage permissionseffectivelyand integrate RDS data through the AWS Glue JDBC connection. Registering the S3 in Lake Formation ensures unified access control.This solution reduces operational overhead while providing fine-grained permissions management.A. Directly writing purchase data to Amazon RDS with RDS access controls lacks comprehensive permissions management for both S3 and RDS data.B. Periodically copying data from RDS to S3 using Lambda and using AWS Glue and Athena for querying does not offer fine\u0002grained permissions management and introduces data synchronization complexities.D. Creating an Redshift cluster and copying data from S3 and RDS to Redshift adds complexityand operational overhead without the flexibility of Lake Formation’s permissions management capabilities. 七、EC2 connect to S3A company needs to move data from an Amazon EC2 instance to an Amazon S3 bucket. The company must ensure that no API calls and no data are routed through public internet routes. Only the EC2 instance can have access to upload data to the S3 bucket.Which solution will meet these requirements? ✅ Create an interface VPC endpoint for Amazon S3 in the subnet where the EC2 instance is located. Attach a resource policy to the S3 bucket to only allow the EC2 instance’s IAM role for access. ❌ Create a gateway VPC endpoint for Amazon S3 in the Availability Zone where the EC2 instance is located. Attach appropriate security groups to the endpoint. Attach a resource policy to the S3 bucket to only allow the EC2 instance’s IAM role for access. Run the nslookup tool from inside the EC2 instance to obtain the private IP address of the S3 bucket’s service API endpoint. Create a route in the VPC route table to provide the EC2 instance with access to the S3 bucket. Attach a resource policy to the S3 bucket to only allow the EC2 instance’s IAM role for access. Use the AWS provided, publicly available ip-ranges.json file to obtain the private IP address of the S3 bucket’s service API endpoint. Create a route in the VPC route table to provide the EC2 instance with access to the S3 bucket. Attach a resource policy to the S3 bucket to only allow the EC2 instance’s IAM role for access. ✨ 关键词：move data from an Amazon EC2 instance to an Amazon S3 bucket、no data are routed through public internet 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：EC2 的数据要走私网传输到 S3 存储桶中。社区在 1️⃣ 和 2️⃣ 争议较大。争议的重点在于 2️⃣ 的 “Attach appropriate security groups to the endpoint” 这句，将适当的安全组附加到终端节点上。如果它可以实现，那么 2️⃣ 显然是最优选择，但如果它无法实现，那就只能选 1️⃣。使用接口 VPC 端点访问 AWS 服务 前提条件为端点网络接口 (endpoint network interface) 创建一个安全组，允许来自 VPC 资源的预期流量。例如，为确保 AWS CLI 可以向 AWS 服务 发送 HTTPS 请求，安全组必须允许入站 HTTPS 流量。 首先我们明确 interface VPC endpoint 是可以配置安全组的。实测了下也确实： 那么网关端点呢？很遗憾的是 AWS 的文档里并没有明说，实践看下吧：创建过程中和创建完成后都没有安全组相关配置，因此得出结论 Gateway endpoint 不支持安全组配置，选 1️⃣。 👨‍👨‍👦‍👦 社区讨论：I thinkanswer should be A and not B.as we cannot “Attach a security groups to a gatewayendpoint.” 八、Files convertA company’s reporting system delivers hundreds of .csv files to an Amazon S3 bucket each day. The company must convert these files to Apache Parquet format and must store the files in a transformed data bucket.Which solution will meet these requirements with the LEAST development effort? Create an Amazon EMR cluster with Apache Spark installed. Write a Spark application to transform the data. Use EMR File System (EMRFS) to write files to the transformed data bucket. ✅ Create an AWS Glue crawler to discover the data. Create an AWS Glue extract, transform, and load (ETL) job to transform the data. Specify the transformed data bucket in the output step. Use AWS Batch to create a job definition with Bash syntax to transform the data and output the data to the transformed data bucket. Use the job definition to submit a job. Specify an array job as the job type. ❌ Create an AWS Lambda function to transform the data and output the data to the transformed data bucket. Configure an event notification for the S3 bucket. Specify the Lambda function as the destination for the event notification. ✨ 关键词：convert files from .csv to Apache Parquet format、S3 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：需要将 S3 存储桶内的 .csv 文件转为 Apache Parquet 格式再存入另一个桶中。4️⃣ 当然可以解决问题，但是太过繁琐。 Glue 是官方建议的解决方式：Three AWS Glue ETL job types for converting data to Apache Parquet On the Amazon Web Services (AWS) Cloud, AWS Glue is a fully managed extract, transform, and load (ETL) service. AWS Glue makes it cost-effective to categorize your data, clean it, enrich it, and move it reliably between various data stores and data streams. 还需要补充一点是 Glue 是支持数据流的：使用流式处理数据源 您可以创建连续运行并使用来自流式处理源的数据的流式处理提取、转换和负载（ETL）任务，例如 Amazon Kinesis Data Streams、Apache Kafka 和 Amazon Managed Streaming for Apache Kafka（Amazon MSK）。 顺便看到 1️⃣ 的时候愣了一下，又忘记 EMR 是什么了：什么是 Amazon EMR？ Amazon EMR（以前称为 Amazon Elastic MapReduce）是一个托管集群平台，可简化在AWS上运行大数据框架（如 Apache Hadoop 和 Apache Spark）的过程，以处理和分析海量数据。使用这些框架和相关的开源项目，您可以处理用于分析目的的数据和业务情报工作负载。Amazon EMR 还允许您转换大量数据并移出/移入到其它AWS数据存储和数据库中，例如 Amazon Simple Storage Service（Amazon S3）和 Amazon DynamoDB。 Amazon EMR 是大数据框架托管平台。 👨‍👨‍👦‍👦 社区讨论：AWS Glue isa fully managed ETL service that simplifies the process of preparing and transforming data for analytics. Using AWS Glue requires minimal development effort compared to the other options. Option A requires more development effort as it involves writing a Sparkapplication to transform the data. It also introduces additional infrastructure management with the EMR cluster.Option C requires writing and managing custom Bash scripts for data transformation. It requires more manual effort and does not provide the built-in capabilities of AWS Glue for data transformation.Option D requires developing and managing a custom Lambda for data transformation. While Lambda can handle the transformation, it requires more effort compared to AWS Glue, which is specifically designed for ETL operations. Therefore, option B provides the easiest and least development effort by leveraging AWS Glue’s capabilities for data discovery, transformation,and output to the transformed data bucket. 九、Second infrastructure for DRA company runs a global web application on Amazon EC2 instances behind an Application Load Balancer. The application stores data in Amazon Aurora. The company needs to create a disaster recovery solution and can tolerate up to 30 minutes of downtime and potential data loss. The solution does not need to handle the load when the primary infrastructure is healthy.What should a solutions architect do to meet these requirements? ✅ Deploy the application with the required infrastructure elements in place. Use Amazon Route 53 to configure active-passive failover. Create an Aurora Replica in a second AWS Region. Host a scaled-down deployment of the application in a second AWS Region. Use Amazon Route 53 to configure active-active failover. Create an Aurora Replica in the second Region. Replicate the primary infrastructure in a second AWS Region. Use Amazon Route 53 to configure active-active failover. Create an Aurora database that is restored from the latest snapshot. Back up data with AWS Backup. Use the backup to create the required infrastructure in a second AWS Region. Use Amazon Route 53 to configure active-passive failover. Create an Aurora second primary instance in the second Region. ✨ 关键词：DR 1️⃣ ✅ 💡 解析：公司需要灾备方案，允许 30 分钟的离线和数据丢失，但是要求这个方案（容灾架构）在主服务正常的情况下不要工作。为了达到主服务正常的情况下不工作的需求，需要使用 Amazon Route 53 的 主动/被动 (active-passive) 故障转移。关于 主动/主动 (active-active) 和 主动/被动 (active-passive) 的区别：主动/主动和主动/被动故障转移 主动/主动故障转移如果您希望所有资源在大部分时间内都可用，可使用此故障转移配置。当某个资源不可用时，Route 53 可以检测到它运行状况不佳并且停止在响应查询时包含该资源。在双活故障转移中，具有相同名称、相同类型（例如 A 或 AAAA）和相同路由策略（如加权或延迟）的所有记录处于活动状态，除非 Route 53 认为它们运行状况不良。Route 53 可以使用任何运行状况良好的记录响应 DNS 查询。 主动/被动故障转移如果您希望主资源或资源组在大部分时间内可用，同时希望辅助资源或资源组处于备用状态以防所有主资源均不可用，可使用主动/被动故障转移配置。响应查询时，Route 53 将只包含运行状况良好的主资源。如果所有主资源的运行状况都不佳，Route 53 将只在 DNS 查询的响应中包含运行状况良好的辅助资源。 4️⃣ 无疑也是可以做到恢复架构的，社区里有人提到了 AWS Backup 的 RTO 是以小时计算的，我并没有找到详细的资料说明。但是可以肯定的是它一定没有选项 1️⃣ 恢复得快。4️⃣ 的多主数据库仅适用于 MySQL 引擎，不过在这里并没有必要，应用都停了，数据库还跑着没有意义。 👨‍👨‍👦‍👦 社区讨论：Anything that is not instant recovery isactive - passive.In active -passive we have: Aws Backup(least op overhead) - RTO/RPO = hours Pilot Light ( Basic Infra isalready deployed, but needs to be fully implemented) -RTO/RPO = 10’s of minutes. Warm Standby- (Basic infra + runs small loads ( might need to add auto scaling) -RTO/RPO= minutes ( ACTIVE -ACTIVE ) : Multi AZ option : instant here we can tolerate 30 minshence B,D are incorrect. AWS backup is in hours, hence D is incorrect.therefore A 十、In-memory tasksA company’s application is having performance issues. The application is stateful and needs to complete in-memory tasks on Amazon EC2 instances. The company used AWS CloudFormation to deploy infrastructure and used the M5 EC2 instance family.As traffic increased, the application performance degraded. Users are reporting delays when the users attempt to access the application.Which solution will resolve these issues in the MOST operationally efficient way? Replace the EC2 instances with T3 EC2 instances that run in an Auto Scaling group. Make the changes by using the AWS Management Console. Modify the CloudFormation templates to run the EC2 instances in an Auto Scaling group. Increase the desired capacity and the maximum capacity of the Auto Scaling group manually when an increase is necessary. Modify the CloudFormation templates. Replace the EC2 instances with R5 EC2 instances. Use Amazon CloudWatch built-in EC2 memory metrics to track the application performance for future capacity planning. ✅ Modify the CloudFormation templates. Replace the EC2 instances with R5 EC2 instances. Deploy the Amazon CloudWatch agent on the EC2 instances to generate custom application latency metrics for future capacity planning. ✨ 关键词：in-memory tasks 4️⃣ ✅ 💡 解析：M5 型的 EC2 运行内存型任务出现了性能瓶颈。问有什么最具操作性价比的行为。1️⃣ 2️⃣ 选择了水平扩容；3️⃣ 4️⃣ 选择了垂直扩容并监控状态为之后的扩容计划做准备。显然是 3️⃣ 4️⃣ 更加合理。过一下各类型的 EC2 实例：Amazon EC2 实例类型 M 系列（通用型实例）- 提供了计算、内存和网络资源的平衡，可用于各种不同的工作负载。 这些实例非常适合于以相等比例使用这些资源的应用程序，例如 Web 服务器和代码库。 C 系列（计算优化型实例）- 是计算限制型应用程序的理想选择，可以受益于高性能处理器。 非常适合于批处理工作负载、媒体转码、高性能 Web 服务器、高性能计算（HPC）、科学建模、专用游戏服务器和广告服务器引擎、机器学习推理和其他计算密集型应用程序。 R 系列（内存优化型实例）- 内存优化型实例旨在为处理内存中大型数据集的工作负载提供快速性能。 内存密集型工作负载，如开源数据库、内存缓存和实时大数据分析。 👨‍👨‍👦‍👦 社区讨论：D is the correct answer.“in-memory tasks” =&gt; need the “R” EC2 instance type to archive memory optimization.So we are concerned about C &amp; D.Because EC2 instances don’t have built-in memory metrics to CW by default. Asa result, we have to install the CW agent to archive the purpose.","link":"/2024/12/01/saa_test_daily_20241201/"},{"title":"SAA 考试每日练习 - 2024&#x2F;12&#x2F;13","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam65 题 (No.901 ~ No.965) 只记录了 9 道首次碰到的、错误的或有疑问的题目，仅供自己复习使用。与正式考试题量一样，总共耗时 101/(130+30) 分钟，正确率为 50/65。如果侵权请联系删除。 一、S3 Access PointsA company manages a data lake in an Amazon S3 bucket that numerous applications access. The S3 bucket contains a unique prefix for each application. The company wants to restrict each application to its specific prefix and to have granular control of the objects under each prefix.Which solution will meet these requirements with the LEAST operational overhead? ✅ Create dedicated S3 access points and access point policies for each application. Create an S3 Batch Operations job to set the ACL permissions for each object in the S3 bucket. Replicate the objects in the S3 bucket to new S3 buckets for each application. Create replication rules by prefix. ❌ Replicate the objects in the S3 bucket to new S3 buckets for each application. Create dedicated S3 access points for each application. ✨ 关键词： 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：Amazon S3 访问点 - 轻松管理对 Amazon S3 上共享数据集的访问 S3 的 Amazon S3 访问点功能可简化在 S3 中存储数据的任何 AWS 服务或客户应用程序的数据访问。通过 S3 访问点，客户可以为每个访问点创建独有的访问控制策略，以轻松地控制对共享数据集的访问权限。拥有共享数据集（包括数据湖、媒体存档和用户生成的内容）的客户可以通过创建针对每个应用程序定制名称和权限的个性化访问点，轻松扩展数百个应用程序的访问范围。可以将任何访问点限制为 Virtual Private Cloud (VPC)，以将 S3 数据访问范围限制在客户的防火墙之后，并且可以使用 AWS 服务控制策略确保所有访问点均受 VPC 限制。S3 访问点可在所有区域免费使用。 配置使用接入点的 IAM 策略 Amazon S3 接入点支持 AWS Identity and Access Management（IAM）资源策略，这些策略允许您按资源、用户或其他条件控制接入点的使用。要使应用程序或用户能够通过接入点访问对象，接入点和底层存储桶都必须允许请求。 使用 S3 Access Points 和对应的策略就已经能解决题目的需求，不需要为每个应用程序再单独创建存储桶存储对象。 👨‍👨‍👦‍👦 社区讨论：Create dedicated S3 access points and access point policies for each application. 二、TCP-based and UDP-basedA company wants to improve the availability and performance of its hybrid application. The application consists of a stateful TCP-based workload hosted on Amazon EC2 instances in different AWS Regions and a stateless UDP-based workload hosted on premises.Which combination of actions should a solutions architect take to improve availability and performance? (Choose two.) ✅ Create an accelerator using AWS Global Accelerator. Add the load balancers as endpoints. ❌ Create an Amazon CloudFront distribution with an origin that uses Amazon Route 53 latency-based routing to route requests to the load balancers. Configure two Application Load Balancers in each Region. The first will route to the EC2 endpoints, and the second will route to the on-premises endpoints. ✅ Configure a Network Load Balancer in each Region to address the EC2 endpoints. Configure a Network Load Balancer in each Region that routes to the on-premises endpoints. Configure a Network Load Balancer in each Region to address the EC2 endpoints. Configure an Application Load Balancer in each Region that routes to the on-premises endpoints. ✨ 关键词： 2️⃣ 4️⃣ ❌ -&gt; 1️⃣ 4️⃣ ✅ 💡 解析：Network Load Balancer 已经可以完成 TCP 和 UDP 流量的负载均衡。Amazon CloudFront 只能对 TCP 流量进行加速，而 AWS Global Accelerator 可以加速 TCP 和 UDP 流量。 👨‍👨‍👦‍👦 社区讨论：TCP &gt;&gt; NLBnon-http &gt;&gt; accelerator 三、DB IO performanceA company recently performed a lift and shift migration of its on-premises Oracle database workload to run on an Amazon EC2 memory optimized Linux instance. The EC2 Linux instance uses a 1 TB Provisioned IOPS SSD (io1) EBS volume with 64,000 IOPS.The database storage performance after the migration is slower than the performance of the on-premises database.Which solution will improve storage performance? ✅ Add more Provisioned IOPS SSD (io1) EBS volumes. Use OS commands to create a Logical Volume Management (LVM) stripe. ❌ Increase the Provisioned IOPS SSD (io1) EBS volume to more than 64,000 IOPS. Increase the size of the Provisioned IOPS SSD (io1) EBS volume to 2 TB. Change the EC2 Linux instance to a storage optimized instance type. Do not change the Provisioned IOPS SSD (io1) EBS volume. ✨ 关键词： 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：已配置 IOPS SSD (io1) 卷 io1卷的大小范围从4 GiB到16 TiB，每个卷可以提供100 IOPS到64,000 IOPS。分配的IOPS与请求的卷大小（以GiB为单位）的最大比例为50:1。例如，100 GiB io1卷最多可以分配5000 IOPS。 You can achieve up to 64,000 IOPS only on instances built on the Nitro System. On other instances, you can achieve performance up to 32,000 IOPS. 这意味着 io1 卷的最大 IOPS 就是 64,000 了（在 Nitro 系统上），没法再通过普通的方式提升。因此 2️⃣ 和 3️⃣ 错误。4️⃣ 切换到存储优化型实例显然是错的。 拓展下 io2 最大能支持到 256,000 的 IOPS（在 Nitro 系统上）：已配置 IOPS SSD (io2) Block Express 卷 Provisioned IOPS up to 256,000, with an IOPS:GiB ratio of 1,000:1. Maximum IOPS can be provisioned with volumes 256 GiB and larger (1,000 IOPS × 256 GiB = 256,000 IOPS). 通过在Nitro系统上构建实例，您可以实现高达256,000 IOPS的目标。在其他实例上，性能最高可达32,000 IOPS。 👨‍👨‍👦‍👦 社区讨论：A is correct, The maximum provisioned IOPS for io1 is 64000 and hence you can achieve higher aggregate performance by adding more io1 volumes 四、NLB SecurityA company hosts a video streaming web application in a VPC. The company uses a Network Load Balancer (NLB) to handle TCP traffic for real-time data processing. There have been unauthorized attempts to access the application.The company wants to improve application security with minimal architectural change to prevent unauthorized attempts to access the application.Which solution will meet these requirements? ❌ Implement a series of AWS WAF rules directly on the NLB to filter out unauthorized traffic. ✅ Recreate the NLB with a security group to allow only trusted IP addresses. Deploy a second NLB in parallel with the existing NLB configured with a strict IP address allow list. Use AWS Shield Advanced to provide enhanced DDoS protection and prevent unauthorized access attempts. ✨ 关键词： 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：NLB need to Attach AWS WAF NLB is a Lyer 3/4 component while WAF is a Layer 7 protection component.That is why WAF is only available for Application Load Balancer in the ELB portfolio. NLB does not terminate the TLS session therefore WAF is not capable of acting on the content. I would consider using AWS Shield at Layer 3/4. 网络负载均衡器现支持安全组 网络负载均衡器 (NLB) 现在支持安全组，这让您能够筛选 NLB 接受并转发到应用程序的流量。使用安全组，您可以配置规则，帮助确保 NLB 只接受来自可信 IP 地址的流量，并集中执行访问控制策略。这可以改善应用程序的安全状况，并简化操作。 社区提到了 4️⃣ 也是对的，当然，不过在这里 2️⃣ 有官方文档提供支持。 👨‍👨‍👦‍👦 社区讨论：I don’t think B is correct. if you only allow selected IPs to access then this company cannot host their video streaming service to the public.D should be the correct answer. AWS shield advanced if I rmb correctly prevent unauthorised attempts 五、SNS encryptionA healthcare company is developing an AWS Lambda function that publishes notifications to an encrypted Amazon Simple Notification Service (Amazon SNS) topic. The notifications contain protected health information (PHI). 一家医疗保健公司正在开发一个AWS Lambda函数，用于向加密的Amazon Simple Notification Service （Amazon SNS）主题发布通知。通知包含受保护的健康信息（PHI）。 The SNS topic uses AWS Key Management Service (AWS KMS) customer managed keys for encryption. The company must ensure that the application has the necessary permissions to publish messages securely to the SNS topic. SNS主题使用AWS密钥管理服务（AWS KMS）客户管理的密钥进行加密。公司必须确保应用程序具有将消息安全地发布到SNS主题所需的权限。 Which combination of steps will meet these requirements? (Choose three.) ✅ Create a resource policy for the SNS topic that allows the Lambda function to publish messages to the topic. ❌ Use server-side encryption with AWS KMS keys (SSE-KMS) for the SNS topic instead of customer managed keys. 对SNS主题使用带有AWS KMS密钥（SSE-KMS）的服务器端加密，而不是客户管理的密钥。 ✅ Create a resource policy for the encryption key that the SNS topic uses that has the necessary AWS KMS permissions. 为SNS主题使用的具有必要AWS KMS权限的加密密钥创建资源策略。 Specify the Lambda function’s Amazon Resource Name (ARN) in the SNS topic’s resource policy. 在SNS主题的资源策略中指定Lambda函数的Amazon Resource Name （ARN）。 Associate an Amazon API Gateway HTTP API with the SNS topic to control access to the topic by using API Gateway resource policies. ✅ Configure a Lambda execution role that has the necessary IAM permissions to use a customer managed key in AWS KMS. ✨ 关键词： 1️⃣ 2️⃣ 6️⃣ ❌ -&gt; 1️⃣ 3️⃣ 6️⃣ ✅ 💡 解析：1️⃣ 和 6️⃣ 没有争议，社区在 2️⃣ 和 3️⃣ 间争议较大。设置使用服务器端加密的 Amazon SNS 主题，这个题目似乎更注重 KMS 密钥策略。 👨‍👨‍👦‍👦 社区讨论：D is correct too and С is not clear, but seems like it is about KMS policy and adding permissions for sns service which has to be added in case of CMK 六、Cross Account SNSA media company has a multi-account AWS environment in the us-east-1 Region. The company has an Amazon Simple Notification Service (Amazon SNS) topic in a production account that publishes performance metrics. The company has an AWS Lambda function in an administrator account to process and analyze log data.The Lambda function that is in the administrator account must be invoked by messages from the SNS topic that is in the production account when significant metrics are reported.Which combination of steps will meet these requirements? (Choose two.) ✅ Create an IAM resource policy for the Lambda function that allows Amazon SNS to invoke the function. ❌ Implement an Amazon Simple Queue Service (Amazon SQS) queue in the administrator account to buffer messages from the SNS topic that is in the production account. Configure the SQS queue to invoke the Lambda function. ✅ Create an IAM policy for the SNS topic that allows the Lambda function to subscribe to the topic. Use an Amazon EventBridge rule in the production account to capture the SNS topic notifications. Configure the EventBridge rule to forward notifications to the Lambda function that is in the administrator account. Store performance metrics in an Amazon S3 bucket in the production account. Use Amazon Athena to analyze themetrics from the administrator account. ✨ 关键词： 1️⃣ 2️⃣ ❌ -&gt; 1️⃣ 3️⃣ ✅ 💡 解析：How do I set up a cross-account AWS Lambda subscription with an SNS topic? 在开始之前，请确保： Lambda函数资源策略允许SNS调用该函数。 SNS主题访问策略允许Lambda订阅主题。 注意：SNS主题驻留在帐户A中，Lambda函数驻留在帐户B中。订阅跨帐户Lambda函数向SNS主题订阅跨帐户Lambda函数有两种可能的方法： 从帐户B中的Lambda控制台添加SNS触发器。 从帐户B（具有Lambda函数的帐户）的SNS控制台添加Lambda订阅 因此 1️⃣ 和 3️⃣ 是最简单最正确的，分别在两个账号允许 SNS 调用自己的 Lambda 函数、允许 Lambda 函数订阅自己的主题。 👨‍👨‍👦‍👦 社区讨论：No need to complicate stuff, AWS services already exist only permissions are missing. A&amp;C will set up the necessary permissions and subscriptions for cross-account invocation of the Lambda function by the SNS topic. 七、Amazon VPC CNI pluginA company is migrating an application from an on-premises location to Amazon Elastic Kubernetes Service (Amazon EKS). The company must use a custom subnet for pods that are in the company’s VPC to comply with requirements. The company also needs to ensure that the pods can communicate securely within the pods’ VPC.Which solution will meet these requirements? Configure AWS Transit Gateway to directly manage custom subnet configurations for the pods in Amazon EKS. Create an AWS Direct Connect connection from the company’s on-premises IP address ranges to the EKS pods. ✅ Use the Amazon VPC CNI plugin for Kubernetes. Define custom subnets in the VPC cluster for the pods to use. ❌ Implement a Kubernetes network policy that has pod anti-affinity rules to restrict pod placement to specific nodes that are within custom subnets. ✨ 关键词： 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：Amazon VPC CNI Amazon VPC CNI plugin for Kubernetes 附加组件部署在 Amazon EKS 集群中的每个 Amazon EC2 节点上。附加组件会创建弹性网络接口并将其附加到 Amazon EC2 节点。附加组件还会将 VPC 中的私有 IPv4 或 IPv6 地址分配给每个 Pod。 How do I choose specific IP subnets to be used for pods in my Amazon EKS cluster? 解决方案使用Amazon VPC CNI的自定义组网组件解决该问题。这个特性允许您在Amazon VPC集群中定义特定的子网，以供您的pod使用。它将您的子网与工作节点使用的子网区分开来。作为一个额外的好处，您可以为您的pod定义安全组。有关自定义网络用例的更多信息，请参阅教程：自定义网络。 👨‍👨‍👦‍👦 社区讨论：The Amazon VPC Container Network Interface (CNI) plugin is the default network plugin for Amazon EKS. It allows Kubernetes pods to receive IP addresses from a VPC’s subnet and enables pods to communicate securely within the VPC as if they were native VPC resources. 八、Kubernetes service access AWS resourcesA company is using an Amazon Elastic Kubernetes Service (Amazon EKS) cluster. The company must ensure that Kubernetes service accounts in the EKS cluster have secure and granular access to specific AWS resources by using IAM roles for service accounts (IRSA).Which combination of solutions will meet these requirements? (Choose two.) Create an IAM policy that defines the required permissions Attach the policy directly to the IAM role of the EKS nodes. Implement network policies within the EKS cluster to prevent Kubernetes service accounts from accessing specific AWSservices. ❌ Modify the EKS cluster’s IAM role to include permissions for each Kubernetes service account. Ensure a one-to-one mapping between IAM roles and Kubernetes roles. ✅ Define an IAM role that includes the necessary permissions. Annotate the Kubernetes service accounts with the Amazon ResourceName (ARN) of the IAM role. ✅ Set up a trust relationship between the IAM roles for the service accounts and an OpenID Connect (OIDC) identity provider. ✨ 关键词： 3️⃣ 4️⃣ ❌ -&gt; 4️⃣ 5️⃣ ✅ 💡 解析：4️⃣ 毫无疑问，需要创建 IAM 角色让服务代入。5️⃣ 的出处为：服务账户的 IAM 角色 2014 年，AWS Identity and Access Management 使用 OpenID Connect（OIDC）增加了对联合身份验证的支持。此功能允许您通过支持的身份提供商对 AWS API 调用进行身份验证，并获得有效的 OIDC JSON Web 令牌（JWT）。您可以将此令牌传递到 AWS STS AssumeRoleWithWebIdentity API 操作并接收 IAM 临时角色凭证。您可以使用这些凭证与任意 AWS 服务交互，包括 Amazon S3 和 DynamoDB。 👨‍👨‍👦‍👦 社区讨论：https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.htmlhttps://docs.aws.amazon.com/eks/latest/userguide/associate-service-account-role.htmlhttps://docs.aws.amazon.com/eks/latest/userguide/enable-iam-roles-for-service-accounts.html=&gt; DE 九、AWS WAFA company uses AWS to host its public ecommerce website. The website uses an AWS Global Accelerator accelerator for traffic from the internet. The Global Accelerator accelerator forwards the traffic to an Application Load Balancer (ALB) that is the entry point for an Auto Scaling group.The company recently identified a DDoS attack on the website. The company needs a solution to mitigate future attacks.Which solution will meet these requirements with the LEAST implementation effort? Configure an AWS WAF web ACL for the Global Accelerator accelerator to block traffic by using rate-based rules Configure an AWS Lambda function to read the ALB metrics to block attacks by updating a VPC network ACL ✅ Configure an AWS WAF web ACL on the ALB to block traffic by using rate-based rules ❌ Configure an Amazon CloudFront distribution in front of the Global Accelerator accelerator ✨ 关键词： 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：How do I use AWS WAF with AWS Global Accelerator to block Layer 7 HTTP method and headers from accessing my application? 您可以使用AWS WAF和具有全局加速器的应用程序负载平衡器来阻止对第7层HTTP方法和头的访问。在此架构中，AWS WAF将web访问控制列表（web ACL）规则与应用程序负载平衡器一起使用。负载平衡器成为全局加速器的一个端点。注意：AWS Global Accelerator本身不支持AWS WAF。 User –&gt; Global Accelerator –&gt; Application Load Balancer with AWS WAF –&gt; EC2 instance 👨‍👨‍👦‍👦 社区讨论：WAF can be applied on ALB, API gateway or cloud front.","link":"/2024/12/13/saa_test_daily_20241213/"},{"title":"SAA 考试每日练习 - 2024&#x2F;12&#x2F;14","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam53 题 (No.966 ~ No.1019) 只记录了 4 道首次碰到的、错误的或有疑问的题目，仅供自己复习使用。如果侵权请联系删除。 一、Amazon RDS automated backupsA company is migrating its on-premises Oracle database to an Amazon RDS for Oracle database. The company needs to retain data for 90 days to meet regulatory requirements. The company must also be able to restore the database to a specific point in time for up to 14 days.Which solution will meet these requirements with the LEAST operational overhead? Create Amazon RDS automated backups. Set the retention period to 90 days. Create an Amazon RDS manual snapshot every day. Delete manual snapshots that are older than 90 days. ❌ Use the Amazon Aurora Clone feature for Oracle to create a point-in-time restore. Delete clones that are older than 90 days. ✅ Create a backup plan that has a retention period of 90 days by using AWS Backup for Amazon RDS. ✨ 关键词： 3️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：使用 AWS Backup 备份和还原 Amazon RDS g. Enable continuous backups for point-in-time recovery（启用连续备份以进行时间点恢复）- 使用连续备份，您可以通过选择恢复时间（精确到秒）来执行时间点还原 (PITR)。工作负载的当前状态与最近的时间点还原之间的最长时间间隔为 5 分钟。连续备份最多可存储 35 天。如果您不启用连续备份，AWS Backup 会为您进行快照备份。 连续备份只能最多保留 35 天，因此 3️⃣ 是错误的。 备份保留期 创建数据库实例或集群后，您可以修改备份保留期。您可以将数据库实例的备份保留期设置为在 0 到 35 天之间。要禁用自动备份，请将备份保留期设置为 0。对于多可用区数据库集群，可以将备份保留期设置为在 1 到 35 天之间。手动快照限制（每个区域 100 个）不适用于自动备份。 自动备份的保留期也是 35 天，因此只有 4️⃣ 正确。 👨‍👨‍👦‍👦 社区讨论：A: Amazon RDS automated backups support a maximum retention period of 35 days. This option does not meet the requirement to retain backups for 90 days.B: This approach requires manual snapshot management, including scheduling snapshots and deleting old ones. This increases operational overhead and is prone to human error.C: This option is not applicable as Aurora Clone is a feature specific to Amazon Aurora and not available for Amazon RDS for Oracle. Additionally, it would require manual management of clones, increasing complexity.D: AWS Backup supports point-in-time recovery for Amazon RDS, enabling you to restore the database to any specific point within the defined retention period, up to 35 days. For the requirement of 14 days, AWS Backup easily supports this capability. 二、IAM Identity CenterA company is building a cloud-based application on AWS that will handle sensitive customer data. The application uses Amazon RDS for the database, Amazon S3 for object storage, and S3 Event Notifications that invoke AWS Lambda for serverless processing.The company uses AWS IAM Identity Center to manage user credentials. The development, testing, and operations teams need secure access to Amazon RDS and Amazon S3 while ensuring the confidentiality of sensitive customer data. The solution must comply with the principle of least privilege.Which solution meets these requirements with the LEAST operational overhead? Use IAM roles with least privilege to grant all the teams access. Assign IAM roles to each team with customized IAM policies defining specific permission for Amazon RDS and S3 object access based on team responsibilities. ✅ Enable IAM Identity Center with an Identity Center directory. Create and configure permission sets with granular access to Amazon RDS and Amazon S3. Assign all the teams to groups that have specific access with the permission sets. Create individual IAM users for each member in all the teams with role-based permissions. Assign the IAM roles with predefined policies for RDS and S3 access to each user based on user needs. Implement IAM Access Analyzer for periodic credential evaluation. Use AWS Organizations to create separate accounts for each team. Implement cross-account IAM roles with least privilege. Grant specific permission for RDS and S3 access based on team roles and responsibilities. ✨ 关键词： 2️⃣ ✅ 💡 解析：IAM Identity Center 是什么？ AWS IAM Identity Center是一种AWS解决方案，用于将您的员工用户连接到AWS管理的应用程序（如Amazon Q Developer和Amazon QuickSight）以及其他AWS资源。您可以连接现有的身份提供者并从您的目录同步用户和组，或者直接在IAM identity Center中创建和管理您的用户。然后，您可以使用IAM身份中心进行以下操作中的一项或两项： 用户访问应用程序 用户访问AWS帐户 使用IAM Identity Center访问AWS管理的应用程序无需对当前AWS帐户工作流进行任何更改。如果您正在与IAM或IAM用户使用federation来访问AWS帐户，则您的用户可以继续以相同的方式访问AWS帐户，并且您可以继续使用现有的工作流来管理该访问。 👨‍👨‍👦‍👦 社区讨论：IAM Identity Center: This service simplifies user management by centralizing credentials and access control.Permission Sets: You can create granular permission sets that align with the principle of least privilege, ensuring that each team has only the access they need. Permission Sets: 您可以创建符合最小权限原则的粒度权限集，确保每个团队只拥有所需的访问权限。 Group Assignments: By assigning teams to groups with specific permission sets, you streamline access management and reduce the complexity of individual user permissions. Group Assignments: 通过将团队分配给具有特定权限集的组，可以简化访问管理并降低单个用户权限的复杂性。 This approach minimizes operational overhead while maintaining secure and compliant access to sensitive customer data 三、AWSEC2-PatchLoadBalancerInstanceA company uses AWS Systems Manager for routine management and patching of Amazon EC2 instances. The EC2 instances are in an IP address type target group behind an Application Load Balancer (ALB).New security protocols require the company to remove EC2 instances from service during a patch. When the company attempts to follow the security protocol during the next patch, the company receives errors during the patching window.Which combination of solutions will resolve the errors? (Choose two.) ❌ Change the target type of the target group from IP address type to instance type. Continue to use the existing Systems Manager document without changes because it is already optimized to handle instances that are in an IP address type target group behind an ALB. ✅ Implement the AWSEC2-PatchLoadBalanacerInstance Systems Manager Automation document to manage the patching process. ✅ Use Systems Manager Maintenance Windows to automatically remove the instances from service to patch the instances. ❌ Configure Systems Manager State Manager to remove the instances from service and manage the patching schedule. Use ALB health checks to re-route traffic. ✨ 关键词： 1️⃣ 5️⃣ ❌ -&gt; 3️⃣ 4️⃣ ✅ 💡 解析：AWSEC2-PatchLoadBalancerInstance 升级并修补附加到任何负载均衡器（经典、ALB 或 NLB）的 Amazon EC2 实例（Windows 或 Linux）的次要版本。在修补该实例之前，会应用默认的连接耗尽时间。您可以为 ConnectionDrainTime 参数输入以分钟 (1-59) 为单位的自定义耗尽时间，从而覆盖等待时间。自动化工作流程如下所示： 确定实例所附加的负载均衡器或目标组，并验证该实例是否运行正常。 该实例已从负载均衡器或目标组移除。 此自动化将等待为连接耗尽时间指定的时间段。 调用 AWS-RunPatchBaseline 自动化以修补该实例。 该实例已从负载均衡器或目标组重新附加。 👨‍👨‍👦‍👦 社区讨论：https://docs.aws.amazon.com/systems-manager-automation-runbooks/latest/userguide/automation-awsec2-patch-load-balancer-instance.html 四、Allow IPs for API GatewayA company is developing an application in the AWS Cloud. The application’s HTTP API contains critical information that is published in Amazon API Gateway. The critical information must be accessible from only a limited set of trusted IP addresses that belong to the company’s internal network.Which solution will meet these requirements? Set up an API Gateway private integration to restrict access to a predefined set of IP addresses. ✅ Create a resource policy for the API that denies access to any IP address that is not specifically allowed. Directly deploy the API in a private subnet. Create a network ACL. Set up rules to allow the traffic from specific IP addresses. ❌ Modify the security group that is attached to API Gateway to allow inbound traffic from only the trusted IP addresses. ✨ 关键词： 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：如何只允许特定的 IP 地址访问我的 API Gateway REST API？ 创建并附加仅允许特定 IP 地址访问您的 API Gateway REST API 的资源策略 👨‍👨‍👦‍👦 社区讨论：answer B","link":"/2024/12/14/saa_test_daily_20241214/"},{"title":"SAA 考试每日练习 - 2024&#x2F;12&#x2F;15","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam160 题 (No.1 ~ No.160) 只记录了 11 道错误的题目，仅供自己复习使用。如果侵权请联系删除。 一、流量审计一家公司最近迁移到了 AWS，并希望实施一套解决方案来保护进出 AWS 生产 VPC 流量。该公司在内部数据中心有一个检查服务器。检查服务器执行流量检查和流量过滤等特定操作。该公司希望在 AWS 云中拥有相同的功能。哪种解决方案能满足这些要求？ 在生产 VPC 中使用 Amazon GuardDuty 进行流量检查和流量过滤。 ❌ 使用流量镜像从生产 VPC 镜像流量，以进行流量检查和过滤。 ✅ 使用 AWS 网络防火墙为生产 VPC 创建流量检查和流量过滤所需的规则。 使用 AWS Firewall Manager 为生产 VPC 创建流量检查和流量过滤所需的规则。 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：AWS Network Firewall - 跨 VPC 部署网络防火墙安全 检查入站互联网流量 - 使用入站加密流量检查、状态检查、协议检测等功能检查流量。 筛选出站流量 - 部署出站流量筛选，以防止数据丢失、帮助满足合规要求，以及阻止已知的恶意软件通信。 防止入站互联网流量入侵 - 使用状态检测、协议检测等功能检查活动流量。 保护 AWS Direct Connect 和 VPN 流量的安全 - 保护来自客户端设备和 AWS Transit Gateway 支持的本地环境的 Direct Connect 和 VPN 流量的安全。 二、Microsoft Active Directory一家公司正在将应用程序迁移到 AWS。这些应用程序部署在不同的账户中。公司使用 AWS 组织集中管理这些账户。公司的安全团队需要一个跨公司所有账户的单点登录（SSO）解决方案。公司必须继续管理内部自管理 Microsoft Active Directory 中的用户和组。哪种解决方案能满足这些要求？ ❌ 从 AWS SSO 控制台启用 AWS 单点登录（AWS SSO）。创建单向林信任或单向域信任，通过使用 AWS Directory Service for Microsoft Active Directory 将公司自主管理的 Microsoft Active Directory 与 AWS SSO 连接起来。 ✅ 从 AWS SSO 控制台启用 AWS 单点登录（AWS SSO）。创建双向森林信任，使用 AWS Directory Service for Microsoft Active Directory 将公司自主管理的 Microsoft Active Directory 与 AWS SSO 连接起来。 使用 AWS 目录服务。与公司自主管理的 Microsoft Active Directory 建立双向信任关系。 在办公场所部署身份提供程序 (IdP)。从 AWS SSO 控制台启用 AWS 单点登录（AWS SSO）。 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：需要在公司内部自管理的 AD 上管理用户和组，这是 AD Connector 的使用场景：AD Connector AD Connector 是一种目录网关，借助它可以将目录请求重定向到本地 Microsoft Active Directory，而无需在云中缓存任何信息。 而选项 1️⃣ 中提到的 AWS Directory Service for Microsoft Active Directory 则是：什么是 AWS Directory Service？ AWS Directory Service for Microsoft Active Directory 也称为 AWS Managed Microsoft AD，由 AWS Cloud 中的 AWS 管理的实际 Microsoft Windows Server Active Directory（AD）提供支持。 它已经是一个完整的 AD 服务了，当然通过它建立与本地 AD 的信任关系（云 AD 信任本地 AD）：这样在云 AD 找不到用户的时候就会前往本地查找了，是可以解决问题。我认为选 2️⃣ 的原因是 1️⃣ 并没有描述得很清楚，2️⃣ 则肯定没错。 三、ACM 导入 HTTPS 证书某公司在亚马逊 Route 53 注册了域名。该公司使用 ca-central-1 区域的亚马逊 API 网关作为其后端微服务 API 的公共接口。第三方服务安全地使用 API。该公司希望使用公司域名和相应证书设计 API Gateway URL，以便第三方服务可以使用 HTTPS。哪种解决方案能满足这些要求？ 在 API Gateway 中创建 Name=”Endpoint-URL” 和 Value=”Company Domain Name” 的阶段变量，以覆盖默认 URL。将与公司域名相关的公共证书导入 AWS 证书管理器 (ACM)。 使用公司域名创建 Route 53 DNS 记录。将别名记录指向区域 API 网关阶段端点。将与公司域名相关的公共证书导入 us-east-1 区域的 AWS 证书管理器 (ACM)。 ✅ 创建区域 API Gateway 端点。将 API Gateway 端点与公司域名关联。将与公司域名相关联的公共证书导入同一区域的 AWS 证书管理器 (ACM)。将证书附加到 API Gateway 端点。配置 Route 53，将流量路由到 API Gateway 端点。 ❌ 创建区域 API Gateway 端点。将 API Gateway 端点与公司域名关联。将与公司域名相关联的公共证书导入 us-east-1 区域的 AWS 证书管理器 (ACM)。将证书附加到 API Gateway API。创建与公司域名相关的 Route 53 DNS 记录。将 A 记录指向公司域名。 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：ALB 和 Amazon API Gateway 可以在相应的区域申请/导入 SSL 证书，而使用 CloudFront 则需要将证书配置在弗吉尼亚北部区域 (us-east-1) 中：第一步 - 确认区域 对于 ALB 或者 Amazon API Gateway 服务，您需要选择在与之相同的区域来申请 ACM 证书；如果您使用的是海外区域 Amazon CloudFront，则需要将证书配置在弗吉尼亚北部区域 (us-east-1)。您可以在页面右上角确认当前所处区域。 四、SQS API 操作某公司希望将一个多层应用程序从公司内部转移到 AWS 云，以提高应用程序的性能。该应用程序由多个应用程序层组成，这些层通过 RESTful 服务相互通信。当其中一个层超载时，事务就会被丢弃。解决方案架构师必须设计一个解决方案来解决这些问题并使应用程序现代化。哪种解决方案既能满足这些要求，又能最大限度地提高运行效率？ ✅ 使用亚马逊 API 网关，并将事务直接连接到 AWS Lambda 函数作为应用层。使用亚马逊简单队列服务（Amazon SQS）作为应用服务之间的通信层。 使用 Amazon CloudWatch 指标分析应用程序性能历史记录，以确定服务器在性能故障期间的峰值利用率。增加应用服务器的 Amazon EC2 实例大小，以满足峰值要求。 使用 Amazon Simple Notification Service (Amazon SNS) 处理自动扩展组中 Amazon EC2 上运行的应用程序服务器之间的消息传递。使用 Amazon CloudWatch 监控 SNS 队列长度，并根据需要进行增减。 ❌ 使用 Amazon Simple Queue Service (Amazon SQS) 处理自动扩展组中 Amazon EC2 上运行的应用程序服务器之间的消息传递。使用 Amazon CloudWatch 监控 SQS 队列长度，并在检测到通信故障时进行扩展。 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：SQS 并不支持之间通过 RESTful API 进行操作：将 API 与亚马逊 SQS 配合使用 本节提供有关构建 Amazon SQS 端点、通过 GET 和 POST 方法发出查询 API 请求以及使用批处理 API 操作的信息。有关 Amazon SQS 操作（包括参数、错误、示例和数据类型）的详细信息，请参阅 Amazon Simple Queue Service API 参考。 它的 API 并不是 RESTful 风格的：Actions The following actions are supported: AddPermission CancelMessageMoveTask ChangeMessageVisibility ChangeMessageVisibilityBatch CreateQueue DeleteMessage 五、Glue 的数据源一家公司需要为其应用程序配置一个实时数据摄取架构。该公司需要一个应用程序接口、一个在数据流中转换数据的流程和一个数据存储解决方案。哪种解决方案能以最少的运行开销满足这些要求？ 部署 Amazon EC2 实例来托管向 Amazon Kinesis 数据流发送数据的 API。创建将 Kinesis 数据流用作数据源的 Amazon Kinesis Data Firehose 交付流。使用 AWS Lambda 函数转换数据。使用 Kinesis Data Firehose 交付流将数据发送到 Amazon S3。 部署一个 Amazon EC2 实例来托管向 AWS Glue 发送数据的 API。在 EC2 实例上停止源/目标检查。使用 AWS Glue 转换数据并将数据发送到 Amazon S3。 ✅ 配置 Amazon API Gateway API，将数据发送到 Amazon Kinesis 数据流。创建一个将 Kinesis 数据流用作数据源的 Amazon Kinesis Data Firehose 交付流。使用 AWS Lambda 函数转换数据。使用 Kinesis Data Firehose 交付流将数据发送到 Amazon S3。 ❌ 配置亚马逊 API Gateway API，将数据发送到 AWS Glue。使用 AWS Lambda 函数转换数据。使用 AWS Glue 将数据发送到 亚马逊 S3。 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：Glue 不支持 API Gateway API 作为数据摄取源：Glue 的工作原理 六、ACM SSL 证书过期提醒某公司在 AWS 云中托管其网络应用程序。该公司将弹性负载平衡器配置为使用导入 AWS 证书管理器 (ACM) 的证书。公司的安全团队必须在每个证书到期前 30 天收到通知。解决方案架构师应如何建议才能满足这一要求？ 在 ACM 中添加一条规则，从任何证书过期前 30 天开始，每天向 Amazon Simple Notification Service (Amazon SNS) 主题发布一条自定义消息。 ✅ 创建一个 AWS Config 规则，检查将在 30 天内过期的证书。配置 Amazon EventBridge（Amazon CloudWatch 事件），以便在 AWS Config 报告不合规资源时通过 Amazon Simple Notification Service (Amazon SNS) 调用自定义警报。 使用 AWS Trusted Advisor 检查将在 30 天内过期的证书。创建一个基于 Trusted Advisor 指标的 Amazon CloudWatch 警报，以检查状态变化。配置警报，以便通过 Amazon Simple Notification Service (Amazon SNS) 发送自定义警报。 ❌ 创建一个 Amazon EventBridge（Amazon CloudWatch 事件）规则，以检测任何将在 30 天内过期的证书。配置该规则以调用 AWS Lambda 函数。配置 Lambda 函数，以便通过 Amazon Simple Notification Service (Amazon SNS) 发送自定义警报。 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：默认 ACM 证书会在到期前的 45 天发送 CloudWatch 事件：Amazon EventBridge support for ACM 客户可以监听此事件，以便在证书续期前必须采取客户行动时收到警报。例如，如果客户添加的 CAA 记录阻止 ACM 更新证书，则 ACM 会在到期前 45 天自动更新失败时发布此事件。如果客户没有采取任何措施，ACM 会在 30 天、15 天、3 天和 1 天时再尝试续期，直到客户采取了措施、证书过期或证书不再符合续期条件为止。每次续期尝试都会发布一个事件。 而修改这个默认的到期时间，需要使用到 AWS Config：当 ACM 导入的证书即将到期时，如何收到通知？ 要创建 AWS Config 规则，请完成下面的步骤： 打开 AWS Config 控制台。 选择规则，然后选择添加规则。 在选择规则类型中，选择添加 AWS 托管规则。 对于 AWS 托管规则，选择 acm-certificate-expiration-check，然后选择下一步。 在参数页上，对于值，在 daysToExpiration 键中输入希望规则调用的天数。 注意：对于接近所输入的天数的到期日期的证书，acm-certificate-expiration-check AWS Config 规则会被标记为 Noncompliant。 选择下一步，然后选择添加规则。 七、MySQL 生产数据库的数据同步到开发数据库某公司运行一个由 MySQL 数据库支持的内部部署应用程序。该公司正在将应用程序迁移到 AWS，以提高应用程序的弹性和可用性。当前的架构显示，在正常运行期间，数据库的读取活动非常频繁。每隔 4 个小时，公司的开发团队就会完全导出生产数据库，以填充暂存环境中的数据库。在此期间，用户会遇到无法接受的应用程序延迟。在程序完成之前，开发团队无法使用暂存环境。解决方案架构师必须推荐能够缓解应用程序延迟问题的替代架构。替换架构还必须让开发团队能够继续使用暂存环境，而不会出现延迟。哪种解决方案能满足这些要求？ ❌ 将亚马逊极光 MySQL 与多 AZ 极光副本一起用于生产。通过使用 mysqldump 实用程序实施备份和还原流程来填充暂存数据库。 ✅ 将亚马逊极光 MySQL 与多 AZ 极光副本一起用于生产。使用数据库克隆按需创建暂存数据库。 使用 Amazon RDS for MySQL 进行多 AZ 部署，并为生产读取副本。将备用实例用于暂存数据库。 使用 Amazon RDS for MySQL 进行多 AZ 部署，并为生产读取副本。通过使用 mysqldump 实用程序实施备份和还原流程来填充暂存数据库。 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：1️⃣ 仍然会造成数据库的查询延迟。而 2️⃣ 是 Create Clone 是官方更推荐的、为（生产等）数据库创造（开发等用途的）备份的方案：Amazon Aurora Fast Database Cloning 八、本地数据传输到 AWS某公司希望将内部部署的数据中心迁移到 AWS。该数据中心托管着一个 SFTP 服务器，其数据存储在一个基于 NFS 的文件系统。服务器上有 200 GB 的数据需要传输。服务器必须托管在使用 Amazon Elastic File System (Amazon EFS) 文件系统的 Amazon EC2 实例上。解决方案架构师应采取哪些步骤组合来自动完成这项任务？(选择两个）。 ❌ 将 EC2 实例启动到与 EFS 文件系统相同的可用性区域。 ✅ 在内部部署数据中心安装 AWS DataSync 代理。 在 EC2 实例上为数据创建辅助 Amazon Elastic Block Store (Amazon EBS) 卷。 手动使用操作系统复制命令将数据推送到 EC2 实例。 ✅ 使用 AWS DataSync 为内部部署 SFTP 服务器创建合适的位置配置。 Use AWS DataSync to create a suitable location configuration for the on-premises SFTP server. 1️⃣ 2️⃣ ❌ -&gt; 2️⃣ 5️⃣ ✅ 💡 解析：EFS 是区域级别（跨可用区）的，这个没有问题。看看 5️⃣ 具体是什么操作：AWS DataSync 入门 步骤 1：注册免费 AWS 账户 步骤 2：了解 DataSync 步骤 3：转到控制台 步骤 4：要在本地存储与 AWS 之间传输数据，请部署代理 步骤 5：创建数据传输任务 通过指定数据传输的源位置和目标位置，并配置要用于传输的任何选项（例如安排任务和启用任务报告）来创建任务。 Create a task by specifying the source location and destination location for your data transfer, and configure any options you want to use with the transfer, such as scheduling the task and enabling task reports. 步骤 6：开始传输 是有位置相关的配置流程的，因此 5️⃣ 需要选择。 九、对未加密的 RDS 实例进行加密某公司正在 AWS 上运行一个在线事务处理 (OLTP) 工作负载。该工作负载使用未加密的 Amazon 多 AZ 部署中的 RDS DB 实例。每天从该实例中提取数据库快照。解决方案架构师应如何确保数据库和快照始终加密？ ✅ 加密最新数据库快照的副本。通过恢复加密快照替换现有数据库实例。 创建新的加密 Amazon Elastic Block Store (Amazon EBS) 卷，并将快照复制到其中。在 DB 实例上启用加密。 ❌ 复制快照并使用 AWS 密钥管理服务 (AWS KMS) 启用加密 恢复加密快照到现有 DB 实例。 将快照复制到使用 AWS 密钥管理服务 (AWS KMS) 管理的密钥 (SSE-KMS) 进行服务器端加密的 Amazon S3 存储桶。 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：加密现有的 Amazon for P RDS ostgre SQL 数据库实例 使用快照进行加密时：拍摄快照 -&gt; 加密快照 -&gt; 还原加密后的快照为加密的数据库实例。 十、单方面连接到其他账户的 VPC 中的服务某公司在 AWS 上运行工作负载。该公司需要连接到外部提供商的一项服务。该服务是在提供商的 VPC 中托管。根据公司安全团队的要求，连接必须是专用的，而且必须仅限于目标服务。连接必须只能从公司的 VPC 启动。哪种解决方案能满足这些要求？ 在公司的 VPC 和提供商的 VPC 之间创建 VPC 对等连接。更新路由表以连接到目标服务。 ❌ 要求提供商在其 VPC 中创建虚拟专用网关。使用 AWS PrivateLink 连接到目标服务。 在公司虚拟机的公共子网中创建一个 NAT 网关更新路由表，以连接到目标服务。 ✅ 要求提供商为目标服务创建一个 VPC 端点。使用 AWS PrivateLink 连接到目标服务。 2️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：How can I use PrivateLink? 作为用户您需要创建VPC端点（由PrivateLink提供支持）来访问服务和资源。这些VPC端点在VPC中显示为具有私有ip的弹性网络接口。一旦创建了这些端点，任何前往这些ip的流量都将被私有地路由到相应的服务或资源。作为服务所有者，您可以通过建立一个网络负载平衡器来为您的服务提供前端服务，并创建一个PrivateLink服务来向网络负载平衡器注册，从而将您的服务装载到AWS PrivateLink。在您允许列出他们的帐户和IAM角色之后，您的客户将能够在他们的VPC内建立端点以连接到您的服务。 十、数据需要滞留在指定区域某公司希望将其内部部署数据中心迁移到 AWS。根据公司的合规要求，公司只能使用 ap-northeast-3 区域。公司管理员不得将 VPC 连接到互联网。哪些解决方案可以满足这些要求？(选择两个）。 ✅ 使用 AWS 控制塔实施数据驻留防护栏，拒绝互联网访问，并拒绝访问除 ap-northeast-3 以外的所有 AWS 区域。 使用 AWS WAF 中的规则阻止互联网访问。在 AWS 账户设置中拒绝访问除 ap-northeast-3 以外的所有 AWS 区域。 ✅ 使用 AWS 组织配置服务控制策略 (SCPS)，防止 VPC 访问互联网。拒绝访问除 ap-northeast-3 以外的所有 AWS 区域。 ❌ 为每个 VPC 中的网络 ACL 创建一条出站规则，拒绝来自 0.0.0.0/0 的所有流量。为每个用户创建 IAM 策略，防止使用除 ap-northeast-3 以外的任何 AWS 区域。 使用 AWS 配置激活受管规则，以检测互联网网关并发出警报，检测部署在 ap-northeast-3 以外的新资源并发出警报。 1️⃣ 4️⃣ ❌ -&gt; 1️⃣ 3️⃣ ✅ 💡 解析：关于 3️⃣ 的正确性：阻止还没有 Internet 访问权的任何 VPC 获取它 此 SCP 阻止任何受影响账户中的用户或角色更改 Amazon EC2 Virtual Private Cloud（VPC）的配置以允许他们直接访问 Internet。它不会阻止现有直接访问或通过您的本地网络环境路由的任何访问。 123456789101112131415161718{ &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Effect&quot;: &quot;Deny&quot;, &quot;Action&quot;: [ &quot;ec2:AttachInternetGateway&quot;, &quot;ec2:CreateInternetGateway&quot;, &quot;ec2:CreateEgressOnlyInternetGateway&quot;, &quot;ec2:CreateVpcPeeringConnection&quot;, &quot;ec2:AcceptVpcPeeringConnection&quot;, &quot;globalaccelerator:Create*&quot;, &quot;globalaccelerator:Update*&quot; ], &quot;Resource&quot;: &quot;*&quot; } ]} 因此 SCP 可以做到控制用户或角色修改 VPC 的配置来联网。 十一、备份 Aurora 数据库长达 5 年某公司在 Amazon Aurora PostgreSQL DB 集群中存储数据。该公司必须将所有数据存储 5 年，并且必须 5 年后删除所有数据。公司还必须无限期地保留在数据库中执行的操作的审计日志。目前，公司已为 Aurora 配置了自动备份。为满足这些要求，解决方案架构师应采取哪些步骤组合？(选择两个）。 手动快照数据库群集。 ❌ 为自动备份创建生命周期策略。 配置自动备份保留 5 年。 ✅ 为数据库群集配置 Amazon CloudWatch 日志导出。 ✅ 使用 AWS 备份进行备份，并将备份保存 5 年。 2️⃣ 4️⃣ ❌ -&gt; 4️⃣ 5️⃣ ✅ 💡 解析：Aurora 数据库的自动备份最多保留 35 天：备份和还原 Aurora 数据库集群的概述 Aurora 自动备份您的集群卷并将还原数据保留备份保留期的时长。Aurora 自动备份是连续和递增的，您可以快速还原到备份保留期内的任何时间点。在写入备份数据时，不会发生任何性能影响或数据库服务中断。在创建或修改数据库集群时，可指定备份保留期（1 天到 35 天）。 因此 2️⃣ 和 3️⃣ 均错误。","link":"/2024/12/15/saa_test_daily_20241215/"},{"title":"SAA 考试每日练习 - 2024&#x2F;12&#x2F;16","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam160 题 (No.161 ~ No.320) 只记录了 12 道错误或需要注意的题目，仅供自己复习使用。如果侵权请联系删除。 一、CloudFront 字段级加密解决方案架构师正在为一个应用程序创建一个新的 Amazon CloudFront 分发。提交的部分信息是敏感的。应用程序使用 HTTPS，但需要另一层安全保护。敏感信息应在整个应用堆栈中受到保护，信息的访问应仅限于某些应用。解决方案架构师应采取哪些行动？ 配置 CloudFront 签名 URL。 配置 CloudFront 签名 cookie。 ✅ 配置 CloudFront 字段级加密 (field-level encryption) 配置文件。 配置 CloudFront 并将 “查看器协议策略 “的 “源协议策略 “设置设为 “仅限 HTTPS”。 3️⃣ ✅ 💡 解析：使用字段级加密帮助保护敏感数据 借助 Amazon CloudFront，您可以使用 HTTPS 对与源服务器的端到端连接实施保护。字段级加密增加了一个额外的安全保护层，可让您在整个系统处理过程中保护特定的数据，以便只有某些应用程序才能查看它。 借助字段级加密，您可以让您的用户安全地向您的 Web 服务器上传敏感信息。用户提供的敏感信息在靠近用户的边缘进行加密，并在整个应用程序堆栈中保持加密状态。此加密确保只有需要数据的应用程序（并且具有用于解密的凭证）能够做到这一点。 二、数据库的读写能力扩展一家公司正在建设一个新的动态订购网站。该公司希望最大限度地减少服务器维护和修补工作。网站必须具有高可用性，并且必须尽快扩展读写能力，以满足用户需求的变化。哪种解决方案能满足这些要求？ ✅ 在亚马逊 S3 中托管静态内容。使用 Amazon API Gateway 和 AWS Lambda 托管动态内容。使用具有按需容量的 Amazon DynamoDB 作为数据库。配置 Amazon CloudFront 以交付网站内容。 ❌ 在亚马逊 S3 中托管静态内容。使用 Amazon API Gateway 和 AWS Lambda 托管动态内容。使用具有 Aurora Auto Scaling 功能的 Amazon Aurora 数据库。配置 Amazon CloudFront 以交付网站内容。 将所有网站内容托管到亚马逊 EC2 实例上。创建一个自动扩展组来扩展 EC2 实例。使用应用程序负载平衡器来分配流量。使用 Amazon DynamoDB 为数据库提供写入容量。 将所有网站内容托管到亚马逊 EC2 实例上。创建一个自动扩展组来扩展 EC2 实例。使用应用程序负载平衡器来分配流量。使用 Amazon Aurora 和 Aurora Auto Scaling 扩展数据库。 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：Amazon Aurora Auto Scaling 只能扩展读副本，而无法扩展写副本来提高写的能力：Amazon Aurora Auto Scaling 与 Aurora 副本结合使用 为了满足您的连接和工作负载要求，Aurora Auto Scaling 动态调整为 Aurora 数据库集群预调配的 Aurora 副本数（读取器数据库实例）。Aurora Auto Scaling 适用于 Aurora MySQL 和 Aurora PostgreSQL。通过使用 Aurora Auto Scaling，Aurora 数据库集群可以处理连接或工作负载突然增加的情况。在连接或工作负载减少时，Aurora Auto Scaling 删除不需要的 Aurora 副本，以便您无需为未使用的配置数据库实例付费。 Aurora Auto Scaling 不适用于写入器数据库实例上的工作负载。Aurora Auto Scaling 只能协助处理读取器实例上的工作负载。 而关于 Amazon DynamoDB 的两种模式：DynamoDB 按需容量模式 按需模式 (On-demand mode) - 动态扩容 Amazon DynamoDB 按需模式是一个无服务器计费选项，可以每秒处理数百万个请求而不需要进行容量规划。 DynamoDB 按需模式针对读取和写入请求提供按请求支付定价，您只需为使用的资源付费。对于按需模式表，您无需指定预期应用程序执行的读写吞吐量。 预置模式 (Provisioned mode) - 控制成本 在预置模式下，您为应用程序指定所需的每秒读取和写入次数。即使您未充分利用预置容量，也需要为吞吐能力付费。 系统将根据您已预置的每小时读取和写入容量向您收费。您可以使用自动扩缩根据流量变化自动调整表的预置容量。这可帮助您控制您对 DynamoDB 的使用，使之保持或低于定义的请求速率，以便获得成本可预测性。 三、Lambda 和 Beanstalk 支持的编程语言某公司有一个在内部 Windows 服务器上运行的 Microsoft .NET 应用程序。该应用程序使用 Oracle 数据库标准版服务器存储数据。该公司正计划迁移到 AWS，并希望在迁移应用程序时尽量减少开发变更。AWS 应用程序环境应具有高可用性。公司应采取哪些行动组合来满足这些要求？(选择两项）。 ❌ 使用运行 .NET Core 的 AWS Lambda 函数将应用程序重构为无服务器应用程序。 ✅ 在 AWS Elastic Beanstalk 中重新托管应用程序，并在多区域部署中使用 .NET 平台。 使用 Amazon Linux Amazon Machine Image (AMI) 将应用程序重新平台化，以便在 Amazon EC2 上运行。 使用 AWS 数据库迁移服务 (AWS DMS) 在多 AZ 部署中将 Oracle 数据库迁移到 Amazon DynamoDB。 ✅ 使用 AWS 数据库迁移服务 (AWS DMS) 在多区域部署中将 Oracle 数据库迁移到 Amazon RDS 上的 Oracle 数据库。 1️⃣ 5️⃣ ❌ -&gt; 2️⃣ 5️⃣ ✅ 💡 解析：Lambda 支持的编程语言：AWS Lambda 支持哪些语言？ AWS Lambda 原生支持 Java、Go、PowerShell、Node.js、C＃、Python 和 Ruby 代码，并提供 Runtime API，允许您使用任何其他编程语言来编写函数。有关使用 Node.js、Python、Java、Ruby、C#、Go 和 PowerShell 的信息，请参阅我们的文档。 同时它还在 24 年 2 月支持了 .NET 8：Introducing the .NET 8 runtime for AWS Lambda AWS Lambda 现在支持作为托管运行时和容器基础映像的 .NET 8。 再来看看 Elastic Beanstalk：AWS Elastic Beanstalk 支持哪些语言和开发堆栈？ AWS Elastic Beanstalk 支持以下语言和开发堆栈： 适用于 Jave 应用程序的 Apache Tomcat 适用于 PHP 应用程序的 Apache HTTP Server 适用于 Python 应用程序的 Apache HTTP Server Node.js 应用程序的 Nginx 或 Apache HTTP 服务器 适用于 Ruby 应用程序的 Passenger 或 Puma 适用于 .NET 应用程序的 Microsoft IIS 7.5、8.0 和 8.5 Java SE Docker Go 请参阅“支持的平台”，查看支持的语言和开发堆栈的最新完整列表。 选 2️⃣ 更加稳妥。 四、Amazon Transcribe 和 Amazon Translate 面对多语种一家电话营销公司正在 AWS 上设计其客户呼叫中心功能。该公司需要一个能提供多语种识别并生成转录文件的解决方案。该公司希望查询转录文件以分析业务模式。出于审计目的，副本文件必须存储 7 年。哪种解决方案能满足这些要求？ 使用 Amazon Rekognition 进行多说话者识别。将文本文件存储在亚马逊 S3 中。使用机器学习模型进行转录文件分析。 ✅ 使用 Amazon Transcribe 进行多语种识别。使用 Amazon Athena 进行文本文件分析。 ❌ 使用 Amazon Translate 进行多语种识别。将转录文件存储在 Amazon Redshift 中。使用 SQL 查询进行转录文件分析。 使用 Amazon Rekognition 进行多说话者识别。将文本文件存储在亚马逊 S3 中。使用 Amazon Textract 进行文本文件分析 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：需要完成题目的需求，要两个功能语音转录和翻译。Amazon Translate 是单纯的语言翻译 AI 服务：什么是 Amazon Translate？ 应用场景 通过集成 Amazon Translate 在您的应用程序中实现多语言用户体验： 翻译公司撰写的内容，如会议纪录、技术报告、知识库文章、帖子等。 翻译人际通讯内容，如电子邮件、游戏内聊天、客户服务聊天，以便客户和员工能够通过其首选语言进行联系。 处理和管理贵公司的传入数据： 以多种语言分析文本，如社交媒体和新闻推送。 以多种语言搜索信息，如 eDiscovery 案例信息。 通过将 Amazon Translate 与其他 AWS 服务集成，以实现语言无关的处理： 使用 Amazon Comprehend，从社交媒体流等非结构化文本中提取指定的实体、情绪和关键短语。 使用 Amazon Transcribe，以多种语言提供字幕和实时字幕。 因此它当然能胜任多语种的识别功能，但是没法完成语音转录功能。 但是相比之下，Amazon Transcribe 可以同时识别多语种并转录文本：Amazon Transcribe 现已支持对多语音频执行自动语言识别 Amazon Transcribe 是一项自动语音识别（ASR）服务，使您能够轻松地为应用程序添加语音转文本功能。今天，我们很高兴地宣布推出以批处理模式对多语音频执行自动语言识别的功能。如果您的录音不止包含一种语言，您便可以启用多语言识别，该功能可识别音频文件中的所有语言，并使用每种识别到的语言来创建脚本。 因此 2️⃣ 更好。 五、短信回复 &amp; 市场营销某公司正在开发一项针对移动应用程序用户的营销传播服务。公司需要用短信服务（SMS）向用户发送确认信息。用户必须能够回复短信。公司必须将回复信息存储一年，以供分析。解决方案架构师应如何满足这些要求？ 创建 Amazon Connect 联系流以发送短信。使用 AWS Lambda 处理响应。 ✅ 构建 Amazon Pinpoint 旅程。配置 Amazon Pinpoint，将事件发送到 Amazon Kinesis 数据流，以便进行分析和存档。 使用亚马逊简单队列服务（Amazon SQS）分发短信。使用 AWS Lambda 处理响应。 创建一个 Amazon Simple Notification Service (Amazon SNS) FIFO 主题。将 Amazon Kinesis 数据流订阅到 SNS 主题，以便进行分析和存档。 2️⃣ ✅ 💡 解析：Amazon Connect 是客服中心：什么是 Amazon Connect？ Amazon Connect 是一款基于人工智能的应用程序，可为您的联络中心客户和用户提供无缝体验。它由跨沟通渠道的一整套功能组成。 使用直观的 Web 应用程序（ Amazon Connect 管理网站），您只需几个步骤即可设置联络中心，添加位于任何地方的客服，然后开始与客户互动。您可以在几分钟（而不是数月）内进行创新并做出改变。无需编码。 而 Amazon Pinpoint 是市场营销工具，可以支持通知、电子邮件、短信和语音消息：什么是 Amazon Pinpoint？ Amazon Pinpoint 是一项 AWS 服务，您可以使用它通过多个消息渠道与客户互动。您可以使用 Amazon Pinpoint 发送推送通知、电子邮件、SMS短信或语音消息。 六、接口端点支持安全组而网关端点不支持安全组一家公司需要将数据从 Amazon EC2 实例转移到 Amazon S3 存储桶。公司必须确保不通过公共互联网路由进行 API 调用和数据传输。只有 EC2 实例有权将数据上传到 S3 存储桶。哪种解决方案能满足这些要求？ ✅ 在 EC2 实例所在的子网中为 Amazon S3 创建一个接口 VPC 端点。为 S3 存储桶附加资源策略，只允许 EC2 实例的 IAM 角色访问。 ❌ 在 EC2 实例所在的可用区为 Amazon S3 创建一个网关 VPC 端点。为端点附加适当的安全组。为 S3 存储桶附加资源策略，只允许 EC2 实例的 IAM 角色访问。 在 EC2 实例内部运行 nslookup 工具，获取 S3 存储桶服务 API 端点的私有 IP 地址。在 VPC 路由表中创建一个路由，以便 EC2 实例访问 S3 存储桶。为 S3 存储桶附加一个资源策略，只允许 EC2 实例的 IAM 角色访问。 使用 AWS 提供的公开可用的 ip-ranges.json 文件，获取 S3 存储桶服务 API 端点的私有 IP 地址。在 VPC 路由表中创建一个路由，以便 EC2 实例访问 S3 存储桶。为 S3 存储桶附加一个资源策略，只允许 EC2 实例的 IAM 角色访问。 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：EC2 的数据要走私网传输到 S3 存储桶中。社区在 1️⃣ 和 2️⃣ 争议较大。争议的重点在于 2️⃣ 的 “Attach appropriate security groups to the endpoint” 这句，将适当的安全组附加到终端节点上。如果它可以实现，那么 2️⃣ 显然是最优选择，但如果它无法实现，那就只能选 1️⃣。使用接口 VPC 端点访问 AWS 服务 前提条件为端点网络接口 (endpoint network interface) 创建一个安全组，允许来自 VPC 资源的预期流量。例如，为确保 AWS CLI 可以向 AWS 服务 发送 HTTPS 请求，安全组必须允许入站 HTTPS 流量。 首先我们明确 interface VPC endpoint 是可以配置安全组的。实测了下也确实： 那么网关端点呢？很遗憾的是 AWS 的文档里并没有明说，实践看下吧：创建过程中和创建完成后都没有安全组相关配置，因此得出结论 Gateway endpoint 不支持安全组配置，选 1️⃣。 七、Aurora 的跨区域副本某公司在应用程序负载平衡器后面的 Amazon EC2 实例上运行一个全球网络应用程序。该应用程序在 Amazon Aurora 中存储数据。该公司需要创建一个灾难恢复解决方案，并能承受长达 30 分钟的停机时间和潜在的数据丢失。当主基础设施健康时，该解决方案无需处理负载。解决方案架构师应如何满足这些要求？ ✅ 在所需基础架构元素到位的情况下部署应用程序。使用 Amazon Route 53 配置主动-被动故障切换。在第二个 AWS区域创建 Aurora 复制。 在第二个 AWS 区域托管应用程序的缩减部署。使用 Amazon Route 53 配置主动-主动故障切换。在第二个区域创建 Aurora 复制。 在第二个 AWS 区域复制主基础设施。使用 Amazon Route 53 配置主动-主动故障切换。创建一个从最新快照还原的 Aurora 数据库。 ❌ 使用 AWS 备份备份数据。使用备份在第二个 AWS 区域创建所需的基础架构。使用 Amazon Route 53 配置主动-被动故障切换。在第二个区域创建 Aurora 第二个主实例。 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：1️⃣ 和 4️⃣ 当然都能解决问题。着重看下 Aurora 数据库能否创建跨区域副本：Cross-Region Aurora Replicas 使用 Amazon Aurora MySQL-Compatible 版群集，您可以使用跨区域 Aurora Replicas，通过数据库引擎本机复制机制在另一个 AWS 区域创建主 DB 群集的副本。Aurora MySQL-兼容版使用二进制日志（binlog）复制。这种复制基于变更数据捕获（CDC）流程。CDC 识别并跟踪数据库中的数据变化。对主数据库的更改会记录在更改日志文件中，该文件会传输到在第二区域运行 Aurora 复制的机器上。第二台机器上的一个进程读取这些更改日志并生成 SQL 语句，然后将其应用到第二台数据库中。 下图显示了跨区域 Aurora 复制的高级架构。 Aurora MySQL-兼容集群最多可通过这种方式创建五个读取副本，每个副本位于不同的区域。Aurora PostgreSQL-Compatible 不支持跨区域 Aurora 复制。不过，对于 Aurora PostgreSQL DB 集群，您可以使用 Aurora 全局数据库。 因此得出结论： Amazon Aurora MySQL-Compatible cluster（注意一定要是 MySQL 兼容且是集群）可以创建跨区域的只读副本。 Aurora PostgreSQL-Compatible 不支持跨区域副本，但是可以通过全球数据库实现一样的效果。 而针对全球数据库的拓展：使用 Amazon Aurora Global Database Amazon Aurora Global Database 跨越多个 AWS 区域，可实现低延迟的全局读取，并可从可能影响整个 AWS 区域 的罕见停机事件中快速恢复。一个 Aurora 全局数据库在一个区域中有一个主数据库集群，在不同区域中最多有五个辅助（只读）数据库集群。 Aurora Global Database 在某些 AWS 区域 可用，且仅适用于特定 Aurora MySQL 和 Aurora PostgreSQL 版本 八、监控到 EC2 的 SSH 或 RDP 连接某公司在 Amazon EC2 实例上为客户运行演示环境。每个环境都隔离在自己的 VPC 中。当对某个环境建立 RDP 或 SSH 访问时，公司的运营团队需要得到通知。 配置 Amazon CloudWatch Application Insights，以便在检测到 RDP 或 SSH 访问时创建 AWS Systems Manager OpsItems。 ❌ 使用 IAM 实例配置文件配置 EC2 实例，该配置文件具有 IAM 角色，并附加了 AmazonSSMManagedInstanceCore 策略。 ✅ 将 VPC 流量日志发布到 Amazon CloudWatch Logs。创建所需的度量过滤器。创建 Amazon CloudWatch 指标警报，并在警报处于 ALARM 状态时执行通知操作。 配置 Amazon EventBridge 规则，以监听 EC2 Instance 状态更改通知类型的事件。将 Amazon Simple Notification Service (Amazon SNS) 主题配置为目标。将操作团队订阅到主题。 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：SSH 连接与 RDP 连接需要手动进行监控：How to Monitor and Visualize Failed SSH Access Attempts to Amazon EC2 Linux Instances 下面是该流程的工作原理，如上图所示并进行了编号： 每个 EC2 实例上都运行一个 CloudWatch 日志代理。代理被配置为从 EC2 实例向由实例 ID 标识的日志流发送 SSH 日志。 日志流汇总到一个日志组中。这样，一个日志组就包含了要分析的来自一个或多个实例的所有日志。 您可将度量筛选器应用到日志组，以搜索特定关键字。当度量过滤器找到特定关键字时，过滤器会在一个基于时间的滑动窗口中计算关键字的出现次数。如果关键字的出现次数超过 CloudWatch 警报阈值，则会触发警报。 IAM 策略定义了一个角色，该角色允许 EC2 服务器在日志组中创建日志，并将日志事件（新日志条目）从 EC2 发送到日志组。然后由应用程序服务器承担该角色。 当超过指定阈值时，CloudWatch 警报会通知用户。 例如，您可以设置一个警报，当 5 分钟内发生超过 2 次 SSH 连接失败时触发该警报。 CloudWatch 面板用于可视化监控过程中的数据和警报。 九、RDS for MySQL 只读副本创建前的工作某公司在亚马逊 RDS for MySQL 中部署了一个数据库。由于交易量增加，数据库支持团队正在报告数据库实例读取速度慢，建议添加读取副本。在实施这一变更之前，解决方案架构师应采取哪些行动组合？(选择两项）。 ❌ 在 RDS 主节点上启用 binlog 复制。 为源 DB 实例选择故障转移优先级。 ✅ 允许在源 DB 实例上完成长期运行的事务。 创建一个全局表，并指定该表可用的 AWS 区域。 ✅ 通过将备份保留期设置为 0 以外的值，在源实例上启用自动备份。 1️⃣ 3️⃣ ❌ -&gt; 3️⃣ 5️⃣ ✅ 💡 解析：没有找到与 5️⃣ 相关的文档，强行记忆吧：“RDS 数据库跨区域副本建立前，需要启用原实例的自动备份”。 十、Route 53 简单路由策略和故障转移路由策略某公司有一个网络应用程序，由 10 个 Amazon EC2 实例托管，流量由 Amazon Route 53 引导。该公司在尝试浏览应用程序时偶尔会出现超时错误。网络团队发现，一些 DNS 查询会返回不健康实例的 IP 地址，从而导致超时错误。解决方案架构师应如何克服这些超时错误？ 为每个 EC2 实例创建 Route 53 简单路由策略记录。为每个记录关联一个健康检查。 ❌ 为每个 EC2 实例创建 Route 53 故障转移路由策略记录。为每个记录关联健康检查。 创建一个以 EC2 实例为起源的 Amazon CloudFront 分发。将健康检查与 EC2 实例关联。 ✅ 在 EC2 实例前创建带健康检查的应用程序负载平衡器 (ALB)。从 Route 53 路由到 ALB。 2️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：4️⃣ 显然是更完美的答案。故障转移路由 故障转移路由允许您将流量路由到某个资源 (如果该资源正常) 或路由到其他资源 (如果第一个资源不正常)。主和辅助记录可以将流量路由到从配置为网站的 Amazon S3 存储桶到复杂记录树的任何目的地 路由简单 简单路由允许您配置标准DNS记录，无需特殊的 Route 53 路由，例如加权路由或延迟。使用简单路由，您通常将流量路由到单个资源，例如，路由到您网站的 Web 服务器。 需要注意的是：⚠ 简单路由策略 (Simple routing policy) 无法附加健康状况检查。 十一、Aurora 全局数据库的 Pilot Light Deployment一家快速发展的电子商务公司正在单一 AWS 区域中运行其工作负载。解决方案架构师必须创建一个灾难恢复 (DR) 战略包括不同的 AWS 区域。该公司希望其数据库能够在灾难恢复区域以尽可能小的延迟进行更新。灾难恢复区域中的其余基础设施需要以较低的容量运行，并且必须能够在必要时进行扩展。哪种解决方案能以最短的恢复时间目标（RTO）满足这些要求？ 使用 Amazon Aurora 全局数据库，进行轻量级试点部署。 ✅ 使用 Amazon Aurora 全局数据库和暖备用部署。 使用 Amazon RDS Multi-AZ DB 实例进行轻量级部署。 使用带有热备用部署的 Amazon RDS Multi-AZ DB 实例。 2️⃣ ✅ 💡 解析：先看看各容灾方案的 RTO：云中的灾难恢复选项 从低成本、低复杂性的制作备份到使用多个活动区域的较复杂策略，可在 AWS 中使用的灾难恢复策略大致分为四种方法。定期测试灾难恢复策略至关重要，这样您就有信心在必要时启用该策略。 其中关于 Pilot Light：Pilot light 利用 Pilot Light 方法，您可以将数据从一个区域复制到另一个区域，并预置核心工作负载基础设施的副本。支持数据复制和备份所需的资源（如数据库和对象存储）始终处于开启状态。其他元素（例如应用程序服务器）加载了应用程序代码和配置，处于关闭状态，仅在测试期间或调用灾难恢复故障转移时使用。不同于备份与还原方法，您的核心基础设施始终可用，而且您始终可以选择通过打开和横向扩展应用程序服务器来快速预置完整的生产环境。 可以理解它是一种只配置架构不启动实例的容灾方式。 十二、EC2 实例上的漏洞扫描一家公司的内部数据中心发生了一起影响多个应用程序的漏洞事件。攻击者利用了服务器上运行的自定义应用程序中的漏洞。该公司目前正在将其应用程序迁移到亚马逊 EC2 实例上运行。该公司希望实施一种解决方案，主动扫描 EC2 实例上的漏洞，并发送报告详细说明发现的情况。哪种解决方案能满足这些要求？ 部署 AWS Shield 扫描 EC2 实例以查找漏洞。创建一个 AWS Lambda 函数，将任何发现记录到 AWS CloudTrail。 部署 Amazon Macie 和 AWS Lambda 功能，扫描 EC2 实例以查找漏洞。将任何发现记录到 AWS CloudTrail。 ❌ 打开 Amazon GuardDuty。将 GuardDuty 代理部署到 EC2 实例。配置 AWS Lambda 函数，以自动生成和分发详细说明调查结果的报告。 ✅ 打开 Amazon Inspector。将 Amazon Inspector 代理部署到 EC2 实例。配置 AWS Lambda 函数，以自动生成和分发详细说明调查结果的报告。 3️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：Amazon GuardDuty 是以 AWS 账号为对象的安全检测服务。 GuardDuty 为您提供准确的账户盗用威胁检测，如果您没有以近乎实时的方式持续监控相关因素，可能难以快速发现这种情况。GuardDuty 可检测出账户盗用的迹象，例如在一天之中的非典型时间从异常地理位置访问 AWS 资源。对于编程 AWS 账户，GuardDuty 能够检查异常 API 调用，例如试图通过禁用 CloudTrail 日志记录或从恶意 IP 地址创建数据库快照掩盖账户活动。 Amazon Inspector 是漏洞检测服务：Amazon Inspector 是什么？ Amazon Inspector 是一项漏洞管理服务，可自动发现工作负载并持续扫描工作负载以查找软件漏洞和意外网络泄露。","link":"/2024/12/16/saa_test_daily_20241216/"},{"title":"SAA 考试每日练习 - 2024&#x2F;12&#x2F;17","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam160 题 (No.321 ~ No.480) 只记录了 13 道错误或需要注意的题目，仅供自己复习使用。如果侵权请联系删除。 一、Amazon Cognito 身份池的自定义属性映射某公司通过 Amazon S3 存储桶托管一个网络应用程序。该应用程序使用 Amazon Cognito 作为身份提供程序来验证用户身份，并返回一个 JSON Web 令牌 (JWT)，该令牌可提供对存储在另一个 S3 存储桶中的受保护资源的访问权限。在部署应用程序时，用户会报告错误，并且无法访问受保护的内容。解决方案架构师必须通过提供适当的权限来解决这个问题，这样用户才能访问受保护的内容。哪种解决方案能满足这些要求？ ✅ 更新 Amazon Cognito 身份池，以承担访问受保护内容的适当 IAM 角色。 更新 S3 ACL，允许应用程序访问受保护的内容。 将应用程序重新部署到 Amazon S3，以防止 S3 存储桶中最终一致的读取影响用户访问受保护内容的能力。 ❌ 更新 Amazon Cognito 池，以便在身份池中使用自定义属性映射，并授予用户访问受保护内容的适当权限。 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：1️⃣ 和 4️⃣ 都能完成题目需求，且 4️⃣ 对权限控制的粒度更细：将属性用于访问控制 访问控制的属性是 Amazon Cognito 身份池实现的基于属性的访问控制 ()。ABAC您可以使用IAM策略根据用户属性控制通过 Amazon Cognito 身份池访问 AWS 资源。可以从社交和企业身份提供商那里获得这些属性。您可以将提供商的访问权限和 ID 令牌或SAML断言中的属性映射到可在IAM权限策略中引用的标签。 您可以选择默认映射或在 Amazon Cognito 身份池中创建自己的自定义映射。默认映射允许您根据一组固定的用户属性编写IAM策略。自定义映射允许您选择IAM权限策略中引用的一组自定义用户属性。Amazon Cognito 控制台中的属性名称映射到主体的标签密钥，即IAM权限策略中引用的标签。 例如，假设您拥有一个具有免费和付费会员资格的媒体流式传输服务。您可以将媒体文件存储在 Amazon S3 中，并使用免费或高级标签对其贴标签。您可以将属性用于访问控制，以允许访问基于用户会员级别（这是用户配置文件的一部分）的免费和付费内容。您可以将成员资格属性映射到标签密钥，以便委托人传递给IAM权限策略。通过这种方式，您可以创建单个权限策略，并根据会员级别的值和内容文件上的标签有条件地允许对高级内容的访问。 通过不同的自定义属性来区分不同等级的会员，以使他们能够访问不同权限要求的资源。 二、Amazon Aurora Global Database headless clusters（全局数据库无头集群）解决方案架构师必须为大容量软件即服务（SaaS）平台创建灾难恢复（DR）计划。该平台的所有数据都存储在 Amazon Aurora MySQL DB 集群中。灾难恢复计划必须将数据复制到辅助 AWS 区域。哪种解决方案能以最具成本效益的方式满足这些要求？ 使用 MySQL 二进制日志复制到辅助区域中的 Aurora 群集。为辅助区域中的 Aurora 群集提供一个 DB 实例。 ✅ 为 DB 集群设置 Aurora 全局数据库。设置完成后，从二级区域中删除 DB 实例。 使用 AWS 数据库迁移服务 (AWS DMS) 将数据持续复制到辅助区域中的 Aurora 群集。从辅助区域删除 DB 实例。 为 DB 集群设置 Aurora 全局数据库。在辅助区域中至少指定一个 DB 实例。 2️⃣ ✅ 💡 解析：在辅助区域中创建无管控 Aurora 数据库集群 尽管 Aurora Global Database 要求在与主区域之外的不同 AWS 区域 中至少有一个辅助 Aurora 数据库集群，但您可以对辅助集群使用无管控配置。无管控辅助 Aurora 数据库集群是没有数据库实例的集群。此类型的配置可以降低 Aurora 全局数据库的开支。在 Aurora 数据库集群中，计算和存储是分离的。如果没有数据库实例，您就无需为计算付费，而只需为存储付费。如果设置正确，无管控辅助存储卷将与主 Aurora 数据库集群保持同步。 在主 Aurora 数据库集群开始复制到辅助数据库集群之后，您可以从辅助 Aurora 数据库集群中删除该 Aurora 只读数据库实例。此辅助集群现在被视为“无管控”集群，因为其不再有数据库实例。即使辅助集群中没有任何数据库实例，Aurora 也会将存储卷与主 Aurora 数据库集群保持同步。 三、SNS 和 SQS 的传输中与静态加密一家医院正在设计一个收集病人症状的新应用程序。医院决定在架构中使用亚马逊简单队列服务（Amazon SQS）和亚马逊简单通知服务（Amazon SNS）。解决方案架构师正在审查基础设施设计。数据在静态和传输过程中都必须加密。只有医院的授权人员才能访问数据。解决方案架构师应采取哪些步骤组合来满足这些要求？(选择两个）。 在 SQS 组件上开启服务器端加密。更新默认密钥策略，将密钥使用限制为一组授权委托人。 ✅ 使用 AWS 密钥管理服务 (AWS KMS) 客户管理的密钥，开启 SNS 组件的服务器端加密。应用密钥策略，将密钥的使用限制在一组授权委托人范围内。 打开 SNS 组件的加密功能。更新默认密钥策略，将密钥使用限制为一组授权委托人。在主题策略中设置一个条件，只允许通过 TLS 进行加密连接。 ✅ 使用 AWS 密钥管理服务 (AWS KMS) 客户管理的密钥，开启 SQS 组件的服务器端加密。应用密钥策略，将密钥的使用限制在一组授权委托人范围内。在队列策略中设置一个条件，只允许通过 TLS 进行加密连接。 使用 AWS 密钥管理服务 (AWS KMS) 客户管理的密钥，开启 SQS 组件的服务器端加密。应用 IAM 策略，将密钥的使用限制在一组授权委托人范围内。在队列策略中设置一个条件，只允许通过 TLS 进行加密连接。 2️⃣ 4️⃣ ✅ 💡 解析：SNS 强制要求使用安全协议操作相关 API，这已经实现了传输中加密：Amazon 的基础设施安全 SNS 使用 AWS API操作SNS通过网络访问 Amazon。客户端必须支持传输层安全 (TLS) 1.2 或更高版本。 SNS 支持使用 KMS 中的密钥对消息进行静态加密：使用服务器端加密保护 Amazon SNS 数据 服务器端加密 (SSE) 允许您使用在 AWS Key Management Service (AWS KMS) 中管理的密钥保护 Amazon 主题中的消息内容，从而将敏感数据存储在加密SNS主题中。SSE Amazon SNS 收到消息后立即对其进行加密。消息以加密形式存储，仅在发送时才解密。 SQS 也强制了需要使用安全协议：Amazon SQS 中的基础设施安全性 您可以使用 AWS 已发布的 API 操作通过网络访问 Amazon SQS。客户端必须支持传输层安全性（TLS）1.2 或更高版本。 SQS 当然也支持使用 KMS 中的密钥对消息进行静态加密：Amazon 中的静态加密 SQS 服务器端加密 (SSE) 允许您在加密队列中传输敏感数据。SSE使用SQS管理的加密密钥 (SSE-SQS) 或在 (-) 中管理的密钥保护队列中的 AWS Key Management Service 邮件内容。SSE KMS有关SSE使用进行管理的信息 AWS Management Console，请参阅以下内容： 配置 SSE-SQS 用于队列（控制台） 配置 SSE-KMS 用于队列（控制台） 四、API Gateway API 的 API 鉴权一家公司的网络应用程序由亚马逊 API Gateway API 和 AWS Lambda 函数以及亚马逊 DynamoDB 数据库。Lambda 函数处理业务逻辑，DynamoDB 表托管数据。应用程序使用 Amazon Cognito 用户池来识别应用程序的单个用户。解决方案架构师需要更新应用程序，以便只有订阅的用户才能访问高级内容。哪种解决方案能以最少的运行开销满足这一要求？ 在 API Gateway API 上启用 API 缓存和节流。 ❌ 在 API Gateway API 上设置 AWS WAF。创建一条规则，过滤已订阅的用户。 对 DynamoDB 表中的高级内容应用细粒度 IAM 权限。 ✅ 实施 API 使用计划和 API 密钥，限制未订阅用户的访问权限。 2️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：API 密钥和使用计划的最佳实践 以下是使用 API 密钥和使用计划时要遵循的建议的最佳实践。 请勿使用 API 密钥进行身份验证或授权以控制对 API 的访问权限。如果您在一个使用计划中有多个 API，则具有该使用计划中的一个 API 的有效 API 密钥的用户可以访问该使用计划中的所有 API。相反，要控制对 API 的访问权限，请使用 IAM 角色、Lambda 授权方或 Amazon Cognito 用户群体。 使用 API Gateway 生成的 API 密钥。API 密钥不应包含机密信息；客户端通常使用可记录的标头传输这些信息。 如果您使用开发人员门户发布 API，请注意，给定使用计划中的所有 API 均可由客户订阅，即使您尚未向您的客户显示它们。 在某些情况下，客户端可能会超过您设置的配额。不要依靠使用计划来控制成本。考虑使用 AWS Budgets 监控成本和 AWS WAF 来管理 API 请求。 将 API 密钥添加到使用计划后，更新操作可能需要几分钟才能完成。 五、跨 VPC 组网并连接到本地数据中心某公司在 us-east-1 区域内的三个独立 VPC 中运行多个业务应用程序。这些应用程序必须能够在 VPC 之间进行通信。这些应用程序还必须能够每天持续向在单个内部数据中心运行的延迟敏感型应用程序发送数百千兆字节的数据。解决方案架构师需要设计一个网络连接解决方案，最大限度地提高成本效益。哪种解决方案能满足这些要求？ 配置三个从数据中心到 AWS 的 AWS 站点到站点 VPN 连接。通过为每个 VPC 配置一个 VPN 连接来建立连接。 在每个 VPC 中启动第三方虚拟网络设备。在数据中心和每个虚拟设备之间建立 IPsec VPN 通道。 ❌ 从数据中心到 us-east-1 中的 Direct Connect 网关设置三个 AWS Direct Connect 连接。通过配置每个 VPC 以使用其中一个 Direct Connect 连接来建立连接。 ✅ 建立一个从数据中心到 AWS 的 AWS Direct Connect 连接。创建一个中转网关，并将每个 VPC 附加到中转网关。在 Direct Connect 连接和中转网关之间建立连接。 3️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：架构 3：AWS Transit Gateway 需要注意的是 Transit Gateway 并不是包含在任意 VPC 内部的。 六、弹性扩展 RDS DB 实例一家公司正在将其内部工作负载迁移到 AWS 云。该公司已经使用了几个 Amazon EC2 实例和 Amazon RDS DB 实例。该公司需要一个能在工作时间外自动启动和停止 EC2 实例和 DB 实例的解决方案。该解决方案必须最大限度地降低成本和基础设施维护成本。哪种解决方案能满足这些要求？ ❌ 使用弹性调整 EC2 实例的大小。在工作时间外将 DB 实例扩展为零。 在 AWS Marketplace 探索合作伙伴解决方案，这些解决方案将按计划自动启动和停止 EC2 实例和 DB 实例。 启动另一个 EC2 实例。配置 crontab 计划，运行 shell 脚本，按计划启动和停止现有 EC2 实例和 DB 实例。 ✅ 创建一个 AWS Lambda 函数，用于启动和停止 EC2 实例和 DB 实例。配置 Amazon EventBridge 以按计划调用 Lambda 函数。 1️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：弹性扩展无法将 DB 实例的个数缩小为 0。虽然我没有找到实际的文档，但是可以理解吧，毕竟停止后如何建立新的数据库连接呢。 七、对不需要本地存储的 EC2 实例进行备份某公司需要为其三层无状态网络应用程序制定备份策略。网络应用程序在自动扩展组中的 Amazon EC2 实例上运行，该组具有动态扩展策略，可对扩展事件做出响应。数据库层在 PostgreSQL 的 Amazon RDS 上运行。网络应用程序不需要 EC2 实例上的临时本地存储。公司的恢复点目标 (RPO) 为 2 小时。备份策略必须最大限度地提高该环境的可扩展性并优化资源利用率。哪种解决方案能满足这些要求？ 每 2 小时对 EC2 实例和数据库的 Amazon Elastic Block Store (Amazon EBS) 卷进行快照，以满足 RPO 要求。 配置快照生命周期策略，以获取 Amazon Elastic Block Store (Amazon EBS) 快照。在 Amazon RDS 中启用自动备份，以满足 RPO。 ✅ 保留 Web 层和应用层的最新 Amazon Machine Images (AMI)。在 Amazon RDS 中启用自动备份，并使用时间点恢复来满足 RPO。 ❌ 每 2 小时对 EC2 实例的 Amazon Elastic Block Store (Amazon EBS) 卷进行快照。在 Amazon RDS 中启用自动备份，并使用时间点恢复来满足 RPO。 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：适用于 Amazon EC2 实例的存储选项 数据块存储 Amazon EBS – Amazon EBS 提供持久的块级存储卷，您可以将其附加到实例或从实例中分离。您可以将多个 EBS 卷附加到一个实例。EBS 卷始终不受其关联实例的生命周期影响。您可以对 EBS 卷进行加密。要保留您数据的备份副本，您可以从 EBS 卷创建快照。快照会存储在 Amazon S3 中。您可以从快照创建 EBS 卷。 适用于 EC2 实例的实例存储临时块存储 – 实例存储可以为实例提供临时性块级存储。实例存储卷的数量、大小和类型由实例类型和实例大小决定。实例存储卷上的数据仅在关联实例的生命周期内保留；如果您停止、休眠或终止实例，则实例存储卷上的所有数据都会丢失。 在题目描述的情况下，就只是对临时块存储进行备份（通过 AMI 的制作）。 八、Amazon Kinesis Data Streams 默认的消息保留期限和管道大小一家公司需要采集和处理其应用程序生成的大量流式数据。该应用程序在 Amazon EC2 实例，并将数据发送到 Amazon Kinesis Data Streams，该数据流采用默认设置配置。每隔一天，应用程序消耗数 据并将数据写入 Amazon S3 存储桶，以便进行商业智能 (BI) 处理。该公司发现，Amazon S3 并未接收到应用程序发送到 Kinesis Data Streams 的所有数据。解决方案架构师应该如何解决这个问题？ ✅ 通过修改数据保留期更新 Kinesis 数据流默认设置。 更新应用程序，使用 Kinesis 生产者库 (KPL) 将数据发送到 Kinesis 数据流。 ❌ 更新 Kinesis 碎片的数量，以处理发送到 Kinesis 数据流的数据吞吐量。 在 S3 存储桶内打开 S3 版本控制，以保存 S3 存储桶中摄取的每个对象的每个版本。 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：Amazon Kinesis Data Streams 的分片随模式不同而不同：限额和限制 按需模式 - 并无上限。分片数量取决于摄取的数据量和所需的吞吐量级别。Kinesis Data Streams 会根据数据量和流量的变化自动扩展分片数量。 预置模式 - 并无上限。以下 AWS 区域每个 AWS 账户的默认分片限额为 500 个分片：美国东部（弗吉尼亚州北部）、美国西部（俄勒冈州）和欧洲地区（爱尔兰）。其余区域每个 AWS 账户的默认分片限额为 200 个分片。 而保留期则同一默认为 24 小时：更改数据留存期 从添加记录到记录不再可访问的时间段称为保留期。Kinesis 数据流存储记录的时间默认为 24 小时，最长可达 8760 小时（365 天）。 九、RDS Multi-AZ 实例和集群部署的 RTO某公司希望使用 Amazon RDS for PostgreSQL DB 集群来简化生产数据库工作负载耗时的数据库管理任务。该公司希望确保其数据库的高可用性，并在大多数情况下在 40 秒内提供自动故障切换支持。该公司希望卸载主实例的读取，并尽可能降低成本。哪种解决方案能满足这些要求？ ❌ 使用 Amazon RDS Multi-AZ DB 实例部署。创建一个读取副本，并将读取工作负载指向读取副本。 使用 Amazon RDS Multi-AZ DB duster 部署 创建两个读副本，并将读工作负载指向读副本。 使用 Amazon RDS Multi-AZ DB 实例部署。将读取工作负载指向多 AZ 对中的辅助实例。 ✅ 使用 Amazon RDS Multi-AZ DB 集群部署 将读取工作负载指向阅读器端点。 1️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：RDS Multi-AZ 实例的恢复时间在 60 ~ 120 秒：Failing over a Multi-AZ DB instance for Amazon RDS The time that it takes for the failover to complete depends on the database activity and other conditions at the time the primary DB instance became unavailable. Failover times are typically 60–120 seconds. However, large transactions or a lengthy recovery process can increase failover time. When the failover is complete, it can take additional time for the RDS console to reflect the new Availability Zone. 而 RDS Multi-AZ 集群的恢复时间在 35 秒左右：Multi-AZ DB cluster The Multi-AZ DB cluster combines automatic failover with two readable standby instances and provides up to 2x faster commit latencies and automated failovers, typically under 35 seconds. 如果要达到题目要求的 40 秒以内的话，只能选集群。同时集群启动的时候会自带只读副本，因此选 4️⃣。 十、RDS for MySQL 使用快照和 mysqldump 还原一家公司在应用测试期间使用了亚马逊 RDS for MySQL DB 实例。在测试周期结束时终止数据库实例之前，解决方案架构师创建了两个备份。解决方案架构师使用 mysqldump 实用程序创建数据库转储，从而创建了第一个备份。解决方案架构师通过启用 RDS 终止时的最终数据库快照选项创建了第二个备份。该公司目前正在计划一个新的测试周期，并希望从最近的备份中创建一个新的数据库实例。公司选择了与 MySQL 兼容的 Aurora 版本来托管数据库实例。哪些解决方案将创建新 DB 实例？(选择两个）。 ✅ 将 RDS 快照直接导入 Aurora。 ❌ 将 RDS 快照上传到 Amazon S3。然后将 RDS 快照导入 Aurora。 ✅ 将数据库转储上传到 Amazon S3。然后将数据库转储导入 Aurora。 使用 AWS 数据库迁移服务（AWS DMS）将 RDS 快照导入 Aurora。 ❌ 将数据库转储上传到 Amazon S3。然后使用 AWS 数据库迁移服务（AWS DMS）将数据库转储导入 Aurora。 2️⃣ 5️⃣ ❌ -&gt; 1️⃣ 3️⃣ ✅ 💡 解析：快照一直保留在 AWS 中因此不需要再次上传。而使用 mysqldump 还原到 Aurora MySQL 引擎，直接导入即可：使用 mysqldump 从 MySQL 逻辑迁移到 Amazon Aurora MySQL 因为 Amazon Aurora MySQL 是与 MySQL 兼容的数据库，所以您可以使用 mysqldump 实用程序从 MySQL 或 MariaDB 数据库中将数据复制到现有 Aurora MySQL 数据库集群。 十一、Amazon Route 53 与 Amazon CloudFront 的容灾选择某公司有一个无状态 Web 应用程序，该程序运行在亚马逊 API Gateway 调用的 AWS Lambda 函数上。该公司希望在多个 AWS 区域部署应用程序，以提供区域故障转移功能。解决方案架构师应如何将流量路由到多个区域？ ✅ 为每个区域创建 Amazon Route 53 健康检查。使用主动-主动故障切换配置。 ❌ 创建一个 Amazon CloudFront 分发，并为每个区域设置一个起源。使用 CloudFront 健康检查来路由流量。 创建中转网关。将中转网关附加到每个区域的 API 网关端点。配置中转网关以路由请求。 在主区域创建应用程序负载平衡器。将目标组设置为指向每个区域的 API Gateway 端点主机名。 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：CloudFront 提供一定程度的容灾：通过 CloudFront 源失效转移来优化高可用性 在为缓存行为配置源故障转移后，CloudFront 将针对查看器请求执行以下操作： 当主源返回不是为故障转移配置的状态代码（如 HTTP 2xx 或 3xx 状态代码）时，CloudFront 将向查看器提供请求的对象。 发生以下任何情况时： 主源返回您为故障转移配置的 HTTP 状态代码 CloudFront 无法连接到主源 来自主源的响应需要太长时间（超时） 然而它并不具备选项中描述的健康检查功能：在CloudFront分配前使用Route53健康检查和故障转移 “评估目标状态”与支持健康检查的别名记录一起使用，但CloudFront不支持此服务，因为它不返回健康检查。我认为你可以使用CloudFront的自定义错误响应，这样，如果ALB出现错误，它可以将流量重定向到托管在S3桶中的自定义静态页面。 十二、EBS 卷的多重挂载某公司正在开发一个应用程序，以支持客户需求。该公司希望在在同一可用区内有多个基于亚马逊 EC2 Nitro 的实例。该公司还希望让应用程序能够同时写入多个基于 EC2 Nitro 的实例中的多个块存储卷，以实现更高的应用程序可用性。哪种解决方案能满足这些要求？ 使用通用 SSD (gp3) EBS 卷与 Amazon Elastic Block Store (Amazon EBS) 多重连接 将吞吐量优化的硬盘 (st1) EBS 卷与 Amazon Elastic Block Store (Amazon EBS) 多连接一起使用 ✅ 使用 Amazon Elastic Block Store (Amazon EBS) Multi-Attach 配置 IOPS SSD (io2) EBS 卷 使用通用 SSD (gp2) EBS 卷与 Amazon Elastic Block Store (Amazon EBS) 多重连接 3️⃣ ✅ 💡 解析：只有 io1 或 io2 卷支持多重挂载：使用多重挂载将 EBS 卷挂载到多个 EC2 实例 通过 Amazon EBS 多重挂载，您可以将单个预置 IOPS SSD（io1 或 io2）卷挂载到位于同一可用区中的多个实例。您可以将多个启用多重挂载的卷附加到一个实例或一组实例。卷附加到的每个实例都对共享卷拥有完全读取和写入权限。通过多重挂载，您可以更轻松地在管理并发写入操作的应用程序中实现更高的应用程序可用性。 十三、将最小权限授予给 IAM 组某公司预计在不久的将来会迅速发展。解决方案架构师需要配置现有用户并授予新用户在 AWS 上的权限。解决方案架构师决定创建 IAM 组。解决方案架构师将根据部门把新用户添加到 IAM 组。向新用户授予权限的最安全方法是哪种附加操作？ 应用服务控制策略 (SCP) 管理访问权限 ❌ 创建权限最小的 IAM 角色。将角色附加到 IAM 组 ✅ 创建一个授予最少权限的 IAM 策略。将策略附加到 IAM 组 创建 IAM 角色。将角色与定义最大权限的权限边界关联起来 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：IAM 组 不能对 IAM 角色 进行扮演：角色术语和概念 角色可由以下用户代入： 相同 AWS 账户 或另一个 AWS 账户 中的 IAM 用户 同一账户中的 IAM 角色 服务主体，用于 AWS 服务和功能，例如： 允许您在计算服务上运行代码的服务，如 Amazon EC2 或 AWS Lambda 代表您对资源执行操作的功能，如 Amazon S3 对象复制 为在 AWS 外部运行的应用程序提供临时安全凭证的服务，如 IAM Roles Anywhere 或 Amazon ECS Anywhere 由与 SAML 2.0 或 OpenID Connect 兼容的外部身份提供者（IdP）服务进行身份验证的外部用户 这里需要注意允许角色链的概念。","link":"/2024/12/17/saa_test_daily_20241217/"},{"title":"SAA 考试每日练习 - 2024&#x2F;12&#x2F;18","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam109 题 (No.481 ~ No.500, 931 ~ 1019) 只记录了 10 道错误或需要注意的题目，仅供自己复习使用。如果侵权请联系删除。 一、Amazon S3 Glacier 快速检索的耗时一家公司正在寻找一种能在 AWS 中存储旧新闻片段视频档案的解决方案。该公司需要最大限度地降低成本，而且很少需要恢复这些文件。当需要这些文件时，必须在最多五分钟内提供。最具成本效益的解决方案是什么？ ✅ 将视频存档存储在 Amazon S3 Glacier 中，并使用快速检索。 将视频存档存储在 Amazon S3 Glacier 中，并使用标准检索。 ❌ 将视频存档存储在 Amazon S3 Standard-Infrequent Access (S3 Standard-IA)。 将视频存档存储在 Amazon S3 One Zone-Infrequent Access（S3 One Zone-IA）中。 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：Amazon S3 Glacier 中各检索模式耗时不同：了解归档检索选项 加速 (Expedited) S3 Glacier Flexible Retrieval 或 S3 Intelligent-Tiering 归档访问：1 – 5 分钟 S3 Glacier Deep Archive 或 S3 Intelligent-Tiering 深度归档访问：不可用 标准 (Standard) S3 Glacier Flexible Retrieval 或 S3 Intelligent-Tiering 归档访问：1 分钟 – 5 小时 S3 Glacier Deep Archive 或 S3 Intelligent-Tiering 深度归档访问：9 - 12 小时内 批量 (Bulk) S3 Glacier Flexible Retrieval 或 S3 Intelligent-Tiering 归档访问：5 – 12 小时 S3 Glacier Deep Archive 或 S3 Intelligent-Tiering 深度归档访问：48 小时内 二、持续备份 DynamoDB 数据到 S3 存储桶一家游戏公司使用 Amazon DynamoDB 来存储用户信息，如地理位置、玩家数据和排行榜。该公司需要用最少的编码将连续备份配置到 Amazon S3 存储桶。备份不得影响应用程序的可用性，也不得影响为表定义的读取容量单位 (RCU)。哪种解决方案能满足这些要求？ 使用亚马逊 EMR 集群。创建 Apache Hive 作业，将数据备份到亚马逊 S3。 ✅ 将数据直接从 DynamoDB 导出到亚马逊 S3，并持续备份。打开表的时间点恢复。 ❌ 配置 Amazon DynamoDB 流。创建一个 AWS Lambda 函数来消费流并将数据导出到亚马逊 S3 存储桶。 创建一个 AWS Lambda 函数，定期将数据从数据库表导出到亚马逊 S3。打开表的时间点恢复。 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：将 DynamoDB 数据导出到 Amazon S3：工作方式 DynamoDB 导出到 S3 是一种完全托管式解决方案，用于将您的 DynamoDB 数据大规模导出到 Amazon S3 桶。使用“DynamoDB 导出到 S3”，可以在从时间点故障恢复（PITR）时段内的任何时间，将数据从 Amazon DynamoDB 表导出到 Amazon S3 桶。您需要在表上启用 PITR 才能使用导出功能。借助此功能，您可以使用其它 AWS 服务（如 Athena、AWS Glue、Amazon SageMaker、Amazon EMR 和 AWS Lake Formation）对数据执行分析和复杂的查询。 三、指定组织内可用的 EC2 实例类型某公司有多个 AWS 账户用于开发工作。一些员工持续使用超大的 Amazon EC2 实例， 导致公司开发账户超出年度预算。公司希望集中限制在这些账户中创建 AWS 资源。哪种解决方案能以最少的开发工作量满足这些要求？ 开发使用经批准的 EC2 创建流程的 AWS 系统管理器模板。使用经批准的系统管理器模板配置 EC2 实例。 ✅ 使用 AWS 组织将账户组织到组织单位（OU）中。定义并附加服务控制策略（SCP），以控制 EC2 实例类型的使用。 配置 Amazon EventBridge 规则，在创建 EC2 实例时调用 AWS Lambda 函数。停止不允许的 EC2 实例类型。 ❌ 为员工设置 AWS 服务目录产品，以创建允许的 EC2 实例类型。确保员工只能使用服务目录产品部署 EC2 实例。 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：来看下什么是 Service Catalog？ 借助 Service Catalog，组织可以创建和管理获准在 AWS 上使用的 IT 服务的目录。这些 IT 服务可谓包罗万象，从虚拟机映像、服务器、软件和数据库，再到完整的多层应用程序架构等。 Service Catalog 允许组织集中管理通常部署的 IT 服务，并帮助组织实现一致的监管和满足合规性要求。最终用户可在遵循组织设定约束的情况下快速部署他们所需的已获得批准的 IT 服务。 看起来似乎可以实现。再来看下 SCP：Amazon Elastic Compute Cloud（Amazon EC2）的示例 SCP 需要 Amazon EC2 实例以使用特定类型借助此 SCP，任何不使用 t2.micro 实例类型启动的实例都将被拒绝。 123456789101112131415161718{ &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Sid&quot;: &quot;RequireMicroInstanceType&quot;, &quot;Effect&quot;: &quot;Deny&quot;, &quot;Action&quot;: &quot;ec2:RunInstances&quot;, &quot;Resource&quot;: [ &quot;arn:aws:ec2:*:*:instance/*&quot; ], &quot;Condition&quot;: { &quot;StringNotEquals&quot;: { &quot;ec2:InstanceType&quot;: &quot;t2.micro&quot; } } } ]} 有典型案例，因此选 2️⃣ 肯定没错。 四、允许特定 IP 访问 API Gateway某公司正在 AWS 云中开发一个应用程序。该应用程序的 HTTP API 包含以下关键信息在亚马逊 API 网关中发布。关键信息必须只能从属于公司内部网络的有限一组受信任 IP 地址访问。哪种解决方案能满足这些要求？ 设置 API Gateway 私有集成，以限制对一组预定义 IP 地址的访问。 ✅ 为应用程序接口创建资源策略，拒绝访问任何未明确允许的 IP 地址。 在专用子网中直接部署 API。创建网络 ACL。设置规则，允许来自特定 IP 地址的流量。 ❌ 修改附加到 API Gateway 的安全组，只允许来自受信任 IP 地址的入站流量。 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：如何只允许特定的 IP 地址访问我的 API Gateway REST API？ 在 Resource Policy (资源策略) 文本框中，粘贴以下示例资源策略： 123456789101112131415161718192021{ &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [{ &quot;Effect&quot;: &quot;Allow&quot;, &quot;Principal&quot;: &quot;*&quot;, &quot;Action&quot;: &quot;execute-api:Invoke&quot;, &quot;Resource&quot;: &quot;execute-api:/*/*/*&quot; }, { &quot;Effect&quot;: &quot;Deny&quot;, &quot;Principal&quot;: &quot;*&quot;, &quot;Action&quot;: &quot;execute-api:Invoke&quot;, &quot;Resource&quot;: &quot;execute-api:/*/*/*&quot;, &quot;Condition&quot;: { &quot;NotIpAddress&quot;: { &quot;aws:SourceIp&quot;: [&quot;sourceIpOrCIDRBlock&quot;, &quot;sourceIpOrCIDRBlock&quot;] } } } ]} 使用资源策略来控制可以访问 API Gateway 的 IP 是 AWS 推荐的做法。 五、对 EC2 进行日常修补并需要暂时从 ALB 中移除某公司使用 AWS 系统管理器对亚马逊 EC2 实例进行日常管理和修补。EC2 实例位于应用程序负载平衡器 (ALB) 后面的 IP 地址类型目标组中。新的安全协议要求公司在打补丁期间从服务中移除 EC2 实例。当公司尝试在下一个补丁期间遵循安全协议时，公司会在补丁窗口期间收到错误。哪种解决方案组合可以解决这些错误？(选择两个）。 ❌ 将目标组的目标类型从 IP 地址类型改为实例类型。 继续使用现有的系统管理器文档，无需更改，因为该文档已经过优化，可以处理 ALB 后面 IP 地址类型目标组中的实例。 ✅ 实施 AWSEC2-PatchLoadBalanacerInstance 系统管理器自动化文件来管理修补程序。 ✅ 使用 “系统管理器维护窗口 “自动将实例从服务中移除，以修补实例。 ❌ 配置系统管理器状态管理器，将实例从服务中移除并管理修补计划。使用 ALB 健康检查重新路由流量。 1️⃣ 5️⃣ ❌ -&gt; 3️⃣ 4️⃣ ✅ 💡 解析：AWSEC2-PatchLoadBalancerInstance 升级并修补附加到任何负载均衡器（经典、ALB 或 NLB）的 Amazon EC2 实例（Windows 或 Linux）的次要版本。在修补该实例之前，会应用默认的连接耗尽时间。您可以为 ConnectionDrainTime 参数输入以分钟 (1-59) 为单位的自定义耗尽时间，从而覆盖等待时间。 自动化工作流程如下所示： 确定实例所附加的负载均衡器或目标组，并验证该实例是否运行正常。 该实例已从负载均衡器或目标组移除。 此自动化将等待为连接耗尽时间指定的时间段。 调用 AWS-RunPatchBaseline 自动化以修补该实例。 该实例已从负载均衡器或目标组重新附加。 先决条件 验证实例上是否安装了 SSM Agent。 因此通过 AWSEC2-PatchLoadBalanacerInstance 操作对 EC2 进行操作的话，会自动将其移出 ALB。 六、组织的标签策略某公司正在为一个使用 AWS 云的新移动应用程序设计架构。该公司使用 AWS 组织中的组织单位 (OU) 管理其账户。该公司希望通过使用敏感和不敏感值来标记亚马逊 EC2 实例的数据敏感性。IAM 身份不得删除标签或创建无标签的实例。哪种步骤组合能满足这些要求？(选择两个）。 ✅ 在 “组织 “中，创建一个新标签策略，指定数据敏感性标签密钥和所需值。为 EC2 实例强制执行标签值。将标签策略附加到相应的 OU。 ❌ 在 “组织 “中，创建一个新的服务控制策略 (SCP)，指定数据敏感性标记密钥和所需的标记值。为 EC2 实例强制执行标签值。将 SCP 附加到相应的 OU。 创建一个标签策略，在未指定标签密钥时拒绝运行实例。创建另一个标签策略，防止身份删除标签。将标签策略附加到相应的 OU。 ✅ 创建服务控制策略 (SCP)，在未指定标签密钥时拒绝创建实例。创建另一个 SCP，防止身份删除标记。将 SCP 附加到相应的 OU。 创建一个 AWS 配置规则，检查 EC2 实例是否使用了数据敏感性标记和指定值。配置 AWS Lambda 函数，以便在发现不合规资源时删除资源。 2️⃣ 4️⃣ ❌ -&gt; 1️⃣ 4️⃣ ✅ 💡 解析：4️⃣ 使用 SCP 对 EC2 实例的创建进行限制没有问题。而 AWS Organizations 其实还有标签策略：标签策略 标签策略 是策略的一种类型，可帮助您在组织账户中跨资源标准化标签。在标签策略中，您可以指定在标记资源时适用于资源的标记规则。 例如，标签策略可以指定当 CostCenter 标签附加到资源时，它必须使用标签策略定义的大小写处理和标签值。标签策略还可以指定在指定资源类型上强制执行 不合规的标记操作。换句话说，阻止在指定的资源类型上完成不合规的标记操作。不会评估未标记的资源或未在标签策略中定义的标签是否符合标签策略。 使用标签策略来定义标签和将其使用到 EC2 上，之后使用 SCP 来拒绝创建不带标签的 EC2 实例并防止删除标签。 七、Amazon Athena SQL 支持的数据格式一家天气预报公司持续从各种传感器收集温度读数。现有的数据摄取流程会收集读数，并将读数汇总到较大的 Apache Parquet 文件中。然后，该流程通过使用 KMS 管理密钥（CSE-KMS）的客户端加密对文件进行加密。最后，该流程将文件写入亚马逊 S3 存储桶，并为每个日历日设置单独的前缀。公司希望偶尔对数据运行 SQL 查询，以获取特定日历日的移动平均值样本。哪种解决方案能最经济高效地满足这些要求？ ✅ 配置 Amazon Athena 以读取加密文件。直接在 Amazon S3 中的数据上运行 SQL 查询。 使用 Amazon S3 Select 直接对 Amazon S3 中的数据运行 SQL 查询。 ❌ 配置 Amazon Redshift 以读取加密文件。使用 Redshift Spectrum 和 Redshift query Editor v2 直接对 Amazon S3 中的数据运行 SQL 查询 。 配置 Amazon EMR Serverless 以读取加密文件。使用 Apache SparkSQL 直接对亚马逊 S3 中的数据运行 SQL 查询。 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：应在何时使用 Athena？ Athena 可帮助您分析在 Amazon S3 中存储的非结构化、半结构化和结构化数据。示例包括 CSV、JSON 或列式数据格式，如 Apache Parquet 和 Apache ORC。您可以使用 ANSI SQL 通过 Athena 运行临时查询，而无需将数据聚合或加载到 Athena 中。 八、 AWS Glue DynamoDB Export connector某公司使用 Amazon DynamoDB 表来存储公司从设备接收到的数据。DynamoDB 表支持面向客户的网站，以显示客户设备上的最近活动。该公司为该表配置了写入和读取的预配置吞吐量。公司希望每天计算客户设备数据的性能指标。解决方案必须对表的预设读写能力影响最小。哪种解决方案能满足这些要求？ ❌ 将 Amazon Athena SQL 查询与 Amazon Athena DynamoDB 连接器配合使用，按周期计算性能指标。 ✅ 使用 AWS Glue 作业和 AWS Glue DynamoDB 导出连接器，按周期计算性能指标。 使用 Amazon Redshift COPY 命令按周期计算性能指标。 使用带有 Apache Hive 外部表的 Amazon EMR 作业，按周期计算性能指标。 1️⃣ ❌ -&gt; 2️⃣ ✅ 全新 AWS Glue DynamoDB 导出连接器 以下是使用 AWS Glue ETL 作业从 DynamoDB 表中读取的典型使用案例： 将数据从 DynamoDB 表移到其他数据存储 将数据与其他服务和应用程序集成 保留历史快照以供审计 根据 DynamoDB 数据构建 S3 数据湖并分析来自各种服务的数据，例如 Amazon Athena、Amazon Redshift 和 Amazon SageMaker 这种方法具有以下好处： 不会占用源 DynamoDB 表的读取容量单位 大型 DynamoDB 表的读取性能一致 九、AWS Backup 的 RTO某公司在应用程序负载平衡器 (ALB) 后面的自动扩展组中的 Amazon EC2 实例上运行一个网络应用程序。该应用程序在 Amazon Aurora MySQL DB 集群中存储数据。公司需要创建灾难恢复（DR）解决方案。灾难恢复解决方案可接受的恢复时间最长为 30 分钟。灾难恢复解决方案不需要在主基础设施健康时支持客户使用。哪种解决方案能满足这些要求？ ✅ 在带有 ALB 和自动扩展组的第二个 AWS 区域中部署灾难恢复基础架构。将自动扩展组的所需容量和最大容量设置为最小值。将 Aurora MySQL DB 集群转换为 Aurora 全局数据库。使用 ALB 端点配置 Amazon Route 53 以实现主动-被动故障切换。 在具有 AL 的第二个 AWS 区域中部署灾难恢复基础架构更新自动扩展组，以包括来自第二个区域的 EC2 实例。使用 Amazon Route 53 配置主动-主动故障切换。将 Aurora MySQL DB 集群转换为 Aurora 全局数据库。 使用 AWS 备份备份 Aurora MySQL DB 集群数据。在带有 ALB 的第二个 AWS 区域中部署灾难恢复基础设施。更新自动扩展组，将第二个区域的 EC2 实例包括在内。使用 Amazon Route 53 配置主动-主动故障切换。在第二个区域中创建 Aurora MySQL DB 群集 从备份中恢复数据。 ❌ 使用 AWS 备份备份基础设施配置。使用备份在第二个 AWS 区域创建所需的基础架构。将自动扩展组所需容量设为零。使用 Amazon Route 53 配置主动-被动故障转移。将极光 MySQL DB 集群转换为极光全局数据库。 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：使用 AWS Backup 和重建的耗时是小时级别：云中的灾难恢复选项 十、Amazon Aurora 的自定义端点某公司在 Amazon Aurora MySQL DB 集群上运行其生产工作负载，该集群包括六个 Aurora Replicas。该公司希望将其一个部门的近实时报告查询自动分布到三个 Aurora 副本中。这三个副本的计算和内存规格与数据库集群的其他部分不同。 ✅ 为工作负载创建并使用自定义端点 创建三节点集群克隆并使用阅读器端点 ❌ 为选定的三个节点使用任意一个实例端点 使用阅读器端点自动分配只读工作量 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：Amazon Aurora 的自定义端点 Aurora 集群的自定义终端节点 表示一组选定数据库实例。在连接到端点时，Aurora 会执行连接平衡并选择组中的某个实例来处理连接。您可以定义此终端节点引用的实例，并确定此终端节点的用途。 在您创建自定义终端节点之前，Aurora 数据库集群没有自定义终端节点。您可以为每个预调配的 Aurora 集群或 Aurora Serverless v2 集群创建最多 5 个自定义端点。您无法对 Aurora Serverless v1 集群使用自定义终端节点。","link":"/2024/12/18/saa_test_daily_20241218/"},{"title":"SAA 考试每日练习 - 2024&#x2F;12&#x2F;19","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam60 题 (No.871 ~ No.930) 只记录了 3 道错误或需要注意的题目，仅供自己复习使用。如果侵权请联系删除。 一、EC2 实例的纵向扩展和横向扩展某公司在 Amazon EC2 实例上托管了一个单体网络应用程序。应用程序用户最近报告在特定时间性能不佳。对 Amazon CloudWatch 指标的分析表明，在性能不佳期间，CPU 使用率为 100%。公司希望解决这一性能问题并提高应用程序的可用性。哪种步骤组合能最经济高效地满足这些要求？(选择两项）。 ✅ 使用 AWS Compute Optimizer 获取实例类型垂直扩展的建议。 从网络服务器创建 Amazon Machine Image (AMI)。在新的启动模板中引用 AMI。 创建自动扩展组和应用程序负载平衡器，以便垂直扩展。 ❌ 使用 AWS Compute Optimizer 获取实例类型的横向扩展建议。 ✅ 创建一个自动扩展组和一个应用程序负载平衡器，以便横向扩展。 4️⃣ 5️⃣ ❌ -&gt; 1️⃣ 5️⃣ ✅ 💡 解析：什么是 AWS Compute Optimizer？ 支持的资源Compute Optimizer 会为以下资源生成建议： 亚马逊弹性计算云 (Amazon EC2) 实例 亚马逊 EC2 自动扩展组 亚马逊弹性块存储（亚马逊 EBS）卷 AWS Lambda 函数 AWS Fargate 上的亚马逊弹性容器服务 (Amazon ECS) 服务 商业软件许可证 亚马逊关系数据库服务 (Amazon RDS) DB 实例和存储 因此它支持对本例中的 EC2 垂直扩展或水平扩展提供建议。而关于 EC2 的自动垂直扩展，没有很好的工具，只能通过性能突增实例实现：Is there a way the EC2 instance scale vertically 回到本题，1️⃣ 和 4️⃣ 都行吧，但是考虑到题目说应用程序时单体应用，选 1️⃣ 更好吧。 二、Amazon API Gateway 中 HTTP API 和 REST API 价格差距一家公司正在将托管在亚马逊 EC2 上的网络应用程序从单体架构迁移到无服务器微服务架构。该公司希望使用支持事件驱动、松散耦合架构的 AWS 服务。公司希望使用发布/订阅（pub/sub）模式。哪种解决方案能以最具成本效益的方式满足这些要求？ 配置 Amazon API Gateway REST API 以调用 AWS Lambda 函数，将事件发布到 Amazon Simple Queue Service (Amazon SQS) 队列。配置一个或多个订阅者，以便从 SQS 队列读取事件。 ❌ 配置 Amazon API Gateway REST API 以调用 AWS Lambda 函数，将事件发布到 Amazon Simple Notification Service (Amazon SNS) 主题。配置一个或多个订阅者，以便从 SNS 主题接收事件。 配置 Amazon API Gateway WebSocket API，以便通过增强的扇出功能写入 Amazon Kinesis Data Streams 中的数据流。配置一个或多个订阅者以接收来自数据流的事件。 ✅ 配置 Amazon API Gateway HTTP API 以调用 AWS Lambda 函数，将事件发布到 Amazon Simple Notification Service (Amazon SNS) 主题。配置一个或多个订阅者，以便从主题接收事件。 2️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：Amazon API Gateway 定价 HTTP API 请求数量（每月） 价格（每百万） 前 3 亿 USD 1.00 3 亿以上 USD 0.90 REST API 请求数量（每月） 价格（每百万） 前 3.33 亿 USD 3.50 接下来的 6.67 亿 USD 2.80 接下来的 190 亿 USD 2.38 超过 200 亿 USD 1.51 WebSocket API 请求数量（每月） 价格（每百万） 前 10 亿 USD 1.00 超过 10 亿 USD 0.80 相比之下 HTTP API 更便宜。 三、限制团队启动大型 EC2 实例一个开发团队为其开发、暂存和生产环境使用多个 AWS 账户。团队成员一直在启动未得到充分利用的大型 Amazon EC2 实例。解决方案架构师必须防止在所有账户中启动大型实例。解决方案架构师如何以最少的运营开销满足这一要求？ 更新 IAM 策略，拒绝启动大型 EC2 实例。将策略应用到所有用户。 ❌ 在 AWS 资源访问管理器中定义一个资源，防止启动大型 EC2 实例。 在每个账户中创建一个拒绝启动大型 EC2 实例的 IAM 角色。授予开发人员 IAM 组访问该角色的权限。 ✅ 在管理账户中的 AWS 组织中创建一个具有默认策略的组织。创建拒绝启动大型 EC2 实例的服务控制策略 (SCP)，并将其应用到 AWS 账户。 2️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：AWS Resource Access Manager 是跨账户共享资源用的，而非限制资源启动的：什么是 AWS Resource Access Manager？ AWS Resource Access Manager (AWS RAM) 可帮助您跨 AWS 账户、在组织或组织单位 (OU) 内以及与 AWS Identity and Access Management (IAM) 角色和用户针对受支持资源类型安全地共享资源。如果您有多个 AWS 账户，可以一次性创建一个资源，然后使用 AWS RAM 使该资源可供其他账户使用。","link":"/2024/12/19/saa_test_daily_20241219/"},{"title":"SAP 考试重点 - 认证","text":"涉及 Active Directory、IAM 和跨账户授权等 AWS 认证的内容。主要用于 SAP-C02 相关题目的关联和背诵使用。 AWS 认证（SAP-C02 考试内容） Active Directory","link":"/2025/01/03/sap_important_identity/"},{"title":"SAA 考试每日练习 - 2024&#x2F;12&#x2F;12","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam100 题 (No.801 ~ No.900) 只记录了 18 道首次碰到的、错误的或有疑问的题目，仅供自己复习使用。其中有 65 题与正式考试题量一样，总共耗时 93/(130+30) 分钟，正确率为 52/65。如果侵权请联系删除。 一、MPP MLA company has an Amazon S3 data lake. The company needs a solution that transforms the data from the data lake and loads the data into a data warehouse every day. The data warehouse must have massively parallel processing (MPP) capabilities.Data analysts then need to create and train machine learning (ML) models by using SQL commands on the data. The solution must use serverless AWS services wherever possible.Which solution will meet these requirements? ❌ Run a daily Amazon EMR job to transform the data and load the data into Amazon Redshift. Use Amazon Redshift ML to create and train the ML models. Run a daily Amazon EMR job to transform the data and load the data into Amazon Aurora Serverless. Use Amazon Aurora ML to create and train the ML models. ✅ Run a daily AWS Glue job to transform the data and load the data into Amazon Redshift Serverless. Use Amazon Redshift ML to create and train the ML models. Run a daily AWS Glue job to transform the data and load the data into Amazon Athena tables. Use Amazon Athena ML to create and train the ML models. ✨ 关键词： 1️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：RedShift 具有 MPP 特性：Amazon Redshift 性能 大规模并行处理大规模并行处理 (MPP) 支持对大量数据快速运行最复杂的查询。多个计算节点处理所有查询处理以获得最终结果聚合，运行相同的编译后查询的每个节点的每个核心在整个数据的各个部分进行分段。 因此 1️⃣ 和 3️⃣ 是合适的。来看下 EMR job：任务运行状态 当您将作业运行提交到 Amazon EMR Serverless 作业队列时，作业运行将进入 SUBMITTED 状态。作业状态从 SUBMITTED 变为 RUNNING，直至达到 FAILED、SUCCESS 或 CANCELLING。 Glue 的：AWS Glue 概念 作业执行 ETL 工作所需的业务逻辑。它由转换脚本、数据源和数据目标组成。作业运行通过可由事件计划或触发的触发器启动。 1️⃣ 和 3️⃣ 还是都符合的，那只能看存不存在 RedShift Serverless 了：Amazon Redshift Serverless Amazon Redshift Serverless 可让您方便地运行和扩展分析，而无需预置和管理本地数据仓库。借助 Amazon Redshift Serverless，数据分析人员、开发人员和数据科学家现在通过将数据加载到云中的数据仓库并从其中查询记录，就可以使用 Amazon Redshift 在几秒钟内从数据中获取见解。Amazon Redshift 会自动预置和扩展数据仓库容量，以便为要求苛刻且不可预测的工作负载提供快速性能。您仅需为实际使用的容量付费。您无需更改现有分析和商业智能应用程序，即可受益于这种简单性。 3️⃣ 更符合题目需求。 👨‍👨‍👦‍👦 社区讨论：Data Warehouse =&gt; redshiftUse AWS Services whereever possible =&gt; Redshift serverless 二、Batch job success callA company uses an AWS Batch job to run its end-of-day sales process. The company needs a serverless solution that will invoke a third-party reporting application when the AWS Batch job is successful. The reporting application has an HTTP API interface that uses username and password authentication.Which solution will meet these requirements? ✅ Configure an Amazon EventBridge rule to match incoming AWS Batch job SUCCEEDED events. Configure the third-party API as an EventBridge API destination with a username and password. Set the API destination as the EventBridge rule target. Configure Amazon EventBridge Scheduler to match incoming AWS Batch job SUCCEEDED events. Configure an AWS Lambda function to invoke the third-party API by using a username and password. Set the Lambda function as the EventBridge rule target. ❌ Configure an AWS Batch job to publish job SUCCEEDED events to an Amazon API Gateway REST API. Configure an HTTP proxy integration on the API Gateway REST API to invoke the third-party API by using a username and password. Configure an AWS Batch job to publish job SUCCEEDED events to an Amazon API Gateway REST API. Configure a proxy integration on the API Gateway REST API to an AWS Lambda function. Configure the Lambda function to invoke the third-party API by using a username and password. ✨ 关键词： 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：EventBridge 支持将 HTTP 终端节点作为目标这个没什么好疑惑的：API将目的地作为亚马逊的目标 EventBridge Amazon EventBridge API目标是您可以作为事件总线规则或管道目标调用的HTTP终端节点，类似于调用 AWS 服务或资源作为目标的方式。使用API目的地，您可以使用API呼叫在 AWS 服务、集成软件即服务 (SaaS) 应用程序和外部应用程序之间路由事件。 API目标不支持私有目标，例如接口VPC终端节点，包括使用私有网络的虚拟私有云 (VPC) HTTPS APIs 中的私有目标、Application Load Balancer 以及接口端点。 当然它也支持认证。我比较好奇的是 AWS Batch job 没有成功的 Hook 吗？尝试搜了下好像只能将 EventBridge 作为作业状态的输出：AWS Batch 事件 AWS Batch将作业状态更改事件发送到 EventBridge。AWS Batch会跟踪作业的状态。如果先前提交的作业的状态发生变化，则会调用一个事件。例如，如果状态为RUNNING的作业变为FAILED状态。这些事件归类为作业状态更改事件。 那么这种情况下就最好选 1️⃣ 了。 👨‍👨‍👦‍👦 社区讨论：https://aws.amazon.com/blogs/compute/using-api-destinations-with-amazon-eventbridge/Amazon EventBridge enables developers to route events between AWS services, integrated software asa service (SaaS) applications,and your own applications. It can help decouple applicationsand produce more extensible, maintainable architectures. With the new API destinations feature,EventBridge can now integrate with services outside of AWS using REST API calls. 三、AWS Glue Studio visual canvasA company hosts a data lake on Amazon S3. The data lake ingests data in Apache Parquet format from various data sources. The company uses multiple transformation steps to prepare the ingested data. The steps include filtering of anomalies, normalizing of data to standard date and time values, and generation of aggregates for analyses.The company must store the transformed data in S3 buckets that data analysts access. The company needs a prebuilt solution for data transformation that does not require code. The solution must provide data lineage and data profiling. The company needs to share the data transformation steps with employees throughout the company.Which solution will meet these requirements? ❌ Configure an AWS Glue Studio visual canvas to transform the data. Share the transformation steps with employees by using AWS Glue jobs. Configure Amazon EMR Serverless to transform the data. Share the transformation steps with employees by using EMR Serverless jobs. ✅ Configure AWS Glue DataBrew to transform the data. Share the transformation steps with employees by using DataBrew recipes. Create Amazon Athena tables for the data. Write Athena SQL queries to transform the data. Share the Athena SQL queries with employees. ✨ 关键词： 1️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：AWS Glue 可视化 (Visual) 任务 API AWS Glue 提供了一个 API，允许客户使用 AWS Glue API 从表示可视化步骤工作流的 JSON 对象创建数据集成任务。然后，客户可以使用 AWS Glue Studio 中的可视化编辑器来处理这些任务。 什么是 AWS Glue DataBrew？ AWS Glue DataBrew 是一种可视化数据准备工具，让用户无需编写任何代码即可清理数据并实现标准化。与定制开发的数据准备相比，使用 DataBrew 可将准备用于分析和机器学习 (ML) 的数据所需的时间缩短多达 80%。您可以从 250 多种现成的转换功能中进行选择，以自动执行数据准备任务，例如筛选异常、将数据转换为标准格式以及更正无效值。 创建和使用 AWS Glue DataBrew 食谱 (Recipes) 在继续开发食谱时，您可以通过发布食谱来保存您所做的工作。 DataBrew 为您的食谱维护已发布版本的列表。您可以在配方作业中使用任何已发布的版本来运行配方（在配方作业中）来转换您的数据集。您也可以下载配方步骤的副本，以便可以在其他项目或其他数据集转换中重复使用该配方。 这意味着 AWS Glue DataBrew 完美符合可视化机器学习数据准备步骤和分享这些转换步骤的需求。 👨‍👨‍👦‍👦 社区讨论：AWS Glue DataBrew:This isa visual data preparation tool that allows you to clean and normalize data without writing code. Ithas built-in transformations for common tasks like filtering anomalies, normalizing dates,and generating aggregates. It alsoprovides data lineage and profiling capabilities, which are required by the company.DataBrew Recipes:These are reusable workflows that define the data transformation steps.They can be easily shared with other employees, making it simple to collaborate on data preparation tasks. 四、S3 encryption automatically rotateA company is planning to migrate data to an Amazon S3 bucket. The data must be encrypted at rest within the S3 bucket. The encryption key must be rotated automatically every year.Which solution will meet these requirements with the LEAST operational overhead? ❌ Migrate the data to the S3 bucket. Use server-side encryption with Amazon S3 managed keys (SSE-S3). Use the built-in key rotation behavior of SSE-S3 encryption keys. Create an AWS Key Management Service (AWS KMS) customer managed key. Enable automatic key rotation. Set the S3 bucket’s default encryption behavior to use the customer managed KMS key. Migrate the data to the S3 bucket. ✅ Create an AWS Key Management Service (AWS KMS) customer managed key. Set the S3 bucket’s default encryption behavior to use the customer managed KMS key. Migrate the data to the S3 bucket. Manually rotate the KMS key every year. Use customer key material to encrypt the data. Migrate the data to the S3 bucket. Create an AWS Key Management Service (AWS KMS) key without key material. Import the customer key material into the KMS key. Enable automatic key rotation. ✨ 关键词： 1️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：SSE-S3 不支持自动轮转： 并且已经存在于桶中的文件在之后开启加密后，不会被加密。 👨‍👨‍👦‍👦 社区讨论：The anwser can’t be A. In addition to other justifications written here in the comments, if the data is copied before enabling encryption, this data will not be encrypted. 五、Aurora storage configurationA company is planning to deploy its application on an Amazon Aurora PostgreSQL Serverless v2 cluster. The application will receive large amounts of traffic. The company wants to optimize the storage performance of the cluster as the load on the application increases.Which solution will meet these requirements MOST cost-effectively? Configure the cluster to use the Aurora Standard storage configuration. ❌ Configure the cluster storage type as Provisioned IOPS. Configure the cluster storage type as General Purpose. ✅ Configure the cluster to use the Aurora I/O-Optimized storage configuration. ✨ 关键词： 2️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：Amazon Aurora 数据库集群的存储配置 Amazon Aurora 有两种数据库集群存储配置： Aurora I/O-Optimized – 提高了 I/O 密集型应用程序的性价比和可预测性。您只需为数据库集群的使用量和存储付费，而无需为读取和写入 I/O 操作支付额外费用。 当您的 I/O 支出占 Aurora 数据库总支出的 25% 或更多时，Aurora I/O-Optimized 是最佳选择。 当您使用支持 Aurora I/O-Optimized 集群配置的数据库引擎版本创建或修改数据库集群时，可以选择 Aurora I/O-Optimized。您可以随时从 Aurora I/O-Optimized 切换到 Aurora Standard。 Aurora Standard – 为许多 I/O 使用率适中的应用程序提供经济实惠的定价。除了数据库集群的使用量和存储外，您还需要为每 100 万个 I/O 操作请求支付标准费率。 当您的 I/O 支出低于 Aurora 数据库总支出的 25% 时，Aurora Standard 是最佳选择。 您可以每 30 天从 Aurora Standard 切换到 Aurora I/O-Optimized 一次。从 Aurora Standard 切换到 Aurora I/O-Optimized 或从 Aurora I/O-Optimized 切换到 Aurora Standard 时不会出现停机。 👨‍👨‍👦‍👦 社区讨论：Aurora only have:-&gt; Standard-&gt; I/O-Optimized (need optimise storage thats why i chose this) 六、AWS Security HubA financial services company that runs on AWS has designed its security controls to meet industry standards. The industry standards include the National Institute of Standards and Technology (NIST) and the Payment Card Industry Data Security Standard (PCI DSS).The company’s third-party auditors need proof that the designed controls have been implemented and are functioning correctly. The company has hundreds of AWS accounts in a single organization in AWS Organizations. The company needs to monitor the current state of the controls across accounts.Which solution will meet these requirements? Designate one account as the Amazon Inspector delegated administrator account from the Organizations management account. Integrate Inspector with Organizations to discover and scan resources across all AWS accounts. Enable Inspector industry standards for NIST and PCI DSS. ❌ Designate one account as the Amazon GuardDuty delegated administrator account from the Organizations management account. In the designated GuardDuty administrator account, enable GuardDuty to protect all member accounts. Enable GuardDuty industry standards for NIST and PCI DSS. Configure an AWS CloudTrail organization trail in the Organizations management account. Designate one account as the compliance account. Enable CloudTrail security standards for NIST and PCI DSS in the compliance account. ✅ Designate one account as the AWS Security Hub delegated administrator account from the Organizations management account. In the designated Security Hub administrator account, enable Security Hub for all member accounts. Enable Security Hub standards for NIST and PCI DSS. ✨ 关键词： 2️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：什么是 AWS Security Hub？ AWS Security Hub 为您提供了 AWS 中安全状态的全面视图，可帮助您评测您的 AWS 环境是否符合安全行业标准和最佳实践。 Security Hub 可跨 AWS 账户、AWS 服务、和受支持的第三方产品收集安全数据，并可帮助您分析安全趋势，以及确定最高优先级的安全问题。 为了帮助您管理组织的安全状态，Security Hub 支持多种安全标准。其中包括由 AWS 制定的 AWS 基础安全最佳实践 (FSBP) 和外部合规性框架，如 Center for Internet Security (CIS)、支付卡行业数据安全标准 (PCI DSS) 和美国国家标准与技术研究所 (NIST)。每个标准都包含多个安全控件，每种控件都代表一种安全最佳实践。Security Hub 对安全控件进行检查并生成控件调查发现，以帮助您评测您是否符合安全最佳实践。 针对是否符合行业标准的评判，需要通过 AWS Security Hub 实现。涉及到的其他安全服务： Amazon Inspector - 是一项自动化漏洞管理服务，可近乎实时地持续扫描 Amazon Elastic Compute Cloud（EC2）、Amazon Lambda 函数以及 Amazon ECR 中的容器映像以及持续集成和持续交付（CI/CD）工具中的软件漏洞和意外网络暴露。 Amazon GuardDuty - 威胁检测服务，可持续监控恶意活动和未经授权的行为。 GuardDuty 可检测出账户盗用的迹象，例如在一天之中的非典型时间从异常地理位置访问 AWS 资源。对于编程 AWS 账户，GuardDuty 能够检查异常 API 调用，例如试图通过禁用 CloudTrail 日志记录或从恶意 IP 地址创建数据库快照掩盖账户活动。 AWS CloudTrail - 可帮助您实现 AWS 账户 的运营和风险审计、治理和合规性。用户、角色或 AWS 服务执行的操作将记录为 CloudTrail 中的事件。 事件包括在 AWS Management Console、AWS Command Line Interface 和 AWS 开发工具包和 API 中执行的操作。 👨‍👨‍👦‍👦 社区讨论：Security Hub: assess your AWS environment against security industry standardsand best practices. 七、Amazon EventBridge event busA company is designing an event-driven order processing system. Each order requires multiple validation steps after the order is created. An idempotent AWS Lambda function performs each validation step. Each validation step is independent from the other validation steps. Individual validation steps need only a subset of the order event information. 某公司正在设计一个事件驱动订单处理系统。创建订单后，每个订单都需要多个验证步骤。一个幂等 AWS Lambda 函数执行每个验证步骤。每个验证步骤都独立于其他验证步骤。单个验证步骤只需要订单事件信息的一个子集。 The company wants to ensure that each validation step Lambda function has access to only the information from the order event that the function requires. The components of the order processing system should be loosely coupled to accommodate future business changes. 公司希望确保每个验证步骤的 Lambda 函数只能访问该函数所需的订单事件信息。订单处理系统的各个组件应松散耦合，以适应未来的业务变化。 Which solution will meet these requirements? ❌ Create an Amazon Simple Queue Service (Amazon SQS) queue for each validation step. Create a new Lambda function to transform the order data to the format that each validation step requires and to publish the messages to the appropriate SQS queues. Subscribe each validation step Lambda function to its corresponding SQS queue. Create an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the validation step Lambda functions to the SNS topic. Use message body filtering to send only the required data to each subscribed Lambda function. ✅ Create an Amazon EventBridge event bus. Create an event rule for each validation step. Configure the input transformer to send only the required data to each target validation step Lambda function. Create an Amazon Simple Queue Service (Amazon SQS) queue. Create a new Lambda function to subscribe to the SQS queue and to transform the order data to the format that each validation step requires. Use the new Lambda function to perform synchronous invocations of the validation step Lambda functions in parallel on separate threads ✨ 关键词： 1️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：Event buses in Amazon EventBridge 事件总线是接收事件并将其传送到零个或多个目的地或目标的路由器。事件总线非常适合将事件从多个源路由到多个目标，在将事件传送到目标之前可以选择转换事件。 活动总线的工作原理 EventBridge它的工作方式可概括如下： 事件源 EventBridge 然后根据为该事件总线定义的每条规则评估事件。 对于每个与规则匹配的事件， EventBridge 然后将该事件发送到为该规则指定的目标。或者，作为规则的一部分，您还可以指定在将事件发送到目标之前 EventBridge 应如何转换事件。 活动巴士可以将事件分解为不同的小事件，并支持对消息进行拆分。而 SNS 无法对消息进行拆分：亚马逊SNS邮件过滤 如果某个订阅没有筛选策略，则订阅者将接收发布到其主题的每条消息。当您向已设置筛选策略的主题发布消息时，Amazon 会将消息属性或消息正文与每个主题订阅的筛选策略中的属性进行SNS比较。如果所有消息属性或消息正文属性都满足筛选策略中指定的条件，Amazon SNS 会将消息发送给订阅者。否则，Amazon SNS 不会向该订阅者发送消息。 👨‍👨‍👦‍👦 社区讨论：not B because SNS cannot make messages manipulation, the option “message body filtering” will make discard or forward the FULL message if there isa matching field:https://docs.aws.amazon.com/sns/latest/dg/sns-message-filtering.htmlC - eventbus instead can manipulate event:https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-event-bus.htmlD - Works, but too much operation IMO 八、Encrypt at restA company is running a highly sensitive application on Amazon EC2 backed by an Amazon RDS database. Compliance regulations mandate that all personally identifiable information (PII) be encrypted at rest.Which solution should a solutions architect recommend to meet this requirement with the LEAST amount of changes to the infrastructure? Deploy AWS Certificate Manager to generate certificates. Use the certificates to encrypt the database volume. ❌ Deploy AWS CloudHSM, generate encryption keys, and use the keys to encrypt database volumes. Configure SSL encryption using AWS Key Management Service (AWS KMS) keys to encrypt database volumes. ✅ Configure Amazon Elastic Block Store (Amazon EBS) encryption and Amazon RDS encryption with AWS Key Management Service (AWS KMS) keys to encrypt instance and database volumes. ✨ 关键词： 2️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：什么是 AWS CloudHSM？ AWS CloudHSM 将 AWS 云的优势与硬件安全模块 (HSM, Hardware security module) 的安全性相结合。硬件安全模块 (HSM) 是一种计算设备，可处理加密操作并提供加密密钥的安全存储。您可通过 AWS CloudHSM 全面控制 Amazon Web Services Cloud 中的高可用性 HSM，以获得低延迟访问，以及可自动执行 HSM 管理（包括备份、预配、配置和维护）的安全信任根。 其他 AWS 产品是否可以使用 AWS CloudHSM 存储和管理密钥？ AWS 服务与 AWS Key Management Service 集成，后者又通过 KMS 自定义密钥存储功能与 AWS CloudHSM 集成。如果要使用许多 AWS 服务（例如 EBS、S3 或 Amazon RDS）提供的服务器端加密，可以通过在 AWS KMS 中配置自定义密钥存储来实现。 AWS CloudHSM 似乎是在用户提供密钥的场景下工作的，并且 4️⃣ 已经能处理当前问题场景，选 4️⃣ 没有问题。同时 4️⃣ 还是最简单的操作方式。 👨‍👨‍👦‍👦 社区讨论：SSL/Certificate =&gt; encrypt in transit, so A and C are wrong.so i feel the answer is between B and D. 九、EBS SnapshotsA company uses Amazon EC2 instances and Amazon Elastic Block Store (Amazon EBS) to run its self-managed database. The company has 350 TB of data spread across all EBS volumes. The company takes daily EBS snapshots and keeps the snapshots for 1 month. The daily change rate is 5% of the EBS volumes.Because of new regulations, the company needs to keep the monthly snapshots for 7 years. The company needs to change its backup strategy to comply with the new regulations and to ensure that data is available with minimal administrative effort.Which solution will meet these requirements MOST cost-effectively? Keep the daily snapshot in the EBS snapshot standard tier for 1 month. Copy the monthly snapshot to Amazon S3 Glacier Deep Archive with a 7-year retention period. ✅ Continue with the current EBS snapshot policy. Add a new policy to move the monthly snapshot to Amazon EBS Snapshots Archive with a 7-year retention period. ❌ Keep the daily snapshot in the EBS snapshot standard tier for 1 month. Keep the monthly snapshot in the standard tier for 7 years. Use incremental snapshots. Keep the daily snapshot in the EBS snapshot standard tier. Use EBS direct APIs to take snapshots of all the EBS volumes every month. Store the snapshots in an Amazon S3 bucket in the Infrequent Access tier for 7 years. ✨ 关键词： 3️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：亚马逊EBS快照 您可以通过制作 point-in-time副本（称为亚马逊EBS快照）来备份您的 Amazon EBS 卷上的数据。快照是增量备份，这意味着我们仅保存卷上自最新快照之后发生更改的块。由于无需复制数据，这将最大限度缩短创建快照所需的时间和增加存储成本节省。 需要注意的是，默认的托管给 AWS 的快照备份是增量的。如果你将快照移动到 S3 等存储时，它是全量的因此容量会提升，从而提升费用。 👨‍👨‍👦‍👦 社区讨论：AnswerBThe problem is that we need to choose best solution which is most cost-effective and have minimal administrative effort. Glacier is the best choice for 1st look, but there is one problem with that solution. From what I know there is no easy way to copy from EBS to Glacier and additionally curent strategy is to make incremental snapshots. To copy file from EBS to (s3) Glacier we would need to run linux to which we will mount EBS and we will need copy everything to S3 and then move to glaceir deep archive. And what is more you will have only incremental snapshot. Hence every solution which will say copy/move to S3 is not minimal administrative effort. Not mentionig that you will not have full snapshothttps://repost.aws/questions/QUsaCoBAfbR6WMOz6BH3vqHA/move-ebs-to-glacier 十、AWS BackupA company runs an application on several Amazon EC2 instances that store persistent data on an Amazon Elastic File System (Amazon EFS) file system. The company needs to replicate the data to another AWS Region by using an AWS managed service solution.Which solution will meet these requirements MOST cost-effectively? ❌ Use the EFS-to-EFS backup solution to replicate the data to an EFS file system in another Region. Run a nightly script to copy data from the EFS file system to an Amazon S3 bucket. Enable S3 Cross-Region Replication on the S3 bucket. Create a VPC in another Region. Establish a cross-Region VPC peer. Run a nightly rsync to copy data from the original Region to the new Region. ✅ Use AWS Backup to create a backup plan with a rule that takes a daily backup and replicates it to another Region. Assign the EFS file system resource to the backup plan. ✨ 关键词： 1️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：备份 EFS 文件系统 Amazon EFS与AWS Backup原生集成，这是一种完全托管的基于策略的服务，您可以使用它来创建和管理备份策略，以保护Amazon EFS中的数据。使用AWS Backup for Amazon EFS，您可以执行以下操作： 通过配置备份计划来管理自动备份调度和保留。您可以指定备份频率、何时进行备份、保留备份的时间以及备份的生命周期策略。 恢复Amazon EFS数据的备份。您可以将文件系统数据恢复到新的或现有的文件系统。您还可以选择是执行完整还原还是项级还原。 官方也推荐使用 AWS Backup 进行 EFS 的备份操作。 👨‍👨‍👦‍👦 社区讨论：Answer D: AWS Backup is a managed service that handles backup operations. If AWS Backup is not available in your region, you can consider using EFS-to-EFS backup. 十一、Amazon Aurora Serverless clusterA large company wants to provide its globally located developers separate, limited size, managed PostgreSQL databases for development purposes. The databases will be low volume. The developers need the databases only when they are actively working. 一家大公司希望为其全球范围内的开发人员提供独立的、有限大小的、托管的 PostgreSQL 数据库，用于开发目的。数据库将是小容量的。开发人员只有在积极工作时才需要数据库。 Which solution will meet these requirements MOST cost-effectively? Give the developers the ability to launch separate Amazon Aurora instances. Set up a process to shut down Aurora instances at the end of the workday and to start Aurora instances at the beginning of the next workday. ❌ Develop an AWS Service Catalog product that enforces size restrictions for launching Amazon Aurora instances. Give the developers access to launch the product when they need a development database. ✅ Create an Amazon Aurora Serverless cluster. Develop an AWS Service Catalog product to launch databases in the cluster with the default capacity settings. Grant the developers access to the product. Monitor AWS Trusted Advisor checks for idle Amazon RDS databases. Create a process to terminate identified idle RDS databases. ✨ 关键词： 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：3️⃣ 的费用相对 2️⃣ 会更低。 👨‍👨‍👦‍👦 社区讨论：(A,B,D) eliminated. Aurora instances &amp; Amazon RDS use On-Demand or Reserved INSTANCES. These are more expensive than a serverless solution.(C) is correct. Amazon Aurora Serverless automatically starts up, shuts down &amp; scales capacity up or down based on your application’s needs; you pay only for capacity consumed. 十二、ACM RegionA company wants to configure its Amazon CloudFront distribution to use SSL/TLS certificates. The company does not want to use the default domain name for the distribution. Instead, the company wants to use a different domain name for the distribution.Which solution will deploy the certificate without incurring any additional costs? Request an Amazon issued private certificate from AWS Certificate Manager (ACM) in the us-east-1 Region. Request an Amazon issued private certificate from AWS Certificate Manager (ACM) in the us-west-1 Region. ✅ Request an Amazon issued public certificate from AWS Certificate Manager (ACM) in the us-east-1 Region. ❌ Request an Amazon issued public certificate from AWS Certificate Manager (ACM) in the us-west-1 Region. ✨ 关键词： 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：获取 SSL/TLS 证书 建议您使用 ACM 在 AWS 托管资源上预置、管理和部署 SSL/TLS 证书。您必须在美国东部（弗吉尼亚州北部）(us-east-1) 区域申请 ACM 证书。 👨‍👨‍👦‍👦 社区讨论：Have to use east-1 region for ACM, and it should be public SSL/TLS for domain, so it should be C 十三、Amazon QuickSight dashboardA company that uses AWS Organizations runs 150 applications across 30 different AWS accounts. The company used AWS Cost and Usage Report to create a new report in the management account. The report is delivered to an Amazon S3 bucket that is replicated to a bucket in the data collection account.The company’s senior leadership wants to view a custom dashboard that provides NAT gateway costs each day starting at the beginning of the current month.Which solution will meet these requirements? Share an Amazon QuickSight dashboard that includes the requested table visual. Configure QuickSight to use AWS DataSync to query the new report. ✅ Share an Amazon QuickSight dashboard that includes the requested table visual. Configure QuickSight to use Amazon Athena to query the new report. Share an Amazon CloudWatch dashboard that includes the requested table visual. Configure CloudWatch to use AWS DataSync to query the new report. ❌ Share an Amazon CloudWatch dashboard that includes the requested table visual. Configure CloudWatch to use Amazon Athena to query the new report. ✨ 关键词： 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：什么是 Amazon QuickSight？ Amazon QuickSight 是一项快速且易于使用的依托云的商业分析服务，它能让组织内的所有员工随时在任何设备上更轻松地构建可视化内容、执行临时分析并快速从数据中获取商业见解。上传 CSV 和 Excel 文件；访问本地数据库（如 SQL Server、MySQL 和 PostgreSQL）；连接到数据湖和数据仓库（如 Databricks、Snowflake 和 Teradat）以及无缝发现亚马逊云科技数据来源，如 Amazon Redshift、Amazon Relational Database Service（Amazon RDS）、Amazon Aurora、Amazon Athena 和 Amazon Simple Storage Service（Amazon S3）。借助 QuickSight，组织能够将其业务分析功能扩展到数十万用户，并通过使用强大的内存引擎（SPICE）实现快速且响应灵敏的查询性能。 Amazon QuickSight 图库 - 探索由 Amazon QuickSight 客户构建的特定于行业和领域的分析示例。联系我们，帮助您开始自己的分析。 使用 Amazon CloudWatch 控制面板 Amazon CloudWatch 控制面板是 CloudWatch 控制台中的可自定义主页，可用于在单个视图中监控资源，即便是分布到不同区域的资源，也能对其进行监控。您可以使用 CloudWatch 控制面板创建 AWS 资源的指标和告警的自定义视图。利用控制面板，您可以创建以下各项： 所选指标和告警的单一视图，用于帮助您跨一个或多个区域评估资源和应用程序的运行状况。您可以在每个图表上选择用于每个指标的颜色，以便轻松地跨多个图表跟踪同一指标。 一个操作手册，为团队成员提供有关如何对操作事件期间发生的特定事故做出响应的指南。 关键资源与应用程序测量的公共视图，团队成员可以共享该视图，以便在操作事件期间加快通信流。 👨‍👨‍👦‍👦 社区讨论：QuickSight for dashboard and Athena for query each month so it is B 十四、CacheA company is hosting a high-traffic static website on Amazon S3 with an Amazon CloudFront distribution that has a default TTL of 0 seconds. The company wants to implement caching to improve performance for the website. However, the company also wants to ensure that stale content is not served for more than a few minutes after a deployment.Which combination of caching methods should a solutions architect implement to meet these requirements? (Choose two.) ✅ Set the CloudFront default TTL to 2 minutes. Set a default TTL of 2 minutes on the S3 bucket. ✅ Add a Cache-Control private directive指令 to the objects in Amazon S3. ❌ Create an AWS Lambda@Edge function to add an Expires header to HTTP responses. Configure the function to run on viewer response. Add a Cache-Control max-age directive of 24 hours to the objects in Amazon S3. On deployment, create a CloudFront invalidation to clear any changed files from edge caches. ✨ 关键词： 1️⃣ 4️⃣ ❌ -&gt; 1️⃣ 3️⃣ ✅ 💡 解析：社区在 1️⃣ 3️⃣ 和 1️⃣ 5️⃣ 间争议较大。我猜测 1️⃣ 的目的是让 CloudFront 缓存 2 分钟内容，而 3️⃣ 的目的是让 CloudFront 每次回源 S3 都获取到最新文件，我认为这样的话就没什么问题。但是我不确定是不是可以这么理解。 👨‍👨‍👦‍👦 社区讨论：AE. By default, each file automatically expires after 24 hours, but you can change the default behavior in two ways: To change the cache duration for all files that match the same path pattern, you can change the CloudFront settings for Minimum TTL, Maximum TTL, and Default TTL for a cache behavior. To change the cache duration for an individual file, you can configure your origin to add a Cache-Control header with the max-age or s-maxage directive, or an Expires header to the file. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html#expiration-individual-objects 十五、BabelfishA company uses a Microsoft SQL Server database. The company’s applications are connected to the database. The company wants to migrate to an Amazon Aurora PostgreSQL database with minimal changes to the application code.Which combination of steps will meet these requirements? (Choose two.) Use the AWS Schema Conversion Tool (AWS SCT) to rewrite the SQL queries in the applications. ✅ Enable Babelfish on Aurora PostgreSQL to run the SQL queries from the applications. ✅ Migrate the database schema and data by using the AWS Schema Conversion Tool (AWS SCT) and AWS Database Migration Service (AWS DMS). Use Amazon RDS Proxy to connect the applications to Aurora PostgreSQL. Use AWS Database Migration Service (AWS DMS) to rewrite the SQL queries in the applications. ✨ 关键词： 2️⃣ 3️⃣ ✅ 💡 解析：Babelfish for Aurora PostgreSQL - 在 PostgreSQL 上运行 Microsoft SQL Server 应用程序，只需很少甚至无需进行代码更改 借助 Babelfish，Aurora PostgreSQL 现在可以理解 Microsoft SQL Server 专有的 SQL 语言 T-SQL，并支持相同的通信协议，因此您最初为 SQL Server 编写的应用程序现在可以与 Aurora 一起使用，并且所需进行的代码更改更少。因此，修改 SQL Server 2005 或更高版本上运行的应用程序并将其移动到 Aurora 所需的工作量将减少，从而可实现更快、风险更低且更具成本效益的迁移。 👨‍👨‍👦‍👦 社区讨论：DMS + SCT is correct, but “ rewrite the SQL queries in the applications.” is wrong so A + E are out.Then only left B + C -&gt; DMS + SCT + Babekfish (for SQL Server) 十六、EBS encryptionA company plans to rehost an application to Amazon EC2 instances that use Amazon Elastic Block Store (Amazon EBS) as the attached storage.A solutions architect must design a solution to ensure that all newly created Amazon EBS volumes are encrypted by default. The solution must also prevent the creation of unencrypted EBS volumes.Which solution will meet these requirements? ✅ Configure the EC2 account attributes to always encrypt new EBS volumes. ❌ Use AWS Config. Configure the encrypted-volumes identifier. Apply the default AWS Key Management Service (AWS KMS) key. Configure AWS Systems Manager to create encrypted copies of the EBS volumes. Reconfigure the EC2 instances to use the encrypted volumes. Create a customer managed key in AWS Key Management Service (AWS KMS). Configure AWS Migration Hub to use the key when the company migrates workloads. ✨ 关键词： 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：How do I turn on automatic encryption for new Amazon EBS volumes and snapshot copies created in my account? Newly created Amazon EBS volumes aren’t encrypted by default. However, you can turn on default encryption for new EBS volumes and snapshot copies that are created within a specified Region. To turn on encryption by default, use the Amazon Elastic Compute Cloud (Amazon EC2) console.Before you turn on encryption by default, note the following: Encryption by default is a Region-specific setting. After you turn on encryption for a Region, you can’t turn encryption off for individual volumes or snapshots in that Region. After you turn on encryption by default, you can launch an instance only if the instance type supports Amazon EBS encryption. When you turn on encryption by default, that change doesn’t affect existing unencrypted or encrypted resources. The encryption configuration change affects only volumes and snapshot copies that you create after you turn on encryption by default. If encryption by default is turned on and you experience delta replication failures when you use AWS Server Migration Service, then turn off encryption by default. For lift-and-shift migration, it’s a best practice to use Application Migration Service. 默认情况下，新创建的Amazon EBS卷不加密。但是，您可以为在指定区域内创建的新EBS卷和快照副本启用默认加密。要默认开启加密，请使用Amazon Elastic Compute Cloud （Amazon EC2）控制台。在启用默认加密之前，请注意以下事项： 默认加密是特定于区域的设置。在为一个区域开启加密后，无法关闭该区域中单个卷或快照的加密。 默认开启加密后，只有实例类型支持Amazon EBS加密，才能启动实例。 当默认情况下启用加密时，该更改不会影响现有的未加密或加密资源。默认情况下，加密配置更改仅影响在启用加密后创建的卷和快照副本。 如果默认开启加密，并且在使用AWS Server Migration Service时遇到增量复制失败，则默认关闭加密。对于升降迁移，使用应用程序迁移服务是最佳实践。 因此开启区域的自动加密后，就无法再启动不带加密卷的 EC2 实例了。 👨‍👨‍👦‍👦 社区讨论：Answer AThe task is to force automatic encryption for every new EBS volume and prevent possibility of creation any unencrypted volumehttps://docs.aws.amazon.com/ebs/latest/userguide/work-with-ebs-encr.html#ebs-encryption_mgmt To enable encryption by default for a RegionOpen the Amazon EC2 console at https://console.aws.amazon.com/ec2/ From the navigation pane, select EC2 Dashboard.In the upper-right corner of the page, choose Account Attributes, Data protection and security.Choose Manage.Select Enable. You keep the AWS managed key with the alias alias/aws/ebs created on your behalf as the default encryption key, or choose a symmetric customer managed encryption key.Choose Update EBS encryption. 十七、AWS Resource Access Manager (RAM)A company wants to isolate its workloads by creating an AWS account for each workload. The company needs a solution that centrally manages networking components for the workloads. The solution also must create accounts with automatic security controls (guardrails).Which solution will meet these requirements with the LEAST operational overhead? ✅ Use AWS Control Tower to deploy accounts. Create a networking account that has a VPC with private subnets and public subnets. Use AWS Resource Access Manager (AWS RAM) to share the subnets with the workload accounts. Use AWS Organizations to deploy accounts. Create a networking account that has a VPC with private subnets and public subnets. Use AWS Resource Access Manager (AWS RAM) to share the subnets with the workload accounts. ❌ Use AWS Control Tower to deploy accounts. Deploy a VPC in each workload account. Configure each VPC to route through an inspection VPC by using a transit gateway attachment. Use AWS Organizations to deploy accounts. Deploy a VPC in each workload account. Configure each VPC to route through an inspection VPC by using a transit gateway attachment. ✨ 关键词： 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：什么是 AWS Resource Access Manager？ AWS Resource Access Manager (AWS RAM) 可帮助您跨 AWS 账户、在组织或组织单位 (OU) 内以及与 AWS Identity and Access Management (IAM) 角色和用户针对受支持资源类型安全地共享资源。如果您有多个 AWS 账户，可以一次性创建一个资源，然后使用 AWS RAM 使该资源可供其他账户使用。如果您的账户由 AWS Organizations 管理，则您可以与组织中的所有其他账户共享资源，也可以仅与一个或多个指定组织单位 (OU) 所包含的账户共享资源。您还可以根据账户 ID 与特定 AWS 账户共享，而不管该账户是否属于组织。一些支持的资源类型还允许您与指定的 IAM 角色和用户进行共享。 RAM 可共享的资源 - Amazon VPC 集中创建和管理子网，并与组织内的 AWS 账户 共享这些子网。这样，多个用户就可以将其应用程序资源 AWS 账户 启动到集中管理状态VPCs。这些资源包括亚马逊EC2实例、亚马逊关系数据库服务 (RDS) 数据库、Amazon Redshift 集群和 AWS Lambda 函数。 👨‍👨‍👦‍👦 社区讨论：Statement: The solution also must create accounts with automatic security controls (guardrails). https://docs.aws.amazon.com/controltower/latest/userguide/what-is-control-tower.htmlAWS Control Tower provides a pre-packaged set of guardrails (policies) and blueprints (best-practice configurations) to ensure that the environment complies with security and compliance standards. It’s designed to simplify the process of creating and managing a multi-account AWS environment while maintaining security and compliance. 十八、Amazon Security LakeA company runs workloads in the AWS Cloud. The company wants to centrally collect security data to assess security across the entire company and to improve workload protection.Which solution will meet these requirements with the LEAST development effort? Configure a data lake in AWS Lake Formation. Use AWS Glue crawlers to ingest the security data into the data lake. Configure an AWS Lambda function to collect the security data in .csv format. Upload the data to an Amazon S3 bucket. ✅ Configure a data lake in Amazon Security Lake to collect the security data. Upload the data to an Amazon S3 bucket. Configure an AWS Database Migration Service (AWS DMS) replication instance to load the security data into an Amazon RDS cluster. ✨ 关键词： 3️⃣ ✅ 💡 解析：什么是 Amazon Security Lake？ Amazon Security Lake 是一项完全托管的安全数据湖服务。您可以使用 Security Lake 自动将来自 AWS 环境、SaaS 提供商、本地、云源和第三方来源的安全数据集中到存储在您的专用的数据湖中。 AWS 账户 Security Lake 可以帮助您分析安全数据，让您更全面地了解整个组织的安全状况。借助 Security Lake，您还可以改善对工作负载、应用程序和数据的保护。数据湖由 Amazon Simple Storage Service (Amazon S3) 存储桶提供支持，您保留数据的所有权。 👨‍👨‍👦‍👦 社区讨论：A, B, D are senseless + .Amazon Security Lake automatically centralizes security data from AWS environments, you can get a more complete understanding of your security data across your entire organization. You can also improve the protection.","link":"/2024/12/12/saa_test_daily_20241212/"},{"title":"SAA 考试每日练习 - 2024&#x2F;12&#x2F;09","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam100 题 (No.501 ~ No.600) 只记录了 21 道首次碰到的、错误的或有疑问的题目，仅供自己复习使用。其中后 65 题与正式考试题量一样，总共耗时 85/(130+30) 分钟，正确率为 48/65。如果侵权请联系删除。 一、TransitA company needs to connect several VPCs in the us-east-1 Region that span hundreds of AWS accounts. The company’s networking team has its own AWS account to manage the cloud network.What is the MOST operationally efficient solution to connect the VPCs? Set up VPC peering connections between each VPC. Update each associated subnet’s route table Configure a NAT gateway and an internet gateway in each VPC to connect each VPC through the internet ✅ Create an AWS Transit Gateway in the networking team’s AWS account. Configure static routes from each VPC. ❌ Deploy VPN gateways in each VPC. Create a transit VPC in the networking team’s AWS account to connect to each VPC. ✨ 关键词： 4️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：需要将几个 VPC 组网。无疑是需要用到 Transit 的，来看下用法：什么是 Amazon VPC Transit Gateway？ Amazon VPC Transit Gateway 是网络中转中心，您可用它来互连虚拟私有云（VPC）和本地网络。随着云基础架构的全球扩展，区域间对等使用全球基础架构将 AWS 中转网关连接在一起。AWS 数据中心之间的所有网络流量都在物理层自动加密。 需要使用到 AWS Transit Gateway 因此选 3️⃣。 👨‍👨‍👦‍👦 社区讨论：The main difference between AWS Transit Gateway and VPC peering is that AWS Transit Gateway is designed to connect multiple VPCs together in a hub-and-spoke model, while VPC peering is designed to connect two VPCs together in a peer-to- peer model.As we have several VPCs here, the answer should be C. 二、Security group ID cross RegionA global marketing company has applications that run in the ap-southeast-2 Region and the eu-west-1 Region. Applications that run in a VPC in eu-west-1 need to communicate securely with databases that run in a VPC in ap-southeast-2.Which network design will meet these requirements? Create a VPC peering connection between the eu-west-1 VPC and the ap-southeast-2 VPC. Create an inbound rule in the eu-west-1 application security group that allows traffic from the database server IP addresses in the ap-southeast-2 security group. ❌ Configure a VPC peering connection between the ap-southeast-2 VPC and the eu-west-1 VPC. Update the subnet route tables. Create an inbound rule in the ap-southeast-2 database security group that references the security group ID of the application servers in eu-west-1. ✅ Configure a VPC peering connection between the ap-southeast-2 VPC and the eu-west-1 VPUpdate the subnet route tables. Create an inbound rule in the ap-southeast-2 database security group that allows traffic from the eu-west-1 application server IP addresses. Create a transit gateway with a peering attachment between the eu-west-1 VPC and the ap-southeast-2 VPC. After the transit gateways are properly peered and routing is configured, create an inbound rule in the database security group that references the security group ID of the application servers in eu-west-1. ✨ 关键词： 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：无法跨区域引用安全组。更新您的安全组以引用对等安全组 对等 VPC 可以是您的账户中的 VPC，也可以是另一AWS账户中的 VPC。要引用位于其他 AWS 账户但属于相同区域的安全组，请将账号与安全组的 ID 一起包括在内。例如，123456789012/sg-1a2b3c4d。 您无法引用位于不同区域内的对等 VPC 的安全组。而是使用对等 VPC 的 CIDR 块。 可以跨账号引用相同区域的安全组。 👨‍👨‍👦‍👦 社区讨论：Answer: C –&gt;”You cannot reference the security group of a peer VPC that’s in a different Region. Instead, use the CIDR block of the peer VPC.”https://docs.aws.amazon.com/vpc/latest/peering/vpc-peering-security-groups.html 三、EKS nodeA company is running a microservices application on Amazon EC2 instances. The company wants to migrate the application to an Amazon Elastic Kubernetes Service (Amazon EKS) cluster for scalability. The company must configure the Amazon EKS control plane with endpoint private access set to true and endpoint public access set to false to maintain security compliance. The company must also put the data plane in private subnets. However, the company has received error notifications because the node cannot join the cluster.Which solution will allow the node to join the cluster? ✅ Grant the required permission in AWS Identity and Access Management (IAM) to the AmazonEKSNodeRole IAM role. ❌ Create interface VPC endpoints to allow nodes to access the control plane. Recreate nodes in the public subnet. Restrict security groups for EC2 nodes. Allow outbound traffic in the security group of the nodes. ✨ 关键词： 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：Amazon EKS 节点 IAM 角色 Amazon EKS 节点 kubelet 守护进程代表您调用 AWS API。节点通过 IAM 实例配置文件和关联的策略获得这些 API 调用的权限。您必须先为节点创建 IAM 角色以在启动它们时使用，然后才能启动这些节点并在集群中注册它们。必须先使用以下权限创建 IAM 角色，然后才能创建节点： kubelet 描述 VPC 中 Amazon EC2 资源的权限，例如 AmazonEKSWorkerNodePolicy 策略提供的权限。该策略还为 Amazon EKS 容器组身份代理提供权限。 👨‍👨‍👦‍👦 社区讨论：Check this : https://docs.aws.amazon.com/eks/latest/userguide/create-node-role.htmlAlso, EKS does not require VPC endpoints. This is not the right use case for EKS 四、Amazon RedshiftA company is migrating an on-premises application to AWS. The company wants to use Amazon Redshift as a solution.Which use cases are suitable for Amazon Redshift in this scenario? (Choose three.) ✅ Supporting data APIs to access data with traditional, containerized, and event-driven applications ✅ Supporting client-side and server-side encryption ❌ Building analytics workloads during specified hours and when the application is not active Caching data to reduce the pressure on the backend database ✅ Scaling globally to support petabytes of data and tens of millions of requests per minute Creating a secondary replica of the cluster by using the AWS Management Console ✨ 关键词： 1️⃣ 3️⃣ 5️⃣ ❌ -&gt; 1️⃣ 2️⃣ 5️⃣ ✅ 💡 解析：1️⃣ 正确：Using the Amazon Redshift Data API to interact with Amazon Redshift clusters 2️⃣ 正确：数据加密 使用服务器端加密 – 您请求 Amazon Redshift 在将数据保存到数据中心的磁盘上之前加密对象，并在下载对象时进行解密。 使用客户端加密 – 您可以在客户端加密数据并将加密的数据上载到 Amazon Redshift。在这种情况下，您需要管理加密过程、加密密钥和相关的工具。 社区争议很大。 👨‍👨‍👦‍👦 社区讨论：A: https://aws.amazon.com/de/blogs/big-data/get-started-with-the-amazon-redshift-data-api/B: https://docs.aws.amazon.com/redshift/latest/mgmt/security-encryption.htmlD: https://docs.aws.amazon.com/redshift/latest/dg/c_challenges_achieving_high_performance_queries.html#result-caching Not C: Redshift is a Data Warehouse; you can use that for analytics, but it is not directly related to an “application” .Not E: “Petabytes of data” yes, but “tens of millions of requests per minute” is not a typical feature of RedshiftNot F: Replicas are not a Redshift feature 五、Lambda concurrencyA company provides an API interface to customers so the customers can retrieve their financial information. Еhe company expects a larger number of requests during peak usage times of the year.The company requires the API to respond consistently with low latency to ensure customer satisfaction. The company needs to provide a compute host for the API.Which solution will meet these requirements with the LEAST operational overhead? Use an Application Load Balancer and Amazon Elastic Container Service (Amazon ECS). ✅ Use Amazon API Gateway and AWS Lambda functions with provisioned concurrency. Use an Application Load Balancer and an Amazon Elastic Kubernetes Service (Amazon EKS) cluster. Use Amazon API Gateway and AWS Lambda functions with reserved concurrency. ✨ 关键词： 2️⃣ ✅ 💡 解析：为函数配置预留并发 预留并发 (Reserved concurrency) – 指分配给函数的最大并发实例数。当一个函数有预留并发时，任何其他函数都不可以使用该并发。对于确保最关键的函数始终具有足够的并发性来处理传入请求，预留并发非常有用。为函数配置预留并发不产生任何额外费用。 预置并发 (Provisioned concurrency) – 指分配给函数的预初始化执行环境的数量。这些执行环境已准备就绪，可以立即响应传入的函数请求。预置并发对于缩短函数冷启动延迟很有用。配置预置并发会让您的 AWS 账户产生额外费用。 预置 (Provisioned) 后相应延迟更低。 👨‍👨‍👦‍👦 社区讨论：In the context of the given scenario, where the company wants low latency and consistent performance for their API during peak usage times, it would be more suitable to use provisioned concurrency. By allocating a specific number of concurrent executions, the company can ensure that there are enough function instances available to handle the expected load and minimize the impact of cold starts. This will result in lower latency and improved performance for the API. 六、AWS Service CatalogA consulting company provides professional services to customers worldwide. The company provides solutions and tools for customers to expedite gathering and analyzing data on AWS. The company needs to centrally manage and deploy a common set of solutions and tools for customers to use for self-service purposes.Which solution will meet these requirements? ❌ Create AWS CloudFormation templates for the customers. ✅ Create AWS Service Catalog products for the customers. Create AWS Systems Manager templates for the customers. Create AWS Config items for the customers. ✨ 关键词： 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：什么是 Service Catalog？ 借助 Service Catalog，组织可以创建和管理获准在 AWS 上使用的 IT 服务的目录。这些 IT 服务可谓包罗万象，从虚拟机映像、服务器、软件和数据库，再到完整的多层应用程序架构等。 和它很像的服务：什么是 Amazon Cognito？ Amazon Cognito 是 Web 和移动应用程序的身份平台。它是一个用户目录、一个身份验证服务器以及一个用于 OAuth 2.0 访问令牌和 AWS 凭据的授权服务。使用 Amazon Cognito，您可以对内置用户目录、企业目录以及 Google 和 Facebook 等使用者身份提供者中的用户进行身份验证和授权。 👨‍👨‍👦‍👦 社区讨论：CloudFormation: a code as infrastructure serviceSystems Manager: management solution for resourcesConfig: assess, audit and evaluate configurationsOther options does not fit this scenario. 七、RDS cluster deploymentA company wants to provide data scientists with near real-time read-only access to the company’s production Amazon RDS for PostgreSQL database. The database is currently configured as a Single-AZ database. The data scientists use complex queries that will not affect the production database. The company needs a solution that is highly available.Which solution will meet these requirements MOST cost-effectively? Scale the existing production database in a maintenance window to provide enough power for the data scientists. Change the setup from a Single-AZ to a Multi-AZ instance deployment with a larger secondary standby instance. Provide the data scientists access to the secondary instance. ❌ Change the setup from a Single-AZ to a Multi-AZ instance deployment. Provide two additional read replicas for the data scientists. ✅ Change the setup from a Single-AZ to a Multi-AZ cluster deployment with two readable standby instances. Provide read endpoints to the data scientists. ✨ 关键词： 3️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：Amazon RDS 的多可用区数据库集群部署 多可用区数据库集群部署是 Amazon RDS 的半同步、高可用性部署模式，具有两个可读副本数据库实例。多可用区数据库集群在同一个 AWS 区域 的三个独立可用区中有一个写入器数据库实例和两个读取器数据库实例。与多可用区数据库实例部署相比，多可用区数据库集群可提供高可用性、增加读取工作负载容量以及更低的写入延迟。 以 Aurora 为例：Amazon Aurora 数据库集群 Amazon Aurora 数据库集群包含一个或多个数据库实例以及一个管理这些数据库实例的数据的集群卷。Aurora 集群卷是一个跨多个可用区的虚拟数据库存储卷，每个可用区具有一个数据库集群数据副本。Aurora 数据库集群由两类数据库实例组成： 主（写入器）数据库实例 – 支持读取和写入操作，并执行针对集群卷的所有数据修改。每个 Aurora 数据库集群均有一个主数据库实例。 Aurora 副本（读取器数据库实例）– 连接到同一存储卷作为主数据库实例，但仅支持读取操作。除主数据库实例之外，每个 Aurora 数据库集群最多可拥有 15 个 Aurora 副本。通过将 Aurora 副本放在单独的可用区中维护高可用性。当主数据库实例不可用时，Aurora 自动故障转移到 Aurora 副本。您可以为 Aurora 副本指定故障转移优先级。Aurora 副本还可以从主数据库实例分载读取工作负载。 集群天生带只读副本，更便宜。 👨‍👨‍👦‍👦 社区讨论：Highly Available = Multi-AZ ClusterRead-only + Near Real time = readable standby.Read replicasare async whereas readable standby is synchronous.https://stackoverflow.com/questions/70663036/differences-b-w-aws-read-replica-and-the-standby-instances It’seither C or D.To be honest, I find the newest questions to be ridiculously hard (roughly 500+). I agree with @alexandercamachop that Multi Az in Instance mode is cheaper than Cluster. However, with Cluster we have readerendpoint available to use out-of-box, so there is no need to provide read-replicas, which also has its own costs.The ridiculous part is that I’m pretty sure even the AWS support would have troubles to answer which configuration is MOST cost-effective. 八、Session storageA company runs a three-tier web application in the AWS Cloud that operates across three Availability Zones. The application architecture has an Application Load Balancer, an Amazon EC2 web server that hosts user session states, and a MySQL database that runs on an EC2 instance. The company expects sudden increases in application traffic. The company wants to be able to scale to meet future application capacity demands and to ensure high availability across all three Availability Zones.Which solution will meet these requirements? ✅ Migrate the MySQL database to Amazon RDS for MySQL with a Multi-AZ DB cluster deployment. Use Amazon ElastiCache for Redis with high availability to store session data and to cache reads. Migrate the web server to an Auto Scaling group that is in three Availability Zones. ❌ Migrate the MySQL database to Amazon RDS for MySQL with a Multi-AZ DB cluster deployment. Use Amazon ElastiCache for Memcached with high availability to store session data and to cache reads. Migrate the web server to an Auto Scaling group that is in three Availability Zones. Migrate the MySQL database to Amazon DynamoDB Use DynamoDB Accelerator (DAX) to cache reads. Store the session data in DynamoDB. Migrate the web server to an Auto Scaling group that is in three Availability Zones. Migrate the MySQL database to Amazon RDS for MySQL in a single Availability Zone. Use Amazon ElastiCache for Redis with high availability to store session data and to cache reads. Migrate the web server to an Auto Scaling group that is in three Availability Zones. ✨ 关键词：session 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：与 Redis OSS 兼容的 Amazon ElastiCache Redis OSS 是一种得到广泛采用的内存数据存储，可用作数据库、缓存、消息代理、队列、会话存储和排行榜。 适用于 Memcached 的 ElastiCache 适用于 Memcached 的 Amazon ElastiCache 可以用作内存数据存储和缓存，能够支持要求最严苛且需要亚毫秒级响应时间的应用程序。 非超低延迟需求的场景都选 Redis 即可。 👨‍👨‍👦‍👦 社区讨论：Memcached is best suited for caching data, while Redis is better for storing data that needs to be persisted. If you need to store data that needs to be accessed frequently, such as user profiles, session data,and application settings, then Redis is the better choice. 九、Multi-AZ DB clusterA company has an on-premises server that uses an Oracle database to process and store customer information. The company wants to use an AWS database service to achieve higher availability and to improve application performance. The company also wants to offload reporting from its primary database system.Which solution will meet these requirements in the MOST operationally efficient way? ❌ Use AWS Database Migration Service (AWS DMS) to create an Amazon RDS DB instance in multiple AWS Regions. Point the reporting functions toward a separate DB instance from the primary DB instance. Use Amazon RDS in a Single-AZ deployment to create an Oracle database. Create a read replica in the same zone as the primary DB instance. Direct the reporting functions to the read replica. Use Amazon RDS deployed in a Multi-AZ cluster deployment to create an Oracle database. Direct the reporting functions to use the reader instance in the cluster deployment. ✅ Use Amazon RDS deployed in a Multi-AZ instance deployment to create an Amazon Aurora database. Direct the reporting functions to the reader instances. ✨ 关键词： 1️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：支持 Amazon RDS 中多可用区数据库集群的区域和数据库引擎 多可用区数据库集群不适用于以下引擎： RDS for Db2 RDS for MariaDB RDS for Oracle RDS for SQL Server 因此本题只能迁移到 Aurora 集群。 👨‍👨‍👦‍👦 社区讨论：Its D Multi-AZ DB clustersaren’t available with the following engines: RDS for MariaDB RDS for Oracle RDS forSQL Server https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RDS_Fea_Regions_DB-eng.Feature.MultiAZDBClusters.html 十、AWS OrganizationA company runs Amazon EC2 instances in multiple AWS accounts that are individually bled. The company recently purchased a Savings Pian. Because of changes in the company’s business requirements, the company has decommissioned a large number of EC2 instances. The company wants to use its Savings Plan discounts on its other AWS accounts.Which combination of steps will meet these requirements? (Choose two.) ✅ From the AWS Account Management Console of the management account, turn on discount sharing from the billing preferences section. From the AWS Account Management Console of the account that purchased the existing Savings Plan, turn on discount sharing from the billing preferences section. Include all accounts. ❌ From the AWS Organizations management account, use AWS Resource Access Manager (AWS RAM) to share the Savings Plan with other accounts. ✅ Create an organization in AWS Organizations in a new payer account. Invite the other AWS accounts to join the organization from the management account. Create an organization in AWS Organizations in the existing AWS account with the existing EC2 instances and Savings Plan. Invite the other AWS accounts to join the organization from the management account. ✨ 关键词： 1️⃣ 3️⃣ ❌ -&gt; 1️⃣ 4️⃣ ✅ 💡 解析：社区在 4️⃣ 5️⃣ 间争执较大，不用纠结。如果想强行记忆的话可以认定管理账户不适合做资源操作，因此 5️⃣ 不合适。明确 1️⃣ 相关知识点吧：预留实例和实惠配套折扣共享 激活共享的预留实例和实惠配套折扣 登录 AWS Management Console 并打开 AWS Billing and Cost Management 控制台 在导航窗格中，选择账单首选项。 在按账户的预留实例和实惠配套折扣共享首选项下，选择要激活折扣共享的账户。 选择激活。 在激活预留实例和实惠配套共享对话框中，选择激活。 您也可以选择操作，然后选择全部激活，以为所有账户激活预留实例和实惠配套共享。 在（Organizations 管理账户的）管理控制台的账单和费用控制台，为所有 AWS 账户启动预留实例和节省套餐。 👨‍👨‍👦‍👦 社区讨论：Organization should be created by a new account that is reserved for management.Thus D, followed by A (discount sharing must be enabled in the management account). 十一、S3 StorageA company has a financial application that produces reports. The reports average 50 KB in size and are stored in Amazon S3.The reports are frequently accessed during the first week after production and must be stored for several years. The reports must be retrievable within 6 hours.Which solution meets these requirements MOST cost-effectively? ✅ Use S3 Standard. Use an S3 Lifecycle rule to transition the reports to S3 Glacier after 7 days. Use S3 Standard. Use an S3 Lifecycle rule to transition the reports to S3 Standard-Infrequent Access (S3 Standard-IA) after 7 days. Use S3 Intelligent-Tiering. Configure S3 Intelligent-Tiering to transition the reports to S3 Standard-Infrequent Access (S3 Standard-IA) and S3 Glacier. ❌ Use S3 Standard. Use an S3 Lifecycle rule to transition the reports to S3 Glacier Deep Archive after 7 days. ✨ 关键词： 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：归档存储检索时间问题，参考社区回答，普通归档在 3 ~ 5 小时，深度在 12 小时。 👨‍👨‍👦‍👦 社区讨论：Answer is AAmazon S3 Glacier:Expedited Retrieval: Providesaccess to data within 1-5 minutes.Standard Retrieval: Providesaccess to data within 3-5 hours.Bulk Retrieval: Providesaccess to data within 5-12 hours. Amazon S3 Glacier Deep Archive:Standard Retrieval: Providesaccess to data within 12 hours.Bulk Retrieval: Providesaccess to data within 48 hours. 十二、SQS security groupA company runs an application in a VPC with publicand private subnets. The VPC extends across multiple Availability Zones. The application runs on Amazon EC2 instances in private subnets. The application uses an Amazon Simple Queue Service (Amazon SQS) queue.A solutions architect needs to design a secure solution to establish a connection between the EC2 instances and the SQS queue.Which solution will meet these requirements? ✅ Implement an interface VPC endpoint for Amazon SQS. Configure the endpoint to use the private subnets. Add to the endpoint a security group that has an inbound access rule that allows traffic from the EC2 instances that are in the private subnets. Implement an interface VPC endpoint for Amazon SQS. Configure the endpoint to use the public subnets. Attach to the interface endpoint a VPC endpoint policy that allows access from the EC2 instances that are in the private subnets. ❌ Implement an interface VPC endpoint for Amazon SQS. Configure the endpoint to use the public subnets. Attach an Amazon SQS access policy to the interface VPC endpoint that allows requests from only a specified VPC endpoint. Implement a gateway endpoint for Amazon SQS. Add a NAT gateway to the private subnets. Attach an IAM role to the EC2 instances that allows access to the SQS queue. ✨ 关键词： 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：VPC 接口终端节点 可以配置安全组：AWS 服务 使用接口VPC终端节点访问一个 为终端节点网络接口创建一个安全组，允许来自您的资源的预期流量VPC。例如，为了确保 AWS CLI 可以向发送HTTPS请求 AWS 服务，安全组必须允许入站HTTPS流量。 👨‍👨‍👦‍👦 社区讨论：BC are using public subnets so not useful for securityD uses gatewayendpoint which is not useful to connect to SQSA: https://docs.aws.amazon.com/vpc/latest/privatelink/aws-services-privatelink-support.html 十三、Amazon EMRA solutions architect manages an analytics application. The application stores large amounts of semistructured data in an Amazon S3 bucket. The solutions architect wants to use parallel data processing to process the data more quickly. The solutions architect also wants to use information that is stored in an Amazon Redshift database to enrich the data.Which solution will meet these requirements? Use Amazon Athena to process the S3 data. Use AWS Glue with the Amazon Redshift data to enrich the S3 data. ✅ Use Amazon EMR to process the S3 data. Use Amazon EMR with the Amazon Redshift data to enrich the S3 data. Use Amazon EMR to process the S3 data. Use Amazon Kinesis Data Streams to move the S3 data into Amazon Redshift so that the data can be enriched. ❌ Use AWS Glue to process the S3 data. Use AWS Lake Formation with the Amazon Redshift data to enrich the S3 data. ✨ 关键词： 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：什么是 Amazon EMR？ Amazon EMR（以前称为 Amazon Elastic MapReduce）是一个托管集群平台，可简化在AWS上运行大数据框架的过程，以处理和分析海量数据。 Amazon EMR 上的 Apache Hadoop Hadoop 可用于处理 Web 和移动应用程序生成的日志。Hadoop 可帮助您将数 PB 的非结构化或半结构化数据转变为与应用程序或用户有关的有用洞察信息。 从 Amazon EMR 中加载数据 您可以使用 COPY 命令从一个具有如下配置的 Amazon EMR 集群并行加载数据（到 RedShift 中）：将文本文件作为固定宽度文件、字符分隔文件、CSV 文件或 JSON 格式文件写入到集群的 Hadoop Distributed File System (HDFS)。 👨‍👨‍👦‍👦 社区讨论：Option B is the correct solution that meets the requirements: Use Amazon EMR to process the semi-structured data in Amazon S3.EMR providesa managed Hadoop framework optimized for processing large datasets in S3. EMR supports parallel data processing across multiple nodes to speed up the processing. EMR can integrate directly with Amazon Redshift using the EMR-Redshift integration.Thisallows querying the Redshift data from EMR and joining it with the S3 data. This enablesenriching the semi-structured S3 data with the information stored in Redshift 十四、EKSA company runs its applications on both Amazon Elastic Kubernetes Service (Amazon EKS) clusters and on-premises Kubernetes clusters. The company wants to view all clusters and workloads from a central location.Which solution will meet these requirements with the LEAST operational overhead? Use Amazon CloudWatch Container Insights to collect and group the cluster information. ✅ Use Amazon EKS Connector to register and connect all Kubernetes clusters. Use AWS Systems Manager to collect and view the cluster information. ❌ Use Amazon EKS Anywhere as the primary cluster to view the other clusters with native Kubernetes commands. ✨ 关键词： 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：使用 Amazon EKS Connector 将 Kubernetes 集群连接到 Amazon EKS 管理控制台 您可以使用 Amazon EKS Connector 注册并将任何符合要求的 Kubernetes 集群连接至 AWS，并在 Amazon EKS 控制台中进行显示。连接集群后，您可以在 Amazon EKS 控制台中查看集群的状态、配置和工作负载。您可以使用此功能在 Amazon EKS 控制台中查看已连接的集群，但您无法对其进行管理。 Amazon EKS Anywhere 是什么？ Amazon EKS Anywhere 是由 AWS 构建的容器管理软件，便于在本地和边缘运行和管理 Kubernetes 集群。 👨‍👨‍👦‍👦 社区讨论：EKS Connector -&gt; ‘view clustersand workloads’as requestedEKS Anywhere -&gt; create and manage on-premisesEKS clusters 十五、Amazon EventBridgeAn Amazon EventBridge rule targets a third-party API. The third-party API has not received any incoming traffic. A solutions architect needs to determine whether the rule conditions are being met and if the rule’s target is being invoked.Which solution will meet these requirements? ✅ Check for metrics in Amazon CloudWatch in the namespace for AWS/Events. Review events in the Amazon Simple Queue Service (Amazon SQS) dead-letter queue. Check for the events in Amazon CloudWatch Logs. ❌ Check the trails in AWS CloudTrail for the EventBridge events. ✨ 关键词： 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：监控亚马逊 EventBridge EventBridge CloudWatch 每分钟向 Amazon 发送指标，从匹配的事件数到规则调用目标的次数，应有尽有。 什么是 AWS CloudTrail？ AWS CloudTrail 是一项 AWS 服务，可帮助您实现 AWS 账户 的运营和风险审计、治理和合规性。用户、角色或 AWS 服务执行的操作将记录为 CloudTrail 中的事件。事件包括在 AWS Management Console、AWS Command Line Interface 和 AWS 开发工具包和 API 中执行的操作。 什么是 Amazon CloudWatch？ Amazon CloudWatch 可实时监控您的亚马逊云科技 (AWS) 资源以及您在 AWS 上运行的应用程序。您可以使用 CloudWatch 收集和跟踪指标，这些指标是您可衡量的相关资源和应用程序的变量。 👨‍👨‍👦‍👦 社区讨论：”EventBridge sends metrics to Amazon CloudWatch every minute foreverything from the number of matched events to the number of timesa target is invoked bya rule.”from https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-monitoring.html B: SQS, irrelevantC: ‘Checkforevents’, this wording is confusing but could mean something in wrong context. I would have chosen C if A wasn’t an optionD: CloudTrail is for AWS resource monitoring so irrelevant 十六、Third-party CA on ACMA company is creating a REST API. The company has strict requirements for the use of TLS. The company requires TLSv1.3 on the API endpoints. The company also requires a specific public third-party certificate authority (CA) to sign the TLS certificate.Which solution will meet these requirements? ✅ Use a local machine to create a certificate that is signed by the third-party CImport the certificate into AWS Certificate Manager (ACM). Create an HTTP API in Amazon API Gateway with a custom domain. Configure the custom domain to use the certificate. ❌ Create a certificate in AWS Certificate Manager (ACM) that is signed by the third-party CA. Create an HTTP API in Amazon API Gateway with a custom domain. Configure the custom domain to use the certificate. Use AWS Certificate Manager (ACM) to create a certificate that is signed by the third-party CA. Import the certificate into AWS Certificate Manager (ACM). Create an AWS Lambda function with a Lambda function URL. Configure the Lambda function URL to use the certificate. Create a certificate in AWS Certificate Manager (ACM) that is signed by the third-party CA. Create an AWS Lambda function with a Lambda function URL. Configure the Lambda function URL to use the certificate. ✨ 关键词： 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：无法在 ACM 上申请第三方证书。 👨‍👨‍👦‍👦 社区讨论：I don’t understand why some many people vote B. In ACM, you can either request certificate from Amazon CA or import an existing certificate.There is no option in ACM that allow you to request a certificate that can be signed by third party CA. 十七、ACUA company runs an application on AWS. The application receives inconsistent amounts of usage. The application uses AWS Direct Connect to connect to an on-premises MySQL-compatible database. The on-premises database consistently uses a minimum of 2 GiB of memory.The company wants to migrate the on-premises database to a managed AWS service. The company wants to use auto scaling capabilities to manage unexpected workload increases.Which solution will meet these requirements with the LEAST administrative overhead? Provision an Amazon DynamoDB database with default read and write capacity settings. ❌ Provision an Amazon Aurora database with a minimum capacity of 1 Aurora capacity unit (ACU). ✅ Provision an Amazon Aurora Serverless v2 database with a minimum capacity of 1 Aurora capacity unit (ACU). Provision an Amazon RDS for MySQL database with 2 GiB of memory. ✨ 关键词： 2️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：Aurora Serverless v2 容量 Aurora Serverless v2 的计量单位是 Aurora 容量单位（ACU）。Aurora Serverless v2 容量与您用于预置集群的数据库实例类无关。每个 ACU 是约 2 GiB 的内存、相应的 CPU 和网络的组合。您可以使用此计量单位指定数据库容量范围。 👨‍👨‍👦‍👦 社区讨论：The key reasons:Aurora Serverless v2 providesauto-scaling so the database can handle inconsistent workloadsand spikesautomatically without admin intervention.It can scale down to zero when not in use to minimize costs.The minimum 1 ACU capacity is sufficient to replace the on-prem 2 GiB database based on the info given.Serverless capabilities reduce admin overhead for capacity management.DynamoDB lacks MySQL compatibilityand requires more hands-on management.RDS and provisioned Aurora require manually resizing instances to scale, increasing admin overhead. 十八、Lambda SnapStartA company wants to use an event-driven programming model with AWS Lambda. The company wants to reduce startup latency for Lambda functions that run on Java 11. The company does not have strict latency requirements for the applications. The company wants to reduce cold starts and outlier latencies when a function scales up.Which solution will meet these requirements MOST cost-effectively? ❌ Configure Lambda provisioned concurrency. Increase the timeout of the Lambda functions. Increase the memory of the Lambda functions. ✅ Configure Lambda SnapStart. ✨ 关键词： 1️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：使用 Lambda SnapStart 提高启动性能 适用于 Java 的 Lambda SnapStart 可以将延迟敏感型应用程序的启动性能提高多达 10 倍，而无需支付额外费用，通常也无需更改您的函数代码。导致启动延迟的最大因素（通常称为冷启动时间）是指 Lambda 在初始化函数上花费的时间，其中包括加载函数代码、启动运行时以及初始化函数代码。 支持的功能和限制 SnapStart 支持 Java 11 和更高版本的 Java 托管运行时系统。不支持其他托管运行时系统（例如 nodejs20.x 和 python3.12）、仅限操作系统的运行时系统 和容器映像。 SnapStart 不支持预置并发、Amazon Elastic File System（Amazon EFS）或大于 512MB 的短暂存储。 之后看到 Java11 + Lambda 的关键词要小心。并且它和 provisioned concurrency 互斥。 👨‍👨‍👦‍👦 社区讨论：Both Lambda SnapStart and provisioned concurrency can reduce cold startsand outlier latencies when a function scales up. SnapStart helps you improve startup performance by up to 10x at no extra cost. Provisioned concurrency keeps functions initialized and ready to respond in double-digit milliseconds. Configuring provisioned concurrency incurs charges to your AWS account. Use provisioned concurrency if your application has strict cold start latency requirements. You can’t use both SnapStart and provisioned concurrency on the same function version. 十九、EBSA company uses locally attached storage to run a latency-sensitive application on premises. The company is using a lift and shift method to move the application to the AWS Cloud. The company does not want to change the application architecture.Which solution will meet these requirements MOST cost-effectively? ❌ Configure an Auto Scaling group with an Amazon EC2 instance. Use an Amazon FSx for Lustre file system to run the application. Host the application on an Amazon EC2 instance. Use an Amazon Elastic Block Store (Amazon EBS) GP2 volume to run the application. Configure an Auto Scaling group with an Amazon EC2 instance. Use an Amazon FSx for OpenZFS file system to run the application. ✅ Host the application on an Amazon EC2 instance. Use an Amazon Elastic Block Store (Amazon EBS) GP3 volume to run the application. ✨ 关键词： 1️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：不想动架构的迁移，确实是部署到一台服务器上最好。2️⃣ 和 4️⃣ 中 GP3 更便宜。 👨‍👨‍👦‍👦 社区讨论：gp3 offersSSD-performance at a 20% lower cost per GB than gp2 volumes. 二十、Multi-AZ RedisA solutions architect is designing a highly available Amazon ElastiCache for Redis based solution. The solutions architect needs to ensure that failures do not result in performance degradation or loss of data locally and within an AWS Region. The solution needs to provide high availability at the node level and at the Region level.Which solution will meet these requirements? ✅ Use Multi-AZ Redis replication groups with shards that contain multiple nodes. ❌ Use Redis shards that contain multiple nodes with Redis append only files (AOF) turned on. Use a Multi-AZ Redis cluster with more than one read replica in the replication group. Use Redis shards that contain multiple nodes with Auto Scaling turned on. ✨ 关键词： 2️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：Redis AOF Redis 分别提供了 RDB 和 AOF 两种持久化机制： RDB 将数据库的快照（snapshot）以二进制的方式保存到磁盘中。 AOF 则以协议文本的方式，将所有对数据库进行过写入的命令（及其参数）记录到 AOF 文件，以此达到记录数据库状态的目的。 👨‍👨‍👦‍👦 社区讨论：It seems like “Multi-AZ Redis replication group” (A) and “Multi-AZ Redis cluster” (C) are different wordings for the same configuration. However, “to minimize the impact of a node failure, we recommend that your implementation use multiple nodes in each shard” - and that is mentioned only in A. high availabilityat the node level = shard and Multi A-Z = region level 二十一、GlueA research company uses on-premises devices to generate data for analysis. The company wants to use the AWS Cloud to analyze the data. The devices generate .csv files and support writing the data to an SMB file share. Company analysts must be able to use SQL commands to query the data. The analysts will run queries periodically throughout the day.Which combination of steps will meet these requirements MOST cost-effectively? (Choose three.) ✅ Deploy an AWS Storage Gateway on premises in Amazon S3 File Gateway mode. ❌ Deploy an AWS Storage Gateway on premises in Amazon FSx File Gateway made. ✅ Set up an AWS Glue crawler to create a table based on the data that is in Amazon S3. Set up an Amazon EMR cluster with EMR File System (EMRFS) to query the data that is in Amazon S3. Provide access to analysts. ❌ Set up an Amazon Redshift cluster to query the data that is in Amazon S3. Provide access to analysts. ✅ Setup Amazon Athena to query the data that is in Amazon S3. Provide access to analysts. ✨ 关键词： 2️⃣ 5️⃣ 6️⃣ ❌ -&gt; 1️⃣ 3️⃣ 6️⃣ ✅ 💡 解析：Amazon S3 File Gateway 提供了 SMB 协议（NFS 也支持）：创建 SMB 文件共享 对于使用以下工具访问对象，选择服务器消息块 (SMB). 因此 1️⃣ 是正确的。在 AWS Glue 中使用 CSV 格式和 AWS Glue 概念 AWS Glue 是一项完全托管式的 ETL（提取、转换、加载）服务，让您能够在不同的数据来源和目标之间轻松移动数据。关键组件包括： Data Catalog：一种元数据存储，其中包含 ETL 工作流的表定义、作业定义和其他控制信息。 爬网程序：连接到数据来源、推断数据架构以及在 Data Catalog 中创建元数据表定义的程序。 ETL 作业：从源中提取数据、使用 Apache Spark 脚本进行转换并将其加载到目标中的业务逻辑。 触发器：基于计划或事件启动作业运行的机制。 典型的工作流涉及： 在 Data Catalog 中定义数据来源和目标。 通过爬网程序以使用来自数据来源的表元数据填充 Data Catalog。 使用转换脚本定义 ETL 作业，以移动和处理数据。 按需运行作业或基于触发器运行作业。 使用控制面板监控作业性能。 因此 3️⃣ 也正确。 👨‍👨‍👦‍👦 社区讨论：SQL Queries is Athena so DE are wrong and we are now dependant on S3A to get files into S3C Glue to convert CSV to S3 table dataB irrelevant as we don’t have anything to consume data from FSx in other options","link":"/2024/12/09/saa_test_daily_20241209/"},{"title":"SAP 考试每日练习 - 2025&#x2F;01&#x2F;02","text":"来源：Amazon AWS Certified Solutions Architect - Professional SAP-C02 Exam10 题 (No.18 ~ No.27)，仅供自己复习使用。如果侵权请联系删除。 一、Video categorization applicationA company has a web application that allows users to upload short videos. The videos are stored on Amazon EBS volumes and analyzed by custom recognition software for categorization.The website contains static content that has variable traffic with peaks in certain months. The architecture consists of Amazon EC2 instances running in an Auto Scaling group for the web application and EC2 instances running in an Auto Scaling group to process an Amazon SQS queue. The company wants to re-architect the application to reduce operational overhead using AWS managed services where possible and remove dependencies on third-party software.Which solution meets these requirements? ❌ Use Amazon ECS containers for the web application and Spot instances for the Auto Scaling group that processes the SQS queue. Replace the custom software with Amazon Rekognition to categorize the videos. Store the uploaded videos in Amazon EFS and mount the file system to the EC2 instances for the web application. Process the SQS queue with an AWS Lambda function that calls the Amazon Rekognition API to categorize the videos. ✅ Host the web application in Amazon S3. Store the uploaded videos in Amazon S3. Use S3 event notification to publish events to the SQS queue. Process the SQS queue with an AWS Lambda function that calls the Amazon Rekognition API to categorize the videos. Use AWS Elastic Beanstalk to launch EC2 instances in an Auto Scaling group for the web application and launch a worker environment to process the SQS queue. Replace the custom software with Amazon Rekognition to categorize the videos. ✨ 关键词： 1️⃣ ❌ -&gt; 3️⃣ ✅ 💡 解析：这里的问题在于 Web 应用程序是否是全静态的，如果是全静态的话无疑 3️⃣ 就是最佳选择：使用的技术栈都是 AWS 托管的。 👨‍👨‍👦‍👦 社区讨论：This solution meets the requirements by using multiple managed services offered by AWS which can reduce the operational overhead. Hosting the web application in Amazon S3 would make it highlyavailable, scalable and can handle variable traffic.The uploaded videos can be stored in S3 and processed using S3 event notifications that trigger a Lambda function, which calls the Amazon Rekognition API to categorize the videos.SQS can be used to process the event notificationsand also it is a managed service.This solution eliminates the need to manage EC2 instances, EBS volumesand the custom software. Additionally, using Lambda function in this case,eliminates the need for managing additional servers to process the SQS queue which will reduce operational overhead.By using this solution, the company can benefit from the scalability, reliability,and cost-effectiveness that these services offer, which can help to reduce operational overhead and improve the overall performance and security of the application. 二、Serverless Application DeployA company has a serverless application comprised of Amazon CloudFront, Amazon API Gateway, and AWS Lambda functions.The current deployment process of the application code is to create a new version number of the Lambda function and run an AWS CLI script to update. If the new function version has errors, another CLI script reverts by deploying the previous working version of the function. The company would like to decrease the time to deploy new versions of the application logic provided by the Lambda functions, and also reduce the time to detect and revert when errors are identified.How can this be accomplished? Create and deploy nested AWS CloudFormation stacks with the parent stack consisting of the AWS CloudFront distribution and API Gateway, and the child stack containing the Lambda function. For changes to Lambda, create an AWS CloudFormation change set and deploy; if errors are triggered, revert the AWS CloudFormation change set to the previous version. ✅ Use AWS SAM and built-in AWS CodeDeploy to deploy the new Lambda version, gradually shift traffic to the new version, and use pre-traffic and post-traffic test functions to verify code. Rollback if Amazon CloudWatch alarms are triggered. Refactor the AWS CLI scripts into a single script that deploys the new Lambda version. When deployment is completed, the script tests execute. If errors are detected, revert to the previous Lambda version. Create and deploy an AWS CloudFormation stack that consists of a new API Gateway endpoint that references the new Lambda version. Change the CloudFront origin to the new API Gateway endpoint, monitor errors and if detected, change the AWS CloudFront origin to the previous API Gateway endpoint. ✨ 关键词： 2️⃣ ✅ 💡 解析：Lambda 的多版本部署问题。使用 AWS SAM 逐步部署无服务器应用程序 AWS Serverless Application Model (AWS SAM) 内置于 CodeDeploy 中，可提供逐步 AWS Lambda 部署。只需几行配置，AWS SAM 即可为您完成以下操作： 部署 Lambda 函数的新版本，并自动创建指向新版本的别名。 逐步将客户流量转移到新版本，直到您确认它按预期方式运行。如果更新无法正常运行，则可以回滚更改。 定义转移流量前和转移流量后的测试函数，来验证新部署的代码是否已正确配置并且您的应用程序是否按预期方式运行。 如果触发了 CloudWatch 警报，则会自动回滚部署。 这里需要注意的是，SAM 内置了 CodeDeploy，并且它的架构是这样的： 👨‍👨‍👦‍👦 社区讨论：AWS Serverless Application Model (SAM) is a frameworkthat helps you build, test and deploy your serverlessapplications. It uses CloudFormation under the hood, so it isa way to simplify the process of creating, updating,and deploying CloudFormation templates. CodeDeploy isa service that automates code deployments to any instance, including on-premises instancesand Lambda functions.With AWS SAM you can use the built-in CodeDeploy to deploy new versions of the Lambda function, gradually shift traffic to the new version,and use pre-traffic and post-traffic test functions to verify code.You can also define CloudWatch Alarms to trigger a rollbackin case of any issues.Thisallows for a faster and more efficient deployment process,as well asa more reliable rollback process when errorsare identified.This way you can increase the speed of deployment and reduce the time to detect and revert when errorsare identified. 三、Glacier Deep ArchiveA company is planning to store a large number of archived documents and make the documents available to employees through the corporate intranet. Employees will access the system by connecting through a client VPN service that is attached to a VPC. The data must not be accessible to the public.The documents that the company is storing are copies of data that is held on physical media elsewhere. The number of requests will be low. Availability and speed of retrieval are not concerns of the company.Which solution will meet these requirements at the LOWEST cost? ✅ Create an Amazon S3 bucket. Configure the S3 bucket to use the S3 One Zone-Infrequent Access (S3 One Zone-IA) storage class as default. Configure the S3 bucket for website hosting. Create an S3 interface endpoint. Configure the S3 bucket to allow access only through that endpoint. Launch an Amazon EC2 instance that runs a web server. Attach an Amazon ElasticFile System (Amazon EFS) file system to store the archived data in the EFS One Zone-Infrequent Access (EFS One Zone-IA) storage class Configure the instance security groups to allow access only from private networks. Launch an Amazon EC2 instance that runs a web server Attach an Amazon Elastic Block Store (Amazon EBS) volume to store the archived data. Use the Cold HDD (sc1) volume type. Configure the instance security groups to allow access only from private networks. ❌ Create an Amazon S3 bucket. Configure the S3 bucket to use the S3 Glacier Deep Archive storage class as default. Configure the S3 bucket for website hosting. Create an S3 interface endpoint. Configure the S3 bucket to allow access only through that endpoint. ✨ 关键词： 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：这里社区存在整体，4️⃣ 的深度归档显然更便宜，但是它存在检索时间超过 12 的问题，如果使用它托管网页并请求下载的话，一定会出现超时问题，因此 4️⃣ 并不是很好。而题目中强调了这些数据只是备份，因此可以使用单区存储，显然 1️⃣ 贴合了考点。 👨‍👨‍👦‍👦 社区讨论：A - Glacier Deep Archive can’t be used for web hosting, regardless if the company says retrieval time is no concern. 四、AWS ADA company is using an on-premises Active Directory service for user authentication. The company wants to use the same authentication service to sign in to the company’s AWS accounts, which are using AWS Organizations. AWS Site-to-Site VPN connectivity already exists between the on-premises environment and all the company’s AWS accounts.The company’s security policy requires conditional access to the accounts based on user groups and roles. User identities must be managed in a single location.Which solution will meet these requirements? ✅ Configure AWS IAM Identity Center (AWS Single Sign-On) to connect to Active Directory by using SAML 2.0. Enable automatic provisioning by using the System for Cross-domain Identity Management (SCIM) v2.0 protocol. Grant access to the AWS accounts by using attribute-based access controls (ABACs). Configure AWS IAM Identity Center (AWS Single Sign-On) by using IAM Identity Center as an identity source. Enable automatic provisioning by using the System for Cross-domain Identity Management (SCIM) v2.0 protocol. Grant access to the AWS accounts by using IAM Identity Center permission sets. In one of the company’s AWS accounts, configure AWS Identity and Access Management (IAM) to use a SAML 2.0 identity provider. Provision IAM users that are mapped to the federated users. Grant access that corresponds to appropriate groups in Active Directory. Grant access to the required AWS accounts by using cross-account IAM users. In one of the company’s AWS accounts, configure AWS Identity and Access Management (IAM) to use an OpenID Connect (OIDC) identity provider. Provision IAM roles that grant access to the AWS account for the federated users that correspond to appropriate groups in Active Directory. Grant access to the required AWS accounts by using cross-account IAM roles. ✨ 关键词： 1️⃣ ✅ 💡 解析：本地有 AD，已经架设了 Site-to-Site VPN，希望用户凭证在单区进行管理。 👨‍👨‍👦‍👦 社区讨论：Both option C and option A are valid solutions that meet the requirements for the scenario.ABAC, or attribute-based access control, isa method of granting access to resources based on the attributes of the user, the resource,and the action.Thisallows for fine-grained access control, which can be useful for implementing a security policy that requires conditional access to the accounts based on user groupsand roles.AWS IAM Identity Center (AWS SSO) allows you to connect to your on-premises Active Directory service using SAML 2.0. Withthis, you can enable automatic provisioning by using the System for Cross-domain Identity Management (SCIM) v2.0 protocol,which allows for the management of user identities in a single location. 五、API throttlingA software company has deployed an application that consumes a REST API by using Amazon API Gateway, AWS Lambda functions, and an Amazon DynamoDB table. The application is showing an increase in the number of errors during PUT requests. Most of the PUT calls come from a small number of clients that are authenticated with specific API keys.A solutions architect has identified that a large number of the PUT requests originate from one client. The API is noncritical, and clients can tolerate retries of unsuccessful calls. However, the errors are displayed to customers and are causing damage to the API’s reputation.What should the solutions architect recommend to improve the customer experience? Implement retry logic with exponential backoff and irregular variation in the client application. Ensure that the errors are caught and handled with descriptive error messages. ✅ Implement API throttling through a usage plan at the API Gateway level. Ensure that the client application handles code 429 replies without error. Turn on API caching to enhance responsiveness for the production stage. Run 10-minute load tests. Verify that the cache capacity is appropriate for the workload. Implement reserved concurrency at the Lambda function level to provide the resources that are needed during sudden increases in traffic. ✨ 关键词： 2️⃣ ✅ 💡 解析：问题的本质是来自单一客户端的大量请求导致出现大量错误，节流进行控制非常合理。 👨‍👨‍👦‍👦 社区讨论：API throttling isa technique that can be used to control the rate of requests to an API.This can be useful in situations where a small number of clientsare making a large number of requests, which is causing errors. By implementing API throttling through a usage plan at the API Gateway level, the solutionsarchitect can limit the number of requests that a client can make, which will help to reduce the number of errors.It’s important that the client application handles the code 429 replies without error, this will help to improve the customer experience by reducing the number of errors that are displayed to customers. Additionally, it will prevent the API’s reputation from being damaged by the errors. 六、S3 lazy loadingA company is running a data-intensive application on AWS. The application runs on a cluster of hundreds of Amazon EC2 instances. A shared file system also runs on several EC2 instances that store 200 TB of data. The application reads and modifies the data on the shared file system and generates a report. The job runs once monthly, reads a subset of the files from the shared file system, and takes about 72 hours to complete. The compute instances scale in an Auto Scaling group, but the instances that host the shared file system run continuously. The compute and storage instances are all in the same AWS Region.A solutions architect needs to reduce costs by replacing the shared file system instances. The file system must provide high performance access to the needed data for the duration of the 72-hour run.Which solution will provide the LARGEST overall cost reduction while meeting these requirements? ✅ Migrate the data from the existing shared file system to an Amazon S3 bucket that uses the S3 Intelligent-Tiering storage class. Before the job runs each month, use Amazon FSx for Lustre to create a new file system with the data from Amazon S3 by using lazy loading. Use the new file system as the shared storage for the duration of the job. Delete the file system when the job is complete. Migrate the data from the existing shared file system to a large Amazon Elastic Block Store (Amazon EBS) volume with Multi-Attach enabled. Attach the EBS volume to each of the instances by using a user data script in the Auto Scaling group launch template. Use the EBS volume as the shared storage for the duration of the job. Detach the EBS volume when the job is complete ❌ Migrate the data from the existing shared file system to an Amazon S3 bucket that uses the S3 Standard storage class. Before the job runs each month, use Amazon FSx for Lustre to create a new file system with the data from Amazon S3 by using batch loading. Use the new file system as the shared storage for the duration of the job. Delete the file system when the job is complete. Migrate the data from the existing shared file system to an Amazon S3 bucket. Before the job runs each month, use AWS Storage Gateway to create a file gateway with the data from Amazon S3. Use the file gateway as the shared storage for the job. Delete the file gateway when the job is complete. ✨ 关键词： 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：Lazy load 当您使用缓存访问链接的 Amazon S3 或 NFS 数据存储库中的数据时，Amazon File Cache 会自动加载元数据（名称、所有权、时间戳和权限）和文件内容（如果缓存中还没有这些内容）。数据存储库中的数据会以文件和目录的形式出现在缓存中。当您在 DRA 目录中读取或写入文件数据或元数据时，会触发懒加载。如果数据尚未可用，Amazon File Cache 会将数据从链接的数据存储库加载到缓存中。例如，当您打开文件、统计文件或对文件进行元数据更新时，就会触发懒加载。 👨‍👨‍👦‍👦 社区讨论：A: Lazy loading is cost-effective because onlya subset of data is used at every jobB:There are hundreds of EC2 instances using the volume which is not possible (one EBS volume is limited to 16 nitro instances attached)C: Batching would load too much dataD: storage gateway is used for on premises data access, I don’t know is you can install a gateway in AWS, but Amazon would never advise this 七、Assign Elastic IP addresses to the NLBA company is developing a new service that will be accessed using TCP on a static port. A solutions architect must ensure that the service is highly available, has redundancy across Availability Zones, and is accessible using the DNS name my.service.com, which is publicly accessible. The service must use fixed address assignments so other companies can add the addresses to their allow lists.Assuming that resources are deployed in multiple Availability Zones in a single Region, which solution will meet these requirements? Create Amazon EC2 instances with an Elastic IP address for each instance. Create a Network Load Balancer (NLB) and expose the static TCP port. Register EC2 instances with the NLB. Create a new name server record set named my.service.com, and assign the Elastic IP addresses of the EC2 instances to the record set. Provide the Elastic IP addresses of the EC2 instances to the other companies to add to their allow lists. Create an Amazon ECS cluster and a service definition for the application. Create and assign public IP addresses for the ECS cluster. Create a Network Load Balancer (NLB) and expose the TCP port. Create a target group and assign the ECS cluster name to the NLCreate a new A record set named my.service.com, and assign the public IP addresses of the ECS cluster to the record set. Provide the public IP addresses of the ECS cluster to the other companies to add to their allow lists. ✅ Create Amazon EC2 instances for the service. Create one Elastic IP address for each Availability Zone. Create a Network Load Balancer (NLB) and expose the assigned TCP port. Assign the Elastic IP addresses to the NLB for each Availability Zone. Create a target group and register the EC2 instances with the NLB. Create a new A (alias) record set named my.service.com, and assign the NLB DNS name to the record set. Create an Amazon ECS cluster and a service definition for the application. Create and assign public IP address for each host in the cluster. Create an Application Load Balancer (ALB) and expose the static TCP port. Create a target group and assign the ECS service definition name to the ALB. Create a new CNAME record set and associate the public IP addresses to the record set. Provide the Elastic IP addresses of the Amazon EC2 instances to the other companies to add to their allow lists. ✨ 关键词： 3️⃣ ✅ 💡 解析：ALB 与 NLB 能否绑定弹性 IP ALB不支持绑定EIP，ALB是会根据业务负载进行扩展的， NLB可以绑定EIP。 解决方式是： 将解析托管到 R53，R53 可以将顶级域名解析到 ALB（ALIAS 记录） 在 Network Load Balancer (NLB) 的目标组中配置 ALB 作为其目标，然后将 EIP 分配给 NLB。 使用 NLB, 替换 ALB。 需要注意的是 ALB 不支持绑定弹性 IP。 👨‍👨‍👦‍👦 社区讨论：Logical answer : Non http port like TCP should hint to NLB immediately.(ALB does not fit here) Sharing IP address of EC2 is not aptwhether it is from individual EC2 instances or those from ECS cluster.thiseliminates A,B.D, infact the NLB’saddress which stays in front of / associates to ec2 instances need to be shared.So, only solution is C 八、SLAA company uses an on-premises data analytics platform. The system is highly available in a fully redundant configuration across 12 servers in the company’s data center.The system runs scheduled jobs, both hourly and daily, in addition to one-time requests from users. Scheduled jobs can take between 20 minutes and 2 hours to finish running and have tight SLAs. The scheduled jobs account for 65% of the system usage. User jobs typically finish running in less than 5 minutes and have no SLA. The user jobs account for 35% of system usage. During system failures, scheduled jobs must continue to meet SLAs. However, user jobs can be delayed.A solutions architect needs to move the system to Amazon EC2 instances and adopt a consumption-based model to reduce costs with no long-term commitments. The solution must maintain high availability and must not affect the SLAs.Which solution will meet these requirements MOST cost-effectively? Split the 12 instances across two Availability Zones in the chosen AWS Region. Run two instances in each Availability Zone as On-Demand Instances with Capacity Reservations. Run four instances in each Availability Zone as Spot Instances. Split the 12 instances across three Availability Zones in the chosen AWS Region. In one of the Availability Zones, run all four instances as On-Demand Instances with Capacity Reservations. Run the remaining instances as Spot Instances. Split the 12 instances across three Availability Zones in the chosen AWS Region. Run two instances in each Availability Zone as On-Demand Instances with a Savings Plan. Run two instances in each Availability Zone as Spot Instances. ✅ Split the 12 instances across three Availability Zones in the chosen AWS Region. Run three instances in each Availability Zone as On-Demand Instances with Capacity Reservations. Run one instance in each Availability Zone as a Spot Instance. ✨ 关键词： 4️⃣ ✅ 💡 解析：公司不想做长期保证因此不选 3️⃣。 👨‍👨‍👦‍👦 社区讨论：Voted D because of the 65% / 35% proportion. C seems to be good but with only 50% instancesavailable we breakthe SLA 九、AWS Secrets Manager RotationScheduleA security engineer determined that an existing application retrieves credentials to an Amazon RDS for MySQL database from an encrypted file in Amazon S3. For the next version of the application, the security engineer wants to implement the following application design changes to improve security:The database must use strong, randomly generated passwords stored in a secure AWS managed service.The application resources must be deployed through AWS CloudFormation.The application must rotate credentials for the database every 90 days.A solutions architect will generate a CloudFormation template to deploy the application.Which resources specified in the CloudFormation template will meet the security engineer’s requirements with the LEAST amount of operational overhead? ✅ Generate the database password as a secret resource using AWS Secrets Manager. Create an AWS Lambda function resource to rotate the database password. Specify a Secrets Manager RotationSchedule resource to rotate the database password every 90 days. Generate the database password as a SecureString parameter type using AWS Systems Manager Parameter Store. Create an AWS Lambda function resource to rotate the database password. Specify a Parameter Store RotationSchedule resource to rotate the database password every 90 days. Generate the database password as a secret resource using AWS Secrets Manager. Create an AWS Lambda function resource to rotate the database password. Create an Amazon EventBridge scheduled rule resource to trigger the Lambda function password rotation every 90 days. Generate the database password as a SecureString parameter type using AWS Systems Manager Parameter Store. Specify an AWS AppSync DataSource resource to automatically rotate the database password every 90 days. ✨ 关键词： 1️⃣ ✅ 💡 解析：AWS::SecretsManager::RotationSchedule 设置密文的旋转时间表和 Lambda 轮转函数。 12345678910{ &quot;Type&quot; : &quot;AWS::SecretsManager::RotationSchedule&quot;, &quot;Properties&quot; : { &quot;HostedRotationLambda&quot; : HostedRotationLambda, &quot;RotateImmediatelyOnUpdate&quot; : Boolean, &quot;RotationLambdaARN&quot; : String, &quot;RotationRules&quot; : RotationRules, &quot;SecretId&quot; : String }} 👨‍👨‍👦‍👦 社区讨论：Ahttps://docs.aws.amazon.com/secretsmanager/latest/userguide/cloudformation.htmlOption B is wrong.The ParameterStore::RotationSchedule resource does not exist in CloudFormation.Option C is wrong. It does not meet the requirement because it does not use CloudFormation.Option D is wrong.The AWS::AppSync::DataSource resource is what to create data sources for resolvers in AWS AppSync to connect to. 十、API Gateway REST API direct integrationsA company is storing data in several Amazon DynamoDB tables. A solutions architect must use a serverless architecture to make the data accessible publicly through a simple API over HTTPS. The solution must scale automatically in response to demand.Which solutions meet these requirements? (Choose two.) ✅ Create an Amazon API Gateway REST API. Configure this API with direct integrations to DynamoDB by using API Gateway’s AWS integration type. Create an Amazon API Gateway HTTP API. Configure this API with direct integrations to Dynamo DB by using API Gateway’s AWS integration type. ✅ Create an Amazon API Gateway HTTP API. Configure this API with integrations to AWS Lambda functions that return data from the DynamoDB tables. Create an accelerator in AWS Global Accelerator. Configure this accelerator with AWS Lambda@Edge function integrations that return data from the DynamoDB tables. Create a Network Load Balancer. Configure listener rules to forward requests to the appropriate AWS Lambda functions. ✨ 关键词： 1️⃣ 3️⃣ ✅ 💡 解析：AWS 介绍了使用 REST API 操作 DynamoDB 的案例：API Gateway 使用案例 使用 API Gateway 创建 REST API例如，使用 DynamoDB 作为后端，API 开发人员会设置集成请求以便将传入方法请求转发到所选的后端。该设置包括适当 DynamoDB 操作的规范、所需的 IAM 角色和策略以及所需的输入数据转换。后端将结果作为集成响应返回到 API Gateway。 👨‍👨‍👦‍👦 社区讨论：A and C.API Gateway REST API can invoke DynamoDB directly.https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-overview-developer-experience.html","link":"/2025/01/02/sap_test_daily_20250102/"},{"title":"针对需要认证的 Seafile 文件分享链接编写 Linux 下可用的下载脚本","text":"前言虽然 Seafile 官方提供了文件操作的 API，但是似乎并未提供对需要认证的文件分享链接直接下载的接口。而我的需求就是这个，没办法只能自己检查每个请求重新封装下流程了。 方案概述 抓包确定下加密文件分享链接下载的全过程 GET 请求文件分享链接获得 sfcsrftoken、csrfmiddlewaretoken 和 token POST 请求文件分享链接获得 sessionid 请求参数为：csrfmiddlewaretoken、token 和 password请求头为：Cookie: sfcsrftoken=$sfcsrftoken GET 请求文件分享链接被 302 跳转到实际的文件下载链接 请求参数为：dl=1请求头为：Cookie: sfcsrftoken=$sfcsrftoken;sessionid=$sessionid GET 请求文件下载链接进行实际下载 请求头为：Cookie: sfcsrftoken=$sfcsrftoken;sessionid=$sessionid 封装下 Bash 代码 托管到 GitHub 和 Gitee 使其能被一键调用 操作步骤一、抓包确定下加密文件分享链接下载的全过程1、GET 请求文件分享链接获得 sfcsrftoken、csrfmiddlewaretoken 和 token对应的是打开链接后显示的密码输入页面：Request 请求没有需要注意的： 123456789101112curl 'https://seafile.ceshiku.cn/f/xxxxxxxxxxxxxxxxx8faebc/' --compressed \\ -H 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:130.0) Gecko/20100101 Firefox/130.0' \\ -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/png,image/svg+xml,*/*;q=0.8' \\ -H 'Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2' \\ -H 'Accept-Encoding: gzip, deflate, br, zstd' \\ -H 'Connection: keep-alive' \\ -H 'Upgrade-Insecure-Requests: 1' \\ -H 'Sec-Fetch-Dest: document' \\ -H 'Sec-Fetch-Mode: navigate' \\ -H 'Sec-Fetch-Site: none' \\ -H 'Sec-Fetch-User: ?1' \\ -H 'Priority: u=0, i' \\ 返回的响应头中有 sfcsrftoken： 1234567891011HTTP/1.1 200 OKServer: nginx/1.26.2Date: Fri, 20 Sep 2024 07:13:39 GMTContent-Type: text/html; charset=utf-8Transfer-Encoding: chunkedConnection: keep-aliveVary: Cookie, Accept-LanguageContent-Language: zh-cn# 这里为之后的请求 Cookie 设置了 sfcsrftoken 的值Set-Cookie: sfcsrftoken=XxxxxxxxxxxxxxxxxxxxxxxxxxoOj4oC; expires=Fri, 19 Sep 2025 07:13:39 GMT; Max-Age=31449600; Path=/; SameSite=LaxContent-Encoding: gzip 返回的响应体中有 csrfmiddlewaretoken 和 token： 12345678910111213&lt;div class=&quot;mt-9 mb-4 mx-auto small-panel&quot;&gt; &lt;p class=&quot;intro&quot;&gt;如需查看共享的文件/目录，请输入解密密码。&lt;/p&gt; &lt;form action=&quot;/f/xxxxxxxxxxxxxxxxx8faebc/&quot; method=&quot;post&quot; id=&quot;share-passwd-form&quot;&gt; &lt;!-- 这里有 csrfmiddlewaretoken 和 token 的值 --&gt; &lt;input type=&quot;hidden&quot; name=&quot;csrfmiddlewaretoken&quot; value=&quot;0EmXExxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&quot;&gt; &lt;input type=&quot;hidden&quot; name=&quot;token&quot; value=&quot;xxxxxxxxxxxxxxxxx8faebc&quot; /&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;password&quot;&gt;密码&lt;/label&gt; &lt;input type=&quot;password&quot; name=&quot;password&quot; id=&quot;password&quot; class=&quot;form-control&quot; autofocus /&gt; &lt;/div&gt; &lt;button type=&quot;submit&quot; class=&quot;btn btn-primary sf-btn-submit&quot;&gt;提交&lt;/button&gt; &lt;/form&gt;&lt;/div&gt; 2、POST 请求文件分享链接获得 sessionid对应的是输入密码后点击提交的那一步。Request 请求把 csrfmiddlewaretoken、token 和 password 传过去了，同时请求头中设置了 sfcsrftoken： 12345678910111213141516171819curl &quot;https://seafile.ceshiku.cn/f/xxxxxxxxxxxxxxxxx8faebc/&quot; --compressed \\ -X POST -H &quot;User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:130.0) Gecko/20100101 Firefox/130.0&quot; \\ -H &quot;Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/png,image/svg+xml,*/*;q=0.8&quot; \\ -H &quot;Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2&quot; \\ -H &quot;Accept-Encoding: gzip, deflate, br, zstd&quot; \\ -H &quot;Content-Type: application/x-www-form-urlencoded&quot; \\ -H &quot;Origin: https://seafile.ceshiku.cn&quot; \\ -H &quot;Connection: keep-alive&quot; \\ -H &quot;Referer: https://seafile.ceshiku.cn/f/xxxxxxxxxxxxxxxxx8faebc/&quot; \\ # Cookie 中设置了 sfcsrftoken -H &quot;Cookie: sfcsrftoken=XxxxxxxxxxxxxxxxxxxxxxxxxxoOj4oC&quot; \\ -H &quot;Upgrade-Insecure-Requests: 1&quot; \\ -H &quot;Sec-Fetch-Dest: document&quot; \\ -H &quot;Sec-Fetch-Mode: navigate&quot; \\ -H &quot;Sec-Fetch-Site: same-origin&quot; \\ -H &quot;Sec-Fetch-User: ?1&quot; \\ -H &quot;Priority: u=0, i&quot; \\ # POST 的数据中有 csrfmiddlewaretoken、token 和 password --data-raw &quot;csrfmiddlewaretoken=0EmXExxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&amp;token=xxxxxxxxxxxxxxxxx8faebc&amp;password=0123456789&quot; 返回的响应体中有 sessionid： 123456789101112HTTP/1.1 200 OKServer: nginx/1.26.2Date: Fri, 20 Sep 2024 07:43:03 GMTContent-Type: text/html; charset=utf-8Transfer-Encoding: chunkedConnection: keep-aliveVary: Cookie, Accept-LanguageContent-Language: zh-cn# 这里为之后的请求 Cookie 设置了 sessionid 的值Set-Cookie: sfcsrftoken=XxxxxxxxxxxxxxxxxxxxxxxxxxoOj4oC; expires=Fri, 19 Sep 2025 07:43:03 GMT; Max-Age=31449600; Path=/; SameSite=Laxsessionid=urqmxtxxxxxxxxxxxxxxxxxxxxxxxxxibb; expires=Sat, 21 Sep 2024 07:43:03 GMT; HttpOnly; Max-Age=86400; Path=/; SameSite=LaxContent-Encoding: gzip 3、GET 请求文件分享链接被 302 跳转到实际的文件下载链接对应的点击下载的那一步。Request 的请求头中设置了 sfcsrftoken 和 sessionid： 123456789101112131415curl &quot;https://seafile.ceshiku.cn/f/xxxxxxxxxxxxxxxxx8faebc/?dl=1&quot; \\ -H &quot;User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:130.0) Gecko/20100101 Firefox/130.0&quot; \\ -H &quot;Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/png,image/svg+xml,*/*;q=0.8&quot; \\ -H &quot;Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2&quot; \\ -H &quot;Accept-Encoding: gzip, deflate, br, zstd&quot; \\ -H &quot;Connection: keep-alive&quot; \\ -H &quot;Referer: https://seafile.ceshiku.cn/f/xxxxxxxxxxxxxxxxx8faebc/&quot; \\ # 这里设置了 sfcsrftoken 和 sessionid -H &quot;Cookie: sfcsrftoken=XxxxxxxxxxxxxxxxxxxxxxxxxxoOj4oC; sessionid=urqmxtxxxxxxxxxxxxxxxxxxxxxxxxxibb&quot; \\ -H &quot;Upgrade-Insecure-Requests: 1&quot; \\ -H &quot;Sec-Fetch-Dest: document&quot; \\ -H &quot;Sec-Fetch-Mode: navigate&quot; \\ -H &quot;Sec-Fetch-Site: same-origin&quot; \\ -H &quot;Sec-Fetch-User: ?1&quot; \\ -H &quot;Priority: u=0, i&quot; 响应代码是 302，响应头里包含了文件的实际下载地址： 1234567891011HTTP/1.1 302 FoundServer: nginx/1.26.2Date: Fri, 20 Sep 2024 07:49:27 GMTContent-Type: text/html; charset=utf-8Content-Length: 0Connection: keep-alive# 文件的实际下载地址Location: https://seafile.ceshiku.cn/seafhttp/files/39acfe42-e492-4281-b503-e519f310ac8f/test.txtVary: Cookie, Accept-LanguageContent-Language: zh-cnSet-Cookie: sfcsrftoken=XxxxxxxxxxxxxxxxxxxxxxxxxxoOj4oC; expires=Fri, 19 Sep 2025 07:49:27 GMT; Max-Age=31449600; Path=/; SameSite=Lax 4、GET 请求文件下载链接进行实际下载下载请求的请求头里设置了 sfcsrftoken 和 sessionid： 123456789101112131415curl &quot;https://seafile.ceshiku.cn/seafhttp/files/39acfe42-e492-4281-b503-e519f310ac8f/test.txt&quot; --compressed \\ -H &quot;User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:130.0) Gecko/20100101 Firefox/130.0&quot; \\ -H &quot;Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/png,image/svg+xml,*/*;q=0.8&quot; \\ -H &quot;Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2&quot; \\ -H &quot;Accept-Encoding: gzip, deflate, br, zstd&quot; \\ -H &quot;Referer: https://seafile.ceshiku.cn/f/xxxxxxxxxxxxxxxxx8faebc/&quot; \\ -H &quot;Connection: keep-alive&quot; \\ # 这里设置了 sfcsrftoken 和 sessionid -H &quot;Cookie: sfcsrftoken=XxxxxxxxxxxxxxxxxxxxxxxxxxoOj4oC; sessionid=urqmxtxxxxxxxxxxxxxxxxxxxxxxxxxibb&quot; \\ -H &quot;Upgrade-Insecure-Requests: 1&quot; \\ -H &quot;Sec-Fetch-Dest: document&quot; \\ -H &quot;Sec-Fetch-Mode: navigate&quot; \\ -H &quot;Sec-Fetch-Site: same-origin&quot; \\ -H &quot;Sec-Fetch-User: ?1&quot; \\ -H &quot;Priority: u=0, i&quot; 实际上在这里，直接使用文件下载链接、不设置任何头就可以完成下载： 1wget https://seafile.ceshiku.cn/seafhttp/files/39xxxe42-exxx-xxx1-bxxx-exxxfxxxaxxx/test.txt 不过显然这并不符合安全规范，也不清楚未来是否会被修复，因此在后续的脚本中依然会带上完整的认证信息头。 二、封装下 Bash 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109#!/bin/bash# 1. 检查依赖# 1.1 检查 curl 是否安装if ! command -v curl &amp;&gt; /dev/null; then echo &quot;curl is not installed. Please install it and try again.&quot; exit 1fi# 1.2 检查 wget 是否安装if ! command -v wget &amp;&gt; /dev/null; then echo &quot;wget is not installed. Please install it and try again.&quot; exit 1fi# 2. 检查参数url=$1password=$2# 未提供 url 或 passwordif [ -z &quot;$url&quot; ] || [ -z &quot;$password&quot; ]; then echo &quot;Usage: $0 &lt;url&gt; &lt;password&gt;&quot; exit 1fi# 3. 第一次请求，获得 sfcsrftoken、csrfmiddlewaretoken 和 tokenecho &quot;==================== Request 01 start ====================&quot;# 3.1 使用 curl 请求response=$(curl -i -s $url)# 3.2 使用正则 &quot;Set-Cookie: sfcsrftoken=(.*);&quot; 提取 sfcsrftokensfcsrftoken=$(echo &quot;$response&quot; | grep -oP 'Set-Cookie: sfcsrftoken=\\K[^;]*')# 3.3 使用正则 '&lt;input type=&quot;hidden&quot; name=&quot;csrfmiddlewaretoken&quot; value=&quot;(.*)&quot;' 提取 csrfmiddlewaretokencsrfmiddlewaretoken=$(echo &quot;$response&quot; | grep -oP '&lt;input type=&quot;hidden&quot; name=&quot;csrfmiddlewaretoken&quot; value=&quot;\\K[^&quot;]*')# 3.4 使用正则 '&lt;input type=&quot;hidden&quot; name=&quot;token&quot; value=&quot;(.*)&quot;'token=$(echo &quot;$response&quot; | grep -oP '&lt;input type=&quot;hidden&quot; name=&quot;token&quot; value=&quot;\\K[^&quot;]*')# 3.5 打印值echo &quot;sfcsrftoken: $sfcsrftoken&quot;echo &quot;csrfmiddlewaretoken: $csrfmiddlewaretoken&quot;echo &quot;token: $token&quot;echo &quot;===================== Request 01 end =====================&quot;# 3.6 检查是否成功提取if [ -z &quot;$sfcsrftoken&quot; ] || [ -z &quot;$csrfmiddlewaretoken&quot; ] || [ -z &quot;$token&quot; ]; then echo &quot;Failed to extract tokens from the response.&quot; exit 1fi# 4. 发送 POST 请求以获得 sessionidecho &quot;==================== Request 02 start ====================&quot;# 4.1 请求体 data-raw 设置为 csrfmiddlewaretoken=$csrfmiddlewaretoken&amp;token=$token&amp;password=$passworddata=&quot;csrfmiddlewaretoken=$csrfmiddlewaretoken&amp;token=$token&amp;password=$password&quot;# 请求头的 Cookie 设置为 sfcsrftoken=$sfcsrftokenheader_cookie=&quot;sfcsrftoken=$sfcsrftoken&quot;header_content_type=&quot;Content-Type: application/x-www-form-urlencoded&quot;header_referer=&quot;$url&quot;response=$(curl -i -s -X POST -H &quot;Cookie: $header_cookie&quot; -H &quot;Referer: $header_referer&quot; -d &quot;$data&quot; &quot;$url&quot;)# 4.2 使用正则 'sessionid=(.*);' 提取 sessionidsessionid=$(echo &quot;$response&quot; | grep -oP 'Set-Cookie: sessionid=\\K[^;]*')# 4.3 打印值echo &quot;sessionid: $sessionid&quot;echo &quot;===================== Request 02 end =====================&quot;# 4.4 检查是否成功提取if [ -z &quot;$sessionid&quot; ]; then echo &quot;Failed to extract sessionid from the response.&quot; echo &quot;Maybe the password is incorrect. Please check and try again.&quot; exit 1fi# 5. 发送 GET 请求以获取实际的文件地址echo &quot;==================== Request 03 start ====================&quot;# 5.1 URL 需要添加参数 dl=1if [[ &quot;$url&quot; == *&quot;?dl=&quot;* ]]; then url=&quot;${url}&amp;dl=1&quot;else url=&quot;${url}?dl=1&quot;fi# 请求头的 Cookie 设置为 sfcsrftoken=$sfcsrftoken; sessionid=$sessionidheader_cookie=&quot;sfcsrftoken=$sfcsrftoken; sessionid=$sessionid&quot;header_referer=&quot;$url&quot;response=$(curl -i -s -H &quot;Cookie: $header_cookie&quot; -H &quot;Referer: $header_referer&quot; &quot;$url&quot;)# 5.2 使用正则 &quot;Location: (.*)&quot; 提取文件地址file_url=$(echo &quot;$response&quot; | grep -oP 'Location: \\K.*')# 5.3 检查是否成功提取echo &quot;file_url: $file_url&quot;echo &quot;===================== Request 03 end =====================&quot;# 5.4 检查是否成功提取if [ -z &quot;$file_url&quot; ]; then echo &quot;Failed to extract file URL from the response.&quot; exit 1fi# 6. 下载文件echo &quot;===================== Download start =====================&quot;# 6.1 获取文件名（用 / 分割，取最后一部分，不使用 basename）filename=$(echo &quot;$file_url&quot; | awk -F/ '{print $NF}')# 去除末尾的 \\rfilename=$(echo &quot;$filename&quot; | tr -d '\\r')if [ -z &quot;$filename&quot; ]; then echo &quot;Failed to extract filename from the file URL.&quot; exit 1fiecho &quot;file_url: $file_url&quot;# 6.2 请求头的 Cookie 设置为 sfcsrftoken=$sfcsrftoken; sessionid=$sessionidheader_cookie=&quot;sfcsrftoken=$sfcsrftoken; sessionid=$sessionid&quot;# 使用 wget 下载文件wget --header=&quot;Cookie: $header_cookie&quot; &quot;$file_url&quot; -O &quot;$filename&quot;# 6.3 检查下载是否成功if [ $? -ne 0 ]; then echo &quot;Failed to download the file.&quot; exit 1fiecho &quot;====================== Download end ======================&quot; 三、托管到 GitHub 和 Gitee 使其能被一键调用GitHub 仓库：seafile-scripts参数可能会变，请总以最新的 GitHub 仓库文档为准！ 1curl -O https://raw.githubusercontent.com/senjianlu/seafile-scripts/master/download.sh &amp;&amp; bash download.sh $seafile_share_link $password 境内需要使用 Gitee 的源： 1curl -O https://gitee.com/senjianlu/seafile-scripts/raw/master/download.sh &amp;&amp; bash download.sh $seafile_share_link $password","link":"/2024/09/20/seafile_download_script/"},{"title":"Selenium 容器 standalone-chrome 的启动和部分 Python3 使用例","text":"将 Selenium 容器化之后，通过远程调用来加载一些页面的前端 JS 是不错的注意。 一、确定容器启动的参数官方镜像仓库：selenium/standalone-chrome官方文档：Docker images for the Selenium Grid Server 不得不说官方对容器各参数的解释真的很乱。因此我总结了一些常用的参数，通过它们启动的容器在我的生产环境运行得非常稳定： --ulimit nofile=32768:32768：防止出现由于限制打开文件数导致无法新建 Session 的问题。 -p 4444:4444：连接 Chrome 用的远程端口。 -p 7900:7900：查看容器内 Chrome 在发生什么的 VNC 端口（直接使用网页浏览器访问即可）。 -e SE_VNC_NO_PASSWORD=1：VNC 端口不设置密码。 -e SE_NODE_SESSION_TIMEOUT=180：Session 多久没有操作后断开连接。 -e SE_NODE_MAX_SESSIONS=2：同时多少个 Session 可以连接容器进行操作（理论上 1 个 Session 对应 1 个容器是最佳实践）。 -e SE_SCREEN_WIDTH=1920 和 -e SE_SCREEN_HEIGHT=1080：页面分辨率。 --shm-size=&quot;2g&quot;：容器可用内存，官方推荐的 2G 其实够用了。 二、启动 Selenium standalone-chrome 容器 如果你是云服务器，那么在启动前请先关闭 4444 端口和 7900 端口对应的防火墙或安全组。这两个端口并没有认证，被扫到后容器会被入侵。 启动命令： 12345678910111213docker run -d \\ --name selenium \\ --restart=unless-stopped \\ --ulimit nofile=32768:32768 \\ -p 4444:4444 \\ -p 7900:7900 \\ -e SE_VNC_NO_PASSWORD=1 \\ -e SE_NODE_SESSION_TIMEOUT=180 \\ -e SE_NODE_MAX_SESSIONS=2 \\ -e SE_SCREEN_WIDTH=1920 \\ -e SE_SCREEN_HEIGHT=1080 \\ --shm-size=&quot;2g&quot; \\ selenium/standalone-chrome:latest 三、Python3 使用例1、连接容器打开 Google 并查看页面标题12345678910from selenium import webdriverchrome_options = webdriver.ChromeOptions()driver = webdriver.Remote( command_executor='http://127.0.0.1:4444/wd/hub', # 远程服务器地址 options=chrome_options)driver.get('https://www.google.com')print(driver.title)driver.quit() 执行结果： 2、为容器内的 Chrome 配置代理注意：只能使用不需要用户认证的 HTTP 或 SOCKS5 代理！ 在其他云服务器上启动 HTTP 代理服务： 123wget https://github.com/go-gost/gost/releases/download/v3.0.0-nightly.20240927/gost_3.0.0-nightly.20240927_linux_amd64.tar.gztar xzvf gost_3.0.0-nightly.20240927_linux_amd64.tar.gz./gost -L socks5://:37215 使用下面的命令测试代理可用性： 1curl -x socks5://1.2.3.4:37215 http://ipinfo.io 123456789101112from selenium import webdriverchrome_options = webdriver.ChromeOptions()# 为 Chrome 设置代理chrome_options.add_argument(&quot;--proxy-server=socks5://1.2.3.4:37215&quot;)driver = webdriver.Remote( command_executor='http://127.0.0.1:4444/wd/hub', # 远程服务器地址 options=chrome_options)driver.get(&quot;http://api.ip.sb/geoip&quot;)print(driver.page_source)driver.quit() 可以看到代理生效了，美国的服务器返回了代理所在的日本的 IP 信息： 如果你出现下面这样的错误： 123This site can’t be reachedThe webpage at https://ip-api.com/ might be temporarily down or it may have &gt; moved permanently to a new web address.ERR_NO_SUPPORTED_PROXIES 那么大概率就是你使用需要认证的代理了，请用 GOST 做下转发去掉它的认证： 1./gost -L socks5://:8888 -F socks5://username:password@1.2.3.4:37215 3、截图页面并保存到本地123456789101112131415from selenium import webdriverchrome_options = webdriver.ChromeOptions()driver = webdriver.Remote( command_executor='http://127.0.0.1:4444/wd/hub', # 远程服务器地址 options=chrome_options)driver.get('https://www.youtube.com')# 将截图保存到本地screenshot_path = &quot;./youtube.png&quot;screenshot = driver.get_screenshot_as_png()with open(screenshot_path, &quot;wb&quot;) as file: file.write(screenshot)print(f&quot;Screenshot saved to {screenshot_path}&quot;) 将服务器上的图片取到本地： 1scp root@1.2.3.4:/root/youtube.png ./ 虽然内容还没加载，但是可以看出是 YouTube 的界面了： 参考资料： [🐛 Bug]: SE_NODE_MAX_SESSIONS not taking effect on node-docker #1817","link":"/2024/09/30/selenium_docker_python3/"},{"title":"日语翻译 - 歌词 - Anytime Anywhere","text":"《Anytime Anywhere》歌词翻译。 TV 动画《葬送的芙莉莲》片尾曲。 🌟 单词： 線路沿い｜せんろぞい⓪ なぞる｜なぞる②1. 照搬，基本上原样模仿现成的诗、文章等；2. 临摹。 大袈裟｜おおげさ⓪1. 夸大，夸张；2. 铺张、小题大做。 鮮明｜せんめい⓪ 有り触れる｜ありふれる⓪④⑤常有的，不稀奇的。 からかう｜からかう③逗，逗弄；戏弄；调戏；嘲弄；开玩笑。 証｜あかし⓪证据。 And you alright And you alright Can you hear me Can you hear me 誰もいない線路沿いせんろぞいをなぞってく 沿着空无一人的铁道前行 大袈裟に泣いて 不必太过夸张地哭泣 笑ってほしくて 愿你露出笑容 鮮明せんめいでいたい思い出を抱きしめている 紧紧拥抱着这些鲜明且痛苦的回忆 さよならよりずっと大切な 想要对你说出 言葉で伝えたいんだ 远比“再见”更加重要的话语 ありふれて でも特別で 它是那么普通 却又无比特别 ほら この目じゃなければ 看啊 只有用这双眼睛 見えなかったものが 才能发现的东西 どうして 溢れてく 不知为何 全都满溢而出 だからもう一度 生まれ変わろうとも 因此如果能够 转世重获新生 また私は ここを選ぶんだろう 我也仍会选择这里吧 だからあなたと また巡り逢ったら 所以 若是有幸与你重新邂逅 もう離さない 今を選ぶんだろう 我将不再离去 留在相伴的此时 約束なんてなくても 即使从未有过约定 孤独に迷う日々でも 即使在孤独中徘徊 その涙だって大丈夫 きっと夜が明けるよ 不知缘故流下的泪水 也终会迎着曙光消散 And I’m alright (I’ll be alright) And I’m alright (I’ll be alright) Yeah I hear you (I care about you) Yeah I hear you (I care about you) 伸びた髪を風がからかってる 微风轻轻地拂过长发 全部意味があるよ 一切都存在着意义 立ち止まった日々も 连同止步不前的日子 今さらわかってあなたに追いついたよ 事到如今我才发现 已经追上你的背影 ほら この目じゃなければ 你瞧 唯独自己的双眼 見えなかったものが 才能看见的东西 どうして 溢れてく 忽然之间 全都满溢而出 だからもう一度 生まれ変わろうとも 然而如果能够 再度轮回转生 また 私はここを選ぶんだろう 我还是会选择此时此刻 だからあなたと また巡り逢ったら 所以 如果还能再次和你相遇 もう離さない 今を選ぶんだろう 我再也不会放手 紧握相守的此刻 Anytime anywhere yah (どこにいても) Anytime anywhere yah （无论何处） Anytime anywhere (笑ってみせて) Anytime anywhere （请让我看见你的笑容） Anytime anywhere yah (目を閉じれば いつも) Anytime anywhere yah （闭上眼睛 你总在） Anytime anywhere yah (歩き出した) Anytime anywhere yah （迈步向前） Anytime anywhere (私を見てて) Anytime anywhere （请看着我） Anytime anywhere yah Anytime anywhere yah せめて 会いたいよ なんて言わないから 至少不会说出“好想见你”这样的话 ねえ 今日だけは 思い出していいかな 呐 只有今天也好 可以偶尔想起你吗 だからあなたと また巡りあったら 所以 如果能与你再度重逢的话 もう迷わない 今を選ぶんだろう 我将不再迷茫 选择眼前的当下 約束なんてなくても (Anytime anywhere yah) 即使从未有过约定 (Anytime anywhere yah) 孤独に迷う日々でも (Anytime anywhere) 即使在孤独中徘徊 (Anytime anywhere) こんなに胸が痛いのは (Anytime anywhere yah) 胸口会传来这般痛楚 (Anytime anywhere yah) あなたといた証あかしかな 定是你曾与我同行的证明 絶対なんてなくても (Anytime anywhere yah) 就算这世间没有绝对 (Anytime anywhere yah) いつでも届いているから (Anytime anywhere) 每时每刻也都在传达 (Anytime anywhere) その涙だって大丈夫 きっと夜が明けるよ (Anytime anywhere yah) 即使现在泪流不止 长夜也终将会破晓 (Anytime anywhere yah) I’m whispering our lullaby for you to come back home 我将轻唱这首指引你回家的摇篮曲","link":"/2024/09/08/song_lyric_anytime_anywhere/"},{"title":"日语翻译 - 歌词 - Hacking to the Gate","text":"《Hacking to the Gate》歌词翻译。 《Hacking to the Gate》TV动画《命运石之门》的片头曲，于第 1 - 24 话使用，由伊藤香奈子演唱。同样也是《命运石之门》OVA《横行跋扈的离家漫游廦》的片尾曲。在动画《命运石之门 0》第 23 话用作插曲。 网易云的歌词翻译的也很好，但是可能是为了让中文更加连贯的，很多地方忽略了动词的被动变形，如果保留下来的话，补足被时间玩弄的无力感可能会更好，并不确定。 🌟 单词： 鼓動｜こどう⓪ 瞬き｜またたき② 些事｜さじ①（不足挂齿的）小事，琐事，细节。 等級｜とうきゅう⓪ 囚われる｜とらわれる④1. 被俘，被逮捕；2. 受拘束，受限制。 嘆く｜なげく②1. 叹息，叹气悲叹，哀叹；2. 慨叹，叹惋。 塵｜ちり② 描く｜えがく② 虚栄｜きょえい⓪ 権利｜けんり① 針｜はり① 約定｜やくじょう⓪ 足る｜たる⓪ 滑稽｜こっけい⓪ 愚か｜おろか① 稚拙｜ちせつ⓪ 彼方｜かなた①那方，那边。 仮想｜かそう⓪ 無慈悲｜むじひ②① 欺く｜あざむく③1. 欺骗；2. 赛过，超过。 飲み込む｜のみこむ⓪③1. （囫囵）咽下，吞下；2. 理解，领会，熟悉；3. 咽，忍住，止住使劲控制住话语或哈欠等；4. 吞没，容纳把人或东西拉进漩涡或裂缝中。 凌ぎ｜しのぎ⓪③忍受，应付。 気取り｜きどり⓪假装，作态。 自惚｜うぬぼれ狂妄自大。 数十億もの 鼓動こどうの数さえ 数十亿的心跳声 あなたには 瞬きまたたき程度の些事さじな等級とうきゅう 对你来说也不过是瞬间的事情 過去に囚われて 未来を嘆くなげくも 被过去所囚禁，对未来的叹息 塵ちり一つ 誤算を許さぬ必然 就算是细微的一个误差也不能被允许 『無限』に広がる夢も 描くえがく未来も 扩张到“无限”的梦和描述的未来 僕達に許された 虚栄きょえいの権利けんり （都是）我们被允诺的虚妄的权利 『有限』それはニつの 針はりが示す 而“有限”的则是，两个指针指引的 残酷な約定やくじょうと 選択へ 作为残酷的约定，选择是 Hacking to the Gate――― 骇入命运石之门！ だからいま 1秒ごとに 世界線を越えて 所以现在，以秒为单位，去跨越时间线 君のその笑顔 守りたいのさ 都是为了守护你的笑容 そしてまた 悲しみの無い 時間のループへと 接着再次跳入没有时间悲伤的轮回里 飲み込まれてゆく 孤独の観測者 逐渐被拉进漩涡，孤独的观测者 🎵 命の主張と 無意味な証明 对生命的论点与无意义的证明 あなたには 退屈しのぎに足らぬたらぬ滑稽こっけい 对你来说，（甚至）是（用来）（委屈忍受）用来消遣都不够的滑稽（行为） 支配者きどりの 愚かおろかな種族は 假装支配的愚蠢的种族 うぬぼれた 稚拙ちせつな定理を並べた 列出狂妄自大而又拙劣幼稚的定理 『無限』と信じた愛も 空の彼方かなたも 相信“无限”的爱和天空的那边 僕達に示された 仮想かそうの自由 都是展示给我们的、虚幻的自由 『有限』それは無慈悲むじひに 時を刻み 而“有限”的是，时间的无情流逝 明日さえも否定する 選択へ 就连明天也要否定，选择是 Hacking to the Gate――― 骇入命运石之门！ いくつもの 輝ける日々 仲間との約束 几度闪耀的时光，与朋友间的约定 無かった事には してはいけない 对于未做之事，不能就这样敷衍了事 そのために 時を欺くあざむく 残された仕掛けに 为此，欺骗时间！对这唯一剩下的方法 もう迷いはない 孤独の観測者 不再有迷茫，孤独的观测者 🎵 だからいま 1秒ごとに 世界線を越えて 所以现在，以秒为单位，去跨越时间线 君のその笑顔 守りたいのさ 都是想要守护你的笑容 そしてまた 悲しみの無い 時間のループへと 接着再次跳入没有时间悲伤的轮回里 飲み込まれてゆく 孤独の観測者 逐渐被拉进漩涡，孤独的观测者","link":"/2024/12/01/song_lyric_hacking_to_the_gate/"},{"title":"日语翻译 - 歌词 - 風になる","text":"《風になる》歌词翻译。 《風になる》（幻化成风）是辻亚弥乃接应当时日本动画工作室吉卜力为了制作 2002 年剧院动画《猫的报恩》时，所完成的曲子。歌曲的部分创作内容来自于辻亚弥乃在骑自行车迎风上坡时、以及回想学生时期在京都市的鸭川河流所仰望的青空所获得的灵感。 🌟 单词： 眺める｜ながめる③ 口ずさむ｜くちずさむ④吟，诵，哼。 託する｜たくする②托，托付，寄托。 翳す｜かざす⓪②1. 1. 举到头上，挥起，举过头，挥动；2. 罩个阴影，（用东西）遮上光。 忘れていた目を閉じて 取り戻せ恋のうた 闭上被忘却的双眼 青空に隠れている 手を伸ばしてもう一度 它躲藏在蓝天之中 只要再次伸出双手 忘れないですぐそばに 僕がいるいつの日も 不要忘记那些 我陪伴在你身边的时光 星空を眺めている 一人きりの夜明けも 即使也曾有过独自一人 仰望星空直到黎明 たった一つの心 悲しみに暮れないで 不要让唯一的心 沉浸于悲伤 君のためいきなんて 春風に変えてやる 我要将你的叹息 也幻化成风 陽のあたる坂道を自転車で駆けのぼる 骑着单车登上洒满阳光的坡道 君と失くした想い出乗せて行くよ 载着与你那些逝去的回忆前行 ララララ 口ずさむ くちびるを染めてゆく 啦啦啦啦 轻声哼唱 旋律萦绕双唇 继续前行 君と見つけた幸せ 花のように 与你寻找到的幸福 如同花儿一样 忘れていた窓開けて 走り出せ恋のうた 打开被忘却的窗 放飞那恋爱之歌 青空に託している 手をかざしてもう一度 再次举起双手 将它寄托在蓝天之上 忘れないよすぐそばに 君がいるいつの日も 我不会忘记 那些有你陪伴的时光 星空に輝いてる 涙揺れる明日も 也不会忘记 星空因泪水而模糊的拂晓 たった一つの言葉 この胸に抱きしめて 唯有一句话 深藏于心中 君のため僕は今 春風に吹かれてる 正因有你 如今我正幻化成风 陽のあたる坂道を自転車で駆けのぼる 骑着单车登上洒满阳光的坡道 君と誓った約束乗せて行くよ 载着我们许下的约定前行 ララララ 口ずさむ くちびるを染めて行く 啦啦啦啦 轻声哼唱 旋律萦绕双唇 继续前行 君と出会えた幸せ祈るように 祈祷能与你再次相遇 陽のあたる坂道を自転車で駆けのぼる 骑着单车登上洒满阳光的坡道 君と誓った約束乗せて行くよ 载着我们许下的约定前行 ララララ 口ずさむ くちびるを染めてゆく 啦啦啦啦 轻声哼唱 旋律萦绕双唇 继续前行 君と出会えた幸せ祈るように 祈祷能与你再次相遇 君と出会えた幸せ祈るように 祈祷能与你再次相遇","link":"/2024/09/07/song_lyric_kaze_ni_naru/"},{"title":"日语翻译 - 歌词 - 君がくれた夏","text":"《君がくれた夏》歌词翻译。 【2015 年新闻】据日本媒体报道，日本歌手家入莉奥（20 岁）将为福士苍汰（22 岁）主演的富士台月九剧《恋仲》（7 月开播）献唱主题曲《君がくれた夏》（8 月 19 日发售）。晃眼 9 年过去了，再听到时感慨良多。 🌟 单词： 色付く｜いろづく③变红，呈红色，渐熟，呈红（黄）色。 夕日｜ゆうひ⓪ 隙間｜すきま 片隅｜かたすみ③⓪角落，一隅。 罠｜わな①陷阱，圈套。 捻る｜ねじる②扭，拧。 彷徨う｜さまよう③ 君の描いた 未来の中に 在你描绘的未来之中 僕はいない その時代もない 没有我，也没有这个时代 まだ少しだけ 傷を抱えたふたりは 还有些许伤痛的两人 夢の 続き探してた 继续追寻着梦想 思うままに 色付いてくと思ってた 曾想照自己所想 去染上色彩 答えなんか 見つけられずに 却找不到答案 それでもこの世界 廻り続けて 尽管如此世界依旧旋转 君がくれた夏 その奇跡 你给我的夏天那场奇迹 僕は忘れない 我不会忘记 溢れそうな想い あの夕日ゆうひに隠して 快要涌出的感情被夕阳隐藏 So why, so why, so why So why, so why, so why 気づいていた 察觉到了 True love, true love True love, true love 時の隙間すきまに 流れ込む風 微风流入时间的隙缝 教室の その片隅かたすみで 教室的那个角落 揺れる前髪 ただ見とれていた僕は 摇曳的刘海看入迷的我 君に 恋をしたんだよ 就这样爱上了你 まるで空を 歩いてるみたいな日々 仿佛在天空中行走一般的那些日子 当たり前に そばにいたこと 你理所当然地在我身旁 未来なんていつもそう 疑いもせず 以为今后也会这样从未怀疑 君がいた夏に この気持ち 你给我的夏天这份心情 うまく言えなくて 无法好好表达 ふたつの心は 何故に離れていくの？ 两颗心为什么渐行渐远 So why, so why, so why So why, so why, so why 届かなくて 无法传递给你 愛情の罠わなだって 気づいた時は遅すぎて 爱情的陷阱察觉到的时候已经太晚 捻れたねじれた感情は 光求め彷徨うさまよう 纠结的情感彷徨着寻求光明 叶わない願い 置き去りのままで 无法实现的愿望仍旧放在一旁 君がくれた夏 その奇跡 你给我的夏天那场奇迹 僕は忘れない 我不会忘记 溢れそうな想い あの夕日に隠して 即将涌出的感情被夕阳隐藏 So why, so why, so why So why, so why, so why 気づいていた 察觉到了 True love, true love True love, true love","link":"/2024/09/07/song_lyric_kimi_ga_kureta_natsu/"},{"title":"日语翻译 - 歌词 - プラスティック・ラブ","text":"《プラスティック・ラブ》歌词翻译。 City Pop 圣经。非常推荐这期专谈该歌的播客：S1E1 『塑料爱』 🌟 单词： 狂わす｜くるわす③1. 使发狂，使精神失常；2. 扰乱，打乱，使错乱。 派手｜はで②1. 华丽，豪华，炫耀；2. 花哨，花俏。 夜更け｜よふけ③ 妖しい｜あやしい③⓪ ハロゲン｜はろげん①(halogen) 卤族元素。 ハロゲンランプ｜はろげんらんぷ碘钨灯，卤素灯。 突然のキスや熱いまなざしで 可别因为突如其来的亲吻或是火热的眼神 恋のプログラムを狂わせくるわせないでね 就让恋爱的程序崩溃掉哦 出逢いと別れ上手に打ち込んで 从邂逅到分手的全套流程我信手拈来 時間がくれば終わる Don’t hurry! 时间到了结束掉就好 无需急躁！ 愛に傷ついたあの日からずっと 自从被爱情深深伤害的那天起 昼と夜が逆の暮らしを続けて 日夜颠倒的生活就伴随我到现在 はやりの Disco で踊り明かすうちに 投身于流行的disco里忘情舞蹈 おぼえた魔術なのよ I’m sorry! 我就只学到了这些把戏 对不起啦！ 私のことを決して本気で愛さないで 千万不要对我动了真情 恋なんてただのゲーム 恋爱于我不过是个游戏 楽しめばそれでいいの 玩得尽兴就够 閉ざした心を飾る 派手はでなドレスも靴も 掩饰我封闭心灵的气派礼服和鞋子 孤独な友だち 都是我孤独的伙伴 私を誘う人は皮肉なものね いつも彼に似てるわ 邀请我的人净是卑鄙肤浅的家伙 个个都像他一样 なぜか思い出と重なり合う 不知为何思绪和过去的记忆重叠 グラスを落として急に涙ぐんでも わけは尋ねないでね 别问我突然掉落在酒杯里的眼泪是为了什么 夜更けよふけの高速で眠りにつくころ 倒在深夜的高速边昏昏欲睡之时 ハロゲンライトだけ妖しくあやしく輝く 只有路灯妖异地发着光 氷のように冷たい女だと 真是冰块般冷淡的女人啊 ささやく声がしても Don’t worry! 被别人偷偷地嘀咕 别在意！ I’m just playing games, I know that’s plastic love 我只不过是在游戏人生 我晓得那不过是如塑料般脆弱的爱情 Dance to the plastic beat, Another morning comes 伴着我脆弱的心跳舞动 另一个清晨又来临了 I’m just playing games, I know that’s plastic love 我只不过是在游戏人生 我晓得那不过是如塑料般脆弱的爱情 Dance to the plastic beat, Another morning comes 伴着我脆弱的心跳舞动 另一个清晨又来临了","link":"/2024/09/07/song_lyric_plastic_love/"},{"title":"日语翻译 - 歌词 - 真夜中のドア〜Stay with Me","text":"《真夜中のドア〜Stay with Me》歌词翻译。 在 《Plastic Love》 之后翻红。 🌟 单词： 染み｜しみ⓪污垢，污点；斑痕，污痕。 ショーウィンドウ｜しょーうぃんどう⓪(show window) 橱窗，展览窗。 映る｜うつる② 真夜中｜まよなか② 叩き｜たたき③ 口ぐせ｜くちぐせ⓪口头禅。 淋しい｜さびしい③空落落的，寂寞，冷清，孤单眷念人而伤感。 紛らわす｜まぎらわす④1. 蒙混过去，掩饰过去；2. 排解。 紛らわしい｜まぎらわしい⑤容易混淆，不易分辨，模糊不清。 針｜はり①1. 针，针状物；2. 裁缝；3. 伤害对方感情。 To you, yes, my love to you To you, yes, my love to you Yes, my love to you, you, to you Yes, my love to you, you, to you 私は私 貴方は貴方と “我就是我，你也不过只是你” 昨夜ゆうべ言ってたそんな気もするわ 总感觉不过是昨晚说过的 グレイのジャケットに 灰色的夹克上 見覚えがある コーヒーのしみ 有眼熟的咖啡污渍 相変らずなのね 看来完全没变呢 ショーウィンドウに 二人映ればうつれば 如果橱窗上倒影这我们两个人 Stay with me Stay with me 真夜中まよなかのドアをたたき叩き 敲响深夜中的门 帰らないでと泣いた 哭着求你不要回去 あの季節が 今 目の前 那个时刻现在就在眼前一样 Stay with me Stay with me 口ぐせを言いながら 一边重复着你的口头禅 二人の瞬間とき​を抱いて 一边拥抱着两人共处的瞬间 まだ忘れず 大事にしていた 依然没有忘记 深藏这份美好 🎵 恋と愛とは 違うものだよと “恋爱和爱情是不一样的” 昨夜言われた そんな気もするわ 总感觉不过是昨晚说过的 二度目の冬が来て 第二个冬天来了 離れていった貴方の心 以及离去了你的心 ふり返ればいつも 每次回首 そこに 貴方を感じていたの 都感觉你还在那里 Stay with me Stay with me 真夜中のドアをたたき 敲响深夜中的门 心に穴があいた 心中留下一个空洞 あの季節が 今 目の前 那个时刻现在就在眼前一样 Stay with me Stay with me 淋しさまぎらわして 为了排遣这份寂寞 置いたレコードの針はり 放下唱机的唱针 同じメロディ 繰り返していた 反复播放同一段旋律 🎵 Stay with me Stay with me 真夜中のドアをたたき 敲响深夜中的门 帰らないでと泣いた 哭着求你不要回去 あの季節が 今 目の前 那个时刻现在就在眼前一样 Stay with me Stay with me 口ぐせを言いながら 一边重复着你的口头禅 二人の瞬間を抱いて 一边拥抱着两人共处的瞬间 まだ忘れず 暖めてた 依然没有忘记 温暖着这份美好 Stay with me Stay with me 真夜中のドアをたたき 敲响深夜中的门 帰らないでと泣いた 哭着求你不要回去 あの季節が 今 目の前 那个时刻现在就在眼前一样 Stay with me Stay with me 口ぐせを言いながら 一边重复着你的口头禅 二人の瞬間を抱いて 一边拥抱着两人共处的瞬间 まだ忘れず 暖めてた 依然没有忘记 温暖着这份美好 Stay with me Stay with me 真夜中のドアをたたき 敲响深夜中的门 帰らないでと泣いた 哭着求你不要回去 あの季節が 今 目の前 那个时刻现在就在眼前一样","link":"/2024/09/08/song_lyric_stay_with_me/"},{"title":"日语翻译 - 歌词 - Rain","text":"《Rain》歌词翻译。 《Rain》这首歌曲是新海诚监督的动画电影《言叶之庭》中的片尾曲，由秦基博演唱。 歌曲歌词非常贴合了动画中所说的《万叶集》的形象：隐约雷鸣，阴霾天空，但盼风雨来，能留你在此。隐约雷鸣，阴霾天空，即使天无雨，我亦留此地。 🌟 单词： 凍う｜こごう 皺寄せ｜しわよせ⓪1. 影响，后果；2. 起皱眉。 常夜灯｜じょうやとう ビラ｜びら⓪(bill) 传单，宣传广告，招贴。 街角｜まちかど⓪街角，街口，巷口。 煙る｜けむる⓪1. 冒烟；2. 模糊不清，朦胧。 ずぶ｜ずぶ①1. 完全，实在是；2. 全身淋湿。 飛沫｜しぶき①③ 飞沫，水花。 小降り｜こぶり⓪雨微降，下小雨下小雪。 口笛｜くちぶえ⓪③口哨。 言葉にできず凍えたこごえたままで 不动声色 无以言表 人前ではやさしく生きていた 扮演温柔 直到今日 しわよせで こんなふうに雑に 所有的冲动都化作 雨の夜にきみを抱きしめてた 这雨夜鲁莽的拥抱 道路わきのビラと壊れた常夜灯 路旁的传单和坏掉的长明灯 街角ではそう だれもが急いでた 街角旁每个人都行色匆匆 きみじゃない 悪いのは自分の激しさを 错的不是你 隠せないぼくのほうさ 而是无法掩藏住激情的我啊 Lady きみは雨にけむる Lady 你被雨幕包裹着 すいた駅を少し走った 跑过空空的车站 どしゃぶりでもかまわないと 不顾大雨滂沱 ずぶぬれでもかまわないと 不顾浑身湿透 しぶきあげるきみが消えてく 你卷起雨花 渐行渐远 路地裏では朝が早いから 小巷的清晨总是更早到来 今のうちにきみをつかまえ 我要趁现在抓住你 行かないで 行かないで そう言うよ 不要离开不要离开这样对你说 🎵 別々に暮らす 泣きだしそうな空を 各自仰望天空 孤单的快要哭泣 にぎりしめる強さは今はもうない 紧握它的坚强 如今已不再 変わらずいる心のすみだけで 但仍有心的一角 未曾改变 傷つくようなきみならもういらない 想着再也不要伤害你 Lady きみは雨にぬれて Lady 你被雨打湿 ぼくの眼を少し見ていた 略微凝视我双眼 どしゃぶりでもかまわないと 不顾大雨滂沱 ずぶぬれでもかまわないと 不顾浑身湿透 口笛くちぶえふくぼくがついてく 我吹着口哨 追随你 ずいぶんきみを知りすぎたのに 分明已对你了解太多 初めて争った夜のように 却仍会像初次争吵的夜晚时般 行かないで 行かないで そう言うよ 不要离开不要离开这样对你说 🎵 肩が乾いたシャツ改札を出る頃 衬衫半干走出车站时 きみの町じゃもう雨は小降りになる 你的城市已只是绵绵细雨 今日だけが明日に続いてる 只有过完今天明天才会到来 こんなふうに きみとは終われない 和你不会就这样结束 Lady きみは今もこうして Lady 此刻你是否一如既往 小さめの傘もささずに 不肯撑伞 どしゃぶりでもかまわないと 不顾大雨滂沱 ずぶぬれでもかまわないと 不顾浑身湿透 しぶきあげるきみが消えてく 你卷起雨花 渐行渐远 路地裏では朝が早いから 小巷的清晨总是更早到来 今のうちにきみをつかまえ 我要趁现在抓住你 行かないで 行かないで 不要离开不要离开 そう言うよ 这样跟你说 どしゃぶりでもかまわないと 不顾大雨滂沱 ずぶぬれでもかまわないと 不顾浑身湿透 口笛くちぶえふくぼくがついてく 我吹着口哨 追随你 ずいぶんきみを知りすぎたのに 分明已对你了解太多 初めて争った夜のように 却仍会像初次争吵的夜晚时般 行かないで 行かないで そう言うよ 不要离开不要离开这样对你说","link":"/2024/09/10/song_rain/"},{"title":"在 Mac 启动时自动运行脚本","text":"前言最近将大量基础设置迁移到了 Mac mini 上，有些应用通过安装可以简单地设置开机自启，但是不少脚本和服务还是需要手动运行。为了方便管理和使用，决定在 Mac 启动时自动运行一些脚本。 方案概述 建立脚本文件 修改脚本的权限 将打开方式修改为终端 添加到登录项 操作步骤一、建立脚本文件我这里需要启动 gost 来转发端口，所以需要创建一个脚本文件 start.sh： 12cd ~/Projects/test./gost -C ./gost.json 于是目录结构就变为： 二、修改脚本的权限接下来需要修改脚本的权限，使其可以执行： 1chmod 777 start.sh 三、将打开方式修改为终端右键点击脚本文件，在 打开方式 中选择 其他：在 启用 处选择 所有应用程序，然后在 实用工具 中选择 终端，勾选 始终使用此应用程序打开，点击 打开：之后尝试运行下： 四、添加到登录项打开 系统设置，点击 通用 并选择 登录项：点击 + 号，选择刚才创建的脚本文件：之后重启，就能看到对应的终端窗口自动打开并运行脚本了。","link":"/2025/07/27/start_script_when_mac_boot/"},{"title":"项目综合状态页开发笔记（一）技术选型","text":"前言自己的各个小项目状态一直都散乱在各处：Zabbix、哪吒监控、Prometheus + Grafana 和 Rancher + Grafana，每天光确认项目运行状态都是一件相当费时费力的事情，由此萌生了开发个项目综合状态页的想法。 前端技术选型语言和框架虽然目前工作中对日方老项目的重构，优先都考虑使用 Vue.js 以提高效率和降低开发门槛。但是由于自己创业期间使用的前端技术栈是 React + TypeScript，带有私心且写的比较久，语言和框架于是就定下为更心水的了。 React TypeScript 组件库对 React + TypeScript 友好，且文档和案例足够全的国内似乎只有 Ant Design 和 Element UI 两个。看下效果：to B 的味道都有点太重了，尤其是白蓝的经典配色，写起来像是在上班 😂。自己的项目还是希望美观一点，即使写起来稍微复杂一些也是可以接受的，于是又稍微找了下，看到了这个帖子：React UI 组件库选择顺手翻了下还有排行：Component set + React于是花了点时间做了调查和比较： 库 UI 库/组件库 优点 缺点 GitHub 数据 备注 Material UI 组建库 极高的自定义上限。 有限的免费；有上手门槛。 92.8k Star, 31.9k Fork, 1.7k Issues shadcn/ui UI 库 免费。 并非组件库，需要自己封装。 65.3k Star, 3.8k Fork, 285 Issues 使用了 Tailwind CSS。 Chakra UI 组件库 有 Figma 资源。 有限的免费；白绿配色有点丑。 37.2k Star, 3.2k Fork, 277 Issues NextUI 组件库 有 Figma 资源；暗色深得我心。 有限的免费。 20.8k Star, 1.3k Fork, 395 Issues 使用了 Tailwind CSS。 非常主观地最后选择了 NextUI，正好也是机会尝试下 Tailwind CSS。免费的组件姑且足够搭建一个状态页了，后续再看情况决定是否付费也可以。 更多虽然一开始并没有考虑使用 Next.js 作为项目的基础框架，但是在选择了 NextUI 之后，发现 NextUI 的文档中给了在 Next.js 项目中导入的示例，于是就顺手选择了 Next.js。之前听说过 Next.js 的特点： 服务器端渲染（SSR）：支持在服务器上渲染 React 组件，提供更快的初始页面加载速度和更好的 SEO。 静态站点生成（SSG）：在构建时生成静态 HTML 文件，适用于内容不经常变化的网站。 客户端路由：内置路由系统，简化页面间的导航。 API 路由：允许在同一项目中创建 API 路由，简化前后端的集成。 优化和性能：自动代码分割、预取、热模块替换等功能提高应用性能。 内置路由系统和 API 路由对于快速开始项目还是很有帮助的，于是坚定了折腾一下的想法。 实际构建的过程主要参考 NextUI 的文档：Next.js | NextUI - Beautiful, fast and modern React UI Library 确定下 Node.js 和 npm 版本： 12345node -v# v20.16.0npm -v# 10.8.1 如果没有安装的话前往：下载 Node.js 进行安装。 安装 NextUI CLI： 12npm install -g nextui-cli# added 73 packages in 9s 初始化一个名为 sbeer-io 的项目： 1nextui init -t app 如果没有安装 yarn 的话可以选择 npm，当然你也可以使用以下命令安装 yarn： 1npm install --global yarn 相比 npm，yarn 有更快的下载速度和更好的缓存机制。 进入项目目录、安装依赖并启动项目： 123cd sbeer-ioyarn installyarn dev 之后前往 http://localhost:3000 即可看到项目的初始页面： 后端技术选型暂时不涉及到权限和复杂的功能，因此怎么方便怎么来吧：Python3 + FastAPI 一把梭就好了。 数据源结合自己已有的项目和监控平台： Prometheus InfluxDB PostgreSQL Zabbix（接口） 后端需要定义好数据结构。 总结前端技术选型： Next.js React TypeScript NextUI Tailwind CSS 后端技术选型： Python3 FastAPI 数据源： Prometheus InfluxDB PostgreSQL Zabbix（接口） 暂时结束，开始写 Home Page 看看还存在什么问题。","link":"/2024/07/29/status_page_01_technology_stack/"},{"title":"项目综合状态页开发笔记（二）完成前端项目的准备工作","text":"前言前端项目的构建，上一次仅执行到这一步 NextUI Docs - #create-next-app，即：仅仅是创建了一个能启动的 Next.js + NextUI 项目。本次还需完成多项前端开发前的准备工作，包括：安装 NextUI 和其实现动画效果的库、安装 Tailwind CSS、添加 NextUI 组件库。当然在最后，我编写了一个测试页面以确保所有准备工作都已完成。 操作步骤一、安装 NextUI 和其实现动画效果的库参考文档：NextUI Docs - #Add dependencies 1yarn add @nextui-org/react framer-motion 二、安装 Tailwind CSS参考文档：Install Tailwind CSS with Next.js 1. 安装 Tailwind CSS 依赖和生成配置文件安装依赖： 1yarn add -D tailwindcss postcss autoprefixer 正常情况下你的项目根目录中会存在 tailwind.config.js 和 postcss.config.js 这两个 Tailwind CSS 的配置文件，因此不需要再按照文档生成。 但如果由于某些原因你缺少了这两个关键的配置文件，那么可以使用下面的命令生成： 1npx tailwindcss init -p 2. 配置模板路径如果 tailwind.config.js 配置文件是构建项目时生成的，而不是上一步手动生成的，那么就不需要做这一步。 否则需要修改 tailwind.config.js 为如下内容： 123456789101112131415/** @type {import('tailwindcss').Config} */module.exports = { content: [ &quot;./app/**/*.{js,ts,jsx,tsx,mdx}&quot;, &quot;./pages/**/*.{js,ts,jsx,tsx,mdx}&quot;, &quot;./components/**/*.{js,ts,jsx,tsx,mdx}&quot;, // Or if using `src` directory: &quot;./src/**/*.{js,ts,jsx,tsx,mdx}&quot;, ], theme: { extend: {}, }, plugins: [],} 3. 将 Tailwind CSS 对应的注解添加到主要的样式文件中确保 ./styles/globals.css 文件为如下内容即可： 123@tailwind base;@tailwind components;@tailwind utilities; 4. 让 NextUI 组件的 Tailwind CSS 样式生效为 tailwind.config.js 添加一行内容使 Tailwind CSS 匹配 node_modules 中的 NextUI 组件： 12345678910111213141516171819import {nextui} from &quot;@nextui-org/react&quot;;/** @type {import('tailwindcss').Config} */const config = { content: [ &quot;./app/**/*.{js,ts,jsx,tsx,mdx}&quot;, &quot;./pages/**/*.{js,ts,jsx,tsx,mdx}&quot;, &quot;./components/**/*.{js,ts,jsx,tsx,mdx}&quot;, // 添加下面这一行内容 &quot;./node_modules/@nextui-org/theme/dist/**/*.{js,ts,jsx,tsx}&quot; ], theme: { extend: {}, }, darkMode: &quot;class&quot;, plugins: [nextui()]}export default config; 5. 让 &lt;NextUIProvider&gt; 标签包裹整个应用确保 ./app/providers.tsx 文件内容，像下面这样存在 &lt;NextUIProvider&gt; 包裹整个应用即可，不需要完全一致： 1234567891011'use client'import {NextUIProvider} from '@nextui-org/react'export function Providers({children}: { children: React.ReactNode }) { return ( &lt;NextUIProvider&gt; {children} &lt;/NextUIProvider&gt; )} 6. 让 &lt;Providers&gt; 标签包裹根节点确保 ./app/layout.tsx 文件内容，像下面这样存在 &lt;Providers&gt; 包裹根节点即可，不需要完全一致： 12345678910111213import {Providers} from &quot;./providers&quot;;export default function RootLayout({children}: { children: React.ReactNode }) { return ( &lt;html lang=&quot;en&quot; className='dark'&gt; &lt;body&gt; &lt;Providers&gt; {children} &lt;/Providers&gt; &lt;/body&gt; &lt;/html&gt; );} 三、添加 NextUI 组件库添加组件库 @nextui-org/react： 1nextui add --all 一般情况下构建项目的时候，就已经添加了这个依赖： 新建页面进行测试创建 ./app/test 目录，然后创建 ./app/test/page.tsx 文件，内容如下： 123456789101112131415161718192021&quot;use client&quot;;import {Button} from '@nextui-org/react'import {RadioGroup, Radio} from '@nextui-org/react'export default function Test() { return ( &lt;div&gt; &lt;Button&gt;Click me&lt;/Button&gt; &lt;RadioGroup label=&quot;Select your favorite city&quot; &gt; &lt;Radio value=&quot;buenos-aires&quot;&gt;Buenos Aires&lt;/Radio&gt; &lt;Radio value=&quot;sydney&quot;&gt;Sydney&lt;/Radio&gt; &lt;Radio value=&quot;san-francisco&quot;&gt;San Francisco&lt;/Radio&gt; &lt;Radio value=&quot;london&quot;&gt;London&lt;/Radio&gt; &lt;Radio value=&quot;tokyo&quot;&gt;Tokyo&lt;/Radio&gt; &lt;/RadioGroup&gt; &lt;/div&gt; )} 启动项目： 1yarn run dev 访问 localhost:3000/test，看上去没有问题，光标移动到按钮上动画效果也正常： 结束至此前端项目的基本准备工作全部完成。","link":"/2024/07/31/status_page_02_prepare_front_end_project/"},{"title":"SAP 考试每日练习 - 2024&#x2F;12&#x2F;27","text":"来源：Amazon AWS Certified Solutions Architect - Professional SAP-C02 Exam4 题 (No.14 ~ No.17)，仅供自己复习使用。如果侵权请联系删除。 一、Auto Scaling Group terminate eventA company is running an application on several Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer. The load on the application varies throughout the day, and EC2 instances are scaled in and out on a regular basis. Log files from the EC2 instances are copied to a central Amazon S3 bucket every 15 minutes. The security team discovers that log files are missing from some of the terminated EC2 instances.Which set of actions will ensure that log files are copied to the central S3 bucket from the terminated EC2 instances? Create a script to copy log files to Amazon S3, and store the script in a file on the EC2 instance. Create an Auto Scaling lifecycle hook and an Amazon EventBridge rule to detect lifecycle events from the Auto Scaling group. Invoke an AWS Lambda function on the autoscaling:EC2_INSTANCE_TERMINATING transition to send ABANDON to the Auto Scaling group to prevent termination, run the script to copy the log files, and terminate the instance using the AWS SDK. ✅ Create an AWS Systems Manager document with a script to copy log files to Amazon S3. Create an Auto Scaling lifecycle hook and an Amazon EventBridge rule to detect lifecycle events from the Auto Scaling group. Invoke an AWS Lambda function on the autoscaling:EC2_INSTANCE_TERMINATING transition to call the AWS Systems Manager API SendCommand operation to run the document to copy the log files and send CONTINUE to the Auto Scaling group to terminate the instance. Change the log delivery rate to every 5 minutes. Create a script to copy log files to Amazon S3, and add the script to EC2 instance user data. Create an Amazon EventBridge rule to detect EC2 instance termination. Invoke an AWS Lambda function from the EventBridge rule that uses the AWS CLI to run the user-data script to copy the log files and terminate the instance. ❌ Create an AWS Systems Manager document with a script to copy log files to Amazon S3. Create an Auto Scaling lifecycle hook that publishes a message to an Amazon Simple Notification Service (Amazon SNS) topic. From the SNS notification, call the AWS Systems Manager API SendCommand operation to run the document to copy the log files and send ABANDON to the Auto Scaling group to terminate the instance. ✨ 关键词： 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：弹性组中的 EC2 实例每 15 分钟发送日志到统一的存储桶中，需要在终止的时候也执行这个操作。如何监听弹性组的实例终止事件：Run code before terminating an EC2 Auto Scaling instance Create a CloudWatch Events rule. Add a Systems Manager automation document as a CloudWatch Event target. 需要使用到 CloudWatch Event 和 Systems Manager document，因此选 2️⃣。这里还需要注意 EC2_INSTANCE_TERMINATING 这个事件，它会在相应的钩子事件触发后进入等待状态，只有钩子事件给予继续的命令才会进行实际的实例终止行为：生命周期钩子 当 Amazon EC2 Auto Scaling 响应缩减事件时，它将终止一个或多个实例。这些实例将从 Auto Scaling 组中分离并进入 Terminating 状态。如果您已将一个 autoscaling:EC2_INSTANCE_TERMINATING 生命周期挂钩添加到您的 Auto Scaling 组，则实例将从 Terminating 状态转换为 Terminating:Wait 状态。完成生命周期操作后，实例将进入 Terminating:Proceed 状态。在完全终止实例后，实例将进入 Terminated 状态。 👨‍👨‍👦‍👦 社区讨论：B. Create an AWS Systems Manager document with a script to copy log files to Amazon S3. Create an Auto Scaling lifecycle hook and an Amazon EventBridge rule to detect lifecycle events from the Auto Scaling group. Invoke an AWS Lambda function on the autoscaling:EC2_INSTANCE_TERMINATING transition to call the AWS Systems Manager API SendCommand operation to run the document to copy the log files and send CONTINUE to the Auto Scaling group to terminate the instance. This approach will use the Auto Scaling lifecycle hook to execute the script that copies log files to S3, before the instance is terminated, ensuring that all log files are copied from the terminated instances. 二、Cross Account DNSA company is using multiple AWS accounts. The DNS records are stored in a private hosted zone for Amazon Route 53 in Account A. The company’s applications and databases are running in Account B.A solutions architect will deploy a two-tier application in a new VPC. To simplify the configuration, the db.example.com CNAME record set for the Amazon RDS endpoint was created in a private hosted zone for Amazon Route 53.During deployment, the application failed to start. Troubleshooting revealed that db.example.com is not resolvable on the Amazon EC2 instance. The solutions architect confirmed that the record set was created correctly in Route 53.Which combination of steps should the solutions architect take to resolve this issue? (Choose two.) ❌ Deploy the database on a separate EC2 instance in the new VPC. Create a record set for the instance’s private IP in the private hosted zone. Use SSH to connect to the application tier EC2 instance. Add an RDS endpoint IP address to the /etc/resolv.conf file. ✅ Create an authorization to associate the private hosted zone in Account A with the new VPC in Account B. Create a private hosted zone for the example com domain in Account B. Configure Route 53 replication between AWS accounts. ✅ Associate a new VPC in Account B with a hosted zone in Account A. Delete the association authorization in Account A. ✨ 关键词： 1️⃣ 3️⃣ ❌ -&gt; 3️⃣ 5️⃣ ✅ 💡 解析：Route 53 的私有托管区在账户 A 中，数据库实例在账户 B 中。将您创建的 Amazon VPC 和私有托管区域关联到不同的账户 AWS 使用创建托管区域的账户 A，授权（其他账户的）VPC 与私有托管区域的关联。 使用创建 VPC 的账户 B，将 VPC 与托管区域关联。 （推荐）删除与托管区域 VPC 关联的授权。 本题的 3️⃣ 选项对应的就是操作 1，而 5️⃣ 选项对应的就是操作 2 和 3。 👨‍👨‍👦‍👦 社区讨论：C and E are correct. C. Create an authorization to associate the private hosted zone in Account A with the new VPC in Account B. This step is necessary because the VPC in Account B needs to be associated with the private hosted zone in Account A to be able to resolve the DNS records. E. Associate a new VPC in Account B with a hosted zone in Account A. Delete the association authorization in Account A. This step is necessary because the association authorization needs to be removed in Account A after the association is done in Account B. 三、Content distributionA company used Amazon EC2 instances to deploy a web fleet to host a blog site. The EC2 instances are behind an Application Load Balancer (ALB) and are configured in an Auto Scaling group. The web application stores all blog content on an Amazon EFS volume.The company recently added a feature for bloggers to add video to their posts, attracting 10 times the previous user traffic. At peak times of day, users report buffering and timeout issues while attempting to reach the site or watch videos.Which is the MOST cost-efficient and scalable deployment that will resolve the issues for users? Reconfigure Amazon EFS to enable maximum I/O. Update the blog site to use instance store volumes for storage. Copy the site contents to the volumes at launch and to Amazon S3 at shutdown. ✅ Configure an Amazon CloudFront distribution. Point the distribution to an S3 bucket, and migrate the videos from EFS to Amazon S3. Set up an Amazon CloudFront distribution for all site contents, and point the distribution at the ALB. ✨ 关键词： 3️⃣ ✅ 💡 解析：静态内容分发使用 CloudFront 和 S3。 👨‍👨‍👦‍👦 社区讨论：C. Configure an Amazon CloudFront distribution. Point the distribution to an S3 bucket, and migrate the videos from EFS to Amazon S3. Amazon CloudFront is a content delivery network (CDN) that can be used to deliver content to users with low latency and high data transfer speeds. By configuring a CloudFront distribution for the blog site and pointing it at an S3 bucket, the videos can be cached at edge locations closer to users, reducing buffering and timeout issues. Additionally, S3 is designed for scalable storage and can handle high levels of user traffic. Migrating the videos from EFS to S3, would also improve the performance and scalability of the website. 四、AWS Direct Connect GatewayA company with global offices has a single 1 Gbps AWS Direct Connect connection to a single AWS Region. The company’s on-premises network uses the connection to communicate with the company’s resources in the AWS Cloud. The connection has a single private virtual interface that connects to a single VPC.A solutions architect must implement a solution that adds a redundant Direct Connect connection in the same Region. The solution also must provide connectivity to other Regions through the same pair of Direct Connect connections as the company expands into other Regions.Which solution meets these requirements? ✅ Provision a Direct Connect gateway. Delete the existing private virtual interface from the existing connection. Create the second Direct Connect connection. Create a new private virtual interface on each connection, and connect both private virtual interfaces to the Direct Connect gateway. Connect the Direct Connect gateway to the single VPC. Keep the existing private virtual interface. Create the second Direct Connect connection. Create a new private virtual interface on the new connection, and connect the new private virtual interface to the single VPC. Keep the existing private virtual interface. Create the second Direct Connect connection. Create a new public virtual interface on the new connection, and connect the new public virtual interface to the single VPC. ❌ Provision a transit gateway. Delete the existing private virtual interface from the existing connection. Create the second Direct Connect connection. Create a new private virtual interface on each connection, and connect both private virtual interfaces to the transit gateway. Associate the transit gateway with the single VPC. ✨ 关键词： 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：New – AWS Direct Connect Gateway – Inter-Region VPC Access AWS Direct Connect 网关 使用 AWS Direct Connect 网关连接您的 VPC。将 AWS Direct Connect 网关与以下任一网关关联： 当您在同一区域有多个 VPC 时的中转网关 (A transit gateway when you have multiple VPCs in the same Region) 虚拟私有网关 (A virtual private gateway) An AWS Cloud WAN core network 👨‍👨‍👦‍👦 社区讨论：A. Provision a Direct Connect gateway. Delete the existing private virtual interface from the existing connection. Create the second Direct Connect connection. Create a new private virtual interface on each connection, and connect both private virtual interfaces to the Direct Connect gateway. Connect the Direct Connect gateway to the single VPC. This solution provides a redundant Direct Connect connection in the same Region by creating a new private virtual interface on each connection, and connecting both private virtual interfaces to a Direct Connect gateway. The Direct Connect gateway is then connected to the single VPC. This solution also allows the company to expand into other Regions while providing connectivity through the same pair of Direct Connect connections.The Direct Connect Gateway allows you to connect multiple VPCs and on-premises networks in different accounts and different regions to a single Direct Connect connection.It also provides automatic failover and routing capabilities.","link":"/2024/12/27/sap_test_daily_20241227/"},{"title":"使用 Docker 自建订阅转换器","text":"前言自建下订阅转换器，方便自己使用。 方案概述 安装最新的 Docker（环境） 启动 subconverter 容器（转换后端） 启动 sub-web 容器（Web 前端） Nginx 反代两个容器 操作步骤一、安装最新的 Docker（环境）参考：Ubuntu 20.04 从官方源安装最新的 Docker 二、启动 subconverter 容器项目地址：tindy2013/subconverterDocker 镜像：tindy2013/subconverter 12345docker run -d \\ --name subconverter \\ --restart=unless-stopped \\ -p 25500:25500 \\ tindy2013/subconverter:latest 三、启动 sub-web 容器项目地址：CareyWang/sub-webDocker 镜像：careywong/subweb 12345docker run -d \\ --name subweb \\ --restart=unless-stopped \\ -p 10080:80 \\ careywong/subweb:latest 四、Nginx 反代两个容器申请和安装下证书： 123456789# 后端acme.sh --issue -d subconverter.ceshiku.cn --webroot /var/acme/webroot/ -k ec-256mkdir -vp /etc/nginx/ssl/subconverter.ceshiku.cn/acme.sh --install-cert -d subconverter.ceshiku.cn --fullchain-file /etc/nginx/ssl/subconverter.ceshiku.cn/certificate.crt --key-file /etc/nginx/ssl/subconverter.ceshiku.cn/private.key --reloadcmd &quot;service nginx force-reload&quot;# 前端acme.sh --issue -d subweb.ceshiku.cn --webroot /var/acme/webroot/ -k ec-256mkdir -vp /etc/nginx/ssl/subweb.ceshiku.cn/acme.sh --install-cert -d subweb.ceshiku.cn --fullchain-file /etc/nginx/ssl/subweb.ceshiku.cn/certificate.crt --key-file /etc/nginx/ssl/subweb.ceshiku.cn/private.key --reloadcmd &quot;service nginx force-reload&quot; Nginx 配置： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677# 后端server { listen 80; server_name subconverter.ceshiku.cn; # 强制跳转 HTTPS location / { return 301 https://$server_name$request_uri; } # 设置证书认证用的路径 location /.well-known/acme-challenge/ { # acme.sh --webroot 模式，认证文件生成后放置的路径 root /var/acme/webroot/; }}server { listen 443 ssl; server_name subconverter.ceshiku.cn; # SSL 配置 ssl_certificate /etc/nginx/ssl/subconverter.ceshiku.cn/certificate.crt; ssl_certificate_key /etc/nginx/ssl/subconverter.ceshiku.cn/private.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; location / { proxy_pass http://127.0.0.1:25500; proxy_set_header Host $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-Port $server_port; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; }}# 前端server { listen 80; server_name subweb.ceshiku.cn; # 强制跳转 HTTPS location / { return 301 https://$server_name$request_uri; } # 设置证书认证用的路径 location /.well-known/acme-challenge/ { # acme.sh --webroot 模式，认证文件生成后放置的路径 root /var/acme/webroot/; }}server { listen 443 ssl; server_name subweb.ceshiku.cn; # SSL 配置 ssl_certificate /etc/nginx/ssl/subweb.ceshiku.cn/certificate.crt; ssl_certificate_key /etc/nginx/ssl/subweb.ceshiku.cn/private.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; location / { proxy_pass http://127.0.0.1:10080; proxy_set_header Host $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-Port $server_port; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; }} 之后重启 Nginx： 12nginx -s reloadservice nginx restart","link":"/2024/09/17/sub_converter/"},{"title":"SAA 考试每日练习 - 2024&#x2F;12&#x2F;03","text":"来源：Amazon AWS Certified Solutions Architect - Associate SAA-C03 Exam50 题 (No.236 ~ No.285) 只记录了 14 道首次碰到的、错误的或有疑问的题目，仅供自己复习使用。如果侵权请联系删除。 🌟 单词： layern. 层，层次，表层，阶层 | v. 把…分层堆放 beanstalkn. 豆茎 amplifyv. 放大，阐发 budgetn. 预算 | v. 做预算；节省开支 | adj. 不贵的，廉价的 associatev. 联系，联想 | n. 同事；合作人；伙伴 | adj. （等级或头衔）副的；准的 hierarchicaladj. 按等级划分的，等级制度的 structuredadj. 有结构的；有组织的 | v. 组织；构成（“structure”的过去式和过去分词） 一、Three-tier application HAA company has a three-tier application for image sharing. The application uses an Amazon EC2 instance for the front-end layer, another EC2 instance for the application layer, and a third EC2 instance for a MySQL database. A solutions architect must design a scalable and highly available solution that requires the least amount of change to the application.Which solution meets these requirements? Use Amazon S3 to host the front-end layer. Use AWS Lambda functions for the application layer. Move the database to an Amazon DynamoDB table. Use Amazon S3 to store and serve users’ images. Use load-balanced Multi-AZ AWS Elastic Beanstalk environments for the front-end layer and the application layer. Move the database to an Amazon RDS DB instance with multiple read replicas to serve users’ images. Use Amazon S3 to host the front-end layer. Use a fleet of EC2 instances in an Auto Scaling group for the application layer. Move the database to a memory optimized instance type to store and serve users’ images. ✅ Use load-balanced Multi-AZ AWS Elastic Beanstalk environments for the front-end layer and the application layer. Move the database to an Amazon RDS Multi-AZ DB instance. Use Amazon S3 to store and serve users’ images. ✨ 关键词：three-tier application 4️⃣ ✅ 💡 解析：前端、后端和数据库三层应用需要高可用化。AWS Elastic Beanstalk 是用来简化应用程序部署流程的，并且使你不需要维护相关的 EC2 等基础设施：什么是 AWS Elastic Beanstalk？ 借助 Elastic Beanstalk，您可以在 AWS Cloud 中快速部署和管理应用程序，而不必了解运行这些应用程序的基础设施。 Elastic Beanstalk 支持在 Go、Java、.NET、Node.js、PHP、Python 和 Ruby 中开发的应用程序。Elastic Beanstalk 还支持 Docker 平台。 顺便带一下 TypeScript 技术栈的 AWS 相关应用服务：AWS Amplify 凭借全栈 TypeScript 功能，Amplify 将 AWS 服务的强大功能和广度融入熟悉的前端开发人员体验中。只需在 TypeScript 中编写数据模型、业务逻辑和身份验证规则等应用程序需求即可。Amplify 会自动配置正确的云资源并将其部署到每个开发人员的云沙盒环境中，以实现快速的本地迭代。 👨‍👨‍👦‍👦 社区讨论：B and D very similar with D being the ‘best’ solution but it is not the one that requires the least amount of development changesas the application would need to be changed to store images in S3 instead of DB 二、Cost notificationA company wants to experiment with individual AWS accounts for its engineer team. The company wants to be notified as soon as the Amazon EC2 instance usage for a given month exceeds a specific threshold for each account.What should a solutions architect do to meet this requirement MOST cost-effectively? Use Cost Explorer to create a daily report of costs by service. Filter the report by EC2 instances. Configure Cost Explorer to send an Amazon Simple Email Service (Amazon SES) notification when a threshold is exceeded. Use Cost Explorer to create a monthly report of costs by service. Filter the report by EC2 instances. Configure Cost Explorer to send an Amazon Simple Email Service (Amazon SES) notification when a threshold is exceeded. ✅ Use AWS Budgets to create a cost budget for each account. Set the period to monthly. Set the scope to EC2 instances. Set an alert threshold for the budget. Configure an Amazon Simple Notification Service (Amazon SNS) topic to receive a notification when a threshold is exceeded. Use AWS Cost and Usage Reports to create a report with hourly granularity. Integrate the report data with Amazon Athena. Use Amazon EventBridge to schedule an Athena query. Configure an Amazon Simple Notification Service (Amazon SNS) topic to receive a notification when a threshold is exceeded. ✨ 关键词：individual AWS accounts、cost notification 3️⃣ ✅ 💡 解析：公司需要得到通知如果账户的 EC2 使用量触发了给定的限额。使用 AWS 预算管理成本 (AWS Budgets) 您可以使用 AWS 预算来跟踪 AWS 成本和使用情况并采取行动。您可以使用 AWS 预算来监控您的预留实例 (RIs) 或 Savings Plans 的总利用率和覆盖率指标。 什么是亚马逊SES？ Amazon Simple Email Service (SES) 是一个电子邮件平台，它为您提供一种简单、经济实惠的方式，让您使用自己的电子邮件地址和域名发送和接收电子邮件。 需要注意的是，SNS 通过邮件订阅（通知以邮件形式发送），是不需要使用到 SES 服务的，它有自己的计费：Amazon SNS 定价 终端节点类型 免费套餐 价格 电子邮件/电子邮件-JSON 1000 个通知 每 10 万个通知 USD 2.00 👨‍👨‍👦‍👦 社区讨论：AWS Budgets allows you to create budgets for your AWS accountsand set alerts when usage exceedsa certain threshold. By creating a budget foreach account, specifying the period as monthlyand the scope asEC2 instances, you can effectively track the EC2 usage foreach account and be notified when a threshold isexceeded.This solution is the most cost-effective option as it does not require additional resources such as Amazon Athena or Amazon EventBridge. 三、ALB to private subnetA company runs a web application on Amazon EC2 instances in multiple Availability Zones. The EC2 instances are in private subnets. A solutions architect implements an internet-facing Application Load Balancer (ALB) and specifies the EC2 instances as the target group. However, the internet traffic is not reaching the EC2 instances.How should the solutions architect reconfigure the architecture to resolve this issue? Replace the ALB with a Network Load Balancer. Configure a NAT gateway in a public subnet to allow internet traffic. Move the EC2 instances to public subnets. Add a rule to the EC2 instances’ security groups to allow outbound traffic to 0.0.0.0/0. ❌ Update the route tables for the EC2 instances’ subnets to send 0.0.0.0/0 traffic through the internet gateway route. Add a rule to the EC2 instances’ security groups to allow outbound traffic to 0.0.0.0/0. ✅ Create public subnets in each Availability Zone. Associate联系 the public subnets with the ALB. Update the route tables for the public subnets with a route to the private subnets. ✨ 关键词：private subnet、ALB、the internet traffic is not reaching the EC2 instances 3️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：流量无法通过 ALB 到达私有子网中的 EC2 实例。3️⃣ 选项中的第一个操作是更新 EC2 所在子网的路由表，使得来自公网的流量能够流经互联网网关，这看上去没有什么问题。但是社区讨论中指出了来自互联网的流量会通过 ALB 的 弹性网络接口 (ENIs, Elastic Network Interfaces) 来到 EC2 实例。 看上去是这样的。而安全组默认是放行所有出栈流量的，因此 3️⃣ 的两个操作都没有必要。 4️⃣ 的操作是为每个可用区创建一个公有子网，将公有子网与 ALB 绑定，然后更新路由表将流量路由到私有子网。唯一的正解。 社区中有人提到 4️⃣ 的第二个操作没有必要 “no need as the local prefix entry in the route tables would take care of this point”，这是对的。同一 VPC 内的 子网 默认有一条本地的路由，可以互相访问：客户 Amazon VPC 内部资源和服务的相互访问 如下图所示，由于主路由表和各个子网隐式关联，因此，上述两个路由表中都可以看到一条本地路由，这条本地路由的目的地（Destination）为 VPC 关联的 CIDR 10.192.0.0/16，目标（Target）为 local， 这里 local 代表一个用于在 VPC 内部通信的本地路由。 👨‍👨‍👦‍👦 社区讨论：I think either the question or the answersare not formulated correctly because of this document:https://docs.aws.amazon.com/prescriptive-guidance/latest/load-balancer-stickiness/subnets-routing.html A - Might be possible but it’s quite impracticalB - Not needed as the setup described should workas is provided the SGs of the EC2 instancesaccept traffic from the ALBC - Update the route tables for the EC2 instances’ subnets to send 0.0.0.0/0 traffic through the internet gateway route - not needed as the EC2 instances would receive the traffic from the ALB ENIs. Add a rule to the EC2 instances’ security groups to allow outbound traffic to 0.0.0.0/0 - the default behaviour of the SG is to allow outbound traffic only.D - Create public subnets in each Availability Zone. Associate the public subnets with the ALB - if it’sa internet facing ALB these should already be in place. Update the route tables for the public subnets with a route to the private subnets - no need as the local prefix entry in the route tables would take care of this point I’m 110% sure the question or answers or both are wrong. Prove me wrong! :) 四、RDS read replicaA company has deployed a database in Amazon RDS for MySQL. Due to increased transactions, the database support team is reporting slow reads against the DB instance and recommends adding a read replica.Which combination of actions should a solutions architect take before implementing this change? (Choose two.) ❌ Enable binlog replication on the RDS primary node. Choose a failover priority for the source DB instance. ✅ Allow long-running transactions to complete on the source DB instance. ❌ Create a global table and specify the AWS Regions where the table will be available. ✅ Enable automatic backups on the source instance by setting the backup retention period to a value other than 0. ✨ 关键词： 1️⃣ 4️⃣ ❌ -&gt; 3️⃣ 5️⃣ ✅ 💡 解析：数据库读取慢，需要只读副本。首先来看下 binlog：必须了解的MySQL三大日志：binlog、redo log和undo log binlogbinlog用于记录数据库执行的写入性操作（不包括查询）信息，以二进制的形式保存在磁盘中。 binlog 使用场景在实际应用中，binlog的主要使用场景有两个，分别是主从复制和数据恢复。 主从复制：在Master端开启binlog，然后将binlog发送到各个Slave端，Slave端重放binlog从而达到主从数据一致。 数据恢复：通过使用mysqlbinlog工具来恢复数据。 虽然使用场景符合，但是它似乎是只能在自建的数据库上开启的，虽然也能获取 RDS for MySQL 的 binlog，但是并不常用：配置、启动和停止二进制日志（binlog）复制而 Global Table 是 DynamoDB 的，因此 4️⃣ 不对。 3️⃣ 的 “long-running transactions” 是长时间运行的事务，不理解开启它的意义。5️⃣ 是创建只读副本的必要措施，需要开启自动备份并将保留时间设置不为 0 的值（我依然没有找到出处，但是这是社区的共识）。 👨‍👨‍👦‍👦 社区讨论：C,E“An active, long-running transaction can slow the process of creating the read replica. We recommend that you wait for long-running transactions to complete before creating a read replica. If you create multiple read replicas in parallel from the same source DB instance, Amazon RDS takes only one snapshot at the start of the first create action.When creating a read replica, there are a few things to consider. First, you must enable automatic backups on the source DB instance by setting the backup retention period to a value other than 0.This requirement also applies to a read replica that is the source DB instance for another read replica”https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html 五、SMBA company is implementing a shared storage solution for a media application that is hosted in the AWS Cloud. The company needs the ability to use SMB clients to access data. The solution must be fully managed.Which AWS solution meets these requirements? Create an AWS Storage Gateway volume gateway. Create a file share that uses the required client protocol. Connect the application server to the file share. Create an AWS Storage Gateway tape gateway. Configure tapes to use Amazon S3. Connect the application server to the tape gateway. Create an Amazon EC2 Windows instance. Install and configure a Windows file share role on the instance. Connect the application server to the file share. ✅ Create an Amazon FSx for Windows File Server file system. Attach the file system to the origin server. Connect the application server to the file system. ✨ 关键词：SMB 4️⃣ ✅ 💡 解析：需要使用 SMB 访问存储，并且存储完全可管理。NFS 和 SMB 之间有什么区别？ SMB 协议是 Windows 原生文件共享的默认协议。Windows 功能是围绕 SMB 构建的。您需要 Samba 等外部工具才能在 Linux 计算机上使用 SMB 来访问远程 Windows 服务器文件。 NFS 协议是专门为 Unix 系统设计的。它是大多数 Linux 发行版中的原生文件共享协议，也是默认的文件传输协议。 因此这里需要选择与 Windows 相关的 3️⃣ 或者 4️⃣。挂载支持 SMB 的文件系统很符合直觉。 👨‍👨‍👦‍👦 社区讨论：SMB + fully managed = fsx for windows imo Amazon FSx has native support for Windows file system featuresand for the industry-standard Server Message Block(SMB) protocol to access file storage over a network.https://docs.aws.amazon.com/fsx/latest/WindowsGuide/what-is.html 六、Security Group IDA company is reviewing a recent migration of a three-tier application to a VPC. The security team discovers that the principle of least privilege is not being applied to Amazon EC2 security group ingress and egress rules between the application tiers.What should a solutions architect do to correct this issue? ❌ Create security group rules using the instance ID as the source or destination. ✅ Create security group rules using the security group ID as the source or destination. Create security group rules using the VPC CIDR blocks as the source or destination. Create security group rules using the subnet CIDR blocks as the source or destination. ✨ 关键词：Security Group、PoLP 1️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：实例的安全组需要使用最小权限原则。涉及到引用安全组 (Security group referencing)：引用安全组 当您指定一个安全组作为规则的源或目标时，该规则会影响与安全组关联的所有实例。实例可以使用其私有 IP 地址，通过指定的协议和端口沿指定方向进行通信。例如，下面的内容表示安全组的入站规则，该入站规则引用了安全组 sg-0abcdef1234567890。此规则允许来自与 sg-0abcdef1234567890 关联的实例的入站 SSH 流量。 来源 协议 端口范围 sg-0abcdef1234567890 TCP 22 在安全组规则中引用安全组时，请注意以下几点： 两个安全组必须属于同一 VPC 或对等 VPC。 不得向引用安全组的安全组添加引用安全组中的任何规则。 对于入站规则，与安全组关联的 EC2 实例可以接收来自与引用安全组关联的 EC2 实例的私有 IP 地址的入站流量。 对于出站规则，与安全组关联的 EC2 实例可以向与引用安全组关联的 EC2 实例的私有 IP 地址发送出站流量。 这意味着，对安全组的引用时链式的，2️⃣ 既可以实现最小权限原则，又易于后续的实例扩容。 👨‍👨‍👦‍👦 社区讨论：B. Create security group rules using the security group ID as the source or destination.This way, the security team can ensure that the least privileged access is given to the application tiers byallowing only the necessary communication between the security groups. Forexample, the web tier security group should onlyallow incoming traffic from the load balancer security group and outgoing traffic to the application tier security group.Thisapproach provides a more granular and secure way to control traffic between the different tiers of the application and also allows foreasy modification of access if needed.It’salso worth noting that it’s good practice to minimize the number of open portsand protocols,and use security groupsasa first line of defense, in addition to networkaccess control lists (ACLs) to control traffic between subnets. 七、Auto Scaling status dataA company is building a solution that will report Amazon EC2 Auto Scaling events across all the applications in an AWS account. The company needs to use a serverless solution to store the EC2 Auto Scaling status data in Amazon S3. The company then will use the data in Amazon S3 to provide near-real-time updates in a dashboard. The solution must not affect the speed of EC2 instance launches.How should the company move the data to Amazon S3 to meet these requirements? ✅ Use an Amazon CloudWatch metric stream to send the EC2 Auto Scaling status data to Amazon Kinesis Data Firehose. Store the data in Amazon S3. Launch an Amazon EMR cluster to collect the EC2 Auto Scaling status data and send the data to Amazon Kinesis Data Firehose. Store the data in Amazon S3. ❌ Create an Amazon EventBridge rule to invoke an AWS Lambda function on a schedule. Configure the Lambda function to send the EC2 Auto Scaling status data directly to Amazon S3. Use a bootstrap script during the launch of an EC2 instance to install Amazon Kinesis Agent. Configure Kinesis Agent to collect the EC2 Auto Scaling status data and send the data to Amazon Kinesis Data Firehose. Store the data in Amazon S3. ✨ 关键词：serverless、store the EC2 Auto Scaling status data in Amazon S3 3️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：需要将 EC2 弹性的状态数据存储到 S3 存储桶中。使用无服务的解决方案。3️⃣ 错在定时 (on a schedule) 调用了 Lambda 。 👨‍👨‍👦‍👦 社区讨论：B - EMR cluster is for Big Data, has nothing to do with thisC - invokes the function “on a schedule”, but you want to capture eventsD - Could work, but would be overcomplex and would “affect the speed of EC2 instance launches” (which it should not) This solution meets the requirements because it is serverlessand does not affect the speed of EC2 instance launches. Amazon CloudWatch metric streams can continuously stream CloudWatch metrics to destinations such as Amazon S3. Amazon Kinesis Data Firehose can capture, transform,and deliver streaming data into data lakes, data stores,and analytics services. It can directly put the data into Amazon S3, which can then be used for near-real-time updates in a dashboard. 八、Windows file server and ADA company’s compliance team needs to move its file shares to AWS. The shares run on a Windows Server SMB file share. A self-managed on-premises Active Directory controls access to the files and folders.The company wants to use Amazon FSx for Windows File Server as part of the solution. The company must ensure that the on-premises Active Directory groups restrict access to the FSx for Windows File Server SMB compliance shares, folders, and files after the move to AWS. The company has created an FSx for Windows File Server file system.Which solution will meet these requirements? ❌ Create an Active Directory Connector to connect to the Active Directory. Map the Active Directory groups to IAM groups to restrict access. Assign a tag with a Restrict tag key and a Compliance tag value. Map the Active Directory groups to IAM groups to restrict access. Create an IAM service-linked role that is linked directly to FSx for Windows File Server to restrict access. ✅ Join the file system to the Active Directory to restrict access. ✨ 关键词：on-premises AD 1️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：需要将 AWS 上的 Windows 文件系统加入自建的 AD 域中。将亚马逊FSx文件系统加入自我管理的 Microsoft Active Directory 域 当你FSx为 Windows 文件服务器创建新的文件系统时，你可以配置 Microsoft Active Directory 集成，使其加入你自行管理的 Microsoft Active Directory 域。为此，请为您的 Microsoft Active Directory 提供以下信息： 您的本地 Microsoft Active Directory 目录的完全限定域名 (FQDN)。 您的域名DNS服务器的 IP 地址。 本地 Microsoft Active Directory 域中的服务账户凭证。Amazon FSx 使用这些凭证加入您自行管理的活动目录。 因此不需要做什么特别的操作，直接将文件系统加入现有 AD 域中即可，即使它是自建的。 👨‍👨‍👦‍👦 社区讨论：D. Join the file system to the Active Directory to restrict access.Joining the FSx for Windows File Server file system to the on-premises Active Directory will allow the company to use the existing Active Directory groups to restrict access to the file shares, folders,and filesafter the move to AWS.This option allows the company to continue using theirexisting access controlsand management structure, making the transition to AWS more seamless. D.allows the file system to leverage the existing AD infrastructure for authentication and access control. Option A is incorrect because mapping the AD groups to IAM groups is not applicable in this scenario. IAM is primarily used for managing access to AWS resources, while the requirement is to integrate with the on-premises AD for access control.Option B is incorrect because assigning a tag with a Restrict tag keyand a Compliance tag value does not provide the necessary integration with the on-premises AD for access control.Tagsare used for organizing and categorizing resourcesand do not provide authentication or access control mechanisms.Option C is incorrect because creating an IAM service-linked role linked directly to FSx for Windows File Server does not integrate with the on-premises AD. IAM rolesare used within AWS for managing permissionsand do not provide the necessary integration with external AD systems. 九、Health checkA company has a web application hosted over 10 Amazon EC2 instances with traffic directed by Amazon Route 53. The company occasionally experiences a timeout error when attempting to browse the application. The networking team finds that some DNS queries return IP addresses of unhealthy instances, resulting in the timeout error.What should a solutions architect implement to overcome these timeout errors? Create a Route 53 simple routing policy record for each EC2 instance. Associate a health check with each record. ❌ Create a Route 53 failover routing policy record for each EC2 instance. Associate a health check with each record. Create an Amazon CloudFront distribution with EC2 instances as its origin. Associate a health check with the EC2 instances. ✅ Create an Application Load Balancer (ALB) with a health check in front of the EC2 instances. Route to the ALB from Route 53. ✨ 关键词：Amazon Route 53、health check 2️⃣ ❌ -&gt; 4️⃣ ✅ 💡 解析：Route53 的 DNS 寻址返回了不可用实例的 IP 导致超时错误。这里 1️⃣ 和 2️⃣ 其实都对，他们都可以做到将流量分发到实例并开启健康检查：简单 Amazon Route 53 配置中的运行状况检查的工作原理 当有两个或更多资源执行相同功能 (例如用于 example.com 的两个或更多 Web 服务器) 时，可使用下列运行状况检查功能，将流量仅路由到运行状况良好的资源。 路由简单 如果您在记录中指定多个值，则 Route 53 将所有值以随机顺序返回到递归解析程序。 但是 4️⃣ 是个更好的选择，后续扩容也不需要修改 DNS 记录。我也更推崇 4️⃣。 👨‍👨‍👦‍👦 社区讨论：ALB performs health checks on the EC2 instances, so it will only route traffic to healthy instances.Thisavoids the timeout errors.ALB provides load balancing across the instances, improving performance and availability.Route 53 routes to the ALB DNS name, so you don’t have to manage records foreach EC2 instance.This is a standard and robust architecture for public-facing web applications. The ALB acts as the entry point and handles health checksand scaling. 十、Amazon Aurora Global Database and DR infrastructureA rapidly growing ecommerce company is running its workloads in a single AWS Region. A solutions architect must create a disaster recovery (DR) strategy that includes a different AWS Region. The company wants its database to be up to date in the DR Region with the least possible latency. The remaining infrastructure in the DR Region needs to run at reduced capacity and must be able to scale up if necessary.Which solution will meet these requirements with the LOWEST recovery time objective (RTO)? Use an Amazon Aurora global database with a pilot light deployment. ✅ Use an Amazon Aurora global database with a warm standby deployment. Use an Amazon RDS Multi-AZ DB instance with a pilot light deployment. ❌ Use an Amazon RDS Multi-AZ DB instance with a warm standby deployment. ✨ 关键词：LOWEST RTO 4️⃣ ❌ -&gt; 2️⃣ ✅ 💡 解析：需要在另一个区域部署缩小的架构，并能在灾难发生时扩容到主架构大小。首先看下 Pilot light 和 Warm standby（温备用） 的区别：云中的灾难恢复选项 Pilot Light - 您可以将数据从一个区域复制到另一个区域，并预置核心工作负载基础设施的副本。 支持数据复制和备份所需的资源（如数据库和对象存储）始终处于开启状态。 其他元素（例如应用程序服务器）加载了应用程序代码和配置，处于关闭状态，仅在测试期间或调用灾难恢复故障转移时使用。 不同于备份与还原方法，您的核心基础设施始终可用，而且您始终可以选择通过打开和横向扩展应用程序服务器来快速预置完整的生产环境。 Warm standby（温备用） - 温备用方法包括确保在另一个区域中有一个缩减但功能齐全的生产环境副本。 这种方法扩展了 Pilot Light 的概念，缩短了恢复时间，因为您的工作负载在另一个区域中始终可用。此方法还使您能够更轻松地执行测试或实施连续测试，从而增强从灾难中恢复的信心。 注意：Pilot Light 和温备用之间的差异有时难以区分。两者都包含灾难恢复区域中的环境，该环境包含主区域资产的副本。区别在于，如果不首先执行其他操作，Pilot Light 就无法处理请求，而温备用可以立即处理流量（在产能降低的情况下）。Pilot Light 方法要求您“打开”服务器，可能还需要部署其他（非核心）基础设施并纵向扩展；而温备用只需纵向扩展（一切均已部署并正在运行）。 因此在本题中，无疑需要选择 Warm standby（温备用）。再来看下 Amazon Aurora 全球数据库 的概念：Amazon Aurora 全球数据库 Amazon Aurora Global Database 针对全球分布式应用程序而设计，允许单个 Amazon Aurora 数据库跨越多个 AWS 区域。它在不影响数据库性能的情况下复制您的数据，在每个区域中实现低延迟的快速本地读取，并且在发生区域级的中断时提供灾难恢复能力。无论辅助区域的数量和位置如何，您的应用程序都享受快速数据访问，典型的跨区域复制延迟小于 1 秒。 这和 DynamoDB 的 Global Table 的概念大致相同：Amazon DynamoDB 全局表 DynamoDB 全局表由多个副本表组成。每个副本表存在于不同的区域中，但所有副本都具有相同的名称和主键。当数据写入任何副本表时，DynamoDB 会自动将该数据复制到全局表中的所有其他副本表。在全局表中，新写入的项目通常会在一秒钟内传播到所有副本表中。 👨‍👨‍👦‍👦 社区讨论：Note:The difference between pilot light and warm standby can sometimes be difficult to understand. Both include an environment in your DR Region with copies of your primary Region assets.The distinction is that pilot light cannot process requests without additional action taken first, whereas warm standby can handle traffic (at reduced capacity levels) immediately.The pilot light approach requires you to “turn on” servers, possibly deployadditional (non-core) infrastructure, and scale up, whereas warm standby only requires you to scale up (everything isalready deployed and running). Use your RTO and RPO needs to help you choose between these approaches.https://docs.aws.amazon.com/whitepapers/latest/disaster-recovery-workloads-on-aws/disaster-recovery-options-in-the-cloud.html 十一、Database instance out of storageA company has a multi-tier application deployed on several Amazon EC2 instances in an Auto Scaling group. An Amazon RDS for Oracle instance is the application’ s data layer that uses Oracle-specific PL/SQL functions. Traffic to the application has been steadily increasing. This is causing the EC2 instances to become overloaded and the RDS instance to run out of storage.The Auto Scaling group does not have any scaling metrics and defines the minimum healthy instance count only. The company predicts that traffic will continue to increase at a steady but unpredictable rate before leveling off.What should a solutions architect do to ensure the system can automatically scale for the increased traffic? (Choose two.) ✅ Configure storage Auto Scaling on the RDS for Oracle instance. ❌ Migrate the database to Amazon Aurora to use Auto Scaling storage. Configure an alarm on the RDS for Oracle instance for low free storage space. ✅ Configure the Auto Scaling group to use the average CPU as the scaling metric. Configure the Auto Scaling group to use the average free memory as the scaling metric. ✨ 关键词：Database instance out of storage 2️⃣ 4️⃣ ❌ -&gt; 1️⃣ 4️⃣ ✅ 💡 解析：Amazon RDS for Oracle 实例的存储超了，且部署应用的 EC2 弹性扩容组也需要设置新的指标。来看下 RDS for Oracle 的创建过程： 因此我们明确，RDS 的数据库创建是需要指定 EC2 实例（类型）的。那它如何实现存储的扩容呢，官方给了解决方案：使用 Amazon RDS 存储自动扩展功能自动管理容量 如果您的工作负载是不可预测的，则可以为 Amazon RDS 数据库实例启用存储自动扩展。为此，您可以使用 Amazon RDS 控制台、Amazon RDS API 或 AWS CLI。如果启用了存储自动扩展，在 Amazon RDS 检测到可用数据库空间不足时，则会自动扩展存储。在以下因素适用时，Amazon RDS 会为启用了自动扩展的数据库实例启动存储修改： 可用空间小于或等于所分配的存储空间的 10%。 存储空间不足状态至少持续 5 分钟。 自上次存储修改以来，至少已过去 6 小时；或在实例上完成存储优化后，至少已过去 6 小时。 因此 1️⃣ 是成立的。关于 5️⃣，官方并没有支持内存指标，你需要通过安装 CloudWatch Agent 并做相应配置：How to create an Amazon EC2 Auto Scaling policy based on a memory utilization metric (Linux)在用户访问的场景下，CPU 指标更简单也更好。 👨‍👨‍👦‍👦 社区讨论：A) Configure storage Auto Scaling on the RDS for Oracle instance.= Makes sense. With RDS Storage Auto Scaling, you simply set your desired maximum storage limit,and Auto Scaling takes care of the rest. B) Migrate the database to Amazon Aurora to use Auto Scaling storage.= Scenario specifiesapplication’s data layer uses Oracle-specific PL/SQL functions.This rules out migration to Aurora. C) Configure an alarm on the RDS for Oracle instance for low free storage space.= You could do this but what does it fix? Nothing.The CW notification isn’t going to trigger anything. D) Configure the Auto Scaling group to use the average CPU as the scaling metric.= Makes sense.The CPU utilization is the precursor to the storage outage. When the ec2 instancesare overloaded, the RDS instance storage hits its limits, too. 十二、Hierarchical structured dataA company wants to create an application to store employee data in a hierarchical按等级划分的 structured有结构的 relationship. The company needs a minimum-latency response to high-traffic queries for the employee data and must protect any sensitive data. The company also needs to receive monthly email messages if any financial information is present in the employee data.Which combination of steps should a solutions architect take to meet these requirements? (Choose two.) Use Amazon Redshift to store the employee data in hierarchies. Unload the data to Amazon S3 every month. ✅ Use Amazon DynamoDB to store the employee data in hierarchies. Export the data to Amazon S3 every month. ❌ Configure Amazon Macie for the AWS account. Integrate Macie with Amazon EventBridge to send monthly events to AWS Lambda. Use Amazon Athena to analyze the employee data in Amazon S3. Integrate Athena with Amazon QuickSight to publish analysis dashboards and share the dashboards with users. ✅ Configure Amazon Macie for the AWS account. Integrate Macie with Amazon EventBridge to send monthly notifications through an Amazon Simple Notification Service (Amazon SNS) subscription. ✨ 关键词：minimum-latency response to high-traffic queries for the data、protect sensitive data、receive monthly email messages 3️⃣ 5️⃣ ❌ -&gt; 2️⃣ 5️⃣ ✅ 💡 解析：需要快速检索雇员数据，并保护其隐私。如果有财务信息被包含的话，需要按月发信通知。Amazon Macie 功能 Amazon Macie 是一种数据安全服务，它使用机器学习和模式匹配来发现敏感数据，提供对数据安全风险的可见性，并使您能够自动防御这些风险。为了帮助您管理 Amazon S3 环境的数据安全状况，Macie 不断评估您的 S3 存储桶的安全性和访问控制，并生成结果，以通知您未加密的存储桶、可公开访问的存储桶以及与您组织外部的 AWS 账户共享的存储桶等问题。 然后，Macie 会自动对 S3 存储桶中的对象进行采样和分析，检查它们是否包含个人身份信息（PII）等敏感数据，构建 S3 中敏感数据跨账户所在位置的交互式数据映射，并为每个存储桶提供敏感度分数。 在这里，Amazon Macie 就完成了对雇员敏感信息的甄别需求。而关于 DynamoDB 对有层级结构信息的存储，官方是这么解决的：Model hierarchical automotive component data using Amazon DynamoDB Partition Key (ComponentId) Location on graph (GraphId) Parent-child relationship (ParentId) Path V1 V1#1 – V1 B11 V1#1 V1 V1 M111 V1#1 V1 V1 C1111 V1#1 V1 V1 暂时没看懂 🤦‍ 不过总之 DynamoDB 在分层数据建模方面有优势就是了：分层数据建模示例 👨‍👨‍👦‍👦 社区讨论：Data in hierarchies : Amazon DynamoDBB. Use Amazon DynamoDB to store the employee data in hierarchies.Export the data to Amazon S3 every month. Sensitive Info: Amazon MacieE. Configure Amazon Macie for the AWS account. Integrate Macie with Amazon EventBridge to send monthly notifications through an Amazon Simple Notification Service (Amazon SNS) subscription. 十三、DynamoDB backupsA company has an application that is backed by an Amazon DynamoDB table. The company’s compliance requirements specify that database backups must be taken every month, must be available for 6 months, and must be retained for 7 years.Which solution will meet these requirements? ✅ Create an AWS Backup plan to back up the DynamoDB table on the first day of each month. Specify a lifecycle policy that transitions the backup to cold storage after 6 months. Set the retention period for each backup to 7 years. Create a DynamoDB on-demand backup of the DynamoDB table on the first day of each month. Transition the backup to Amazon S3 Glacier Flexible Retrieval after 6 months. Create an S3 Lifecycle policy to delete backups that are older than 7 years. Use the AWS SDK to develop a script that creates an on-demand backup of the DynamoDB table. Set up an Amazon EventBridge rule that runs the script on the first day of each month. Create a second script that will run on the second day of each month to transition DynamoDB backups that are older than 6 months to cold storage and to delete backups that are older than 7 years. Use the AWS CLI to create an on-demand backup of the DynamoDB table. Set up an Amazon EventBridge rule that runs the command on the first day of each month with a cron expression. Specify in the command to transition the backups to cold storage after 6 months and to delete the backups after 7 years. ✨ 关键词：backup must be available for 6 months、must be retained for 7 years 1️⃣ ✅ 💡 解析：需要备份 DynamoDB 数据库，6 个月内可用并存档 7 年。首先看下 AWS Backup 是否支持定时备份以及生命周期：备份计划选项和配置 Backup frequency (备份频率)备份频率决定了 AWS Backup 创建快照备份的频率。使用控制台，您可从每小时、每 12 个小时、每天、每周或每月中选择频率。您还可以创建 Cron 表达式，以每小时一次的频率创建快照备份。使用 AWS Backup CLI，您可以将快照备份的频率安排为每小时一次。 生命周期和存储层备份将存储您指定的天数（即备份生命周期）。备份可以还原，直到其生命周期结束。每个备份都已创建并存储在暖存储中。根据您选择的备份存储时间长短，您可能希望将备份转移到成本较低的层（名为“冷存储”）。 再看下 AWS Backup 的作用范围： Amazon EBS Amazon EC2 Amazon RDS Amazon DynamoDB Amazon EFS AWS Storage Gateway Amazon FSx EC2、数据库和文件系统，因此 1️⃣ 完全正确。2️⃣ 似乎也没有错误，且官方也有推荐将存储备份到 S3 存储桶中：Set up scheduled backups for Amazon DynamoDB using AWS Backup 但是我是觉得只使用 S3 Glacier Flexible Retrieval 这个存储桶是不对的，题目明确有访问频率的变化。 👨‍👨‍👦‍👦 社区讨论：Option B mentions using Amazon S3 Glacier Flexible Retrieval, but DynamoDB doesn’t natively support transitioning backups to Amazon S3 Glacier. Options C and D involve custom scripts and EventBridge rules, which add complexity and may not be as reliable or efficient as using AWS Backup for this purpose. https://docs.aws.amazon.com/aws-backup/latest/devguide/creating-a-backup-plan.html 十四、Amazon FSx for NetApp ONTAPA research company runs experiments that are powered by a simulation application and a visualization application. The simulation application runs on Linux and outputs intermediate data to an NFS share every 5 minutes. The visualization application is a Windows desktop application that displays the simulation output and requires an SMB file system.The company maintains two synchronized file systems. This strategy is causing data duplication and inefficient resource usage. The company needs to migrate the applications to AWS without making code changes to either application.Which solution will meet these requirements? Migrate both applications to AWS Lambda. Create an Amazon S3 bucket to exchange data between the applications. Migrate both applications to Amazon Elastic Container Service (Amazon ECS). Configure Amazon FSx File Gateway for storage. Migrate the simulation application to Linux Amazon EC2 instances. Migrate the visualization application to Windows EC2 instances. Configure Amazon Simple Queue Service (Amazon SQS) to exchange data between the applications. ✅ Migrate the simulation application to Linux Amazon EC2 instances. Migrate the visualization application to Windows EC2 instances. Configure Amazon FSx for NetApp ONTAP for storage. ✨ 关键词：SMB、NFS 4️⃣ ✅ 💡 解析：需要能够同时支持 SMB 和 NFS 的存储解决方案。Amazon FSx for NetApp ONTAP 通过符合行业标准的 NFS、SMB、iSCSI 和 NVMe-over-TCP 协议向广泛的工作负载和用户提供您的数据。 👨‍👨‍👦‍👦 社区讨论：Amazon FSx for NetApp ONTAP provides shared storage between Linux and Windows file systems.","link":"/2024/12/03/saa_test_daily_20241203/"},{"title":"SAP 考试每日练习 - 2024&#x2F;12&#x2F;26","text":"来源：Amazon AWS Certified Solutions Architect - Professional SAP-C02 Exam13 题 (No.1 ~ No.13)，仅供自己复习使用。如果侵权请联系删除。 一、DNS solutionA company needs to architect a hybrid DNS solution. This solution will use an Amazon Route 53 private hosted zone for the domain cloud.example.com for the resources stored within VPCs.The company has the following DNS resolution requirements:On-premises systems should be able to resolve and connect to cloud.example.com.All VPCs should be able to resolve cloud.example.com.There is already an AWS Direct Connect connection between the on-premises corporate network and AWS Transit Gateway.Which architecture should the company use to meet these requirements with the HIGHEST performance? ✅ Associate the private hosted zone to all the VPCs. Create a Route 53 inbound resolver in the shared services VPC. Attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the inbound resolver. Associate the private hosted zone to all the VPCs. Deploy an Amazon EC2 conditional forwarder in the shared services VPC. Attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the conditional forwarder. Associate the private hosted zone to the shared services VPC. Create a Route 53 outbound resolver in the shared services VPAttach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the outbound resolver. ❌ Associate the private hosted zone to the shared services VPC. Create a Route 53 inbound resolver in the shared services VPC. Attach the shared services VPC to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the inbound resolver. ✨ 关键词： 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：公司需要一个混合 DNS 解决方案。本地和所有 AWS 的 VPC 都需要能够使用 Route 53 的私有托管区来解析 cloud.example.com 域名之后访问存储在 VPC 中的资源。目前在本地和 AWS Transit Gateway 之间已经有了一条 DX 连接。问为了追求最高性能还需要做什么？1️⃣ 和 4️⃣ 的差别在于是将 Route 53 的私有托管区连接到所有 VPC 还是单纯附加给共享服务的 VPC，还有是将所有 VPC 还是只将共享服务的 VPC 附加给 AWS Transit Gateway。针对题目中的所有 VPC 都需要能够解析域名，其实就该选 1️⃣ 了。 不过还是确认两个概念： 可以为 Route 53 的私有托管区联系更多 VPC Associating more VPCs with a private hosted zone 可以将 VPC 附加到 AWS Transit Gateway 以实现互联 AWS Transit Gateway AWS Transit Gateway 是一种高可用性和可扩展性的服务，用于为具有中心辐射架构的区域整合 AWS VPC 路由配置。每个辐条 VPC 只需连接到转接网关，即可访问其他已连接的 VPC。AWS Transit Gateway 支持 IPv4 和 IPv6 流量。 相应实践：Centralized DNS management of hybrid cloud with Amazon Route 53 and AWS Transit Gateway 👨‍👨‍👦‍👦 社区讨论：A. Correct answer.Source: https://aws.amazon.com/blogs/networking-and-content-delivery/centralized-dns-management-of-hybrid-cloud-with-amazon-route-53-and-aws-transit-gateway/ NOT B. EC2 conditional forwarder will not meet Highest performance requirement. NOT C. Missing: Need to associate private hosted zone to all VPC.“All VPC’s will need to associate their private hosted zones to all other VPC’s if required to.” NOT D. Missing: Need to associate private hosted zone to all VPC.“All VPC’s will need to associate their private hosted zones to all other VPC’s if required to.” 二、DNS HA over RegionsA company is providing weather data over a REST-based API to several customers. The API is hosted by Amazon API Gateway and is integrated with different AWS Lambda functions for each API operation. The company uses Amazon Route 53 for DNS and has created a resource record of weather.example.com. The company stores data for the API in Amazon DynamoDB tables.The company needs a solution that will give the API the ability to fail over to a different AWS Region.Which solution will meet these requirements? Deploy a new set of Lambda functions in a new Region. Update the API Gateway API to use an edge-optimized API endpoint with Lambda functions from both Regions as targets. Convert the DynamoDB tables to global tables. Deploy a new API Gateway API and Lambda functions in another Region. Change the Route 53 DNS record to a multivalue answer. Add both API Gateway APIs to the answer. Enable target health monitoring. Convert the DynamoDB tables to global tables. ✅ Deploy a new API Gateway API and Lambda functions in another Region. Change the Route 53 DNS record to a failover record. Enable target health monitoring. Convert the DynamoDB tables to global tables. Deploy a new API Gateway API in a new Region. Change the Lambda functions to global functions. Change the Route 53 DNS record to a multivalue answer. Add both API Gateway APIs to the answer. Enable target health monitoring. Convert the DynamoDB tables to global tables. ✨ 关键词： 3️⃣ ✅ 💡 解析：Configure custom health checks for DNS failover for an API Gateway API 您可以使用 Amazon Route 53 健康检查来控制从主 AWS 区域中的 API Gateway API 到辅助区域中的 API Gateway API 的 DNS 故障转移。这有助于在发生区域问题时减轻影响。如果使用自定义域，则无需客户更改 API 端点即可执行故障转移。 1️⃣ 的选项中提到了 edge-optimized API endpoint，确认下：API endpoint types for REST APIs in API Gateway Edge-optimized API endpoints （边缘优化的应用程序接口端点）- 边缘优化的 API 端点通常会将请求路由到最近的 CloudFront 存在点 (POP)，这对于客户分布在不同地理位置的情况很有帮助。这是 API Gateway REST API 的默认端点类型。 Regional API endpoints （区域应用程序接口端点）- 区域 API 端点面向同一区域的客户端。当运行在 EC2 实例上的客户端调用同一区域的 API 时，或者当 API 的目的是为少量需求较高的客户端提供服务时，区域 API 可以减少连接开销。 Private API endpoints （专用应用程序接口端点）- 私有 API 端点是只能从亚马逊虚拟私有云 (VPC) 使用接口 VPC 端点访问的 API 端点，接口 VPC 端点是您在 VPC 中创建的端点网络接口 (ENI)。 它更多是用以优化延迟，而非容灾。 👨‍👨‍👦‍👦 社区讨论：https://docs.aws.amazon.com/apigateway/latest/developerguide/dns-failover.html 三、OU and SCPA company uses AWS Organizations with a single OU named Production to manage multiple accounts. All accounts are members of the Production OU. Administrators use deny list SCPs in the root of the organization to manage access to restricted services.The company recently acquired a new business unit and invited the new unit’s existing AWS account to the organization. Once onboarded, the administrators of the new business unit discovered that they are not able to update existing AWS Config rules to meet the company’s policies.Which option will allow administrators to make changes and continue to enforce the current policies without introducing additional long-term maintenance? Remove the organization’s root SCPs that limit access to AWS Config. Create AWS Service Catalog products for the company’s standard AWS Config rules and deploy them throughout the organization, including the new account. Create a temporary OU named Onboarding for the new account. Apply an SCP to the Onboarding OU to allow AWS Config actions. Move the new account to the Production OU when adjustments to AWS Config are complete. Convert the organization’s root SCPs from deny list SCPs to allow list SCPs to allow the required services only. Temporarily apply an SCP to the organization’s root that allows AWS Config actions for principals only in the new account. ✅ Create a temporary OU named Onboarding for the new account. Apply an SCP to the Onboarding OU to allow AWS Config actions. Move the organization’s root SCP to the Production OU. Move the new account to the Production OU when adjustments to AWS Config are complete. ✨ 关键词： 4️⃣ ✅ 💡 解析：旧的策略附加到了根上，导致组织中所有非管理账户的用户都无法操作 AWS Config。SCP 不授予权限只控制权限，因此 2️⃣ 不对，只能选 4️⃣：服务控制策略 (SCPs) SCP 不会向组织中的 IAM 用户和 IAM 角色授予权限。SCP 不授予任何权限。SCP 为组织中的 IAM 用户和 IAM 角色可以执行的操作定义了权限护栏或设置了限制。要授予权限，管理员必须附加控制访问的策略，如附加到 IAM 用户和 IAM 角色的基于身份的策略，以及附加到账户资源的基于资源的策略。更多信息，请参阅《IAM 用户指南》中的基于身份的策略和基于资源的策略。 👨‍👨‍👦‍👦 社区讨论：Right answer is D.An SCP at a lower level can’t add a permission after it is blocked byan SCP at a higher level.SCPs can only filter; they never add permissions.SO you need to create a new OU for the new account assign an SCP,and move the rootSCP to Production OU.Then move the new account to production OU when AWS config is done. 四、Auto ScalingA company is running a two-tier web-based application in an on-premises data center. The application layer consists of a single server running a stateful application. The application connects to a PostgreSQL database running on a separate server. The application’s user base is expected to grow significantly, so the company is migrating the application and database to AWS.The solution will use Amazon Aurora PostgreSQL, Amazon EC2 Auto Scaling, and Elastic Load Balancing.Which solution will provide a consistent user experience that will allow the application and database tiers to scale? Enable Aurora Auto Scaling for Aurora Replicas. Use a Network Load Balancer with the least outstanding requests routing algorithm and sticky sessions enabled. Enable Aurora Auto Scaling for Aurora writers. Use an Application Load Balancer with the round robin routing algorithm and sticky sessions enabled. ✅ Enable Aurora Auto Scaling for Aurora Replicas. Use an Application Load Balancer with the round robin routing and sticky sessions enabled. Enable Aurora Scaling for Aurora writers. Use a Network Load Balancer with the least outstanding requests routing algorithm and sticky sessions enabled. ✨ 关键词：stateful application 3️⃣ ✅ 💡 解析：针对弹性扩展器的路由策略：路由算法 轮询 (Round robin) - 轮询路由算法按顺序将请求均匀地路由到目标组中运行状况良好的目标。 最少未完成请求 (Least outstanding requests) - 最少未完成的请求路由算法将请求路由到正在进行的请求数最少的目标。 加权随机 (Weighted random) - 加权随机路由算法以随机顺序在目标组中运行状况良好的目标之间均匀路由请求。 👨‍👨‍👦‍👦 社区讨论：C. Aurora writers is a distractor. Single master mode only has read replica - with Aurora replicas. Multi master mode, not in the options NLB does not support round robin and least outstanding algorithm https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Integrating.AutoScaling.html 五、CloudFront functionA company uses a service to collect metadata from applications that the company hosts on premises. Consumer devices such as TVs and internet radios access the applications. Many older devices do not support certain HTTP headers and exhibit errors when these headers are present in responses. The company has configured an on-premises load balancer to remove the unsupported headers from responses sent to older devices, which the company identified by the User-Agent headers.The company wants to migrate the service to AWS, adopt serverless technologies, and retain the ability to support the older devices. The company has already migrated the applications into a set of AWS Lambda functions.Which solution will meet these requirements? ✅ Create an Amazon CloudFront distribution for the metadata service. Create an Application Load Balancer (ALB). Configure the CloudFront distribution to forward requests to the ALB. Configure the ALB to invoke the correct Lambda function for each type of request. Create a CloudFront function to remove the problematic headers based on the value of the User-Agent header. Create an Amazon API Gateway REST API for the metadata service. Configure API Gateway to invoke the correct Lambda function for each type of request. Modify the default gateway responses to remove the problematic headers based on the value of the User-Agent header. Create an Amazon API Gateway HTTP API for the metadata service. Configure API Gateway to invoke the correct Lambda function for each type of request. Create a response mapping template to remove the problematic headers based on the value of the User-Agent. Associate the response data mapping with the HTTP API. ❌ Create an Amazon CloudFront distribution for the metadata service. Create an Application Load Balancer (ALB). Configure the CloudFront distribution to forward requests to the ALB. Configure the ALB to invoke the correct Lambda function for each type of request. Create a Lambda@Edge function that will remove the problematic headers in response to viewer requests based on the value of the User-Agent header. ✨ 关键词： 4️⃣ ❌ -&gt; 1️⃣ ✅ 💡 解析：CloudFront 是支持简单的 JavaScript 方法的：使用 CloudFront Functions 在边缘进行自定义 借助 CloudFront Functions，您可以在 JavaScript 中编写轻量级函数，以实现大规模、延迟敏感的 CDN 自定义。您的函数可以操作通过 CloudFront 的请求和响应、执行基本身份验证和授权、在边缘生成 HTTP 响应等。CloudFront Functions 运行时环境提供亚毫秒的启动时间，可立即扩展，从而每秒处理数百万个请求，并且非常安全。CloudFront Functions 是 CloudFront 的原生功能，这意味着您可以完全在 CloudFront 中构建、测试和部署代码。 在将 CloudFront 函数与 CloudFront 分配相关联时，CloudFront 在 CloudFront 边缘站点中截获请求和响应并将它们传递到您的函数。当发生以下事件时，您可以调用 CloudFront Functions： 在 CloudFront 收到查看器的请求时 (查看器请求) 在 CloudFront 将响应返回到查看器之前（查看器响应） 同时它也能够对 HTTP 请求头进行处理：使用策略在 CloudFront 响应中添加或删除 HTTP 标头 您可以配置 CloudFront 以修改它发送给查看器（Web 浏览器和其他客户端）的响应中的 HTTP 标头。在将响应发送给查看器之前，CloudFront 可以删除从源接收到的标头，或者在响应中添加标头。进行这些更改不需要编写代码或更改源。 社区对 1️⃣ 和 4️⃣ 存在争议，这里 1️⃣ 可以更简单地实现需求。 👨‍👨‍👦‍👦 社区讨论：A.The only difference between A and D is CloudFront function vs Lambda@Edge. In this case the CloudFront function can remove the response header based on request header and much faster/light-weight. 六、Cross Account S3 AccessA retail company needs to provide a series of data files to another company, which is its business partner. These files are saved in an Amazon S3 bucket under Account A, which belongs to the retail company. The business partner company wants one of its IAM users, User_DataProcessor, to access the files from its own AWS account (Account B).Which combination of steps must the companies take so that User_DataProcessor can access the S3 bucket successfully? (Choose two.) ❌ Turn on the cross-origin resource sharing (CORS) feature for the S3 bucket in Account A. In Account A, set the S3 bucket policy to the following: ✅ In Account A, set the S3 bucket policy to the following: ✅ In Account B, set the permissions of User_DataProcessor to the following: In Account B, set the permissions of User_DataProcessor to the following: ✨ 关键词： 1️⃣ 3️⃣ ❌ -&gt; 3️⃣ 4️⃣ ✅ 💡 解析：3️⃣ 不存在问题，在账户 A 允许账户 B 的某个 IAM 用户 访问存储桶。而针对 4️⃣，相关的事件文章中有准确描述：如何授予对 Amazon S3 存储桶中对象的跨账户访问权限？ 向账户 B 中的 IAM 用户或角色授予 GetObject 和 PutObject 权限。此外，授予 IAM 用户或角色调用 PutObjectAcl 的权限，该权限向存储桶所有者授予对象权限： 1234567891011121314{ &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: [ &quot;s3:GetObject&quot;, &quot;s3:PutObject&quot;, &quot;s3:PutObjectAcl&quot; ], &quot;Resource&quot;: &quot;arn:aws:s3:::AccountABucketName/*&quot; } ]} 相关的文档还有：示例 4：存储桶拥有者针对自己未拥有的对象授予跨账户权限 👨‍👨‍👦‍👦 社区讨论：C &amp; DTo allow User_DataProcessor to access the S3 bucket from Account B, the following steps need to be taken: In Account A, set the S3 bucket policy to allow access to the bucket from the IAM user in Account B.This is done byadding a statement to the bucket policy that allows the IAM user in Account B to perform the necessaryactions (GetObject and ListBucket) on the bucket and its contents. In Account B, create an IAM policy that allows the IAM user (User_DataProcessor) to perform the necessaryactions (GetObject and ListBucket) on the S3 bucket and its contents.The policy should reference the ARN of the S3 bucket and the actions that the user isallowed to perform. Note: turning on the cross-origin resource sharing (CORS) feature for the S3 bucket in Account A is not necessary for this scenario as it is typically used for allowing web browsers to access resources from different domains. 七、Microservices and serverlessA company is running a traditional web application on Amazon EC2 instances. The company needs to refactor the application as microservices that run on containers. Separate versions of the application exist in two distinct environments: production and testing. Load for the application is variable, but the minimum load and the maximum load are known. A solutions architect needs to design the updated application with a serverless architecture that minimizes operational complexity.Which solution will meet these requirements MOST cost-effectively? Upload the container images to AWS Lambda as functions. Configure a concurrency limit for the associated Lambda functions to handle the expected peak load. Configure two separate Lambda integrations within Amazon API Gateway: one for production and one for testing. ✅ Upload the container images to Amazon Elastic Container Registry (Amazon ECR). Configure two auto scaled Amazon Elastic Container Service (Amazon ECS) clusters with the Fargate launch type to handle the expected load. Deploy tasks from the ECR images. Configure two separate Application Load Balancers to direct traffic to the ECS clusters. Upload the container images to Amazon Elastic Container Registry (Amazon ECR). Configure two auto scaled Amazon Elastic Kubernetes Service (Amazon EKS) clusters with the Fargate launch type to handle the expected load. Deploy tasks from the ECR images. Configure two separate Application Load Balancers to direct traffic to the EKS clusters. Upload the container images to AWS Elastic Beanstalk. In Elastic Beanstalk, create separate environments and deployments for production and testing. Configure two separate Application Load Balancers to direct traffic to the Elastic Beanstalk deployments. ✨ 关键词： 2️⃣ ✅ 💡 解析：微服务和容器化的无服务器架构离不开 Fargate，ECS 相比 EKS 操作更简单。 👨‍👨‍👦‍👦 社区讨论：B. Upload the container images to Amazon Elastic Container Registry (Amazon ECR). Configure two auto scaled Amazon Elastic ContainerService (Amazon ECS) clusters with the Fargate launch type to handle the expected load. Deploy tasks from the ECR images. Configure two separate Application Load Balancers to direct traffic to the ECS clusters.This option meets the requirement of using a serverlessarchitecture by utilizing the Fargate launch type for the ECS clusters, which allows for automatic scaling of the containers based on the expected load. It also allows for separate deployments for production and testing by configuring separate ECS clustersand Application Load Balancers foreach environment.This option also minimizes operational complexity by utilizing ECS and Fargate for the container orchestration and scaling. 八、Route 53 health checkA company has a multi-tier web application that runs on a fleet of Amazon EC2 instances behind an Application Load Balancer (ALB). The instances are in an Auto Scaling group. The ALB and the Auto Scaling group are replicated in a backup AWS Region.The minimum value and the maximum value for the Auto Scaling group are set to zero. An Amazon RDS Multi-AZ DB instance stores the application’s data. The DB instance has a read replica in the backup Region. The application presents an endpoint to end users by using an Amazon Route 53 record.The company needs to reduce its RTO to less than 15 minutes by giving the application the ability to automatically fail over to the backup Region. The company does not have a large enough budget for an active-active strategy.What should a solutions architect recommend to meet these requirements? Reconfigure the application’s Route 53 record with a latency-based routing policy that load balances traffic between the two ALBs. Create an AWS Lambda function in the backup Region to promote the read replica and modify the Auto Scaling group values. Create an Amazon CloudWatch alarm that is based on the HTTPCode_Target_5XX_Count metric for the ALB in the primary Region. Configure the CloudWatch alarm to invoke the Lambda function. ✅ Create an AWS Lambda function in the backup Region to promote the read replica and modify the Auto Scaling group values. Configure Route 53 with a health check that monitors the web application and sends an Amazon Simple Notification Service (Amazon SNS) notification to the Lambda function when the health check status is unhealthy. Update the application’s Route 53 record with a failover policy that routes traffic to the ALB in the backup Region when a health check failure occurs. Configure the Auto Scaling group in the backup Region to have the same values as the Auto Scaling group in the primary Region. Reconfigure the application’s Route 53 record with a latency-based routing policy that load balances traffic between the two ALBs. Remove the read replica. Replace the read replica with a standalone RDS DB instance. Configure Cross-Region Replication between the RDS DB instances by using snapshots and Amazon S3. Configure an endpoint in AWS Global Accelerator with the two ALBs as equal weighted targets. Create an AWS Lambda function in the backup Region to promote the read replica and modify the Auto Scaling group values. Create an Amazon CloudWatch alarm that is based on the HTTPCode_Target_5XX_Count metric for the ALB in the primary Region. Configure the CloudWatch alarm to invoke the Lambda function. ✨ 关键词：RTO less than 15 minutes 2️⃣ ✅ 💡 解析：公司在另一个区域部署了 0 容量的自动扩容组等架构，同时有只读的 RDS 副本。在没有太多预算的情况下希望控制 RTO 少于 15 分钟。3️⃣ 涉及到启动空闲实例，不满足预算要求，首先排除。4️⃣ 在两个 ALB 前面部署全球加速器，没有必要也排除。1️⃣ 对 ALB 响应码进行判断，调用 Lambda 函数启动备份架构。2️⃣ 使用 Route 53 的健康检查和 SNS 调用 Lambda 函数启动备份架构。 2️⃣ 设计到了 Route 53 的健康检查这个 AWS 提供的功能，更加符合出题目的：Amazon Route 53 如何检查您的资源的运行状况 Amazon Route 53 运行状况检查可监控您的资源（如 Web 服务器和电子邮件服务器）的运行状况。您可以选择为运行状况检查配置 Amazon CloudWatch 警报，以便在资源不可用时收到通知。如果您希望在资源变得不可用时收到通知，下面概述了运行状况检查的工作原理： 👨‍👨‍👦‍👦 社区讨论：B is correct, because it meets the company’s requirements for reducing RTO to less than 15 minutesand not having a large budget for an active-active strategy. In this solution, the company createsan AWS Lambda function in the backup region which promotes the read replica and modifies the Auto Scaling group values. Route 53 is configured with a health checkthat monitors the web application and sendsan Amazon SNS notification to the Lambda function when the health checkstatus is unhealthy.The Route 53 record is also updated with a failover policy that routes traffic to the ALB in the backup region when a health checkfailure occurs.This way, when the primary region goes down, the failover policy triggersand traffic is directed to the backup region,ensuring a quickrecovery time. 九、HA infrastructureA company is hosting a critical application on a single Amazon EC2 instance. The application uses an Amazon ElastiCache for Redis single-node cluster for an in-memory data store. The application uses an Amazon RDS for MariaDB DB instance for a relational database. For the application to function, each piece of the infrastructure must be healthy and must be in an active state.A solutions architect needs to improve the application’s architecture so that the infrastructure can automatically recover from failure with the least possible downtime.Which combination of steps will meet these requirements? (Choose three.) ✅ Use an Elastic Load Balancer to distribute trafficacross multiple EC2 instances. Ensure that the EC2 instances are part of an Auto Scaling group that has a minimum capacity of two instances. Use an Elastic Load Balancer to distribute trafficacross multiple EC2 instances. Ensure that the EC2 instances are configured in unlimited mode. Modify the DB instance to create a read replica in the same Availability Zone. Promote the read replica to be the primary DB instance in failure scenarios. ✅ Modify the DB instance to create a Multi-AZ deployment that extends across two Availability Zones. Create a replication group for the ElastiCache for Redis cluster. Configure the cluster to use an Auto Scaling group that has a minimum capacity of two instances. ✅ Create a replication group for the ElastiCache for Redis cluster. Enable Multi-AZ on the cluster. ✨ 关键词： 1️⃣ 4️⃣ 6️⃣ ✅ 💡 解析：1️⃣ 4️⃣ 6️⃣ 都是可用性最高的选择。通过使用 Valkey 和 Redis OSS 的 Multi-AZ 将 ElastiCache 的停机时间降至最短 在许多情况下，ElastiCache for Valkey 和 Redis OSS 可能需要替换主节点；其中包括某些类型的计划维护，以及主节点或可用区发生故障的可能性不大的情况。这种替换会导致群集出现一定的停机时间，但如果启用了多可用区，停机时间会降到最低。主节点的角色将自动切换到其中一个读取副本。无需创建和配置新的主节点，因为 ElastiCache 会以透明的方式进行处理。这种故障切换和副本升级可确保您在升级完成后立即恢复写入新的主节点。 👨‍👨‍👦‍👦 社区讨论：I go with ADFhttps://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/AutoFailover.html 十、ALB error pageA retail company is operating its ecommerce application on AWS. The application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The company uses an Amazon RDS DB instance as the database backend. Amazon CloudFront is configured with one origin that points to the ALB. Static content is cached. Amazon Route 53 is used to host all public zones.After an update of the application, the ALB occasionally returns a 502 status code (Bad Gateway) error. The root cause is malformed HTTP headers that are returned to the ALB. The webpage returns successfully when a solutions architect reloads the webpage immediately after the error occurs.While the company is working on the problem, the solutions architect needs to provide a custom error page instead of the standard ALB error page to visitors.Which combination of steps will meet this requirement with the LEAST amount of operational overhead? (Choose two.) ✅ Create an Amazon S3 bucket. Configure the S3 bucket to host a static webpage. Upload the custom error pages to Amazon S3. Create an Amazon CloudWatch alarm to invoke an AWS Lambda function if the ALB health check response Target.FailedHealthChecks is greater than 0. Configure the Lambda function to modify the forwarding rule at the ALB to point to a publicly accessible web server. Modify the existing Amazon Route 53 records by adding health checks. Configure a fallback target if the health check fails. Modify DNS records to point to a publicly accessible webpage. Create an Amazon CloudWatch alarm to invoke an AWS Lambda function if the ALB health check response Elb.InternalError is greater than 0. Configure the Lambda function to modify the forwarding rule at the ALB to point to a publicaccessible web server. ✅ Add a custom error response by configuring a CloudFront custom error page. Modify DNS records to point to a publicly accessible web page. ✨ 关键词： 1️⃣ 5️⃣ ✅ 💡 解析：配置错误响应行为 您可以通过多个选项，管理 CloudFront 在出错时如何进行响应。要配置自定义错误响应，您可以使用 CloudFront 控制台、CloudFront API 或 AWS CloudFormation。无论您选择哪种方式来更新配置，请考虑以下提示和建议： 在 CloudFront 可访问的位置保存自定义错误页面。建议您将这些页面存储在 Amazon S3 存储桶中，并且不要将它们与您的网站或应用程序的其余内容存储于同一位置。如果您将自定义错误页面与您的网站或应用程序存储在同一个源上，且源开始返回 5xx 错误，则 CloudFront 无法获取自定义错误页面，因为源服务器不可用。有关更多信息，请参阅将对象和自定义错误页面存储在不同的位置。 👨‍👨‍👦‍👦 社区讨论：A &amp; Ehttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/GeneratingCustomErrorResponses.html#custom-error-pages-procedure 十一、Share AWS Resources cross accoutns in AWS OrganizationA company has many AWS accounts and uses AWS Organizations to manage all of them. A solutions architect must implement a solution that the company can use to share a common network across multiple accounts.The company’s infrastructure team has a dedicated infrastructure account that has a VPC. The infrastructure team must use this account to manage the network. Individual accounts cannot have the ability to manage their own networks. However, individual accounts must be able to create AWS resources within subnets.Which combination of actions should the solutions architect perform to meet these requirements? (Choose two.) ❌ Create a transit gateway in the infrastructure account. ✅ Enable resource sharing from the AWS Organizations management account. Create VPCs in each AWS account within the organization in AWS Organizations. Configure the VPCs to share the same CIDR range and subnets as the VPC in the infrastructure account. Peer the VPCs in each individual account with the VPC in the infrastructure account. ✅ Create a resource share in AWS Resource Access Manager in the infrastructure account. Select the specific AWS Organizations OU that will use the shared network. Select each subnet to associate with the resource share. Create a resource share in AWS Resource Access Manager in the infrastructure account. Select the specific AWS Organizations OU that will use the shared network. Select each prefix list to associate with the resource share. ✨ 关键词：a common network across multiple accounts 1️⃣ 4️⃣ ❌ -&gt; 2️⃣ 4️⃣ ✅ 💡 解析：组织中的其他账户不能管理网络，需要一个共通的账户单独管理网络。共通的账号拥有一个 VPC，同时，各个帐户必须能够在子网内创建 AWS 资源。这里的重点似乎并不是网络，而是组织中其他账户在单一账户的 VPC 的 子网 中创建资源的能力。 这里需要参考官方关于资源共享的文档：共享您的 AWS 资源 要使用共享您拥有的资源 AWS RAM，请执行以下操作： 在 AWS Organizations中启用资源共享 创建资源共享 2️⃣ 是必须的措施。再来看看什么是 AWS Resource Access Manager？ AWS Resource Access Manager (AWS RAM) 可帮助您跨 AWS 账户、在组织或组织单位 (OU) 内以及与 AWS Identity and Access Management (IAM) 角色和用户针对受支持资源类型安全地共享资源。如果您有多个 AWS 账户，可以一次性创建一个资源，然后使用 AWS RAM 使该资源可供其他账户使用。如果您的账户由 AWS Organizations 管理，则您可以与组织中的所有其他账户共享资源，也可以仅与一个或多个指定组织单位 (OU) 所包含的账户共享资源。您还可以根据账户 ID 与特定 AWS 账户共享，而不管该账户是否属于组织。一些支持的资源类型还允许您与指定的 IAM 角色和用户进行共享。 它是服务于 AWS 资源跨账户共享需求的。而关于是附加到 子网 还是 前缀：可共享的资源 AWS - Amazon VPC 资源类型和代码 应用场景 可以与IAM用户和角色共享 可以与组织外部的账户共享 可以使用客户托管权限 可以与服务主体共享 前缀列表 ec2:PrefixList 集中创建和管理前缀列表，并与其他人 AWS 账户 或您的组织共享。这允许在其资源中使用多个 AWS 账户 引用前缀列表，例如 VPC 安全组和子网路由表。有关更多信息，请参阅《Amazon VPC 用户指南》中的使用共享前缀列表。 否 是 否 否 子网 ec2:Subnet 集中创建和管理子网，并与组织内的 AWS 账户 共享这些子网。这样，多个用户就可以将其应用程序资源 AWS 账户启动到集中管理状态VPCs。这些资源包括亚马逊EC2实例、亚马逊关系数据库服务 (RDS) 数据库、Amazon Redshift 集群和 AWS Lambda 函数。有关更多信息，请参阅《Amazon VPC 用户指南》中的使用VPC共享。 否 否 否 否 4️⃣ 和 5️⃣ 看起来都可以，4️⃣ 更贴合题意吧。 👨‍👨‍👦‍👦 社区讨论：Step B is needed because it enables the organization to share resourcesacrossaccounts.Step D is needed because it allows the infrastructure account to share specific subnets with the other accounts in the organization, so that the other accounts can create resources within those subnets without having to manage their own networks. 十二、AWS PrivateLink interfaceA company wants to use a third-party software-as-a-service (SaaS) application. The third-party SaaS application is consumed through several API calls. The third-party SaaS application also runs on AWS inside a VPC.The company will consume the third-party SaaS application from inside a VPC. The company has internal security policies that mandate the use of private connectivity that does not traverse the internet. No resources that run in the company VPC are allowed to be accessed from outside the company’s VPC. All permissions must conform to the principles of least privilege.Which solution meets these requirements? ✅ Create an AWS PrivateLink interface VPC endpoint. Connect this endpoint to the endpoint service that the third-party SaaS application provides. Create a security group to limit the access to the endpoint. Associate the security group with the endpoint. Create an AWS Site-to-Site VPN connection between the third-party SaaS application and the company VPC. Configure network ACLs to limit access across the VPN tunnels. Create a VPC peering connection between the third-party SaaS application and the company VPUpdate route tables by adding the needed routes for the peering connection. Create an AWS PrivateLink endpoint service. Ask the third-party SaaS provider to create an interface VPC endpoint for this endpoint service. Grant permissions for the endpoint service to the specificaccount of the third-party SaaS provider. ✨ 关键词： 1️⃣ ✅ 💡 解析：通过以下方式访问 SaaS 产品 AWS PrivateLink 下图显示了如何使用 VPC 端点连接到 SaaS 产品。服务提供商创建端点服务并向其客户授予端点服务的访问权限。作为服务使用者，您可以创建一个接口VPC终端节点，用于在您的 VPC 和终端节点服务中的一个或多个子网之间建立连接。 👨‍👨‍👦‍👦 社区讨论：AccessSaas products throgh AWS Private Linkis the answer. 十三、A variety of tools to perform patchingA company needs to implement a patching process for its servers. The on-premises servers and Amazon EC2 instances use a variety of tools to perform patching. Management requires a single report showing the patch status of all the servers and instances.Which set of actions should a solutions architect take to meet these requirements? ✅ Use AWS Systems Manager to manage patches on the on-premises servers and EC2 instances. Use Systems Manager to generate patch compliance reports. Use AWS OpsWorks to manage patches on the on-premises servers and EC2 instances. Use Amazon QuickSight integration with OpsWorks to generate patch compliance reports. Use an Amazon EventBridge rule to apply patches by scheduling an AWS Systems Manager patch remediation job. Use Amazon Inspector to generate patch compliance reports. Use AWS OpsWorks to manage patches on the on-premises servers and EC2 instances. Use AWS X-Ray to post the patch status to AWS Systems Manager OpsCenter to generate patch compliance reports. ✨ 关键词： 1️⃣ ✅ 💡 解析：混合云环境中本地实例的修补解决方案设计 下图描述了另一种使用 Systems Manager 自定义清单选项修补本地实例的方法。此过程是我们前面描述的针对可变 EC2 实例的自动修补解决方案的扩展。 👨‍👨‍👦‍👦 社区讨论：A is correct. AWS Systems Manager can manage patches on both on-premises serversand EC2 instancesand can generate patch compliance reports. AWS OpsWorksand Amazon Inspector are not specifically designed for patch management and therefore would not be the best choice for this use case. Using Amazon EventBridge rule and AWS X-Ray to generate patch compliance reports is not a practical solution as theyare not designed for patch management reporting.","link":"/2024/12/26/sap_test_daily_20241226./"},{"title":"Mac 下安装 Terraform 基础结构即代码工具，并添加 AWS 云服务提供商","text":"前言AWS 的官方课程有提到这些基础结构即代码工具，恰巧部署博客评论代码 Twikoo 时也需要用到，于是在这里记录下配置过程。 关于 Terraform 的介绍：什么是 Terraform？一言以蔽之，它可以让你通过写代码和配置来部署云服务提供商的资源，你也可以直接拷贝开源项目推荐的云服务部署模板，这对自动化和迁移来说极为便利。 方案概述 AWS 官方提供的文档：开始使用 Terraform 产品 安装 Terraform（MacOS 平台） 前往 AWS 控制台获取 Access Key 和 Secret Key 配置 AWS 云服务提供商 测试部署一个 VPC 网络资源 操作步骤一、安装 Terraform（MacOS 平台）参考：Install Terraform我这里是 Mac，使用 brew 安装： 12brew tap hashicorp/tapbrew install hashicorp/tap/terraform 如果出现了 Error: Your Command Line Tools are too outdated. 错误： 12Error: Your Command Line Tools are too outdated.Update them from Software Update in System Settings. 则需要更新 Xcode Command Line Tools，前往 https://developer.apple.com/download/more/ 下载最新的对应自己 Xcode 版本的 Command Line Tools 安装即可，我这里是 Command Line Tools for Xcode 16。 确认安装成功： 1terraform -v 二、前往 AWS 控制台获取 Access Key 和 Secret KeyAWS IAM 控制台（us-west-2 区域）：IAM 控制台这里不为根用户生产密钥，而是为 Terraform 创建一个新的用户 terraform，并给予 AdministratorAccess 权限。 1、创建新的用户 2、为 terraform 用户创建 Access Key 和 Secret Key点击用户信息，可以看到右侧有 创建访问密钥 的链接：选择 其他：之后创建访问密钥即可，密钥大概是这样的： 12AKIA5J2Z5J2Z5J2Z5J2Zcpt_jqc7TUG6mtg1avjzce*quq4BXQ8gec 三、配置 AWS 云服务提供商 参考：AWS Provider Terraform 是以目录（项目）为单位的。我们需要新建一个项目专用的目录，之后在其中创建配置文件。在初始化后，云服务提供商的资源将会存在于这个目录下。这里新建一个目录 terraform_aws_test，并在其中创建一个 main.tf 文件，用于配置 AWS 云服务提供商： 123mkdir terraform_aws_testcd terraform_aws_testtouch main.tf main.tf 文件内容如下，不填入真实的 Access Key 和 Secret Key 暂时也没有关系： 12345provider &quot;aws&quot; { region = &quot;us-west-2&quot; access_key = &quot;my-access-key&quot; secret_key = &quot;my-secret-key&quot;} 之后初始化一下，Terraform 默认会记载当前目录下的配置文件： 1terraform init 之后在目录中，可以看到下载了 AWS Provider 相关的资源： 四、测试部署一个 VPC 网络资源在刚刚我们创建的目录中，稍微修改下 main.tf 文件，添加上 Access Key 和 Secret Key，然后再创建一个 VPC 网络资源： 1234567891011# Configure the AWS Providerprovider &quot;aws&quot; { region = &quot;us-west-2&quot; access_key = &quot;AKIA5J2Z5J2Z5J2Z5J2Z&quot; secret_key = &quot;cpt_jqc7TUG6mtg1avjzce*quq4BXQ8gec&quot;}# Create a VPCresource &quot;aws_vpc&quot; &quot;example&quot; { cidr_block = &quot;10.0.0.0/16&quot;} 之后执行 terraform apply，会提示你输入 yes 确认，然后就会开始部署资源了： 1terraform apply 回到 AWS 控制台，可以看到我们刚刚创建的 VPC 网络资源： 当然这种将 Access Key 和 Secret Key 直接写入配置文件的方式绝对不是最佳实践，更多的时候我们会使用环境变量或者其他方式来配置这些敏感信息，详细可以参考：Input Variables 参考资料： Terraform —— 使用代码管理基础设施 📺 Terraform课程-安装Terraform和本地设置 📺 Terraform课程-(实操)创建一个AWS帐户和一个AWS用户 📺 Terraform课程-(实操)Providers - 连接到 AWS 提供商","link":"/2024/10/02/terraform_aws/"},{"title":"Terraform 学习笔记（二）Terraform 是什么以及如何使用","text":"仅做个人学习笔记复习使用，如果侵权请联系。 前言关于 Terraform 的优势、特性、使用场景、架构（实现）以及常用命令等。 什么是 TerraformTerraform 是一款强大的工具，它可以帮助自动化并管理： 基础设施 平台 运行在平台上的各种服务 一、优势和特性这款工具是开源的，并且使用声明式语言进行操作，这意味着您无需定义每一步的自动化和管理过程，你只需要明确你想要的最终的结果，而 Terraform 会帮助搞定如何实现。 它这与命令式（程序式）风格的操作方式不同，命令式风格需要您详细定义每一步的执行过程。 二、能力和角色Terraform 是一款专注于基础设施配置和部署的工具。简单来说它可以帮助快速搭建起运行应用程序所需的基础设施环境。 在我们实际的应用程序部署中，往往包含两个独立任务的过程： 提供并配置基础设施，并准备部署应用程序所需的一切。 在基础设施上实际部署应用程序。 这两个任务甚至可能需要有两个独立的团队或人员来执行。 例如：您刚开始一个新项目，想要从头开始设置一个基础设施来运行您的应用程序。这个基础设施可能包括几台服务器，用于部署您的微服务应用程序，而这些微服务以 Docker 容器的形式存在。此外您可能还需要一个数据库容器，您决定选择 AWS 作为构建整个基础设施的平台。在 AWS 上准备和配置资源，以便部署应用程序。这是一个复杂的过程，需要：创建私有网络空间和 EC2 服务器实例；在每个实例上安装所需的其他的工具；设置服务器安全性（防火墙等）；配置网络等等……一旦基础设施就绪，就需要将 Docker 应用程序或容器部署到已经准备好的基础设施上。 那么在这其中，Terraform 扮演什么角色呢？很明显，它负责第一部分的工作：基础设施的配置和部署，以准备应用程序的部署。它可以帮助您创建 VPC、启动服务器、设置安全性、创建 AWS 用户和权限，以及比如在服务器上安装特定版本的 Docker 等等…… BTW 所有这些任务都需要以正确的顺序完成，因为一项任务可能依赖于另一项任务。 三、Ansible 和 Terraform 的区别1、相同都是基础设施及代码的工具，用于自动化提供配置和管理基础设施。 2、不同 侧重点不同。 Terraform 主要用于基础设施的配置和部署。 当然也支持在该基础设施上通过其他工具部署应用程序。 Ansible 主要是配置工具，一旦提供了基础设施，就可以对其进行配置。 例如：配置基础设施、该基础设施上部署应用程序安装和更新软件。 新旧差异。 Terraform 较新，还在不断地动态的发展。 Ansible 在 2012 年被创造，历经 12 年的发展，相对成熟。 通常使用的领域不同。 Terraform 在资源编排方面展现出了更强大的能力，因此被用于基础设施的预配置。 Ansible 则更多地被用于配置基础设施，以及部署和安装软件、应用程序等任务。 使用场景一、创建基础设施这是 Terraform 的强项且反复被提及，因此不再赘述。 二、管理现有的基础设施 回到之前的微服务部署案例，现在我们使用了 Terraform 成功地创建了基础设施，并在 AWS 上为项目进行了一些必要的配置，随后在基础设施上面部署了应用程序。 然而随着开发团队开发出更多的新功能需要部署，我们决定要在现有的基础设施中增加 6 台服务器以支持更多的微服务的部署需求，然后还想添加一些安全配置，以及删除一些在开始时配置的东西。很明显现在我们处于管理现有基础设施的阶段，包括添加一些东西，重新配置删除一些东西等等…… 使用 Terraform，上述的这些操作也都可以很容易的实现。管理基础设施的任务同样重要，因为一旦为项目创建了初始的基础设施之后，就需要不断的调整和更改它。也正因为如此，就更需要自动化的工具来完成大部分繁重的工作，而不必每次都需要手动来完成这些任务。 三、复制基础设施 通过前面创建和调整，在测试了配置并确保一切正常后，你可能希望将开发环境的应用程序发布到生产环境中。因此你可能需要创建生产环境，然后完全复制之前的这套环境所有的设置。因为这套环境的基础设施和环境等配置都是测试验证过了，直接复制是最好的选择，不容易出现问题且效率高，而不是在生产环境中重新再从头来一遍。 而 Terraform 同样能在这里表现的很好。使用 Terraform 可以复制构建一套与开发环境相同的基础设施，也就是直接使用与第一个设置开发环境相同的 Terraform 代码，轻松地进行复制启动和设置相同的基础设施。 Terraform 架构Terraform 是如何实现这上述场景中对应功能的呢？它是如何与这些基础设施提供商平台通信对接，并利用各种技术来配置资源的呢？这就要讲到 Terraform 的架构了。 一、核心的两组件（Core 和 State）Terraform 主要由两个组件构成其架构： 第一个主要组件是其核心库 (Core)​：它负责接收并处理输入源，以执行相应的操作。 这些输入源主要是用户编写的 Terraform 配置文件，其中定义了需要创建配置或管理的资源。 第二个组件是状态 (State)​：Terraform 用它来跟踪和更新基础设施的当前配置状态。 当 Core 接收到用户提供的配置输入后，它会根据这些信息计算出需要执行的操作计划，以确保实际的基础设施状态与期望的状态一致。而之后 Terraform 会比较当前的基础设施状态与您所期望的配置状态，当检测到当前的状态与期望的状态之间存在差异时，它就会计算出需要执行的操作，用以将当前的实际状态与配置文件中所定义的状态一致，这可能包括：创建新资源、更新现有资源或删除不再需要的资源。此外 Terraform 还会确定应该以何种顺序执行这些操作，以确保整个过程的顺利和高效。 二、提供商 (Providers)这是 Terraform 的最重要的组成部分。通过 Providers 提供的特定的技术接口，Terraform 才得以与提供商平台进行通信，并执行相应的操作。这些 Providers 可以是： 云服务提供商 (IaaS)。 例如：AWS、微软云、阿里云、腾讯云等。 更高级别的组件、平台及服务 (PaaS) 工具。 例如：Kubernetes 等容器编排平台。 软件即服务 (SaaS) 工具。 例如：Fastly。 你可以做到：创建 AWS 基础设施，然后在其上部署创建 Kubernetes 集群，最后在集群内部创建服务或组件。这就实现了从基础设施到应用程序的全方位配置和管理。 你可以在这里看到所有的 Providers：Providers有些是官方提供的，有些是服务提供商自己提供的，也有一部分是用户编写并共享的。 三、流程当 Core 根据配置文件和 State 的输入创建执行计划时，它会利用这些不同供应商的 Provider 来执行该计划。而这些 Provider 负责与相应的供应商进行通讯，并执行实际的配置和管理操作。 四、配置样例1、将 AWS 作为云服务提供商的例子12345678910# 定义 Providerprovider &quot;aws&quot; { version = &quot;~&gt; 2.0&quot; region = &quot;us-west-2&quot;}# 配置 Providers 的资源resource &quot;aws_vpc&quot; &quot;test&quot; { cidr_block = &quot;10.0.0.0/16&quot;} 2、将 Kubernetes 作为平台及服务工具的例子123456789101112# 定义 Providerprovider &quot;kubernetes&quot; { config_context_auth_info = &quot;ops&quot; config_context_cluster = &quot;my_cluster&quot;}# 配置 Providers 的资源resource &quot;kubernetes_namespace&quot; &quot;test&quot; { metadata { name = &quot;my-test-namespace&quot; }} 五、Terraform 声明式配置所带来的优势简单来说，当创建 Terraform 的配置文件时，不需要详细定义每一步的执行过程，比如：如何创建 VPC、如何启动多台实例或如何配置网络等。而是只需要定义期望的最终状态是什么样的，比如：我想要几台具备特定网络配置的服务器，以及一个拥有特定权限的 AWS 用户来访问这些服务器，然后 Terraform 就会根据您的配置自动为您完成这些操作。 在对资源进行初始配置时，声明式方法或许并不会带来太直观的感受，它与命令式方法在呈现上可能大致接近。但当需要更新基础设施的时候，例如增删服务器或进行其他调整时，两者之间的区别就会凸显出来： 命令式方法需要您在配置文件中具体的说明要执行的每一步操作。 这些操作都需要被详细记录为步骤：删除两台服务器，添加一个防火墙配置，以及为 AWS 的用户某某某分配某些权限等。 声明式方法只需要描述您期望的最终状态。 Terraform 会自动处理所有必要的操作，确保从当前状态平滑过渡到你所描述的期望状态。 这带来的好处就是： 配置足够简单。 所见即所得，可以清晰地预测最终状态是什么样子的。 降低了出错的风险，所有的参数复杂的具体操作都由 Terraform 计划和实现。 Terraform 命令一、refresh 获取当前状态1terraform refresh Terraform 会联系基础设施供应商，来获取基础设施的当前状态。 二、plan 创建执行计划以供预览1terraform plan Core 会根据当前的基础设施状态 State 和配置文件中定义的目标状态，制定一个详细的执行的计划。详细地列出需要执行的操作，以及执行这些操作的顺序。但是它并不会实际执行这些操作，只是提供一个预览。 三、apply 执行计划1terraform apply Core 会根据 plan 生成的执行计划，执行实际的操作，以确保当前的基础设施状态与配置文件中所定义的状态一致。 四、destroy 销毁基础设置及资源1terraform destroy Terraform 会销毁配置文件涉及到的所有资源，以确保基础设施回到最初的状态。 Terraform 当然会智能地按照资源之间的依赖关系，以正确的顺序销毁资源。 在销毁资源之前，它会再次像 apply 命令一样检查当前的状态，并制定一个详细的删除计划。 All in One由于巨量的 Providers 和 Resources，Terraform 可以帮助您实现几乎所有主流的基础设施的配置和管理。当需要同时使用公司内部的私有云和多个公共云服务提供商时，Terraform 可以成为你的统一管理工具。一个 Terraform 搞定这一切，而不再需要学习每个云服务提供商的专有工具。同时得益于 Providers 的封装，无需再学习并掌握每个工具的 API 的使用方法。Terraform 屏蔽了底层的复杂性，让我们能够更专注于业务逻辑的实现，这太棒了不是吗？ 参考资料： 📺 Terraform课程-Terraform简介 Terraform – 从初级到高级 非常非常好的中文课程，恶魔老师有浅入深讲得非常好，强烈推荐！","link":"/2024/10/06/terraform_note_02/"},{"title":"Terraform 学习笔记（一）基础设施即代码 (IaC, Infrastructure as Code) 的概念及相关工具","text":"仅做个人学习笔记复习使用，如果侵权请联系。 前言在开始学习使用 Terraform 之前，首先需要了解什么是基础设施即代码（IaC, Infrastructure as Code）。 自动化之前的 DevOps 任务自动化尚未普及的时代，当编写完一个应用程序，想要部署它到服务器上，意味着要经历一系列繁琐的步骤。常常需要：准备服务器配置网络、创建路由表、安装必要的软件、配置这些软件。 比如为 Java 应用程序安装特定版本的 Java 环境、为应用程序配置数据库，以及执行一系列其他操作来确保服务器准备就绪，以便应用程序能够顺利的运行。 所有这些繁琐的任务通常由系统管理员手动完成，这不仅耗时耗力，需要更多的人力成本，而且容易出错。然而部署准备仅仅是开始之后的配置和维护同样的重要。可能还需要做：更新版本、部署应用程序的新版本、执行数据库备份升级、在服务器崩溃后恢复应用程序或更改网络配置等等各种各样的工作，这些工作同样需要手动完成。 自动化之后的 DevOps 任务好消息是不再需要手动的执行这些操作。通过基础设施及代码，可以实现整个流程的自动化，即 IaC: Infrastructure as Code。 什么是基础设施即代码一、概念基础设施记代码是一种方法，它通过编写和执行代码来自动化基础设施的配置和管理。这意味着系统管理员和运维团队的专业知识和经验被编码到各种程序或应用程序中，从而可以自动地执行上述所有的任务。 二、涉及到的工具基础设施及代码不仅仅是一个概念，它还有一系列的工具，比如 Ansible、Puppet、Terraform 和 CloudFormation 等等，这些工具可以用于不同的场景和任务。 可能会好奇为什么有这么多不同的工具，难道我们就不能只用一个基础设施记代码工具来完成所有的任务吗？实际上目前没有一个 IaC 工具能够从头到尾的完成上面所有的任务，每个工具都有其擅长的领域和特定的用途，因此通常需要组合使用两个或更多的工具来实现整个流程的自动化。 三、三个主要的任务类别（步骤）为了更好地理解这些工具的使用，我们可以将配置和管理任务大致分为三个类别（步骤）： 提供或创建基础设施。 比如：创建全新的服务器进行网络配置，创建负载均衡器以及在基础设施层面配置所有其他的内容。 对已提供的基础设施进行配置。 这一步涉及在服务器上安装应用程序和软件，并进行必要的配置。比如：准备将要部署的应用程序的基础设施（服务器环境），这可能包括安装 Java、数据库以及应用程序所需的其他的服务和进程。 应用程序的部署。 这是前面的所有任务的最终目的。 随着 Docker 容器技术的普及，上面的第二步和第三步也就是配置和部署应用程序的步骤，在一定程度上已经合并在一起了。因为使用 Docker 可以将应用程序及其所有的配置和所需的环境一起打包成一个容器镜像，配置已经打包在容器镜像里了。因此在第一步提供基础设施并安装 Docker 运行环境之后，只需要运行刀客容器即可，无需在服务器上进行过多的配置或安装额外的服务。 四、两个不同的阶段此外我们还需要区分初始设置和维护这两种阶段的不同： 初始设置阶段是：第一次提供和配置基础设施的过程。 提供或创建基础设置 配置基础设置 软件的初始安装 软件的初始配置 维护阶段则涉及：对基础设施的调整更改和优化，以及添加和删除服务器更改网络设置等等 调整基础设置 添加或删除服务器 更新软件 重新配置软件 五、IaC 工具的差异1、适合的任务类别的差异这是我们需要了解的、它们最重要的差别！ 在我们清楚任务类别和阶段的区别后，我们很容易就能意识到需要： 在不同阶段自动执行不同类别的任务。 组合使用两个或更多的工具来实现整个流程的自动化。 例如 Terraform 是一个专注于提供和管理基础设施的工具，但它也可以用于对基础设施上的应用程序进行初始化安装和配置。然而对于这些应用程序的进一步维护，Terraform 则可能不是最佳的选择。相比之下，Ansible、Puppet、和 CHEF 等工具更适用于配置和部署应用程序和之后对他们的管理任务，以及对于已经提供的基础设施的一些配置工作，但它们都不能用于服务器的初始配置。 一个常见的场景是：使用 Terraform 来提供和配置基础设施，然后使用 Ansible 来安装和部署应用程序。 2、工作原理差异 - 程序性和声明性 程序性：需要逐步执行所需的操作来达到目标的状态。 比如：先创建服务器，然后添加服务器等等。 声明性：只需要声明期望的最终状态，而工具将负责实现该状态。 比如：“我想要两台服务器”。 3、工作原理差异 - 可变基础设施与不可变基础设施 可变基础设施：顾名思义，创建的基础设置配置可以调整。 比如：在创建三台服务器后，编辑其中一台或多台服务器的网络配置。 可变基础设施：核心理念是任何基础设施的实例一旦创建之后，就成为只读的状态，不可对其进行任何的更改。 如果需要对基础设施进行更新或升级，唯一的方式是创建一批新的实例来替换旧的实例子。 4、其他的差别还有诸如代理和无代理、主节点和无主节点等等其他的差异。由于我们的目的暂时仅是学习 Terraform 这一种工具，因此不再做深入研究，如有需要请自行了解。 参考资料： 📺 什么是基础设施即代码? Terraform – 从初级到高级 非常非常好的中文课程，恶魔老师有浅入深讲得非常好，强烈推荐！","link":"/2024/10/06/terraform_note_01/"},{"title":"Terraform 学习笔记（三）安装 Terraform 和本地设置 Vultr 供应商并创建实例","text":"仅做个人学习笔记复习使用，如果侵权请联系。 前言虽然在 Mac 下安装 Terraform 基础结构即代码工具，并添加 AWS 云服务提供商中已经做了一次实践，但是还是想记录下从安装到实例部署到完整过程，以便之后切换至 Windows 开发环境时可以参考。这篇文章以 Vultr 云服务提供商为例，从下一篇开始会回到 AWS 云服务提供商。 方案概述官方文档：Install Terraform MacOS 系统 使用 Homebrew 等包管理工具安装（推荐） 下载 Terraform 的可执行文件并手动配置 Linux 系统 视发行系统使用 apt 或 yum 等包管理工具安装（推荐） 下载 Terraform 的可执行文件并手动配置 Windows 系统 使用 Chocolatey 等包管理工具安装 下载 Terraform 的可执行文件并手动配置（推荐） 后文以此安装方式为例。 下载 Terraform 的可执行文件 将下载的二进制文件解压到系统的 PATH 环境变量中 验证安装 配置 Vultr 供应商和相应的凭证 由于 AWS 云服务提供商的配置在之前已经记录过，因此这次尝试配置 Vultr 供应商。 部署基础设施 操作步骤由于 Linux 系统下的安装与 MacOS 类似，而 MacOS 下的安装在之前已经记录过，所以这里实操下 Windows 系统下的安装。选择对系统影响更小的可执行文件安装方式。 一、下载 Terraform 的可执行文件 官方下载地址：Windows 选择 64 位版本：之后会下载一个 zip 压缩包，解压到一个合适的目录即可，我这里解压到了桌面上：可执行的 terraform.exe 文件就在其中。 二、将下载的二进制文件解压到系统的 PATH 环境变量中此时直接在命令行中输入 terraform 会提示找不到命令，这是因为没有将其添加到系统的环境变量中。在 Windows 搜索处输入 PATH，点击 编辑系统环境变量： 在弹出的窗口中点击 环境变量： 在 系统变量 中找到 Path，点击 编辑： 添加你解压的 terraform.exe 文件所在的路径即可： 之后一路确定保存退出。 三、验证安装打开一个新的命令行窗口，输入 terraform -v，如果出现以下提示则说明安装成功： 1terraform -v 四、配置 Vultr 供应商和相应的凭证 官方文档：Vultr Provider 先去获取下 VULTR_API_KEY，这个 API 密钥可以在 Vultr 的控制台中找到： 操作步骤：Account -&gt; API -&gt; Enable API -&gt; View API Key直达链接：Vultr API Key 需要注意的是，同时需要配置允许访问密钥的 IP 白名单。 然后我们在本地新建一个 Terraform 的工作目录，之后在其中新建一个 main.tf 文件： 文件内容如下： Vultr Provider 实例配置文档：vultr_instanceVultr 实例 API 文档：Vultr APIVultr 实例可选的数据中心：RegionsVultr 实例可选的操作系统：OSVultr 实例可选的计划：List available plans in region 1234567891011121314151617181920212223242526terraform { required_providers { vultr = { source = &quot;vultr/vultr&quot; version = &quot;2.21.0&quot; } }}# Configure the Vultr Providerprovider &quot;vultr&quot; { # 刚刚获取的 API 密钥 api_key = &quot;&quot;QUKTBFAXXXXXXXXXXXXXXXXXXXQUSFXCFQ&quot;&quot; rate_limit = 100 retry_limit = 3}# 新建一个 Vultr 实例resource &quot;vultr_instance&quot; &quot;test_instance&quot; { # 计划选择共享 CPU 1 核 2GB 内存 plan = &quot;vc2-1c-2gb&quot; # 选择西雅图数据中心 region = &quot;sea&quot; # 系统选择 Ubuntu 22.04 LTS x64 os_id = 1743} 之后保存。 五、部署基础设施在命令行中进入到 main.tf 文件所在的目录，输入 terraform init 初始化配置： 1terraform init 然后使用 terraform plan 查看即将执行的操作： 1terraform plan 确定符合预期后，使用 terraform apply 应用配置进行实际部署： 1terraform apply 中间需要输入下 yes 进行确认，稍等片刻即可完成部署： 回到 Vultr 的控制台，可以看到新建的实例： 至此，Windows 下的安装、Vultr 供应商的配置和实例的创建都已经完成。 参考资料： Terraform课程-安装Terraform和本地设置 Terraform – 从初级到高级 非常非常好的中文课程，恶魔老师有浅入深讲得非常好，强烈推荐！ 在本地安装和配置Terraform","link":"/2024/10/07/terraform_note_03/"},{"title":"Terraform 学习笔记（四）创建 AWS 账户和 API 访问密钥","text":"仅做个人学习笔记复习使用，如果侵权请联系。 前言虽然在 Mac 下安装 Terraform 基础结构即代码工具，并添加 AWS 云服务提供商已经做过了一次完整的实践，但这个系列毕竟是一套完整的学习笔记，如果之后都是操作 AWS 资源而在这里缺少一篇注册和配置用户的文章，着实会有些奇怪。于是乎即使重复也再来一遍吧！BTW 如果你只是想实操并通过 Terraform 部署一些开源项目的话，直接参考上面的文章即可。 大致流程 注册 AWS 根用户 使用 AWS 根用户创建具有管理员权限的管理员用户 如果直接使用 AWS 根用户做后续操作的话，违背了 AWS 的最佳实践。 为管理员用户创建 API 访问密钥 操作步骤一、注册 AWS 根用户 官方文档：步骤 1：注册 AWS 账户 访问 Sign up for AWS 按流程操作即可，这里就不再赘述。 我们可以看下 AWS 的免费服务：亚马逊云服务免费体验中心除开新注册用户一年的免费 EC2 实例和 750 小时的 Lightsail 实例外，光是永久免费服务，类似 S3、Lambda、DynamoDB、API Gateway 等就已经能帮助我们做很多事情了：因此即使你不主要使用 AWS，也可以注册一个账号，偶尔用用这些免费服务来写一些小玩具。 二、使用 AWS 根用户创建具有管理员权限的管理员用户 因为根用户拥有最高权限，所以在平常的时候不建议使用它来进行登录和管理。AWS 最佳实践是为不同的用户（比如为您的组织中的人员）创建个人的 AWS 账户，包括您自己，之后用它们来管理资源。这可能与我们的日常习惯很不一样： 之后在这些个人用户访问 AWS 资源时，AWS Identity and Access Management (IAM) 服务会对用户进行身份验证和授权，以确保他们只能访问他们被授权的资源： 当我们使用注册完成的根用户登录 AWS 后，首先需要前往 IAM 控制面板： 点击右侧的 创建用户 按钮，输入用户名、选择 AdministratorAccess 权限，最后创建用户： 之后，我们就可以看到创建的用户了：不过现在，它还没有 API 访问密钥，我们需要为它创建一个。 三、为管理员用户创建 API 访问密钥点击刚刚创建的用户，进入用户详情页： 点击右侧 访问密钥 1 下方的 创建访问密钥 按钮，即可创建一个 API 访问密钥： 选择 其他 方案，跳过设置描述标签，然后创建并下载密钥： 文件中包含了 Access key ID 和 Secret access key： 访问密钥 (Access key ID)：AKIAXXXXXXXXXXXXXXWNH 秘密访问密钥 Secret access key(Secret access key)：xxxxxxXXXXXXxxxxXXXXXxxxXoo1AAbbccDDRg 保存好密钥，之后的 Terraform 配置文件中会用到。结束。 参考资料： Terraform课程-(实操)创建一个AWS帐户和一个AWS用户 Terraform – 从初级到高级 非常非常好的中文课程，恶魔老师有浅入深讲得非常好，强烈推荐！","link":"/2024/10/07/terraform_note_04/"},{"title":"日语翻译 - 商业文档 -「BLUE PROTOCOL」サービス終了のお知らせ","text":"蓝色协议 (BLUE PROTOCOL) 服务停止的通知。 来源：「BLUE PROTOCOL」運営チーム 链接：「BLUE PROTOCOL」サービス終了のお知らせ 🌟 单词： 日頃｜ひごろ⓪平日，素日，平常。 下岡｜しもおか エグゼクティブプロデューサー(executive producer) 执行制作人。 誠｜まこと⓪ 詫びる｜わびる⓪ キャンペーン｜きゃんぺーん③1. (campaign) 宣传活动，促销活动；2. 战役；战场服役；运动，竞选运动。 尽力｜じんりょく⓪① 報時｜ほうじ① 🌟 惯用句： 力及ばず｜ちからおよばず力不从心。 🌟 文法： 〜に就きまして（〜に関しまして） 「～に就（つ）きまして」和「～に関（かん）しまして」的意思都是“关于……”，可以让自己表述的主题更强明晰。 日頃より「BLUE PROTOCOL」の世界に足を運んでいただきありがとうございます。プロジェクトスカイブルー エグゼクティブプロデューサーの下岡です。 感谢大家一直以来在《蓝色协议》的世界中的游玩。我是“PROJECT SKY BLUE”注 ①的执行制作人下岡。 この度、ブループロトコルにつきましては、誠まことに勝手ながら2025年1月18日（土）にサービスを終了させていただくことになりました。プレイヤーの皆様には突然のお知らせとなりましたこと、深くお詫び申し上げます。 这次，关于蓝色协议，真诚地、非常抱歉地请让我们决定在 2025 年 1 月 18 日（周六）结束它的服务。让各位玩家突然知道这个消息，我深表歉意。 アニメの世界に入り込んだような体験を届けたい。 我们想传递沉静于动漫的世界的体验。 一人一人のプレイヤーがアニメの主人公として冒険を楽しめる世界を生み出すことを目指しプロジェクトはチャレンジをしてまいりました。 我们以创造出让每一个玩家都作为动漫的主人公进行冒险的有趣的世界为目标，进行了挑战。 発表以来より多くの期待を寄せていただき、長い方だと2019年のCαTの初報時から、さまざまな形でプレイ・応援をいただいてきましたが、我々の力及ばず、今後皆様に満足いただけるサービスを継続けいぞく的に行うことが困難であると判断しサービス終了の決定をいたしました。 我们收到了比发布以来更多的期待，从 2019 年 CαT 的首次报道以来的长时间里，收到了各式各样的支持活动。但是我们力不能及，判断为了满足各位而继续服务的行为很困难，才做了停止服务的决定。 本日以降いこう、終了となる1月18日まで新規ストーリーを含むコンテンツのアップデートを行わせていただき、プレイ期間の最後までプレイヤーの皆様に楽しんでいただけるよう尽力じんりょくさせていただきますので、今後こんごともよろしくお願いいたします。 今天以后，在 1 月 18 日的服务中止前我们还进行包含新故事的内容更新，尽力让各位玩家在游玩期间的最后也享受到乐趣，也请大家今后多多关照。 主なサービス終了までのスケジュールにつきましては以下をご確認ください。 请大家确认如下，关于直到主服务停止为止的日程表。 ※本お知らせ内でのご案内内容以外にもイベント、キャンペーンの実施を予定しております。詳細はアップデート当日の公式サイトをご確認ください。 我们也预定实施本通知以外的活动和促销。详细信息请确认更新当天的官方网站（发布的信息）。 注 ①：PROJECT SKY BLUE：是由株式会社万代南梦宫在线和株式会社万代南梦宫工作室共同打造的，从日本面向世界的全新娱乐 IP。是以创造内容为目的的企划、制作、开发的共同项目团队。","link":"/2024/09/01/translate_business_blue_protocol_news_506/"},{"title":"日语翻译 - 商业文档 - 佐川急便についてのご挨拶","text":"佐川急便的致辞 来源：SG 链接：佐川急便についてのご挨拶 🌟 单词： 真｜まこと 物流｜ぶつりゅう⓪ ソリューションパートナー(solution partner) 解决方案提供者。 預かり｜あずかり⓪④1. 收存，保管；2. 存条，存单；3. 未解决，保留；4. 保管看家。 ステークホルダー｜すてーくほるだー⑤(stakeholder) 企业的利害相关方。 多様｜たよう⓪ 迅速｜じんそく⓪ 取締役｜とりしまりやく⓪⑤董事。 ホールディングス｜ほーるでぃんぐす⑥(holdings) 持株会社，控股或控股集团，金融控股集团。 ビジョン｜びじょん(vision) 理想，想象（想象力）；梦幻，幻想（幻影）愿景。 掲げる｜かかげる⓪ 図る｜はかる②图谋，策划，谋求。 あらゆる全部，所有。 越境｜えっきょう⓪ 合意｜ごうい⓪ 持続｜じぞく⓪ 横断｜おうだん⓪ 潜在的｜せんざいてき⓪ プロデュース｜ぷろでゅーす③(produce) 生产，提供。 保全｜ほぜん⓪ 歩み｜あゆみ③ 運輸｜うんゆ① ロジスティクス｜ろじすてぃくす⓪(logistics) 物流，后勤。 シナジー｜しなじー①(synergy) 共同作用，相乘作用，协同作用。 最適化｜さいてきか⓪最佳化，最优化。 「お客さまの発展に貢献する『真の物流ソリューションパートナー』」 为了客户的发展做贡献的“真正的物流解决方案合作伙伴” 1957年、京都－大阪間で1個のお荷物をお届けすることからスタートした佐川急便は、以来、「飛脚の精神（こころ）」を受け継ぎながら、お預かりした大切なお荷物を「お客さまの心とともに」お届けしてまいりました。 1957 年在京都和大阪之间运送第一个货物开始而由此开始的佐川急便，一边传承着“飞脚的精神”，一边将被寄托的重要的货物带着“客户的心情”一同运送。 現在、私たちを取り巻く社会はこれまでにないスピードで変化し、ステークホルダーから求められることはより高度こうど化・多様たよう化しております。多くの企業では経営戦略の実現をサポートする大きな役割として物流の改革が注目されており、社会環境への迅速な対応力と的確な提案力が求められております。 现在，我们所处的社会，在以迄今为止没有过的高速变化，利益相关方对我们的要求也正在变得更加高度化和多样化。（我们由于提供）众多的企业支撑经营战略实现的重要角色的物流改革而备受瞩目，同时也被要求（要有）对社会环境的迅速的反应能力，和实实在在的提案能力。 ＳＧホールディングスグループでは、このような課題や社会背景に対処すべく、SGHビジョン2030「Grow the new Story. ～新しい物流で、新しい社会を、共に育む。～」を新たに掲げるかかげるとともに、佐川急便では「お客さまの発展に貢献する『真の物流ソリューションパートナー』」を基本方針として2022年4月より新たな中期経営計画「SGH Story 2024」をスタートさせました。 随着 SG 控股集团为了应付处理这样的问题和社会背景，而新揭晓的 SGH 2030 的愿景“书写新的故事通过新的物流，共同培育新的社会”，佐川急便（也）将“助力客户发展的‘真正的物流解决方案合作伙伴’”作为基本方针，在 2022 年 4 月开始了新的中期经营计划“SGH 故事 2024”。 今後、さらに高度化・多様化するお客さまのニーズや社会課題の解決に向けて総合物流ソリューションの高度化を図りはかります。あらゆる「運ぶ」をプロデュースする「TMS（トランスポーテーション・マネジメント・システム）」、越境えっきょうECをシームレスに手掛ける「国際海外向け物流」などの各種サービスの発展、強化、また、世界的に合意ごういされた持続じぞく可能な開発目標「SDGs」に対しても、私たちはあらゆる取り組みを通じて貢献していきたいと考えております。これらをグループ横断おうだん型けいの先進的ロジスティクス・プロジェクトチーム「ＧＯＡＬ®」が、グループ各社とのシナジーによりお客さまの潜在的せんざいてきニーズまでに対応することで物流の最適化を実現いたします。 今后，为了高度化、多样化的客户的使用和社会问题的解决，我们会致力于提高综合物流解决方案的水平。对于发展和加强提供所有运送服务的 TMS、主要着手跨境业务的“国际海外向物流”等各种服务，以及全球商定的可持续发展为目标的“SDGs”，我们也想尽所有的努力做贡献。跨集团的先进物流项目团队“GOAL®”，通过借由各公司的同步满足客户的潜在需求，实现物流的最优化。 これからも運輸うんゆ・物流企業の社会的責任として、安全を第一に考えるとともに、環境保全や社会貢献活動に力を入れ、持続可能な成長を実現するために、すべてのステークホルダーの皆さまとともに歩みあゆみ続けて参りたいと考えております。 作为运输物流企业的社会责任，今后为了实现“不止安全第一，还要致力于环境保护和社会贡献活动，实现持续发展的可能。”（这一目标），我想和利益相关方的各位一起继续前进。 佐川急便株式会社代表取締役社長本村 正秀","link":"/2024/08/26/translate_business_sgs_company_message/"},{"title":"日语翻译 - 商业文档 - ＳＧホールディングスグループ　企業理念","text":"SG 控股集团的企业理念 来源：SG 链接：ＳＧホールディングスグループ 企業理念 🌟 单词： 共感｜きょうかん⓪ 宣言｜せんげん③ 役員｜やくいん②1. 干部，干事；2. 董事。 徹する｜てっする⓪③ 競争｜きょうそう⓪ 創出｜そうしゅつ⓪ 担う｜になう② 人権｜じんけん⓪ 尊重｜そんちょう⓪ 遵守｜じゅんしゅ① 倫理観｜りんりかん③ 優れた｜すぐれた重要的。 努める｜つとめる③ 必須｜ひっす⓪ 固より｜もとより①原来根本当然固然不用说。 株主｜かぶぬし②⓪股东。 憲章｜けんしょう⓪ 率先垂範｜そっせんすいはん⑤率先示范，充当表率。 則る｜のっとる③效法，遵守，根据。 🌟 惯用句： いかなる時｜いかなるとき任何时候 ＳＧホールディングスグループ 行動憲章 SG 控股集团的企业理念 社会の信頼と共感を得るための宣言 为了获得社会的信任与共鸣的宣言。 ＳＧホールディングスグループは、公正な競争きょうそうを通じて付加価値を創出そうしゅつし、経済社会の発展を担うになうとともに、広く社会にとって有用な企業を目指します。そのためＳＧホールディングスグループのすべての役員および従業員じゅうぎょういんは、いかなるときでも一致団結して、ステークホルダー経営に徹してっし、国の内外において、人権じんけんを尊重そんちょうし、関係法令、国際ルールおよびその精神を遵守じゅんしゅしつつ、持続可能な社会の創造に向けて、次の8原則げんそくと経営姿勢に基づき、高い倫理観りんりかんをもって社会的責任を果たします。 SG 控股集团目标是：通过公平的竞争创造附加价值，承担经济社会的发展的同时，成为对社会有用的企业。为此 SG 控股集团所有管理人员和员工，任何时候都团结一致，贯彻经营相关方的利益，在国内外尊重人权、遵守相关法律和国际规则及精神，为了创造可持续发展的社会，（我们将）基于以下的 8 项原则和经营理念，带有高度的道德观履行社会责任。 お客さまの期待とともに 伴随着客人的期待 1.私たちは、有用で利便性に優れたすぐれた商品を開発、提供し、サービスレベルの持続的な向上を目指すことにより、満足と信頼を獲得かくとくします。 1.我们将通过开发并提供有用的、便利的优良商品（服务），和持续提升服务水平来获得用户的满意和信赖。 従業員の期待とともに 伴随着员工的期待 2.私たちは、従業員の多様性、人格じんかく、個性こせいを尊重するとともに、安全で働きやすい職場づくりに努めつとめ、ゆとりと豊かさゆたかさの実現を目指します。 2.我们将尊重员工的多样性、任何和个性，并致力于打造安全并且轻松的工作环境，同时目标提升（他们的）薪资水平。 地域社会の期待とともに 伴随着地方社会的期待 3.私たちは、安全と環境への取り組みは当社グループの存在と活動に必須の要件として、主体的しゅたいてきに行動します。 3.我们将把保证安全和环境作为本集团存在和活动的必要条件，积极主动地进行活动。 4.私たちは、「良きよき企業市民」として、積極的に社会貢献活動を行います。 4.我们将作为“优良企业”，积极地进行对社会有贡献的活动。 5.私たちは、国際的な事業活動においては、各国・地域の法律の遵守、人権を含む各種の国際規範の尊重はもとより、文化や慣習かんしゅう等、ステークホルダーに配慮した&lt;経営を行い、当該とうがい国・地域の発展に貢献します。 5.我们在执行国际地事业活动中，不仅遵守各国、地区的法律，尊重包含人权在内的的各种国际规范，而且在文化和习惯等方面，开展兼顾利益相关者的经营，为该国、地区的发展做贡献。 株主・取引先の期待とともに 伴随着股东、客户（交易方）的期待 6.私たちは、株主かぶぬしはもとより、広く社会とのコミュニケーションを図り、企業情報を積極的かつ公正に開示かいじします。また、個人情報・顧客情報をはじめとする各種情報の保護ほご・管理を徹底します。 6.我们谋求与社会的交流，不仅（对）股东、（也对社会）积极地公正地公开企业信息。并且，我们还贯彻始终将保护和管理个人信息、客户信息放在首位。 経営姿勢 经营姿态 1.私たち経営者は、本憲章けんしょうの精神の実現が自らの役割であることを認識し、率先そっせん垂範すいはんの上、グループ内にその徹底を図るとともに取引先にも実現を促しうながします。また、さまざまなステークホルダーの期待に応える事業活動を推進し、実効性のある社内体制を確立します。 我们经营者，在认识到为了实现本宪章的精神需要发挥自己的作用、充当表率的基础之后，在组织内谋求贯彻落实的同时，也敦促客户实现（宪章的精神）。并且，推进为了回应众多利益相关方期待的事业活动，确立有实效性的公司体制。 2.私たち経営者は、本憲章に反するような事態が発生したときには、自らが問題解決にあたる姿勢を内外に明らかにし、原因究明と再発防止に努めるとともに、社会への迅速かつ的確な情報の公開を行います。 在发生违反本宪章的事情的时候，我们经营者会向内外明确在自己解决问题的姿态，不仅是努力查明原因和防止再犯，还会向社会公开及时且准确的信息。 ＳＧホールディングスグループ 倫理・行動規範 SG 控股集团的道德行动准则 私たちは、「ＳＧホールディングスグループ行動憲章」を具体的に表現した本倫理・行動規範に則り行動します。 我们遵守该具体化表现“SG 控股集团的行动章程”的道德行动准则。 1.お客さまの期待とともに、私たちはお互いたがいに発展を続けます。 在客人的期待下，我们将继续互相发展（进步）。 2.従業員の期待とともに、私たちはお互いに明るい職場をつくります。 在员工的期待下，我们将互相创造光明的职场。 3.地域社会の期待とともに、私たちはお互いに歩み続けます。 在地区社会的期待下，我们将继续互相走下去。 4.株主・取引先の期待とともに、私たちはお互いに信頼を築ききずきます。 在股东和交易方的期待下，我们将互相构建信赖。","link":"/2024/08/27/translate_business_sgs_company_philosophy/"},{"title":"日语翻译 - N1 阅读真题 - 2014&#x2F;12 問題 9","text":"2014 年 12 月 N1 真题，阅读问题 9。 来源：MOJi 日期：2024-03-25 15:00 链接：【JLPT阅读真题精析-N1】第3期 🌟 单词： 正体｜しょうたい①1. 原形，真面目，本来面目；2. 意识，意志。 噛み切れない｜かみきれない咬不动。 膨らむ｜ふくらむ⓪1. 鼓起，膨胀，凸起；2. 涨大，膨胀规模变大。 ⭐ 都合｜つごう⓪① 危機感｜ききかん② 湧く｜わく⓪ 見極める｜みきわめる③看清，看透，弄清。 講じる｜こうじる⓪③1. 讲说，讲授；2. 谋求，寻求，想出对策等；3. 讲和，和解。 不安は、正体がつかみきれないときほど膨らんふくらんでいく。長く引きずる。 不安这种东西，越是在找不到问题核心的时候越是会膨胀。并持续很长时间。 人間だれでも、自分に都合の悪いこと、恐ろしいことは考えたくない。そういう心理が働くはたらくから、無意識のうちに問題をあいまいにして解決を保留にする。そうして結局、いつまでも不安をダラダラと抱え続けてしまう。 无论是谁，都不想考虑自己不擅长的东西、害怕的东西。由于这种心理活动，无意识保留了将问题随便应付解决（的这种处理方式），这样的结果是，无论到何时都拖拖拉拉地持续焦虑。 逆に自分の何がどのように不安なのか、不安に思う必要があるのかどうかを把握すれば、それだけで不安は減る。 反而是弄清楚自己为什么不安、是否有必要不安的话，仅仅通过这个就能减少不安。 不安の正体が明確になって、これは何かしなくてはまずいと認識されれば、それは「危機感ききかん」になる。危機感は不安と違う。危機感をもてば、行動を起こそうという意欲が湧くわく。さらに情報を集めて、行動計画をたてようとする。やるべきことが明確になる。だからスタートが切れるのだ。 明确了不安的原因，将它认识为不做什么就麻烦了的话，它就变成了“危机感”。危机感和焦虑不安不同。带有危机感的话，就会涌现行动起来的欲望（动力）。更进一步开始收集信息，确立行动计划。要做的事情变得明确。因此彻底地开始（行动、改变）。 問題は鍵となる不安は何なのかということだ。 问题的关键是，不安焦虑究竟是什么。 様々な不安の中から、それを特定して意識する。その不安に、思い切り光を当てて自分で正体を見極められれば、次にどうすればいいかの対策も講じられる。 从各种各样的不安中，要将（单个不安）特定化。如果自己能正中要害地彻底看清问题本质的话，就能谋求下一步该做什么了。 （中略）不安には、しばらく保留しておいても大丈夫な不安もある。それがわかった瞬間、不安は、また少し減る。 对于不安，也有稍微保留一段时间也没关系的不安。理解这个道理的瞬间，不安也会稍微减少一些。 こうして、自分が何をやらなければいけないかが見えてくる。やる気が出てくる。動く気になる。不安の解決策を考えながら、夢が膨らんでくることもある。 这么做以后，就能逐渐看清自己必须要做什么了，干劲会变成行动的动力。考虑不安的解决方法的同时，梦想也会逐渐变大。","link":"/2024/09/30/translate_exam_n1_2014_12_9/"},{"title":"日语翻译 - N1 阅读真题 - 2022&#x2F;12 問題 9","text":"2022 年 12 月 N1 真题，阅读问题 9。 来源：MOJi 日期：2024-03-18 15:01 链接：【JLPT阅读真题精析-N1】第2期 🌟 单词： 年商｜ねんしょう一年的销售额。 取捨｜しゅしゃ① 殊更｜ことさら⓪1. 故意，特意；2. 特别。 力点｜りきてん⓪③ 嗅ぐ｜かぐ⓪ 汚染｜おせん⓪ 付随｜ふずい⓪ 歪む｜ゆがむ 無色｜むしょく① 🌟 文法： 必ずしも｜かならずしも不一定，后接否定表达。 必ずしもそうとはかぎらない。也不一定是那样。金持ちが必ずしも幸福ではない。有钱也未必会幸福。 企業Aと企業Bがあり、ある契約をそのどちらと取り交わすべきか考えるときに、A社は資本金1000万円、B社は資本金１億円であるという情報は、おそらく重要な情報の一つであると想定されるが、すべてではない。 有 A 公司和 B 公司两家公司，考虑与其中哪一个签订合同的时候，认为“A 公司有 1000 万日元的资金、B 公司有 1 亿日元的资金”这样的情报恐怕是重要的信息中的一个，然而完全不是这样。 従業員数、年商、営業継続年数、支社数、支店数、などなどのうちから、意思決定者が、意思決定の方針に基づいて重要な情報を取捨しゅしゃ選択しなければならないだろう。 决策者一定会从员工数、年销售额、持续经营年数、分公司数、分店数等等中，基于决策的方针将重要的进行进行取舍选择吧。 そのとき、ことさらにいくつかの情報に力点りきてんを置く報告書があげられたときに、意思決定者（経営者）はそこに存在する「意図いと」を充分に嗅ぎかぎ取らなくてはならない。つまり、汚染おせんされている可能性があるということである。ここで、報告された情報がすべて確実な事実であったとしても汚染は生じている可能性があるという点に注意が必要である。 在那时，决策者在收到着力记录多个特意信息的报告书的时候，一定要充分嗅探出其中存在的“意图”。总之，有被污染（误导）的可能性。在这里，必须注意：即使报告的信息全部是真实的实际情况，也有产生污染（误导）的可能性。 したがって、情報汚染とは、ある情報に、本来想定しているもの以外の何かが付随ふずいしていて、それによってその情報の理解が歪むゆがむことをいう。その何かとは、その情報をもたらした側の意図である。 因此，信息污染可以说是：在那个信息上，附带上原本的想定的信息以外的其他东西，通过这种方式，歪曲对信息的理解。要说这种东西是什么，可以说是带来这个信息的人的意图。 この世界に「データのみで構成されていて、そこに意図の混入が認められない」という意味での無色むしょく透明な情報など存在しない。 这个世界上不存在“只由数据构成、绝不掺杂（自我）意图”的这样的完全透明的信息。 どのような情報であっても、意図という色で染められている。そして、重要なのはそれが必ずしも汚染ではないという点である。 无论是怎样的信息，都在被意图所修饰。然后，重要的是其中不一定被污染的信息。 意図が混入するのは当然のことであり、すべての情報には意図が混入しているのであるから、それだけでもってそれを汚染とまでは呼べない。それが汚染となるのは、その情報に含まれる「意図」によって、その情報の本質部分である「データ」の理解が歪められるからである。 （信息）混入意图这件事是当然的，也不能因为所有的情报都混入意图，就说（信息）被污染了。污染这件事情是：因为信息所含的“意图”，这个信息中本质数据的理解被歪曲了。","link":"/2024/09/26/translate_exam_n1_2022_12_9/"},{"title":"日语翻译 - N1 阅读真题 - 2022&#x2F;12 問題 12","text":"“保持原原本本的自己，就已经足够有个性了。” 2022 年 12 月 N1 真题，阅读问题 12。 来源：MOJi 日期：2024-03-18 15:00 链接：【JLPT阅读真题精析-N1】第1期 🌟 单词： 当て嵌める｜あてはめる④1. 适用，应用，套用。 青年期｜せいねんき③ 仮に｜かりに⓪1. 暂时；2. 假设。 挫折｜ざせつ⓪ 証｜あかし⓪ 模索｜もさく⓪ 装う｜よそう② 発揮｜はっき⓪ いじける｜いじける⓪1. 畏缩，气馁，无精打采；2. 不开朗，乖僻，没有干劲，消极，怯懦。 気楽｜きらく⓪1. 舒畅，舒适，舒服，舒坦；2. 无挂虑，无顾虑，舒心，无忧无虑，坦然。 以下は、十代の若者に向けて書かれた文章である。 下面是，面向 10 来岁的年轻人写的文章。 だれでも、自分が自分であることを望み、個性的であろうと願っている。そしてその一方では、自分が他のみんなと違った、自分であることを恐れている。 无论是谁，都希望自己是自己，希望自己是由个性的。然而另一方面，又害怕自己和别人不同、自己（太）有个性了。 本当は、「個性的」であろうと思って、個性的になれるものでもない。それはたいてい、「個性的」といわれる一つの型に、自分をあてはめていることだったりする。人間にとっては、「個性的であれ」などと言われても、どうしてよいかわからないものであって、「個性的」とよばれる型を持ったほうが楽なのだ。しかしそれは、本当に個性的なわけではない。 实际上，想着去“有个性”，并非就能够变得有个性。大体是，将自己套进被成为“有个性”的其中一个模板。作为人类，虽然被说“有点个性！”之类的，但实际上并不知道做什么才好。如果有一个被成为“有个性”的目标就更轻松了。然而实际上，这并非是真正的有个性。 それでも、青年期せいねんきに向けて、個性的であろうと試みることは、よいことだ。かりにそれが、一つの型にすぎなくても、あるいは、個性的であろうとして挫折ざせつしたり、個性的であることから逃避することも含めて、自分にとって個性とはと、考えるのはよいことだ。それは、自分が自分であることの、あかし証でもある。 不过，尝试去变得有个性对于（迈入）青年期是一件好事。哪怕（追寻的“有个性”）不过只是其中一种模板。换言之，对于自己个性的思考，包含变得有个性的途中遭遇挫折、以及对自己个性的逃避，是有益的。这也是，证明自己是自己的一个证据。 そこでは、ときに悩むことがあったり、どうしたら個性的な人間になれるかと、模索もさくすることもあるかもしれない。それはじつは、「個性的」であること以上に、自分というものを意識していく、一つの過程である。そうした意味では、「個性的」であるかどうかなんて、本当はたいしたことではなくて、自分というものが確立していくことが、大事なこととも言える。 在这件事上，有时会有烦恼，有时也要摸索怎样才能成为有个性的人。这实际上，是超过“有个性”的这件事情、意识到自我的一个过程。这也意味着，可以说是不是“有个性”，真的不是了不起的事情，反而确立自我这件事情，才是重要的事情。 そしてじつは、個性というものは、人間のひとりひとりに備わったもので、その個性がありのままに出ていることが、本当の意味で個性的である。むしろ、本当の自分が出せないから、没ぼつ個性的にもなるのだ。 实际上，个性这种东西，是每个人都具备的东西，将这些个性原原本本地展现出来，才是真正的有个性。反过来说，展现不出真正的自己，才是没有个性的。 もちろん、人間はまわりの社会を気にするものであって、自分をよそおう装うことも含めてしか、社会のなかで存在できない。無理につっぱって、自分のよそおいを捨てようとしても、捨てきれるものではない。そうした、社会とのかかわりも含めて、自分というものはある。 当然，人如果不在意自己所处的社会、装饰自己，就没法在社会上生存。就算彻底逞强地抛弃自己的伪装，也无法真正做到。像这样的与社会的连接，也是自我的一部分。 たいていの場合、つっぱったり、いじけたりしていては、自分の個性は発揮できない。つっぱるまいとするのが一種のつっぱりだったり、いじけまいとしてそのことにいじけり、なんてことまで問題にしだすと、ちょっと言葉の遊びみたいになるが、ま、そうしたことまで含めて、気楽に自分であるようにしなくては、本当の意味で個性的にはなれないものだ。 大多数情况下，逞强、气馁都无法发挥自己的个性。不打算不逞强也是一种逞强，不准备不气馁有时也会气馁，虽然把话说到这个份上，看起来有点像文字游戏，但把这些一起考虑进去，轻松惬意地让自己成为自己，才能变得真正意义上的有个性。 そして、ありのままの自分を出すことへの不安が、「個性的」を一つの型にしたり、あるいはそうした型から逃げる道へ向かわせたりもする。 之后，而对展现原原本本自己的不安，会将“有个性”等同于某一个模板，或者指引我们逃离那个模板。 それでも結局、自分とはありのままの自分しかない。それを自覚したとき、きみは個性的なきみになる。 即便如此，结果自我也不过是原原本本的自己。意识到这件事情的时候，你就会变成有个性的你。","link":"/2024/09/25/translate_exam_n1_2022_12_12/"},{"title":"日语翻译 - 新闻 - 声優の田中敦子さん死去、61歳　アニメ「攻殻機動隊」草薙素子役などで活躍、息子で声優の田中光と所属事務所が公表","text":"声优田中敦子女士去世，享年 61 岁，因为给动漫《攻壳机动队》中的草薙素子配音而出名，消息由同样身为声优的儿子田中光与所属的事务所发布 来源：中日 日期：2024-08-20 21:17 链接：声優の田中敦子さん死去、61歳 アニメ「攻殻機動隊」草薙素子役などで活躍、息子で声優の田中光と所属事務所が公表 🌟 单词： 声優｜せいゆう⓪ 前田敦子｜まえだあつこ 攻殻機動隊｜こうかくきどうたい 草薙素子｜くさなぎもとこ 死去｜しきょ①② 所属｜しょぞく⓪ 投稿｜とうこう⓪ 実母｜じつぼ⓪① 永眠｜えいみん⓪ お茶目｜おちゃめ⓪ 伏せる｜ふせる② 闘病｜とうびょう①和疾病作斗争。 凛々｜りんりん1. 寒冷；2. 害怕；3. 充满勇气。 ちょっぴり｜ちょっぴり③一点，有点，少许。 吹き替え｜ふきかえ⓪ 名探偵｜めいたんてい 呪術廻戦｜じゅじゅつかいせん 声優の田中敦子さんが２０日、亡くなったことが分かった。６１歳だった。息子で声優の田中光と所属事務所が同日、公表した。 已知晓声优田中敦子女士去世的消息，享年 61 岁。消息由同样身为声优的儿子田中光与所属的事务所在当天发布。 田中光は自身のＸ（旧ツイッター）で「いつもお世話になっている皆様へ」と題したコメントを投稿。「令和６年８月２０日、私の実母であります声優田中敦子が永眠いたしました」と報告。「本人の意向により具体的な病名は伏せさせていただきますが、約１年に及ぶ闘病生活も含め、真面目で凜々しく、ちょっぴりお茶目な、田中敦子らしい人生だったように思います。こんなに自慢の母を持つことができ、本当に幸せです」などとつづった。 田中光先生在自己的 X 平台发布了题为《给一直以来关照我的各位》的帖子，通知：“令和 6 年 8 月 20 日，我的母亲同样也是声优的前田敦子女士永远长眠了。”，同时还写下了：“请允许我按照本人的意向隐瞒具体的病名。（她的一生）包括与病魔斗争的一年，严肃认真充满勇气（凛然），有时又有点孩子气，是有田中敦子女士风范的一生。有这样让人骄傲的母亲，我非常辛福。”。 田中敦子さんは多くの吹き替えを担当。アニメ「攻殻機動隊こうかくきどうたい」の草薙素子くさなぎもとこ役をはじめ、「名探偵めいたんていコナン」のメアリー・世良せら、「呪術廻戦じゅじゅつかいせん」の花御はなみ役などで知られる。 田中敦子女士负责了众多配音。从动漫《攻壳机动队》中的草薙素子作为开始，之后是《名侦探柯南》中的玛丽世良，还有《咒术回战》中的花御等等，以这些角色出名。","link":"/2024/08/21/translate_news_chunichi_946392/"},{"title":"日语翻译 - 新闻 -「山形と秋田で記録的大雨 東北日本海側 あすから再び大雨見込み」（第一部分）","text":"山形县和秋田县创纪录的大雨，预计东北日本沿海从明天开始会再次下大雨 来源：NHK 日期：2024-07-26 20:08 链接：山形と秋田で記録的大雨 東北日本海側 あすから再び大雨見込み 記録的な大雨となった山形県と秋田県では雨は弱まっているものの、東北とうほくの日本海側を中心に 27 日の午後以降、30 日火曜日ごろにかけて長期間ちょうきかん、大雨となる見込みです。 虽然在山形县和秋田县创下纪录的大雨，已经在变弱了，但是以东北的日本海沿岸为中心，从 27 日的下午到 30 号周二左右的长时间内，预计会下大雨。 大雨になった地域ちいきでは少しの雨でも災害の危険度が高まるおそれがあり川の氾濫はんらんや浸水しんすい、土砂災害に厳重げんじゅうな警戒けいかいを続けてください。それ以外の地域でも 26 日のうちに大雨への備えそなえを再確認するようにしてください。 在下大雨的地区，即使是一点小雨也会导致增加灾害的危险度，请对河流的泛滥、浸水和泥石流灾害继续进行严格的警戒。即使是除此以外的地区，也请在 26 日之内再确认应对大雨的准备工作。 気象庁きしょうちょうによりますと、梅雨つゆ前線の活動が活発になった影響で山形県や秋田県では記録的な大雨となり、24 時間に降った雨の量は山形県の新庄市しんじょうしで 389 ミリ、真室川町まむろがわまちで 384 ミリ、酒田市さかたしで 289 ミリとなっています。 根据气象厅的描述，受到梅雨前线的活动活跃的影响，山形县和秋田县已经下了创纪录的大雨，24 小时的降雨量：山形县的新庄市为 389 毫米、真室川小镇为 384 毫米、酒田市为 289 毫米。 また、48 時間に降った雨の量は秋田県の由利本荘市ゆりほんじょうし東由利ひがしゆりで 275 ミリ、湯沢市ゆざわしで 246.5 ミリと多いところでは平年の 7 月 1 か月分の 1.7 倍余りに達していて、いずれも気象庁が統計を取り始めてから最も多くなりました。 然后、48 小时的降雨量为：秋田县的「由利本荘市」的「東由利」为 275 毫米、「湯沢市」为 246.5 毫米，多数地方都达到了往年的 7 月的降雨量的 1.7 倍，无论是那个地区都达到了气象厅有记录以来的降雨量记录。 25 日の昼すぎと夜遅くの 2 度にわたって大雨の特別警報が発表された山形県では、最上川さいじょうがわ、鮭川さけがわ、日向川ひなたがわが氾濫したほか、秋田県では子吉川こよしがわが氾濫しました。 25 日午后和深夜，2 次发表了大雨的特别警报的山形县，「最上川」、「鮭川」、「日向川」都发生了泛滥，除此之外秋田县的「子吉川」也发生了泛滥。 国土交通省のまとめによりますと、26 日午後 2 時現在、秋田県の 7 か所で川の堤防ていぼうが決壊けっかいしたということです。 根据国土交通省的统计，截止现在 26 日午后的 2 点，秋田县的 7 个地方的河流发生了决堤。 また、山形県では川の水位の高い状況が続いているほか、土砂災害警戒情報が発表されている地域もあり、土砂災害の危険性も非常に高くなっています。 然后、除了山形县的河流水位还在持续高涨之外，还有一些地区发布了泥石流灾害警戒信息，泥石流灾害的危险性也在变得非常高。 東北 27 日午後～ 30 日ごろ 長く大雨の見通し 东北地区，预计 27 日下午到 30 日左右会下长时间的大雨 今後の見通しです。 之后是往后的预测。 東北の雨はいったん弱まっていますが、前線に向かって暖かく湿ったしめった空気が流れ込むため、27 日午後から再び雨が強まって日本海側を中心に断続的だんぞくてきに激しい雨が降ると予想されています。 虽然东北地区的雨已经开始变弱了，但是由于温暖潮湿的空气流向锋面，预计从 27 日下午开始雨势会再次变强，以日本海沿岸为中心出现间歇性的暴雨天气。 27 日夕方までの 24 時間に降る雨の量は、東北の多いところで 100 ミリと予想され、その後、28 日日曜日の夕方までの 24 時間にはいずれも多いところで、東北の日本海側で 200 ミリ、太平洋たいへいよう側で 150 ミリの大雨になる見込みです。 预测到 27 日傍晚为止的 24 小时的降雨量，东北地区最多的地方是 100 毫米，在这之后到 28 日星期日的傍晚为止的 24 小时的降雨量，预计最多的地区将在东北的日本海沿岸为 200 毫米，和太平洋沿岸为 150 毫米。 その後も今月 30 日の火曜日ごろにかけて長期間、大雨になるおそれがあります。 在这之后直到本月 30 日的周二为止的长时间内，仍然下大雨的可能性。 下一部分：日语翻译 - 新闻 -「山形と秋田で記録的大雨 東北日本海側 あすから再び大雨見込み」（第二部分）","link":"/2024/07/26/translate_news_nhk_20240726_k10014524291000_1/"},{"title":"日语翻译 - 新闻 -「山形と秋田で記録的大雨 東北日本海側 あすから再び大雨見込み」（第二部分）","text":"山形县和秋田县创纪录的大雨，预计东北日本沿海从明天开始会再次下大雨 来源：NHK 日期：2024-07-26 20:08 链接：山形と秋田で記録的大雨 東北日本海側 あすから再び大雨見込み 上一部分：日语翻译 - 新闻 -「山形と秋田で記録的大雨 東北日本海側 あすから再び大雨見込み」（第一部分） 被災地域だけでなくほかの地域も大雨 并不只有受灾地区，其他地区也有大雨 これまでの雨で川の堤防が傷んいたんだり地盤じばんが緩んゆるんだりしている地域では少しの雨でも災害の危険度が高まるおそれがあります。川の氾濫や浸水、土砂災害に厳重な警戒を続けてください。 由于至今为止的雨，导致河流的堤坝受损、地势变得平缓，这些地方即使是少量的雨水也有导致灾害危险度上升的风险。请继续对河流的泛滥、浸水和泥石流灾害保持严格的警戒。 また、前線や低気圧ていきあつの位置が変わることから今回とは別の場所で大雨になる可能性もあります。 还有、由于锋面和低气压的位置改变，这次其他的地方也有下大雨的可能性。 東北の日本海側を中心に、26日のうちにハザードマップを確認して何をきっかけに避難するかなど、大雨への備えを再確認するようにしてください。 以东北的日本海沿岸为中心，请在 26 日之内确认灾害地图，然后（决定）以什么作为契机进行避难等，（同时）也请再次确认对大雨的应对措施。 新潟県にいがたけんや北海道などでも大雨になるおそれがあり、週末も、最新の気象情報に注意してください。 即使是「新潟県」和北海道等地方也有下大雨的肯能，周末也请注意最新的天气信息。 山形 酒田 八幡はちまん地域の大沢おおさわ地区ちく 自衛隊じえいたい入り被害状況の確認 山形、酒田和八幡地区的大沢地区，自卫队的受灾情况确认 大雨で道路が冠水かんすいして近づけなくなっている山形県酒田市八幡地域の大沢地区には 26 日午前、自衛隊が入り、被害状況の確認にあたっています。自衛隊によりますと、これまでのところけが人の情報は入っていないということです。 26 日的上午，自卫队进入了由于大雨导致的路面被水覆盖而无法进入的山形县、酒田市和八幡地区的大沢地区，并正在确认受灾情况。根据自卫队所述，到目前为止没有收到受伤人员的信息。 酒田市によりますと、八幡地域の大沢地区は、25日夜から大雨で周辺の道路が冠水して近づけなくなっていた上に停電も発生し、地区に住む 186 世帯 464 人の状況が確認できなくなっていました。 根据酒田市的描述，在八幡地区的大沢地区，从 25 日晚上开始由于大雨导致周边的道路被淹而无法靠近，而且还发生了停电，无法确认住在这个地区的 186 户 464 人的情况。 このため自衛隊が状況を確認するためけさ早く、現地に向かいました。自衛隊によりますと、この地区と周辺の地域を結ぶ国道は冠水したり、複数か所で土砂が流れ込んで道をふさいで塞いでいたため土砂を撤去てっきょするなどして現地に入ったということです。 因此自卫队为了尽快确认上述情况，今早迅速赶往了当地。按照自卫队所述，这个地区和周边地区连接的国道被淹、多个地方由于泥石流经过导致道路被覆盖，清理了泥沙才得以进入当地。 午前 10 時時点で、けが人や救助きゅうじょが必要な人がいるという情報は入っていないということですが、住宅の浸水被害が確認されているということです。 截止在上午 10 点，没有收到信息说存在受伤的人或事需要救助的人，据说已经确认了住宅被淹的情况。 また、酒田市によりますと、大沢地区では昨夜さくやから停電と断水が続いていて、通信状態が悪く電話がつながりにくくなっているということです。自衛隊は引き続き、現地で情報収集しゅうしゅうを行い、被害の状況を確認しています。 还有，根据酒田市的描述，从昨夜开始大沢地区停电和停水的情况还在持续，信号状态也不好电话变得难以接通。自卫队正在当地继续进行信息收集，确认受灾情况。 下一部分：日语翻译 - 新闻 -「山形と秋田で記録的大雨 東北日本海側 あすから再び大雨見込み」（第三部分）","link":"/2024/07/27/translate_news_nhk_20240726_k10014524291000_2/"},{"title":"日语翻译 - 新闻 -「山形と秋田で記録的大雨 東北日本海側 あすから再び大雨見込み」（第三部分）","text":"山形县和秋田县创纪录的大雨，预计东北日本沿海从明天开始会再次下大雨 来源：NHK 日期：2024-07-26 20:08 链接：山形と秋田で記録的大雨 東北日本海側 あすから再び大雨見込み 上一部分：日语翻译 - 新闻 -「山形と秋田で記録的大雨 東北日本海側 あすから再び大雨見込み」（第二部分） 山形県戸沢とざわ村 村長そんちょう「状況の把握はあく進める」 山形县户沢村，村长说：“我们将进一步了解情况” 広い範囲で浸水被害が出ている山形県戸沢村の加藤文明ぶんめい村長は NHK の取材に対し、被害状況の把握と復旧を急ぐ考えを示ししめしました。 水浸受灾范围很广的山形县户沢村的加藤文明村长，在接受 NHK 的采访时，表示要尽快了解受灾情况并进行修复。 山形県戸沢村は大雨の影響で、▽村を流れる最上川さいじょうがわや鮭川の水があふれたほか、▽雨水あまみずが低い場所にたまり水路などの排水はいすいが追いつかなくなる「内水氾濫」も起きていて、▽役場や住宅街が立ち並ぶ中心部の古口地区や▽蔵岡地区くらおかで住宅などの浸水被害が起きています。 山形县户沢村收到大雨的影响，▽ 不仅流经村子的最上川和鲑川的水溢出了，▽ 雨水向低处积存、排水之类的水路无法赶上积水的速度导致了内水泛滥，▽ 在工作场所和住宅街并排林立的中心区的古口地区和「蔵岡」地区，住宅之类的被水浸泡的灾害也发生了。 村によりますと、被害の全容は把握できていないものの少なくとも住宅など 300 棟とうが浸水しているということです。 据村长所述，虽然无法把握受灾的全貌，但是确定了至少有 300 栋房屋被水浸泡了。 いずれの地区にも、排水用のポンプ場が設置されていますが、ポンプの容量以上の雨が降り、排水が追いつかなかったということです。 虽然这两个地区都设置了排水泵站，但是降雨量超过了泵的容量，导致排水的速度无法跟上。 また、蔵岡地区は道路が冠水して通行止めになっているため行き来ができなくなっています。 然后、由于「蔵岡」地区的道路被水淹没之后无法通行，也无法前往（获取信息）。 地区に取り残され、自宅の 2 階などに避難している人がおよそ 40 人いて、自衛隊や県がヘリコプターを出して救助きゅうじょを進めているということです。 被困在（受灾）地区、在自家的二楼之类的地方进行避难的还有 40 人，自卫队和县政府经出动了直升机继续进行救援。 戸沢村の加藤文明村長は、NHK の電話インタビューに対し、役場の周辺も浸水し、被害の把握が進まないとした上で「想定されていないことが起きてしまった。まずは被害の状況や住民じゅうみんの方々が何を求めているのかを把握して復旧を速やかすみやかに進めていくことを一番に考えていく」などと話していました。 户沢村的加藤文明村长，面对 NHK 的电话采访，事务所周围也被水淹没，因此无法进一步掌握浸水和受灾情况，但是表示：“预想外的事情发生了。首先要掌握受灾的情况和地区居民的需求，接着迅速推进修复的速度，我这些作为当前的第一要务考虑”。 秋田県 佐竹さたけ知事ちじ 状況を迅速じんそくに把握 支援策示すよう指示 秋田县的佐竹市长，迅速把握情况并指示支援对策。 秋田県内で記録的な大雨となるなか、佐竹知事は、災害対策本部の会議で住宅や農地のうちの浸水被害の状況を迅速に把握し、支援策を示すよう指示しました。 在秋田县经历创纪录的大雨期间，佐竹市长在灾害对策本部的会议上迅速掌握了住宅和农田的浸水受灾情况，并指示了支援的对策。 秋田県庁では 25 日に続き 26 日も災害対策本部の会議が開かれ、佐竹知事や幹部職員が出席しました。 秋田县政府继 25 日之后的 26 日夜召开了了灾害对策本部的会议，佐川市长和干部职员出席了会议。 会議の中では▽これまでに浸水した住宅が由利本荘市や横手市、湯沢市などで少なくとも 116 棟に上るのぼることや▽浸水した田んぼたんぼや農作物のうさくぶつの畑はたけが少なくとも 1000 ヘクタールになるなど被害状況について報告されました。 在会议中，▽ “至今为止「由利本荘市」、横手市和「湯沢市」等地，浸水受灾的房屋至少有 116 栋以上，▽ 浸水受灾的稻田和农作物的田地至少有 1000 公顷。”报告了如上信息。 これに対し、佐竹知事は、「水が引かないとわからないが、迅速に被害状況を把握してほしい」と述べたうえで、被災ひさい者の生活再建さいけんに向けてさまざまな支援策を示すよう指示しました。 对此，佐竹市长说：“虽然水不退我们就不知道，但是还是希望能尽快掌握受灾情况。”，之后针对受灾者的生活重建指示了各种支援策略。 下一部分：日语翻译 - 新闻 -「山形と秋田で記録的大雨 東北日本海側 あすから再び大雨見込み」（最终部分）","link":"/2024/07/28/translate_news_nhk_20240726_k10014524291000_3/"},{"title":"日语翻译 - 新闻 -「山形と秋田で記録的大雨 東北日本海側 あすから再び大雨見込み」（最终部分）","text":"山形县和秋田县创纪录的大雨，预计东北日本沿海从明天开始会再次下大雨 来源：NHK 日期：2024-07-26 20:08 链接：山形と秋田で記録的大雨 東北日本海側 あすから再び大雨見込み 上一部分：日语翻译 - 新闻 -「山形と秋田で記録的大雨 東北日本海側 あすから再び大雨見込み」（第三部分） 岸田きしだ首相しゅしょう “引き続き情報収集を行い 万全の対応行っていく” 岸田首相：“继续收集情报，做好万全的应对。” 岸田総理大臣は、政府与党よとう政策懇談会こんだんかいで「最上川の氾濫など、大雨により東北地方ちほうを中心に大きな被害が発生しており、安否あんぴ不明の方もいる。政府としては、自衛隊の災害派遣はけんを行うなどしているところだが、引き続き情報収集を行い、万全の対応を行っていく」と述べました。 岸田总理大臣，在政府执政党政策恳谈会上说到：“由于大雨，以东北地区为中心正在发生最上川的泛滥等灾害，仍然有下落不明的人。作为政府，虽然正在进行自卫队的灾害派遣工作，但将继续进行信息收集，采取万全的应对措施。” 林はやし官房かんぼう長官ちょうかん “被害情報の把握と災害応急対策に全力尽くす” 林官房长官：“将近全力掌握受灾情况和采取灾害应急对策” 林官房長官は閣議かくぎのあとの記者会見で「被災ひさい現場では山形県から要請ようせいを受け自衛隊が災害派遣されるなど警察・消防・自衛隊を中心に救命きゅうめい・救助活動が行われている。被災自治じち体と緊密に連携し、被害情報の把握と災害応急対策に全力を尽くしていく」と述べました。 林官房长官在内阁会议后的记者见面会上说：“受山形县要求，自卫队被派往灾害现场，以警察、消防和自卫队为中心的救援救助活动正在进行。将与受灾的地方政府密切合作，尽全力掌握受灾情况和采取灾害应急对策。” その上で「被害がすでに発生している地域や大雨に関する警報が発出はっしゅつされている地域に住んでいる方々は引き続き、避難情報や最新の気象情報に留意し、早め早めに身の安全を守る行動を取って欲しい」と呼びかけました。 在此之上，还呼吁：“正在发生灾害的地区和发出了大雨相关警报的地区的各位居民，请你们继续留意避难信息和最新的天气信息，尽早采取保护自身安全的行动。” 松本まつもと総務相しょう 被害の自治体に普通交付こうふ税ぜいを繰り上げ交付 松本总务提前向受灾地方政府提供普通补贴税 山形県と秋田県の記録的な大雨を受けて松本総務大臣は記者会見で、被害が出ている自治体に対し普通交付税を繰り上げて交付する方針を明らかあきらかにしました。 受山形县和秋田县遭遇破纪录的大雨的影响，松本总务在记者见面会上明确表示，将提前对受灾的地方政府补贴普通交付税。 この中で松本総務大臣は、記録的な大雨で被害が出ている山形県と秋田県の 5 つの市と町に対し、ことし 9 月に交付される普通交付税の一部を繰り上げて、今月 31 日に交付する方針を明らかにしました。 在这启动，松本总务还明确表示：针对受破纪录大雨灾害影响的 5 个市和城市，会提前将 9 月的普通交付税的一部分，于本月 31 日进行交付。 対象となるのは山形県の酒田市、遊佐町、秋田県の横手市、由利本荘市、にかほ市で、このほかの自治体についても、今後の要望に応じて繰り上げて交付する方針です。松本大臣は「命に関わる事態にも至っており大変厳しい状況だ。引き続き、被災した自治体の支援に努めてつとめていく」と述べました。 作为提前交付对象的是山形县的酒田市、「遊佐町」、秋田县的横手市、「由利本荘市」、「にかほ市」，即使是除此以外的地方政府，也有应对今后的要求进行提前交付的方针。松本总务表示：“这已经是性命攸关的严峻形势了，会继续努力支援受灾的地方政府。” 坂本さかもと農相 サポートチームを現地に派遣 坂本农林水产大臣：会向现场派遣支援团队 山形県と秋田県の記録的な大雨を受けて、坂本農林水産のうりんすいさん大臣は、26 日の閣議のあとの記者会見で、農林水産省のうりんすいさんしょうからサポートチームを現地に派遣したことを明らかにした上で、農林水産関連の被害状況の把握を急ぎ、対応していく考えを示しました。 受山形县和秋田县遭受创纪录大雨的影响，坂本农林水产大臣在 26 日内阁会议之后的记者招待会上明确已经从农林水产部向当地派遣了支援团队，表示会尽快掌握农林水产相关的受灾情况，进行对应措施。 この中で、坂本農林水産大臣は「被害に遭わあわれたすべての方々に心よりお見舞い申し上げる。農林水産関係の被害については現時点で調査中だが、山形県および秋田県からは農作物の冠水、浸水や林地りんちの荒廃こうはいなどの被害の報告を受けている」と述べました。 在此之上，坂本农林水产大臣还表示：“我们向受到灾害影响的所有人表示诚挚的慰问。虽然关于农林水产相关的受灾情况还在调查中，但是无论山形县还是秋田县都报告了农作物被淹、浸水和林地荒废之类的受灾情况。” さらに、坂本大臣は、農林水産省の職員によるサポートチームを山形県や秋田県に派遣し、支援に当たっていることを明らかにした上で、現地との連携を密みつにして被害状況の把握を急ぎ、対応していく考えを示しました。 此外，坂本大臣还明确表示向山形县和秋田县派遣了由农林水产部职员组成的支援团队进行支援，在此之上，还表示会尽快和当地紧密合作掌握受灾情况，进行应对措施。","link":"/2024/07/29/translate_news_nhk_20240726_k10014524291000_4/"},{"title":"日语翻译 - 新闻 -「千代田区官製談合 調査報告書“議員と職員の関わり方に課題”」","text":"千代田区发生了官制串通 调查报告书以议员和职员的关系作为课题 来源：NHK 日期：2024-07-31 17:27 链接：千代田区官製談合 調査報告書“議員と職員の関わり方に課題” 東京 千代田ちよだ区くの元区議会議員が区の元部長らと共謀きょうぼうして、工事の入札にゅうさつに関する情報を業者に漏らした見返りみかえりに賄賂わいろを受け取っていた事件を受けて、区は、議員と職員の関わり方に課題があったなどとする調査報告書を取りまとめ、再発防止に取り組む考えを明らかにしました。 东京千代田区的原区议会议员和原区部长合谋、将工程的投标相关的情报泄露给从业者、作为回报收取贿赂的事件，受此影响，千代田区汇总了将议员和职员的相关人员作为课题等的调查报告书，并表明了致力于防止在类似事件再次发生的想法。 東京 千代田区が発注はっちゅうした工事の一般競争きょうそう入札をめぐり、元区議会議員は元部長らと共謀して入札に関する情報を業者に漏らし、見返りに賄賂を受け取ったとして官製かんせい談合だんごう防止法違反などの罪つみに問われ、今月、執行しっこう猶予ゆうよ1. 延期，缓期；2. 犹豫付きの有罪判決を受けました。 围绕东京千代田区提出的施工的一般公开招标、原区议会议员和原部长合谋、将招标相关的情报泄露给了从业者、作为回报收取贿赂的、违反了《官制串通防止法》的犯罪行为，本月，执行了缓期的有罪判决。 事件を受けて、区は調査委員会を設けもうけて再発防止策などを検討し、31 日、樋口高顕ひぐちたかあき区長が調査報告書を公表しました。 受此事件影响，千代田区设立了调查委员会探讨防止再次发生的对策，31 日樋口高顕区长公布了调查报告书。 それによりますと、元部長らは元議員の求めに応じて入札に関する情報を提供していたということで、議員と良好な関係を構築こうちくして円滑えんかつな議会運営をしたいという強い思いなどが、違法行為につながった可能性が高いと指摘しています。 据此时他们指出：原部长通过回应原议员的请求提供招标相关的信息的方式、构建和议员的良好的关系的进行圆滑的议会运行的这种强烈的想法，很有可能导致违法行为。 そのうえで、再発防止策として、議員に対し職員 1 人ではなく複数の職員で対応することや、議員や利害りがい関係者などとの対応内容を記録して、定期的に区のホームページで公表することなどを挙げています。 在此技术上，作为防止再发生的对策，还推举了：“不是一个职员对应一个议员、而是多个议员对应”、“对议员和利益相关的对应内容进行记录并定期在区政府的主页进行公布”的对策。 樋口区長は「議員からの働きかけ1. 推动力影响、施压があったとしても、情報漏えいろうえいは区民の信頼を損ねるそこねる、決してあってはならない行為であり、組織改革を進めていきたい」と述べました。 樋口区长表示：“即使有议员施压、泄漏信息也会损害了区民信赖，一定是不能发生的行为，我们将推进组织改革。”","link":"/2024/07/31/translate_news_nhk_20240731_k10014531221000/"},{"title":"日语翻译 - 新闻 -「6 月の有効求人倍率 全国平均 1.23 倍 前月比は 3 か月連続低下」","text":"6 月的有效招聘倍数是全国平均 1.23 倍，与前月相比连续 3 个月下降 来源：NHK 日期：2024-07-30 08:31 链接：6 月の有効求人倍率 全国平均 1.23 倍 前月比は 3 か月連続低下 先月の有効求人倍率は全国平均で 1.23 倍となり、前の月に比べて 0.01 ポイント下がって 3 か月連続で低下ていかしました。厚生労働省は「円安や物価高ぶっかだかによる原材料費の高騰こうとうの影響で製造業や建設業けんせつぎょうで求人を出せない状況が続いている」としています。 上个月的全国平均有效招聘倍数为 1.23 倍，和之前一个月相比下降了 0.03，已经连续 3 个月下降了。厚生劳动省表示：“受到日元贬值和高物价导致的原材料价格飞涨的影响，制造业和建造业不招聘的情况正在持续。” 厚生労働省によりますと、仕事を求めている人 1 人に対して何人の求人があるかを示す有効求人倍率は先月、全国平均で 1.23 倍となり前の月を 0.01 ポイント下回りしたまわりました。 据厚生劳动省所述，与正在求职的 1 个人相对的、在招聘多少人的有效招聘倍数、上个月全国平均是 1.23 倍，与前一个月相比下降了 0.01。 有効求人倍率が前の月を下回るのは 3 か月連続です。 有效招聘倍数和前月相比下降已经连续 3 个月了。 都道府県とどうふけん別の有効求人倍率を就業しゅうぎょう地別でみると、最も高いのは▽ 福井県で 1.85 倍▽ 山口県で 1.67 倍などとなりました。 按就业地来看，各都道府县的有效招聘倍数最高的是：▽ 福井县 1.85 倍▽ 山口県 1.67 倍 一方、最も低かったのは▽ 大阪府で 1.02 倍▽ 北海道で 1.03 倍などとなりました。 另一方面，最低的是：▽ 大阪府 1.02 倍▽ 北海道 1.03 倍 新規求人を主なおもな産業別にみると、去年の同じ月に比べて各産業で減少げんしょうしていて、中でも▽ 製造業は 14.6％▽ 生活関連サービス業は 13.7％▽ 建設業は 12.8％ と大きく減少しています。 从主要行业的职位空缺来看，和去年同期相比各行业都有减少，但是其中：▽ 制造业大幅减少了 14.6%▽ 生活相关的服务业大幅减少了 13.7％▽ 制造业大幅减少了 12.8% 厚生労働省は「去年 5 月は新型コロナが 5 類に移行し、経済活動が回復する中で求人が増加していた時期のため、前年と比べると全体で求人が減少している。円安や物価高による原材料費の高騰の影響で、製造業や建設業では新しい求人を出せない状況が続いている」としています。 厚生劳动省表示：“因为去年 5 月是新冠转为 5 类疫情、经济活动恢复、招聘人数增加的时期，因此去年与前一年相比整体的职位空缺是在减少的。受到日元贬值和高物价导致的原材料费飞涨的影响，制造业和建造业不招聘新人的情况还在持续。”","link":"/2024/07/30/translate_news_nhk_20240730_k10014528561000/"},{"title":"日语翻译 - 新闻 -「円高ドル安 大手商社 “違和感ない” “落ち着くことを期待”」","text":"面对日元升值美元贬值 大商社表示：“没有什么奇怪的，期待汇率稳定。” 来源：NHK 日期：2024-08-01 17:46 链接：円高ドル安 大手商社 “違和感ない” “落ち着くことを期待” 外国為替かわせ市場で円高えんだかドル安が進んでいることについて、大手おおて1. 前门，正门；2. 大户头；大企业，大公司商社・丸紅まるべにの古谷ふるや孝之たかゆき CFO は「もともと今年度は想定レートを 1 ドル ＝ 140 円としていて、円安から円高へふれると考えていたので違和感はない」と述べ、事業へのマイナス1. minus 减号；2. 亏损；3. 不利の影響はないという考えを示しました。 关于外汇交易市场日元持续升值美元持续贬值的事情，大商社丸红的 CFO 古谷孝之表示：“原本想定的汇率今年变成 1 美元可换 140 日元，之前想到过日元从贬值到升值所以并没有什么奇怪的。“，也表示不会对企业有坏的影响。 ただ「急激きゅうげきな為替変動や過度かどな円高や円安は事業の安定化という観点から望ましくないので、為替レートが安定することを期待している」と述べました。 但是，他还表示了：“从事业稳定化的立场来看，是不期望激烈的汇率变化、过度的日元贬值或日元升值的，之后期待汇率稳定。” 一方、三井みい物産の重田しげた哲也てつや CFO は、「1 ドル ＝ 160 円近くの円安は、日本経済にも悪い影響が出かねない状況だったが、今、為替市場は転換点に近づいている」と述べました。 另一方面，三井物业的 CFO 重田哲也表示：“1 美元接近可换 160 日元的日元贬值情况，即使对日本经济来说也到了可能出现坏影响的状况了，不过现在，汇率市场正在接近转折点。” そのうえで、「しばらくは変動幅はばの大きい状況が続くとみているが、これが落ち着くことを期待している。その中で、日本経済の強みがグローバルに再確認されていくにつれ、円高が緩やかゆるやかに進んでいくことが、日本経済とマーケットにとってベストなシナリオscenario 剧本，脚本だ」と述べました。 不仅如此，他还表示：“虽然认为暂时汇率还将持续大幅变化，但是期待稳定。其中，随着日本经济的优势被全球范围内再次确认，日元继续缓慢升值的这件事，对于日本经济和市场来说是最好的剧本。”","link":"/2024/08/01/translate_news_nhk_20240801_k10014532871000/"},{"title":"日语翻译 - 新闻 -「株価 4451円余下落 終値で過去最大の値下がり 米経済減速懸念」","text":"股价下跌 4451 日元，创历史最大跌幅，担忧美国经济减速 来源：NHK 日期：2024-08-05 15:09 链接：株価 4451円余下落 終値で過去最大の値下がり 米経済減速懸念 🌟 单词： 懸念｜けねん⓪① 膨らむ｜ふくらむ⓪ 投機筋｜とうきすじ 嘗て｜かつて① 投資家｜とうしか⓪ 冷え込む｜ひえこむ⓪③④ 東証株価指数｜とうしょうかぶかしすう 売買｜ばいばい① 避ける｜さける 震災｜しんさい⓪ 大荒れ｜おおあれ⓪ 長期｜ちょうき① 国債｜こくさい⓪ 林官房長官｜はやしかんぼうちょうかん 動向｜どうこう⓪ 期す｜きす② 差し控える｜さしひかえる⑤⓪ 財政｜ざいせい⓪ 政権｜せいけん⓪ 賃上げ｜ちんあげ⓪ 賃下げ｜ちんさげ⓪ 実現｜じつげん⓪ 稼ぐ｜かせぐ② 資産｜しさん①⓪ 立国｜りっこく⓪ 週明けの 5 日の東京株式市場は、アメリカの景気減速げんそくへの懸念けんねや円高の進行を受けて全面安の展開となり、日経にっけい平均株価の終値おわりねは 4451 円あまりのかつてない未曾有过的急落となりました。日経平均株価の下げ幅は、世界的に株価が暴落した 1987 年のブラックマンデーの翌日よくじつにつけた 3836 円 48 銭せんを超えて、終値として、過去最大の下落げらく幅を記録しました。 本周初的 5 号，受美国经济减速的担忧、和日元持续升值的影响，东京股市全面下跌，日经平均指数收盘价暴跌 4451 日元。本次日经平均股价的跌幅超过了全球股价暴跌的黑色星期一翌日创下的 3836.48 日元，创下了历史最大跌幅。 5 日の東京株式市場は午後に入っても一段と売り注文が膨らみふくらみました。 5 号的东京股市，虽然到了下午但是卖单进一步膨胀。 日経平均株価は午後 2 時 20 分すぎに世界的に株価が暴落した 1987 年のブラックマンデーの翌日につけた 3836 円 48 銭を超えて過去最大の下落幅を記録しました。 日经平均股价在下午的 2 点 20 分过后，（跌幅）打破全球股价暴跌的 1987 年黑色星期一翌日创下的 3836.48 日元，创下历史最大跌幅。 値下がりの幅はさらに拡大かくだいし、株価の下落に歯止めはどめ刹住，制止，抑制が掛からない状況となりました。 下跌的幅度进一步扩大，股价下跌的趋势变得不可阻挡。 東京市場では、アメリカの景気減速への懸念や円高の進行を背景に株価は大きく下落しましたが、投機筋とうきすじによる売り注文が一気に膨らんだという指摘もあり売りが売りを呼ぶ展開となりました。 虽然日本东京股市，在担忧美国经济减速和日元持续增值的背景下，股票价格发生了暴跌，但也有人指出：是因为来自投机者的卖单迅速增加，导致踩踏效应。 投資家とうしか心理が急速に冷え込みひえこみかつてない株価の急落となっています。 投资者情绪迅速冷却，股价出现前所未有的暴跌。 「サーキットブレーカー」(circuit breaker) 熔断机制の措置も 熔断机制等措施 東証株価指数とうしょうかぶかしすう＝トピックスの先物やオプション取引でも大量の売り注文が出て、大阪取引所では午前 9 時 16 分から 10 分間、売買ばいばいを一時中断する「サーキットブレーカー」と呼ばれる措置がとられました。 东证股价指数的期货和期权交易也出现了大量抛售，大阪交易所在上午 9 点 16 分之后 10 分钟，临时中断了交易、采取了被称为“熔断”的措施。 「サーキットブレーカー」は取り引きの混乱を避けるため、取引所が一時的に売買を止める措置です。 “熔断”是交易所为了避免交易混乱、临时中断买卖的行为。 トピックスの先物取引などで発動されるのは、東日本大震災しんさいのあと、株式市場が大荒れおおあれの展開となった 2011 年 3 月以来、およそ 13 年ぶりです。 期货交易上的熔断，从 2011 年 3 月的东日本大地震后、股票市场大幅波动以来，已经 13 年（没有发生过）了。 このほか、5 日は長期ちょうき国債こくさいの先物取引などでも取り引きが一時、中断されました。 除此以外，在8 月 5 号长期国债的期货交易等也一度中断。 林官房長官はやしかんぼうちょうかん「市場動向どうこうを注視 万全を期すきす」 林官房长官：“会注意市场动向、确保万无一失。” 林官房長官は記者会見で「株価は経済状況や企業の活動などさまざまな要因により市場で決まるもので、日々の動向にコメントすることは差し控えさしひかえ1. 节制，控制；2. 保留，避免，不作；3. 控制，注意。たい。緊張感を持って市場の動向を注視し、経済財政ざいせい運営に万全を期していく」と述べました。 林官房长官在记者见面会上表示：“股价是受经济形势、企业活动等多种因素（影响）进而由市场决定的，我们不会评论日常趋势。我们将带有紧张感密切注意市场、确保经济财政运营万无一失。” その上で「今回の株価急落や日本経済について市場でさまざまな評価があることは承知しているが、岸田きしだ政権せいけんとしては物価高に負けない賃上げちんあげの実現じつげんや企業の稼ぐかせぐ力の強化に引き続き取り組む。国内外の資金を呼び込み、力強い日本経済の実現につなげることも重要で、資産しさん運用立国りっこくに向けた取り組みを進めたい」と述べました。 在此之上，他还表示：“我知道就这次的股价暴跌和日本经济形势、市场有各种各种的评价，但岸田政权会继续致力于：不输给物价上涨的工资增长和强化企业的盈利能力。吸引国内外资金来实现日本经济的强大也是重要的，我们将努力推进「资产运营立国」注 ①。” 注 ①：日本再试“金融立国”？","link":"/2024/08/05/translate_news_nhk_20240805_k10014537281000/"},{"title":"日语翻译 - 新闻 -「日経平均株価 一時 3400 円以上の値上がり 過去最大の上昇幅」","text":"日经平均股价一度上涨超 3400 日元，创下历史最大涨幅 来源：NHK 日期：2024-08-06 10:40 链接：日経平均株価 一時 3400 円以上の値上がり 過去最大の上昇幅 🌟 单词： 銘柄｜めいがら⓪ 凡そ｜およそ⓪ 景況｜けいきょう⓪ 上回る｜うわまわる④⓪ 先行き｜さきいき⓪ 過度｜かど① 幾分｜いくぶん⓪ 輸出｜ゆしゅつ⓪ 相次ぐ｜あいつぐ① 全米｜ぜんべい⓪ 供給｜きょうきゅう⓪ 雇用｜こよう⓪ 利下げ｜りさげ⓪ 連邦準備制度理事会｜れんぽうじゅんびせいどりじかい 会合｜かいごう⓪ 見方｜みかた③② 掻き立てる｜かきたてる④⓪ ハイテク｜はいてく⓪ 半導体｜はんどうたい⓪ 著名｜ちょめい⓪ 率いる｜ひきいる③ 売却｜ばいきゃく⓪ 現象｜げんしょう⓪ 日銀｜にちぎん⓪ 穴埋め｜あなうめ⓪④ 急激｜きゅうげき⓪ 5 日、日経平均株価の下落幅が過去最大となった東京株式市場。 8 月 5 日，东京股票市场创下日经平均股价的最大跌幅。 6 日は、取り引き開始直後ちょくごから大幅に値下がりした銘柄めいがら1. 品种；2. 商标，牌子。を買い戻す動きが出て日経平均株価は一時、3400 円以上値上がりし、上げ幅は 1990 年 10 月につけた 2677 円 54 銭を超えて取り引き時間中として過去最大となりました。 8 月 6 日交易开始后，出现了对（前一日）大跌的股票的买回行为，日经平均股价一度涨超 3400 日元，涨幅超过 1990 年 10 月的 2677.54 日元创下了历史之最。 6 日の東京株式市場は、取り引き開始直後から全面高の展開となり、日経平均株価は、一時、3400 円以上値上がりしています。 8 月 6 日的东京股市，交易开始后股价全面走高，日经平均股价一度涨超 3400 日元。 5 日のニューヨーク株式市場はアメリカの景気減速への懸念から売り注文が膨らみ、ダウ平均株価はおよそ1. 大概，概略；2. 凡是，一般地；3. 完全，全然，根本（多用于否定） 1 年 11 か月ぶりに 1000 ドルを超える急落となりました。 8 月 5 日的纽约股市因对美国经济减速的担忧而出现大量抛售，道琼斯工业指数时隔大约 1 年 11 月（又）发生了超 1000 美元的暴跌。 ただ、日経平均株価は、5 日まで 3 営業日連続で値下がりし、下落幅が 7600 円余りになっていたこともあり、買い戻しの動きが出ています。 然而，日经指数到 8 月 5 日为止已经连续 3 个交易日下跌，跌幅达到 7600 多日元，（由此）出现了回购的动向。 このため日経平均株価の上昇幅は 1990 年 10 月につけた 2677 円 54 銭を超えて取り引き時間中として過去最大となりました。 因此本次日经指数的上涨幅度超过 1990 年 10 月达到的 2677.54 日元、创下交易时间段中的历史之最。 市場関係者は「5 日、アメリカで公表されたサービス業の景況けいきょう感に関する経済指標が市場の予想を上回り、アメリカ経済の先行きさきゆき1. 将来，前途；2. 将来的行情，行情的前景。に対する過度かどな警戒感がいくぶん和らいでいる。これを踏まえて東京外国為替市場でも円安ドル高が進んでいて輸出ゆしゅつ関連の銘柄などを買い戻す動きが加速している」と話しています。 市场关系者表示：“8 月 5 日，美国公布的与服务业景气经济指标好于市场的预期，针对美国经济预测的过度警戒有所缓和。基于这个，在东京的外汇市场上日元贬值美元升值，加速出现对出口相关的股票的回购动向。” 《株価急落の背景》 股价暴跌的背景 ニューヨーク株式市場の株価急落の背景にはさまざまな要因が重なったと指摘されています。 普遍认为纽约股市的股价暴跌是由多种多样的原因共同导致的。 【相次ぐ経済指標の悪化】 （原因 1）接连的经济指标的恶化 先週、アメリカでは弱い内容の経済指標が相次ぎました。全米ぜんべいの企業を調査する「ISM＝供給きょうきゅう管理協会」が 1 日に発表した製造業の「景況感指数」は先月 46.8 と、前の月から低下し市場予想も下回りました。 上周，美国经济数据疲软。进行全美企业调查的 ISM（供给管理协会）在 8 月 1 日发表了制造业 PMI注① 为上月 46.8，比前一个月低并且也低于市场预期。 また、2 日に発表された先月の雇用こよう統計では、就業者数の伸びが市場の予想を大幅に下回ったほか失業率が 4.3％ と前の月に比べて 0.2 ポイント上昇しました。失業率の上昇は 4 か月連続です。 还有，8 月 2 日发表的上个月的雇佣统计显示：就职人数的增加比市场预期的少了太多，并且失业率为 4.3% 与前一个月相比上升了 0.2 个百分点。失业率连续 4 个月上升。 【利下げ遅いのでは】 （原因 2）利率下降是不是太慢了 市場では FRB＝連邦準備制度理事会れんぽうじゅんびせいどりじかいが 9 月の会合かいごうで利下げに踏み切るとの見方が強まっていました。そこに弱い内容の経済指標が相次いだことで景気減速を避けるには 9 月の利下げでは遅すぎるのではないかとの見方が投資家の間で広がり、不安心理をかきたてた掻き立てた1. 搅拌；2. 引起；3. 挑灯，添柴；4. 立领；5. 弹琴。と指摘されています。 市场强烈认为 FRB（联邦准备制度理事会）在 9 月的会议后会下调利率。此外，投资者广泛认为：在经济数据疲软的当下，为了避免经济减速而在 9 月发布利率下调太晚了，这引发了不安心理。 【ハイテク関連株の急落】 （原因 3）科技股暴跌 ことしのニューヨーク株式市場の株価上昇を支えてきたのはハイテク(high tech) 科技股関連銘柄です。 支撑去年纽约股票市场股价上涨的是科技股相关的股票。 アメリカの半導体はんどうたいメーカー(maker) 制造商、インテルが 1 日、赤字決算と人員削減を発表すると 2 日にはこの会社の株価が 26％ の急落となり、ほかの IT 企業の株価下落にもつながりました。著名な投資家のウォーレン・バフェット氏が率いるひきいる投資会社バークシャー・ハサウェイが IT 大手アップルの株式を大量に売却ばいきゃくしたことも明らかになり、5 日の株式市場の下落要因となりました。 美国的半导体制造商英特尔刚在 8 月 1 日发布了亏损报告和裁员计划，8 月 2 日这个公司的股价就暴跌了 26%，还带动了其他 IT 企业的股价下跌。著名的投资家巴菲特领导的投资公司伯克希尔哈撒韦大量抛售 IT 大企业苹果的股票的事实，也成为了 8 月 5 日股票市场下跌的原因。 【「キャリートレード」取り引きに逆転現象】 （原因 4）“利差交易注②” 恶化交易的现象 さらに指摘されているもうひとつの大きな要因は、金利きんりの低い円で資金を調達してその資金を投資に回す「キャリートレード」と呼ばれる取り引きに逆転現象が起きたことです。 更进一步被指出的（导致股市暴跌的）主要原因是发生了：通过日元的低利率调集资金之后，再将其投回投资领域的被称为“利差交易”的恶化交易的现象。 主要国の中央銀行がインフレ通货膨胀を抑え込むおさえこむために利上げをするなか、日銀にちぎんは数少ないかずすくない超低金利政策を続けた中央銀行として世界にも知られ、円を活用した「キャリートレード」が活発に行われてきました。それが日銀の利上げと円高によって、この取り引きがうまく回らなくなり、円高による損失そんしつを穴埋めあなうめしようと株式を売る投資家が数多くいたと市場関係者は話しています。 全球主要国家的中央银行为了抑制通货膨胀都会采取高利率，而日本银行则因是少数的、持续进行超低利率政策的银行而被世界熟知，（由此）活用日元的套利交易盛行。市场人士表示，由于日本银行的利率上调和日元升值，这个（套利）交易无法顺利进行，许多投资者出售股票，试图弥补日元升值带来的损失。 大阪取引所では「サーキットブレーカー」 大阪交易所采取“熔断”措施 株価が急激きゅうげきに上昇するなか、東証株価指数＝トピックスの先物やオプション取引でも大量の買い注文が出て大阪取引所では午前 9 時 56 分から 10 分間、売買を一時中断する「サーキットブレーカー」と呼ばれる措置がとられました。 在股价急速上涨时，东证股价指数的期货和期权交易也出现大量的买单，大阪交易所在上午 9 点 56 开始的 10 分钟，临时停止了买卖行为采取了被称为“熔断”的措施。 「サーキットブレーカー」は取り引きの混乱を避けるため、取引所が一時的に売買を止める措置です。トピックスの先物取引などでは株価が記録的な急落となった 5 日も、「サーキットブレーカー」が発動されました。 “熔断机制”是为了避免交易的混乱，由交易所采取的临时的、停止买卖行为的措施。期货交易等发生股价暴跌的 8 月 5 日，“熔断”也被发动了。 注 ①：美国 ISM 制造业 PMI注 ②：利差交易","link":"/2024/08/06/translate_news_nhk_20240806_k10014538541000/"},{"title":"日语翻译 - 新闻 -「岸田首相 映画やアニメのコンテンツ産業強化で戦略会議設置へ」","text":"岸田首相将设立强化电影和动漫等文化产业的战略会议 来源：NHK 日期：2024-08-07 15:13 链接：岸田首相 映画やアニメのコンテンツ産業強化で戦略会議設置へ 🌟 单词： 岸田文雄｜きしだふみお 首相｜しゅしょう⓪ コンテンツ｜こんてんつ③①(contents)内容; 目录，目次 戦略｜せんりゃく⓪ 監督｜かんとく⓪ 待遇｜たいぐう⓪ 受賞｜じゅしょう⓪ 是枝裕和｜これえだひろかず 交える｜まじえる③ 交わす｜かわす⓪ 整える｜ととのえる④③ 鉄鋼｜てっこう⓪ 半導体｜はんどうたい⓪ 賃金｜ちんぎん① 側面｜そくめん⓪ 上旬｜じょうじゅん⓪ 映画やアニメといったコンテンツ産業を強化するため、岸田総理大臣は、映画監督かんとくやクリエーターなども参加する戦略会議を設置して、制作現場の待遇たいぐう改善などに向けた支援策の検討を進める考えを示しました。 为了强化电影和动漫所在的文化产业，岸田总理大臣表示：将设立电影导演和创作者等参加的战略会议，推进旨在改善制作现场待遇的支援策略的讨论。 岸田総理大臣は 7 日、東京大田区で夏休みに合わせて中学生を対象に開かれている映画制作教室を視察し、カンヌ映画祭などで数々かずかずの賞を受賞じゅしょうした是枝裕和これえだひろかず監督らを交えてまじえて意見を交わしかわしました。 岸田总理大臣 7 号，在东京大田区视察了暑假期间、以中学生为对象举办的电影制作教室（活动），并与得过包括戛纳电影节在内的众多奖项的是枝裕和导演等人交换了意见。 この中で、中学生からは「日本の映画やアニメで自慢できるのはどこだと思うか」といった質問が出され、岸田総理大臣は「作品の質が高いことだ。作り手が正当に評価される環境を整えてととえて1. 弄齐整理整顿；2. 备齐备至准备；3. 谈妥办妥使达成。いきたい」と答えていました。 在过程中，被中学生问到：“您认为日本的电影和动漫最值得骄傲的地方在哪里？”，岸田总理大臣回答道：“就是作品的质量很高。（因此）想要创造一个能让制作者被正当评价的环境。” また是枝監督は「皆さんが大人になって映画の職場を選んでもらえるように取り組んでいきたい」と話していました。 是枝导演还说了：“我会努力让大家长大后选择电影的工作岗位。” 視察のあと岸田総理大臣は記者団に対し「日本のコンテンツ産業は鉄鋼てっこうや半導体はんどうたい産業に匹敵する輸出規模きぼがあるが、労働環境や賃金ちんぎんの支払いの側面そくめんでクリエーターが安心して働ける環境は未整備せいびだ」と述べました。 在视察之后，岸田总理大臣向记者团表示：“虽然日本的文化产业有着可以和钢铁、半导体产业匹敌的出口规模，但在劳动环境和工资支付方面，还未具备能让创作者安心工作的环境（的因素）。” そのうえで、関係省庁に加え、映画監督やクリエーターなども参加する戦略会議を 9 月上旬じょうじゅんにも設置して、制作現場の待遇改善などに向けた支援策の検討を進める考えを示しました。 之后，岸田总理大臣表示：9 月上旬将设置了除了关系的政府部门以外、电影导演和创作者等参加的战略会议，推进旨在改善制作现场待遇的支援策略的讨论。","link":"/2024/08/07/translate_news_nhk_20240807_k10014540201000/"},{"title":"日语翻译 - 新闻 - 円相場 値上がり FRBが利下げに踏み切る見方 一段と強まる","text":"日元相对升值，FBR 降息预期导致进一步升值 来源：NHK 日期：2024-08-22 18:51 链接：円相場 値上がり FRBが利下げに踏み切る見方 一段と強まる 🌟 单词： 円相場｜えんそうば 一段｜いちだん②⓪1. 一级，一层；2. 一段，一节；3. 更加，越发。​ 議事録｜ぎじろく②会议记录 大多数｜だいたすう③④ 総裁｜そうさい⓪ 国会｜こっかい⓪ 見通し｜みとおし⓪1. 瞭望，眺望；**2. 预料，预见；**3. 看穿，看透，洞察；4. 一直看下去，一直看完。 2日の東京外国為替市場は、アメリカの中央銀行にあたるFRB＝連邦準備制度理事会が、来月利下げに踏み切るとの見方が一段と強まってドル売り円買いが進み、円相場は値上がりしました。 在 8 月 2 日的东京外汇市场，受到相当于美国中央银行的 FRB（联邦准备制度理事会）下月降息预期进一步增强的影响，（投资者）持续卖出美元买入日元，日元相对升值。 午後5時時点の円相場は、21日と比べて88銭円高ドル安の1ドル＝145円26銭～28銭でした。 （8 月 22 日）下午 5 点的日元汇率，和 21 日相比日元升值 88 钱达到了 1 美元 = 145 日元 26 ~ 28 钱。 また、ユーロに対しては、21日と比べて66銭円高ユーロ安の1ユーロ＝161円77銭～81銭でした。 还有，相对于欧元，和 21 日相比日元升值 66 钱达到了 1 欧元 = 161 日元 77 ~ 81 钱。 ユーロはドルに対して1ユーロ＝1.1136～38ドルでした。 欧元相对美元达到了 1 欧元 = 1.1136 ~ 38 美元。 市場関係者は「アメリカのFRBが先月の金融政策を決める会合の議事録を公表し、この中で大多数だいたすうの参加者が『次回・9月会合で利下げすることが適切になるだろう』という認識を示していたことを受けて、ドルを売って円を買う動きが出た。投資家の間では、あす日銀の植田うえだ総裁そうさいが国会こっかいの閉会中審査で今後の利上げの見通しなどについて、どう発言するかが注目されている」と話しています。 市场关系者说：“美国的 FRB 公布了上个月决定金融政策会议的会议记要，在这其中大多数的参加者接受‘下回也就是 9 月的会议中进行降息是合适的’的认知表示，出现了出美元买入日元的动向。在投资家之间，关注着明天日银的植田总裁在国会的闭会中审查中就今后的加息前景如何发言这件事情。”","link":"/2024/08/22/translate_news_nhk_20240822_k10014556231000/"},{"title":"日语翻译 - 新闻 - 「南海トラフ地震臨時情報」を受け企業も対応進める","text":"收到“南海海槽地震临时信息”，企业也将推进对应 来源：NHK 日期：2024-08-09 11:41 链接：「南海トラフ地震臨時情報」を受け企業も対応進める 🌟 单词： トラフ｜とらふ槽；沟；池；阱；尾流；导板；低压槽（气象）；滤槽。 臨時｜りんじ⓪ 宮崎市｜みやざきし 正午｜しょうご① スプリンクラー｜すぷりんくらー③(sprinkler) 淋灌装置，喷水设备；自动洒水灭火设备。 目処｜めど①目标，眉头，头绪。 誤作動｜ごさどう⓪ 態勢｜たいせい⓪ 備蓄品｜びちくひん 拠点｜きょてん⓪据点，基地；依据。 名古屋｜なごや 御前崎市｜おまえざきし 浜岡｜はまおか 原子力発電所｜げんしりょくはつでんしょ 施設｜しせつ① 九州｜きゅうしゅう 大分｜だいぶ⓪ 鹿児島｜かごしま 三菱｜みつびし② 従業員｜じゅうぎょういん③ フィナンシャル(financial) 金融。 傘下｜さんか① 安否｜あんぴ① 沿岸｜えんがん⓪ 気象庁が８日夜、南海トラフの巨大地震への注意を呼びかける「臨時情報」を発表したことを受けて、企業の間では対応が進められています。 收到气象厅在 8 日的晚上发布的呼吁注意南海槽巨大地震的临时情报，企业之间也正在推进对应。 宮崎市「イオンモール宮崎」 正午から営業再開 宫崎市的宫崎永旺商场，从中午开始恢复营业 宮崎市にある「イオンモール宮崎」は、建物の安全性が確認されたことなどとして、9 日の午後 0 時から営業を再開することになりました。 宫崎市的宫崎永旺商场，在进行了建筑物安全性的确认等等之后，从 9 日的中午 12 点恢复营业。 ただ同じ建物内ある総合そうごうスーパー「イオン宮崎店」は、地震でスプリンクラーが誤作動ごさどうした影響などで、現在も営業再開のめど目処が立っていないということです。 但是在同一栋建筑内的综合超市宫崎永旺（超市），受到由于地震误触发喷淋装置等的影响，（直到）现在还没有恢复营业的迹象。 通信各社 態勢を強化 各个通信公司，强化了（应对）态势 通信各社の対応です。 （以下）是各个通信公司的应对。 ▽NTTはグループの各社で「情報連絡室」を設置し、情報収集態勢を強化しました。 NTT 集团的各公司设立了“情报联络室”，强化信息收集的态势。 ▽KDDIは社内の連絡態勢を強化したほか、水や食料など備蓄品びちくひんの確認を進めています。 KDDI 除了强化公司内部的联络态势，还在推进确认水和食物等储备品（的状态）。 ▽ソフトバンクは臨時情報の対象地域にある拠点きょてんで情報連絡態勢を強化しています。 软银在临时情报对象地区的分支机构强化信息联络态势。 大手電力でんりょく各社 対策本部立ち上げ状況確認 各大电力公司，设立对策本部确认状况 大手電力各社は、それぞれ対策本部を立ち上げるなどして、各地の状況の確認を進めています。 各大电力公司，分别成立了对策本部，推进确认各地的状况。 このうち、▽中部電力は、名古屋なごや市内の本店に「連絡所」を設置し、各地の情報収集にあたる当たるとともに、本店と各支店に昼夜を問わず 1 人以上が待機する体制を取っています。 在这之中，中部电力在名古屋的总店设立了“联络所”，负责收集各地的信息，同时采取不论昼夜总店和各分店都有至少 1 人待机的制度。 また静岡県御前崎市にある浜岡はまおか原子力発電所げんしりょくはつでんしょでも、「地震待機体制」を発令はつれいして、一時、およそ 300 人を待機させ、施設しせつの点検などを行ったということです。 此外静冈县御前崎市的浜冈核能发电所也发布了“地震待机制度”，暂时安排了大雨 300 人待机，并对设施进行了检查。 ▽九州電力も、福岡市内の本店に「南海トラフ地震対策総本部」を設置するとともに、大分だいぶ、宮崎、鹿児島かごしまの各支店に対策本部を設置しました。 九州电力也在福冈市内的总店设立了“南海海槽地震对策总本部”，同时还在大分、宫崎、鹿儿岛的各分店设立了对策总部。 各地の状況や関係機関との連絡体制の確認などを進めているということです。 还在推进确认各地状况与关联机构的联络制度等。 さらに、▽関西かんさい電力も、大阪市内の本店に対策本部を立ち上げて、情報収集を進めるとともに、9 日午前中、対策会議を開き、今後の対応を検討することにしています。 另外，关西电力也在大阪市内的总店设立的对策总部，持续收集情报，同时还在 9 号的上午展开了对策会议，研究今后的对应措施。 銀行 三菱みつびしUFJやみずほ瑞穂 通常営業 三菱 UFJ 银行和瑞穗银行正常营业 ▽三菱 UFJ 銀行では、9 日は通常どおり営業することにしていて、従業員に対して避難場所や避難ルートの周知を徹底することにしています。 三菱 UFJ 银行决定在 9 日向往常一样营业，对员工彻底告知避难所和避难路线。 ▽金融大手のみずほフィナンシャルグループは、傘下のみずほ銀行など全国の店舗に確認したところ、今回の地震による被害は出ていないということで、現時点では、9日は通常どおり営業することにしています。 金融巨头瑞穗金融集团旗下瑞穗银行等全国店铺确认，本次地震未造成任何损失，目前 9 日正常营业。 ただ、各自治体からの情報を確認したうえで、対応を検討するということです。 不过，在确认各地方政府的信息后，将讨论应对措施。 自動車 コンビニ 社員や店舗に安全周知 向汽车（驾驶员）、便利店、公司职员和店铺告知安全事项 ▽自動車メーカーの「スズキ」は、全社員にメールを出して、安否確認の方法や自宅の備蓄品の点検など、地震への備えを再確認するよう呼びかけました。 汽车制造商铃木向全体员工发送了邮件，呼吁再次确认保证自身安全的方法、检查自己房屋的储备品等对地震的准备措施。 ▽コンビニ大手の「ローソン」は、全国の沿岸えんがん部にある店舗に対して、再度、避難場所を確認するよう周知することにしています。 便利店大公司罗森，决定再次向全国的沿海地区的店铺告知确认避难所的事。","link":"/2024/08/09/translate_news_nhk_20240809_k10014543121000/"},{"title":"日语翻译 - 新闻 - 日銀 植田総裁「市場 引き続き不安定な状況と認識」","text":"日本银行的植田行长说：“我认为市场还处于持续不稳定的状况中。” 来源：NHK 日期：2024-08-23 10:27 链接：日銀 植田総裁「市場 引き続き不安定な状況と認識」 🌟 单词： 衆議院｜しゅうぎいん③ 乱高下｜らんこうげ③大幅度波动，猛涨猛落，狂涨暴跌。 内外｜ないがい① 当面｜とうめん⓪1. 目前，眼前，当前，面临；2. 现在，目前，眼下。 動向｜どうこう⓪ 極めて｜きわめて② 見極め｜みきわめ⓪看清，看透。 緩和｜かんわ⓪ 姿勢｜しせい⓪ 日銀の植田総裁は、23日に開かれている衆議院の財務金融委員会の閉会中審査で、8月上旬、株価が記録的な乱高下らんこうげを繰り返すなど金融市場が不安定な状況になったことについて「内外ないがいの金融資本市場は引き続き不安定な状況にあると認識している。当面はその動向どうこう⓪を極めて高い緊張感を持ちつつ注視していく」と述べました。 日本银行的植田行长，在 23 日举行的众议院的财务金融委员会的闭会中审查上，就 8 月上旬股价创纪录的反复剧烈波动等金融市场不稳定的状况，说道：“我认为国内外的金融资本市场还处于持续不稳定的状况中。当前，我们会带有最高的紧张感持续关注动向。” また、追加の利上げを決めたあとの今後の金融政策について植田総裁は「金融資本市場の動向が経済物価の見通しやリスクなどに及ぼす影響、それに、7月に決定した利上げの影響を見極めつつ、経済物価の見通しが私たちが考えているとおり実現していくという確度が高まっていくことが確認できれば、今後、金融緩和かんわの度合いを調整していくという基本的な姿勢しせいに変わりはない」と述べました。 之后，就决定继续加息后的今后的金融政策，植田行长表示：“我们将密切关注金融资本市场的动向对经济物价的预测和风险等的影响，以及 7 月决定的加息的影响。如果能像我们想的那样、提高对经济物价的预测准确度的话，今后调整金融宽松程度的基本态势不会变。”","link":"/2024/08/23/translate_news_nhk_20240823_k10014556771000/"},{"title":"日语翻译 - 新闻 - 沖縄の不発弾処理4万件に “全処理にあと70年から100年”","text":"针对冲绳已经处理的 4 万枚未爆弹，预计全部处理还需 70 ~ 100 年 来源：NHK 日期：2024-08-24 10:02 链接：沖縄の不発弾処理4万件に “全処理にあと70年から100年” 🌟 单词： 不発弾｜ふはつだん 本土｜ほんど① 陸上｜りくじょう⓪ 末期｜まっき① 空襲｜くうしゅう⓪ 艦砲｜かんぽう①⓪ 射撃｜しゃげき⓪ 砲弾｜ほうだん⓪ 日中｜にっちゅう⓪① トラック｜とらっく②(truck) 卡车。 務める｜つとめる③ 🌟 惯用句： こうした中……面对这种情况…… 今もなお至今为止 沖縄の本土復帰以降、50年以上にわたって陸上自衛隊が行っている不発弾処理の件数が、23日4万件に達しました。不発弾のすべてを処理するにはあと70年から100年ほどかかるとみられ、“終わらない戦後処理”とも言われています。 自冲绳回归本土以后，历经 50 年陆上自卫队处理的未爆弹数量在 23 日达到了 4 万枚。处理全部的未爆弹预计还需要 70 ~ 100 年，也被称为“永无止境的战后处理”。 太平洋戦争の末期まっき、「鉄てつの暴風ぼうふう」と言われるほどに多くの空襲くうしゅうや艦砲かんぽう射撃しゃげき、それに地上ちじょう戦による無数むすうの砲弾ほうだんにさらされた沖縄は、およそ1万トンが不発弾として残ったと推定され、本土復帰後に地上で発見されたものは陸上自衛隊の不発弾処理隊が処理を続けています。 在太平洋战争的末期，（由于）被称为“铁的风暴”的程度的数量众多的空袭和舰炮射击，又因为地上战留下了无数炮弹的冲绳，推测大约残留着 1 万吨的未爆弹，回归本土后在地上发现的未爆弹由陆上自卫队的未爆弹处理队持续处理。 こうした中、処理隊には23日も日中に複数の不発弾の発見情報が寄せられ、対応にあたっていました。 在这种情况下，处理队在 23 日的白天收到多件未爆弹的发现信息，进行了对应。 那覇市泊なはしとまりの住宅工事現場でアメリカ製の長さおよそ40センチの5インチ艦砲弾が見つかると、現場にかけつけた隊員が危険性がないか確認したうえで不発弾をトラックに載せて回収していました。 「那覇市泊」的住宅施工现场，发现了美国制的大概长 40 厘米的 5 英尺舰炮弹，到达现场的队员在确认了没有危险之后，将未爆弹运回卡车做了回收。 この回収で本土復帰後に部隊が処理した件数が4万件に達しました。 通过这次回收，冲绳回归本土后部队处理的未爆弹件数达到了 4 万枚。 現場の対応にあたった第101不発弾処理隊の岩瀬亘隊長は「きょうだけで3件対応したが、それだけ多くの不発弾が沖縄には存在している。引き続き無事故で不発弾を除去し、県民が安全な生活を送れるようしっかり務めてつとめていきたい」と話していました。 处理现场对应的第 101 未爆弹处理队的队长岩瀬亘说：“虽然今天只处理了 3 枚，但是冲绳还有那么多的未爆弹存在。我们会继续认真工作持续平安无事地去除未爆弹，为县民保障安全的生活（环境）。” 不発弾の処理は、今もなお、平均すると1日に1件以上のペースで続けられていて、すべてを処理するにはあと70年から100年ほどかかるとみられ、“終わらない戦後処理”とも言われています。 未爆弹的处理，至到今天，以平均 1 天 1 枚以上的速度进行着，处理完所有的未爆弹预计之后大概还要 70 ~ 100 年，也被称为“永无止境的战后处理”。","link":"/2024/08/24/translate_news_nhk_20240824_k10014557821000/"},{"title":"日语翻译 - 新闻 - ボーイング宇宙船 飛行士乗せた帰還を断念 別の宇宙船で","text":"宇航员乘坐波音公司的宇宙飞船返航的念头断了，只能通过其他的宇宙飞船返航 来源：NHK 日期：2024-08-24 10:02 链接：ボーイング宇宙船 飛行士乗せた帰還を断念 別の宇宙船で 🌟 单词： 帰還｜きかん⓪ 宇宙船｜うちゅうせん⓪ ステーション｜すてーしょん②(station) 火车站，车站。 留まる｜とどまる③ 乗組｜のりくみ 先行き｜さきゆき⓪1. 将来，前途；2. 将来的行情，行情的前景。 打ち上げ後に見つかった不具合のため、地球への帰還が大幅に遅れている航空機大手ボーイングの宇宙船について、NASA＝アメリカ航空宇宙局は国際宇宙ステーションにとどまったままとなっている宇宙飛行士2人を乗せて帰還させる計画を断念し、2人は別の宇宙船で帰還することになりました。 由于发生后发现的不匹配，有关回归地球的时间大幅延迟的航空大公司波音的宇宙飞船，NASA（美国航空宇宙局）断了至今仍停留在国际宇宙空间站的两位宇航员乘坐其返航的念头，两人决定通过其他的宇宙飞船返航。 ボーイングが開発を進めてきた新しい宇宙船スターライナー(Starliner) 星际航线。は、ことし6月、試験飛行のため、NASAの宇宙飛行士2人を乗せて打ち上げられ、国際宇宙ステーションに到着しました。 波音公司最新研发的宇宙飞船“星际航线号”，在今年 6 月，因为实验飞行的原因，让给 NASA 的两位宇航员乘坐并将他们发射升空，到达了国际宇宙空间站。 この宇宙船は当初、1週間程度で地球に戻る予定でしたが、推進装置の一部に不具合が見つかり、2か月以上、国際宇宙ステーションにとどまったままになっています。 这个宇宙飞船当初预定 1 周后返回地球，（但是）发现了推进装置的一部分有问题，过了 2 月以上，仍然停留在国际宇宙空间站。 これについてNASAは、24日、会見を開き、スターライナーに2人を乗せて帰還させることを断念したと発表しました。 关于这件事，NASA 在 24 号召开了见面会，公布了放弃让两人搭乘“星际航线号”号返回（的事情）。 新しい計画では、アメリカの企業、スペースXが、来月以降いこうに打ち上げる予定の宇宙船の乗組のりくみ員を4人から2人に減らし、宇宙ステーションに到着後、スターライナーの2人も乗せて、来年2月に帰還するということです。 新计划是：美国的企业 SpaceX 将把预定在下个月之后发射的宇宙船的乘组人员从 4 人减到 2 人，在到达空间站后，“星际航线号”的两人也乘坐并在明年 2 月返回地球。 NASAのネルソン長官ちょうかんは「今回の決定は、われわれが安全への責任を果たした結果だ。安全は私たちが最も大切にしている価値観だ」と強調きょうちょうしました。 NASA 的尼尔森长官强调：“这次的决定，是我们实现保证安全责任（履行安全责任）的结果。保证安全是我们最为重视的价值观。” スターライナーは、今回の試験飛行を経てNASAが承認すれば、国際宇宙ステーションと地球との間を行き来する手段になる予定でしたが、計画の変更で先行きさきゆきは不透明になっています。 如果经过了本次实验飞行并被 NASA 认可的话，“星际航线”号本将预定会成为国际空间站和地球间的往返手段，但由于计划的变更前景正变得不明朗。","link":"/2024/08/25/translate_news_nhk_20240825_k10014558431000/"},{"title":"日语翻译 - 新闻 - 東京 港区 ビル解体工事現場で資材落下 警備員 意識不明の重体","text":"东京港区，大楼拆除工地现场材料坠落，警备员意识不明生命垂危 来源：NHK 日期：2024-09-02 11:49 链接：東京 港区 ビル解体工事現場で資材落下 警備員 意識不明の重体 🌟 单词： 港区｜みなとく 芝大門｜しばだいもん地名，位于港区。 搬送｜はんそう⓪ 通報｜つうほう⓪ 歩行者｜ほこうしゃ② 手当て｜てあて①1. 准备，预备；2. （对伤病的）处置，救治；3. 报酬，工资；4. （基本工资之外的报酬）补贴，津贴。 コンクリート｜こんくりーと④(concrete) 混凝土。 何らか｜なんらか⓪①④什么，一些，某些，多少。 物々しい｜ものものしい1. 森严；2. 过分，小题大做。 ヘルメット｜へるめっと①③(helmet) 头盔。 2日午前、東京 港区のビルの解体工事現場で資材が落下して、下にいた警備員の頭に当たる事故があり、警備員は病院に搬送はんそうされましたが、意識不明の重体だということです。警視庁が詳しい状況を調べています。 9 月 2 日上午，在东京港区的大楼拆除工地现场发生了材料落下、砸到下面的警备员的事故，虽然警备员已经被搬送到了医院，但是仍然意识不明生命垂危。警视厅正在调查详细的状况。 2日午前9時半ごろ、港区芝大門しばだいもんのビルの解体工事現場で「建物の上から物が落下し、下にいた警備員がけがをした」と通報つうほうがありました。 2 日的上午 9 点半左右，在港区芝大门的大楼拆除现场通报了：“物体从建筑物上落下，砸伤了下面的警备员”。 警察官が駆けつけたところ、現場で歩行者ほこうしゃの誘導作業にあたっていた警備員の男性が頭から血を流して倒れていて、病院に搬送されて手当てを受けていますが、意識不明の重体だということです。 警察刚刚赶到，就看见了进行现场行人引导作业的男性警备员头部流血倒下了，虽然正在被搬运和接受救治，但是意识不明生命垂危。 警視庁によりますと、近くにはコンクリート混凝土片のようなものが散乱さんらんしていて、警視庁は工事の資材が何らかの原因で落下したとみて詳しい状況を調べています。 根据警视厅描述，附近散乱着像混凝土片一样的东西，警视厅正在调查工地的材料为什么落下的详细情况。 現場は、都営三田線の御成門駅から南東におよそ200メートル離れた会社やホテルなどが建ち並ぶところです。 现场是位于「都営三田線」的「御成門駅」东南大概 200 米远的公司和旅馆之类的并排建立的地方。 近くで作業の男性「ものものしい雰囲気で怖かった」 在附近干活的男人：“很森严的气氛有点恐怖。” 現場近くで電気工事の作業をしていた60代の男性は、「現場のほうから『早く来てください』と誰かを呼ぶ声が聞こえて事故に気付いた。現場を見ると、50代くらいの警備員の男性が倒れていて、その周辺には壁の一部やヘルメットが落ちていた。そのあと警察が来て現場を規制してものものしい雰囲気で怖かった」と話していました。 在现场附近从事电力工作的 60 岁的男人说：“从现场的方向听到‘快点过来！’的某人的呼喊，意识到发生了事故。从现场来看，50 岁左右的警备员倒在地上，他的周围散落着墙壁的一部分和安全帽。在这之后警察来了并对现场进行控制，森严的气氛有点恐怖。”","link":"/2024/09/02/translate_news_nhk_20240902_k10014569201000/"},{"title":"日语翻译 - 新闻 - 関東甲信 局地的に雷伴った激しい雨のおそれ 土砂災害など警戒","text":"关东甲信地区，局部恐怕有伴有雷电的暴雨，警戒泥石流灾害 来源：NHK 日期：2024-09-03 07:41 链接：関東甲信 局地的に雷伴った激しい雨のおそれ 土砂災害など警戒 🌟 单词： 雷｜かみなり③④ 関東甲信｜かんとうこうしん⓪ 土地｜とち⓪ 千島｜ちしま 停滞｜ていたい⓪ 佐倉｜さくら 北部｜ほくぶ① 地盤｜じばん⓪ 緩む｜ゆるむ② 雨量｜うりょう① 落雷｜らくらい⓪ 竜巻｜たつまき⓪ 突風｜とっぷう⓪ 積乱雲｜せきらんうん③ 頑丈｜がんじょう⓪ 前線の影響で、関東南部では局地的に非常に激しい雨が降っています。関東甲信では4日にかけて大気たいきが不安定な状態が続き、局地的に雷を伴った激しい雨や、非常に激しい雨が降るおそれがあり、気象庁は土砂災害や低い土地の浸水、川の増水ぞうすいに警戒するよう呼びかけています。 受到锋面的影响，关东南部正在局部地下非常大的暴雨。关东甲信地区 9 月 4 号大气都会持续处于不稳定的状态，并且有局部地降下伴有雷电的暴雨、非常大的暴雨的可能性，气象厅正在呼吁警戒泥石流灾害、低洼地区的浸水灾害和河流水位上涨（的问题）。 気象庁によりますと、関東の東から千島ちしまの東の海上に停滞ていたいしている前線に向かって暖かく湿った空気が流れ込んでいる影響で、関東甲信では大気の状態が非常に不安定になっています。 据气象厅描述，受到湿暖空气流入关东以东到千岛以东海上停滞的锋面的影响，关东甲信地区的大气的状态正在变得非常不稳定。 千葉県佐倉さくら市では午前7時20分までの1時間に50ミリの非常に激しい雨が降りました。 千叶县佐仓市在上午 7 点 20 分为止的 1 小时内降下了 50 毫米的大暴雨。 これまでの雨で千葉県では土砂災害の危険性が非常に高くなり土砂災害警戒情報が発表されている地域があります。 受到目前为止大雨的影响，千叶县存在泥石流灾害的危险性变得非常高、正在发布泥石流灾害警戒信息的地区。 関東甲信では4日にかけて大気の不安定な状態が続く見込みで、局地的に雷を伴った激しい雨や非常に激しい雨が降るおそれがあります。 预计关东甲信地区 4 号会保持大气不稳定的状况，有局部降下雷雨、大暴雨的可能性。 4日朝までの24時間に降る雨の量は、いずれも多いところで▽伊豆諸島いずしょとうで150ミリ、▽関東北部と南部で100ミリ、▽甲信で80ミリと予想されています。 到 4 日早上为止的 24 小时的降雨量，最多的是：伊豆诸岛预计 150 毫米关东北部和南部预计 100 毫米甲信地区预计 80 毫米 これまでの大雨で地盤じばんが緩んでゆるんでいるところがあり、今後、少ない雨量うりょうでも土砂災害の危険度が高まるおそれがあります。 由于到目前为止的大雨会让地面松弛，之后，恐怕即使是少量的大雨也会提高泥石流的危险度。 気象庁は、土砂災害や低い土地の浸水、川の増水に警戒するとともに落雷らくらいや竜巻たつまきなどの激しい突風とっぷうに注意し、急に冷たい風が吹くなど発達した積乱雲せきらんうんが近づく兆しきざしがある場合は、頑丈がんじょうな建物の中に移動するなど安全を確保するよう呼びかけています。 气象厅呼吁：警戒泥石流灾害、低地浸水、河流涨水的同时，注意落雷和龙卷风等强风，如果有急速的冷风之类的积乱云靠近的迹象，请采取向坚固的建筑中移动等措施以保证安全。","link":"/2024/09/03/translate_news_nhk_20240903_k10014570191000/"},{"title":"日语翻译 - 新闻 - 沖縄 歌や踊りささげる伝統の「シニーグ」地元中学生も初参加","text":"冲绳当日中学生首次参加献上歌唱和舞蹈的传统活动「シニーグ」 来源：NHK 日期：2024-08-30 05:45 链接：沖縄 歌や踊りささげる伝統の「シニーグ」地元中学生も初参加 🌟 单词： 初参加｜はつさんか⓪ 本部町｜もとぶちょう 五穀豊穣｜ごこくほうじょう五谷丰登。 神々｜かみがみ② 行事｜ぎょうじ①⓪ 紺色｜こんいろ⓪深蓝色。 練り歩く｜ねりあるく④⑤（结成队伍）游行，缓步前进。 円陣｜えんじん 祈願｜きがん① 多彩｜たさい⓪ 身近｜みぢか⓪ 沖縄県本部町では28日、五穀豊じょうごこくほうじょうや健康を願って、女性たちが神々に歌や踊りをささげる伝統行事「シニーグ」が行われました。 冲绳县本部市在 8 月 28 日，举行了祈求五谷丰登和健康、女性们向众神献上歌曲和舞蹈的传统仪式「シニーグ」。 本部町の「具志堅ぐしけん区のシニーグ」は、300年余りの伝統があると言われています。 据说本部市的「具志堅区のシニーグ」已经有了超过 300 年的历史。 28日は地元の中学校の女子生徒8人も初めて参加し、合わせて40人余りの女性たちが紺色こういろの着物を着て、集落を練りねり歩きながら、神々が降り立つとされる場所へ向かいました。 28 日当地中学的 8 名女学生也首次参加，总共 40 多人的女性们身着深蓝色的衣服，在村落中结队缓步行走，向着被当成神明降临的地方前进。 このあと白い衣装をまとった女性を先頭せんとうに、参加者たちが円陣えんじんを組んで踊る「シニーグ舞い」が行われ、地域の五穀豊じょうと健康などを祈願していました。 在这之后，以身着白色服装的女性为首，参加者们围成圆圈跳了「シニーグ舞い」（舞蹈），祈求这个地区的五谷丰登和人们健康。 生徒たちは1か月ほど練習を重ねたということで、多彩たさいな手の動きを披露ひろうしていました 学生们重复练习了一个月，展现出丰富的手部（舞蹈）动作。 女子生徒の1人は「足や手の動きが難しかったです。できるだけ参加して身近みぢかな人にも伝えていきたいです」と話していました。 一名女学生说：“脚部和手部的动作很难。想尽力参加活动、向身边的人传达（传统文化）。” また別の女子生徒は「地域の行事に参加できて楽しかったです。貴重な経験ができたので、後輩にも引き継いでいきたいです」と話していました。 还有别的女学生说：“能参加地区的活动非常开心。因为获得了宝贵的经验，我向继续引导后辈（也参与）。” 具志堅地区の金城均 区長は「子どもたちが成長してシニーグに参加してくれたらうれしいです。皆さんに関心を持ってほしいです」と話していました。 「具志堅」地区的金城均区长说：“孩子们成长了、参加了「シニーグ」非常令人欣喜。我希望大家也能对它保持关心。”","link":"/2024/09/05/translate_news_nhk_20240905_k10014563971000/"},{"title":"日语翻译 - 新闻 - 約3割が外国産“業務用野菜” リスク踏まえ国産調達の動き","text":"业务用蔬菜约有 3 成是外国产 由于风险开始出现国产采购动向 来源：NHK 日期：2024-09-04 06:51 链接：約3割が外国産“業務用野菜” リスク踏まえ国産調達の動き 🌟 单词： 纏まる｜まとまる⓪ 仕入れる｜しいれる③ 占める｜しめる② 手がける｜てがける③亲自动手。 玉ねぎ｜たまねぎ③洋葱。 拡大｜かくだい⓪ 長期｜ちょうき① 効率化｜こうりつか 抑える｜おさえる③② 卸｜おろし③①批发，批售，批卖，趸卖。 備える｜そなえる③② 工夫｜くふう⓪ 外国産がおよそ3割を占める業務用の野菜について、加工会社の中には、海外からの調達リスクを踏まえて、国産の調達を増やす動きが出ています。 关于外国产的蔬菜大概占采购总数的 3 成这件事，蔬菜加工公司根据从海外的采购风险，出现了增加国产采购的动向。 農林水産省によりますと、飲食店などに使われる業務用野菜のうち、外国産は、まとまった数量を比較的安く仕入れられることから、およそ20年にわたって全体の3割程度を占めるしめる状況が続いています。 据农林水产省描述，饭店之类的正在使用的业务用蔬菜中，外国产的由于购入的价格相对更便宜，占采购总量的 3 成左右大概已经持续 20 年了。 こうした中、加工会社の中には、海外からの調達リスクを念頭に、国産の調達を増やす動きが出ています。 在这其中，蔬菜加工公司考虑来自海外的采购风险，出现了增加国产采购的动向。 このうちカット野菜などを手がける「デリカフーズホールディングス」は、タマネギに洋葱。ついて、国産より割安な中国産を多く仕入れてきましたが、新型コロナが拡大した際、安定的に入ってこなかったことなどを踏まえ、国産の割合を増やす方針です。 在这这种从事蔬菜切割的「デリカフーズホールディングス」公司，虽然之前大量采购比国产更便宜的中国产洋葱，但是在新冠疫情扩散的时候，由于（洋葱）无法稳定地运送进来之类的原因，（采取）增加国产采购占比的方针。 農家との長期ちょうき契約や、物流の効率こうりつ化などで仕入れ価格を抑えおさえ、現在、4割程度の国産タマネギの割合を、5年後の2029年ごろまでに8割程度に引き上げる考えです。 （公司）考虑通过和农户签订长期合同、让物流更有效率之类的方式控制采购价格，将现在是 4 成国产洋葱的按比例，在 5 年后的 2029 年左右提升到 8 成。 大崎善保社長は「さまざまな理由で輸入の止まることに備えて、日本でしっかり野菜を作ることが大事だ。価格差を埋める工夫など、生産者と一緒に考えていきたい」と話していました。 大崎善保社长说：“防备由于各种原因导致的进口停止，在日本好好地生产蔬菜是非常重要的事情。想法设法弥补价格差之类的，会和生产者一起考虑。” 国産野菜の活用をめぐっては、農林水産省も、生産や卸おろし、外食などの事業者が参加する協議会で、利用拡大に向けた対策を検討しています。 围绕国产蔬菜的有效利用，农林水产省也通过生产、批发售卖和餐馆的从业者参加的协商会，讨论扩大利用的对策。","link":"/2024/09/04/translate_news_nhk_20240904_k10014570981000/"},{"title":"日语翻译 - 新闻 - 首都直下地震 被害想定見直しで国の会合 中長期的影響も検討へ","text":"首都正下方的地震，重新进行了预想受灾（评估）的国家会议，也讨论了中长期的影响 来源：NHK 日期：2024-09-05 22:03 链接：首都直下地震 被害想定見直しで国の会合 中長期的影響も検討へ 🌟 单词： 首都｜しゅと①② 直下｜ちょっか① 中長期｜ちゅうちょうき 兆｜ちょう①万亿。 算出｜さんしゅつ⓪ 元日｜がんじつ⓪ 教訓｜きょうくん⓪ 目処｜めど①目标，眉目，头绪。 首都直下地震の被害想定の見直しに向けた国の会合が開かれ、地震発生から1年間で、およそ95兆円にのぼるとされる経済被害について、中長期的な影響も踏まえて算出してはどうかといった意見があがり上がり、国は検討することにしています。 召开了就重新进行首都正下方地震的受灾预想（评估）的会议，关于从地震发生开始的一年间大概会造成 95 兆日元的经济损失的事情，（有人）提出了“是否是基于中长期的影响而算出”的意见，国家正在开会讨论。 首都直下地震について、国は2013年に公表した被害想定などの見直しに向けて、2023年12月にワーキンググループを立ち上げ、9月5日に開かれた5回目の会合では、経済への影響などをテーマに地震や経済の専門家などからなる委員が意見を交わしました。 关于首都正下方的地震，国家为了重新评估 2013 年公布的受害假定等，于 2023 年 12 月成立工作组，在 9 月 5 日召开的第 5 次会议上，由地震和经济的专家组成的委员以（地震）对经济的影响为主题交换了意见。 会合は非公開で行われ、国によりますと、地震発生から1年間でおよそ95兆円にのぼるとする経済被害について、委員から「阪神はんしん・淡路あわじ大震災では復旧に20年かかる地域もあったため、中長期的に試算してもいいのではないか」といった意見があがったということです。 会议是非公开的，由国家决定的关于地震发生开始的一年间大概会造成 95 兆日元的经济损失的事，委员提出了意见：“在阪神・淡路大地震中也有花了 20 年才恢复的地区，进行中长期的试算似乎更高。” 国は、5日の意見を受けて、長期的な経済への影響を算出できるか検討することにしています。 国家接受了 9 月 5 号（委员的）意见，正在讨论是否能算出（地震发生后）对长期经济的影响。 ワーキンググループは、今後も議論を重ね、年明け以降に新たな被害想定を取りまとめたうえで、元日に発生した能登半島地震の教訓も踏まえて、2025年秋ごろをめど目処に対策を盛り込んだ基本計画を見直す方針です。 工作组之后也会重复讨论，不仅是汇总年初以后新的受灾假设，也会基于元旦发生的能登半岛地震的教训，在 2025 年秋左右重新制定加入对策的基本计划。","link":"/2024/09/06/translate_news_nhk_20240905_k10014573741000/"},{"title":"日语翻译 - 新闻 - ボーイングの宇宙船 スターライナー 無人で地球帰還の飛行開始","text":"波音公司的宇宙飞船“星际航线”号开始以无人的形式飞回地球 来源：NHK 日期：2024-09-07 09:00 链接：ボーイングの宇宙船 スターライナー 無人で地球帰還の飛行開始 🌟 单词： 航空機｜こうくうき③ 考慮｜こうりょ① 噴射｜ふんしゃ⓪ 徐々｜じょじょ① 大気圏｜たいきけん③ 打ち上げ後に見つかった不具合のため宇宙飛行士を乗せて帰還することを断念した、航空機大手ボーイングの宇宙船「スターライナー」が、無人の状態で国際宇宙ステーションから切り離され、地球への帰還に向けて飛行を始めました。 发射后才发现有问题导致宇航员无法乘坐其返航的、波音航空公司的宇宙飞船“星际航线”号，以无人的状况从国际宇宙空间站分离，开始朝着地球返航。 アメリカのボーイングが開発を進めてきた新しい宇宙船スターライナーは、ことし6月、試験飛行のため、NASA＝アメリカ航空宇宙局の宇宙飛行士2人を乗せて打ち上げられ、国際宇宙ステーションに到着しました。 美国波音公司推进开发的新的宇宙飞船“星际航线”号，在今年 6 月为了试验飞行，将 NASA 的两名宇航员运载发射，达到了国际宇宙空间站。 宇宙船は当初、1週間程度で地球に戻る予定でしたが、推進装置の一部に不具合が見つかり、NASAは先月、安全性を考慮した結果、2人を乗せて帰還させることを断念していました。 宇宙飞船当初预定是在 1 周左右后返回地球，但是发现了推进装置的一部分有问题，作为安全性考虑的结果，NASA 在上个月放弃了让 2 人乘坐其返回的念头。 この宇宙船が日本時間の7日朝、地球に帰還するため、無人の状態で国際宇宙ステーションから切り離されました。 这个宇宙飞船在日本时间的 7 日早上，因为（要）返回地球，以无人的状况从国际宇宙空间站分离了。 宇宙船はこのあと、エンジンを噴射しながら徐々に高度を下げて大気圏たいきけんに突入する予定で、7日午後にも地上に戻る予定です。 宇宙飞船在这之后，预计会一遍喷射燃料一遍徐徐下降进入大气层，并在 7 日的午后返回地面。 スターライナーは、今回の試験飛行を経てNASAが承認すれば、宇宙飛行士が国際宇宙ステーションと地球との間を行き来する手段になる予定でしたが、今後の見通しは立っていません。 “星际航线”号，如果经过了这次的试验飞行被 NASA 承认的话，预计会称为宇航员们在国际宇宙空间站和地球之间的来往的手段，但是今后的前途并不明朗。 一方、スターライナーに乗っていた2人の飛行士は、このまま宇宙ステーションにとどまり、来年2月に別の宇宙船で帰還する計画です。 另一方面，乘坐了“星际航线”号的两位宇航员，预计只能就这样呆在宇宙空间站，在明年 2 月乘坐别的宇宙飞船返回了。","link":"/2024/09/07/translate_news_nhk_20240907_k10014575401000/"},{"title":"日语翻译 - 新闻 - 70代男性 散歩中クマに襲われ頭や腕に大けが 山口 岩国","text":"山口县岩国市，70 岁的男性在散步中被熊袭击，头部和手腕受伤严重 来源：NHK 日期：2024-09-08 12:43 链接：70代男性 散歩中クマに襲われ頭や腕に大けが 山口 岩国 🌟 单词： 襲う｜おそう⓪② 別状｜べつじょう⓪不正常的情况，异状，毛病。 相次ぐ｜あいつぐ①相继发生，连续不断。 両腕｜りょううで⓪ パトカー｜ぱとかー②③巡逻车，警车。 8日朝、山口県岩国市で山道を散歩していた70代の男性がクマに襲われ、頭や腕などに大けがをしました。男性は命に別状ないということですが、県内ではクマの目撃情報が相次いでいることから、警察などは注意を呼びかけています。 9 月 8 日早上，山口县岩国市在山路上散步的 70 岁的男性被熊袭击了，头和手腕之类的受伤严重。虽然该男性没有生命危险，但是因为县内陆续有熊的目击情报，警察正在呼吁注意。 8日午前6時20分ごろ、岩国市本郷町波野ほんごうまちはのの住民から消防に、70代の男性が「クマに襲われた」と言って駆け込んできたという通報がありました。 8 日上午的 6 点 20 分左右，岩国市「本郷町波野」地区的居民向消防通报称有 70 岁的男性说着“被熊攻击了”，然后跑了进来。 警察によりますと、男性は頭や両腕に大けがをしていて、病院に搬送されましたが、意識はあり、命に別状はないということです。 据警察所述，男性的头和手腕都受伤严重，已经送到了医院，但任然有意识、也没有生命危险。 この地域は住宅が点在する山あいの集落で、男性は山道を散歩していたところ、突然クマに襲われたと話しているといういうことです。 这个地区是散步着住宅的山间村落，据说男性在山路上散步的时候，突然被熊袭击了。 クマはその後、山の中に逃げていったということで、警察は、クマの行方や男性が襲われた状況を調べるとともに、パトカーで近くの住民に注意を呼びかけています。 据说熊在之后，逃回了山里。警察不仅调查熊的去向和男性被袭击的情况，还在通过巡逻车呼吁周遭居民注意。 山口県によりますと、県内ではことし4月から8月末までの5か月間に、去年の同じ期間と比べて2倍近い317件のクマの目撃情報が寄せられています。 据山口县所述，从 4 月开始到 8 月末到 5 个月时间中，被告知和去年同期相比近 2 倍多的 317 件的熊目击情报。 山口県内でクマに襲われてケガをしたのは、2年前のおととし6月に岩国市美川みかわ町で70代の男性が襲われて以来だということです。 （本次）山口县被熊袭击受伤的事，是（2 年前的）前年 6 月在岩国市美川镇发生的 70 岁男性被熊袭击以来的首次。","link":"/2024/09/08/translate_news_nhk_20240908_k10014576171000/"},{"title":"日语翻译 - 新闻 - コンビニなどで低価格帯の商品拡充する動き 続く節約志向で","text":"便利店等有扩充低价格区商品的动向 （消费者）继续有节约的意向 来源：NHK 日期：2024-09-09 06:34 链接：コンビニなどで低価格帯の商品拡充する動き 続く節約志向で 🌟 单词： 低価格帯｜ていかかくたい 拡充｜かくじゅう⓪ 志向｜しこう⓪ お握り｜おにぎり②手握饭团。 工程｜こうてい⓪ 洗剤｜せんざい⓪ 日用品｜にちようひん⓪ 品ぞろえ｜しなぞろえ商品丰富。 幅広い｜はばひろい④广泛。 限定｜げんてい⓪ 焦点｜しょうてん① 物価高を背景に消費者の節約志向が続く中、コンビニやスーパーでは、顧客を呼び込むため低価格帯の商品を拡充する動きが出ています。 在高物价的背景下，消费者的节约意向在持续，便利店和超市等因为顾客的呼吁而出现了扩充低价格区商品的动向。 コンビニ大手の「セブン-イレブン・ジャパン」は、ことし7月におにぎりお握り手握饭团。2種類を値下げしたほか、今月には、3種類の弁当の価格を引き下げました。 大型连锁便利店 711 在今年 7 月下调了 2 种手握饭团的价格，不止如此在这个月还下降了 3 种便当的价格。 原材料の調達の見直しや製造工程こうていの効率化によって価格を抑えることができたということで会社は今後、トイレットペーパーや洗剤せんざいなどの日用品についても低価格帯の商品を拡充するとしています。 得益于原材料的采购恢复和制造工程的效率化，降低价格的事情也变得可能，因此关于卫生纸和洗涤剂之类的日用品，公司之后也会继续扩充其低价格区的商品。 セブン-イレブン・ジャパンの羽石はねいし奈緒なお商品本部長は「コンビニは割高だというイメージを変えたいと思っている。物価の上昇が続く中、今後も商品の見直しを進め、幅広く来店してもらえるような品ぞろえ商品丰富。を目指していきたい」と話していました。 711 的羽石奈緒商品本部長说：“我们想要改变便利店价格过高的印象。在物价持续上涨的情况下，今后也会持续修改商品，以商品丰富吸引顾客作为目标。” またコンビニチェーンの「ミニストップ」は、ことし7月から従来より価格を抑えたおにぎりやパンなどのシリーズを新たに設けています。 还有便利连锁店 Ministop 从今年 7 月以来，新上架了比以往价格更低的手握饭团和面包等。 このほか、スーパー各社の中には、食品や日用品を期間限定で値下げする取り組みを進めるところもあります。 还有超市的各公司种，也在努力推进限时的食品和日用品降价活动。 物価高を背景に消費者の節約志向が続く中、コンビニやスーパーのこうした動きが需要の取り込みにどこまでつながるかが焦点となります。 高物价背景下消费者持续希望节省的情况下，便利店和超市的这一举动能在多大程度上吸引需求成为焦点。","link":"/2024/09/09/translate_news_nhk_20240909_k10014576511000/"},{"title":"日语翻译 - 新闻 - 川崎 団地の部屋の前のすだれに火付けた疑い 28歳の容疑者逮捕","text":"川崎市，有将住宅区的房屋门前的竹帘点燃的嫌疑，逮捕了 28 岁的嫌疑人 来源：NHK 日期：2024-09-10 09:39 链接：川崎 団地の部屋の前のすだれに火付けた疑い 28歳の容疑者逮捕 🌟 单词： 団地｜だんち⓪①住宅区。 簾｜すだれ⓪竹帘，横条纹的纺织品，卷寿司的小竹帘。 不審火｜ふしんび②原因不明的火灾。 関与｜かんよ①干预，参与。 仄めかす｜ほのめかす④暗示，略微表示，略微透露。 住人｜じゅうにん⓪ 放火｜ほうか⓪ 供述｜きょうじゅつ⓪ 段ボール｜だんぼーる③瓦楞纸。 ベンチ｜べんち①(bench) 长凳。 集積場｜しゅうせきじょう堆积场。 強盗｜ごうとう⓪ 未遂｜みすい⓪ 先月、川崎市幸区さいわいくの県営けんえい団地で住人の28歳の容疑者が、団地の別の部屋の前にあったすだれに火を付けたとして逮捕されました。 上个月，在川崎市幸区的「県営」住宅区居住的 28 岁的嫌疑人，因为点燃住宅区其他房屋门前的竹帘而被捕。 警察によりますと容疑者はこの団地で相次いだほかの2件の不審火についても、関与かんよをほのめかしているということで警察は関連を捜査しています。 据警察所述，嫌疑人与这个住宅局相继发生的其他两期原因不明的火灾似乎有些关系，因此被警察连带着搜查。 逮捕されたのは、現場の川崎市幸区の県営団地の住人で無職、宮川怜斗容疑者（28）です。 被逮捕的是，居住在火灾现场的川崎幸区的「県営」住宅区的、无业的 28 岁嫌疑人宮川怜斗。 警察によりますと、先月23日、同じ団地の60代の女性が住む部屋の前にあったすだれに火を付けたとして、放火の疑いがもたれています。 据警察所述，上个月 23 号，同住宅区的住有 60 岁女性的房屋门前的竹帘着火了，存在被人放火的嫌疑。 今月9日夜、容疑者が「話を聞いてほしい」などと警察に電話をかけ、事情を聴いたところ、火を付けたことを認めたことなどから逮捕しました。 本月的 9 日晚上，嫌疑人打电话给警察说“你们听我说”之类的，并询问了事情经过，警方因其承认纵火而将其逮捕。 調べに対し、「私がしたことに間違いありません」と供述きょうじゅつしているということです。 针对调查，他说了：“就是我做的没错。” この団地では、先月、ほかにもすだれや段ボールなどが焼ける不審火が2件相次いでいて警察によりますと、容疑者が関与をほのめかす供述をしているということです。警察は、関連を捜査しています。 上个月这个住宅区还相继发生 2 件其他的竹帘和瓦楞纸着火的不明火灾，据警方称，嫌疑人提供了暗示参与的供述。警方正在调查相关事情。 一方 周辺の不審火 別の容疑者が一部関与認める 另外，（嫌疑人）承认了周边的不明火灾，其他的嫌疑人也参与了一部分 一方、団地の周辺でも、公園のベンチや集積場のごみが焼ける不審火が5件相次ぎました。 另外，住宅区周边，也相继发生了 5 件公园的长椅和堆积场的垃圾发生不明原因火灾的事情。 捜査関係者によりますと、横浜市で起きた強盗ごうとう未遂みすい事件で先月、逮捕された56歳の容疑者が一部について関与を認めているということで、警察は詳しく調べています。 据调查相关方所述，因为上个月在横滨市发生的抢劫未遂事件而被逮捕的 56 岁的嫌疑人，承认与一些（火灾）有关联，警察正在做更详细的调查。","link":"/2024/09/10/translate_news_nhk_20240910_k10014577671000/"},{"title":"日语翻译 - 新闻 - 中国 8月の新車販売台数 3か月連続減少 国内販売の低迷で","text":"中国 8 月份的新车销量由于国内销售情况低迷已经连续 3 个月下滑 来源：NHK 日期：2024-09-10 17:55 链接：中国 8月の新車販売台数 3か月連続減少 国内販売の低迷で 🌟 单词： 台数｜だいすう③ 欧米｜おうべい⓪ 占める｜しめる② 主な｜おもな① プラス｜ぷらす⓪①1. (plus) 加号，正数记号。2. 利益，好处，盈余。 堅調｜けんちょう⓪（行情）坚挺，上升倾向，涨价趋势。 輸出｜ゆしゅつ⓪ 補助｜ほじょ① 中国の8月の新車の販売台数は、国内販売の低迷で、3か月連続で減少しました。輸出は拡大が続いているものの、中国製のEV＝電気自動車をめぐって欧米で関税引き上げの動きが出ていて、先行きには不透明感が広がっています。 中国 8 月的新车销量，由于国内销售情况低迷，已经连续 3 个月下滑了。虽然在持续扩大出口，但是欧美围绕中国产的电车采取了提高关税等措施，前景的不明朗扩大了。 中国の自動車メーカーなどでつくる「自動車工業協会」によりますと、8月の新車の販売台数は、輸出も含めて245万3000台となり、去年の同じ月と比べて5％減り、3か月連続の減少となりました。 据中国的汽车制造厂组成的“汽车工业协会”所述：8 月的新车销量，加上出口的总计是 245 万 3000 台，和去年的同月相比减少了 5%，已经连续 3 个月下滑了。 これは、新車販売の8割近くを占める中国国内での販売台数が、消費者の間で節約志向が強まる中、去年の同じ月と比べて10.7％減ったことが主な要因です。 主要原因是：占新车销量靠近 8 成的中国国内的销量，在消费者之间节省意向加强的情况下，和去年相比减少了 10.7%。 一方、EVなどの「新エネルギー車」の販売は、去年の同じ月と比べて30％のプラスと堅調けんちょうで、販売台数に占める新エネルギー車の割合は、44.8％となりました。 另一方面，EV 之类的新能源汽车的销售，和去年同期相比提升了 30%，新能源汽车占总销量的比例，到了 44.8%。 また、ガソリン車も含めた全体の輸出台数は、51万1000台と、去年の同じ月と比べて25.4％増え、輸出が新車販売を支える形となっています。 然后，包含汽油车的整体的出口量是 51 万 1000 台，和去年同期相比增加了 25.4%，出口正在成为新车销量的支柱。 ただ、中国製のEVをめぐっては、補助金によって不当に安く輸出されているなどとして、欧米で関税引き上げの動きが出ていて、先行きには不透明感が広がっています。 不过，围绕中国产的新能源汽车，因为凭借补助金而进行不正当的便宜价格出口，欧美等国采取了提高关税的措施，使得前景更不明朗。","link":"/2024/09/10/translate_news_nhk_20240910_k10014578111000/"},{"title":"日语翻译 - 新闻 - 中国 定年延長法案を審議 “労働人口減少の歯止めをねらい”","text":"中国审议延迟退休的法案“以抑制劳动人口的减少作为目标” 来源：NHK 日期：2024-09-11 01:01 链接：中国 定年延長法案を審議 “労働人口減少の歯止めをねらい” 🌟 单词： 歯止め｜はどめ⓪③1. 刹住，制止，抑制；2. 车闸，制动器；3. 楔子，挡头。 少子高齢化｜しょうしこうれいか 全人代｜ぜんじんだい③ 人民｜じんみん⓪ 建国｜けんこく⓪ 定める｜さだめる③ 間もない｜まもない指某件事物发生之后没有经过多少时间，刚刚。 財政｜ざいせい⓪ 失業率｜しつぎょうりつ③ 高止まり｜たかどまり③居高不下。 🌟 惯用句： ひっ迫する｜ひっぱくする严重影响。 中国の国営テレビは、急速に進む少子しょうし高齢化に対応するため、段階的に定年を延長する法案を国会に当たる相当于。立法機関で審議したと伝えました。労働人口の減少に歯止めをかけることなどがねらいですが、若い世代の雇用を奪うことになるのではないかという懸念も出ています。 据中国国家电视台报道：为了应对急速的少子高龄化，相当于国会的立法机关审议了分阶段延迟退休的法案。虽然是以抑制劳动人口的减少作为目标，但是也产生了会不会剥夺年轻人的工作这样的疑问。 国営の中国中央テレビは、立法機関に当たる全人代ぜんじんだい＝全国人民じんみん代表大会の常務委員会で10日、定年の延長に関する法案を審議したと伝えました。 据国营的中国中央电视台报道：作为立法机关的全国人名代表大会的常务委员会，在 10 日审议了延长退休相关的法案。 中国では、建国けんこくまもない1950年代に定年年齢が定められさだめられ、男性はすべての従業員が60歳、女性は幹部が55歳で、そのほかの従業員が50歳となっています。 中国在刚建国没多久的 1950 年确定了退休年龄：全部男性作为职工 60 岁（退休），女性干部是 55 岁、其他的职工是 50 岁（退休）。 ただ、近年は、急速に少子高齢化が進み、2035年ごろには60歳以上の人口が4億人を超え全体の3割以上を占めるという予測もあり、労働人口の減少やひっ迫する年金財政ざいせいに対応する必要があるとして、定年を延長する議論が本格化していました。 但是，最近几天少子高龄化急速加剧，预计 2035 年左右 60 岁以上的人口会超过 4 亿人占全体人口的 3 成，为了应对劳动人口的减少和紧张的养老金财政，延迟退休的讨论被正式化了。 具体的な法案の内容は明らかになっていませんが、男女とも今後、段階的に65歳まで延長する案などが伝えられています。 虽然具体的法案内容还未明确，但是已经有传言说无论男性还是女性今后都会分阶段地延迟到 65 岁退休。 ただ、中国経済の減速などを背景に若い世代の失業しつぎょう率が高止まっていて、定年の延長は若い世代の雇用を奪うことになるのではないかという懸念も出ています。 但是，在中国经济增速放缓的背景下，年轻人的失业率居高不下，也有人怀疑延迟退休会不会剥夺年轻人的工作机会。","link":"/2024/09/11/translate_news_nhk_20240911_k10014578661000/"},{"title":"日语翻译 - 新闻 - “運転していない男性”を警察が誤認逮捕 愛知の交通事故で","text":"在爱知县的交通事故中，警察错误逮捕了“没有驾驶的男性” 来源：NHK 日期：2024-09-12 09:06 链接：“運転していない男性”を警察が誤認逮捕 愛知の交通事故で 🌟 单词： 愛知県｜あいちけん 同乗｜どうじょう⓪ 過失｜かしつ⓪ 電柱｜でんちゅう⓪ 衝突｜しょうとつ⓪ ベトナム人｜べとなむじん越南人。 画像｜がぞう⓪ 釈放｜しゃくほう⓪ 怠る｜おこたる③⓪ 鵜呑み｜うのみ⓪ 11日、愛知県西尾市内で起きた交通事故で、車を運転しておらず、同乗どうじょうしていた男性を誤って過失運転傷害の疑いで逮捕していたと、西尾警察署が発表しました。副署長は「誤って逮捕した方に大変申し訳ない」などとコメントしています。 9 月 11 日，西尾警察局发布了消息：在爱知县西尾市内发生的交通事故中，错误地以开车过失伤人嫌疑逮捕了同乘的、并没有开车的男性。副局长就此评价：“对于错误逮捕的男性感到非常抱歉！” 西尾警察署によりますと、11日午後3時半ごろ、西尾市内の県道で乗用車が電柱でんちゅうに衝突しょうとつしたあと、走ってきたトラックと衝突する事故があり、トラックを運転していた男性が足にけがをしました。 据西尾警察局描述：11 日下午 3 点半左右，在西尾市内的县道发生了轿车撞了电线杆之后、又撞上开来的卡车的事故，驾驶卡车的男性脚受伤了。 警察は目撃者からの「運転席から出てきた」という情報に基づいて、乗用車に乗っていた30歳のベトナム人の男性を過失運転傷害の疑いでその場で逮捕しました。 警察基于来自目击者的“从驾驶座位出来”的信息，以开车过失伤人嫌疑当场逮捕了乘坐轿车的 30 岁的越南男性。 ところが、事故のあと、現場から立ち去さっていた別の人物が30分ほど後に戻ってきて「自分が運転していた」と警察官に話したため、ドライブレコーダーの画像がぞうを調べたところ、逮捕された男性が運転していなかったことがわかったということです。 然而，由于事故之后、从事故现场逃离的其他人在 30 分钟后回来并向警察说“是我开的车。”，警察调查了行车记录仪，之后明白了已经被逮捕的男性并没有开车的事情。 男性は当初から「運転していない」と否認していたということで、警察は誤って逮捕したことを認めて男性を釈放しゃくほうし、12日未明、運転していたベトナム人の男を過失運転傷害の疑いで逮捕しました。 （再加上）误捕的男性从一开始就说着“没有开车”来进行否认，警察便承认了错误逮捕的事情并释放了该男性。12 日凌晨，以开车过失伤人罪将实际开车的男性逮捕了。 西尾警察署は目撃情報をうのみうのみにして確認を怠ったおこたったとしていて、纐纈靖央 副署長は「誤って逮捕してしまった方に大変申し訳なく思っています。今後、署員の指導を徹底し、再発防止につとめる」とコメントしています。 对于西尾警察署对目击信息不严谨、怠慢确认的是，副局长纐纈靖央表示：“我对错误逮捕的男性感到非常抱歉！今后会贯彻对警员的指导，努力不（让这种事情）再次发生！”","link":"/2024/09/12/translate_news_nhk_20240912_k10014579791000/"},{"title":"日语翻译 - 新闻 - 米 民間宇宙船 アポロ計画以降 有人では地球から最も遠くに","text":"美国，民间宇宙飞船到达了阿波罗计划之后载人飞船离地球的最远距离 来源：NHK 日期：2024-09-12 08:09 链接：米 民間宇宙船 アポロ計画以降 有人では地球から最も遠くに 🌟 单词： 民間人｜みんかんじん 付近｜ふきん②① 所属｜しょぞく⓪ 衛星｜えいせい⓪ 民間人4人を乗せて打ち上げられたアメリカの宇宙船が高度およそ1400キロに到達し、アメリカのアポロ計画以降では、人が乗った宇宙船としては地球から最も離れた場所を飛行しました。 四位民间宇航员乘坐发射的美国的宇宙飞船到达了高度大约 1400 千米的高度，是美国的阿波罗计划之后的，载人飞船飞行的距离地球最远的地方。 アメリカの民間企業スペースXの宇宙船「クルードラゴン」は10日、民間人4人を乗せてフロリダ州にあるケネディ宇宙センターから打ち上げられ、地球をまわる軌道を飛行しています。 美国的民间企业 Space X 的龙飞船在 9 月 10 日，搭载四位民间宇航员从佛罗里达州的肯尼迪航天中心发射升空，绕地球按轨道飞行。 11日、この宇宙船がエンジンを噴射して軌道を変更し、高度およそ1400キロに到達しました。 9 月 11 号，该宇宙飞船引擎喷射变更轨道，达到了约 1400 千米的高度。 スペースXによりますと、およそ50年前、人類が地球と月を行き来したアメリカのアポロ計画以降では、有人の宇宙船が地球から最も離れた場所を飛行したことになるということです。 据 Space X 所述：（这个是）大概 50 年前人类往返地球和月球的阿波罗计划之后的、载人宇宙飞船飞到的距离地球最远的地方。 宇宙船にはアメリカのIT企業の創業者ジャレッド・アイザックマン氏ら4人の民間人が乗っていて、12日は、高度700キロ付近ふきんでスペースXが開発した宇宙服を着て宇宙船から外に出る「船外活動」が行われる予定です。 宇宙飞船由美国 IT 企业创业家贾里德·艾萨克曼等四人乘坐，预计在 12 日高度 700 千米附近，他们将穿上由 Space X 开发的宇航服到宇宙飞船外面进行“舱外活动”。 国の宇宙機関に所属しょぞくしない民間人が宇宙空間での船外活動に成功すれば、宇宙開発の歴史上、初めてのことになります。 如果不属于国家宇宙机关的民间宇航员成果进行舱外活动的话，将成为宇宙开发历史上的首例。 今回の飛行はアイザックマン氏らが企画した「ポラリス計画」というプロジェクトの一環いっかんで、このほかにも通信用の人工衛星を使った実験などが行われる予定です。 这次的飞行是艾萨克曼规划的“北极星黎明”项目种的一环，在这之外还预计进行使用通信用的人工卫星的实验。","link":"/2024/09/12/translate_news_nhk_20240912_k10014579851000/"},{"title":"日语翻译 - 新闻 - 米実業家ら 民間人初の「船外活動」高度700キロ付近の宇宙空間","text":"美国企业家等在高度 700 千米附件的宇宙空间进行了作为民间宇航员的首次“舱外活动” 来源：NHK 日期：2024-09-13 00:11 链接：米実業家ら 民間人初の「船外活動」高度700キロ付近の宇宙空間 🌟 单词： 上空｜じょうくう⓪ ハッチ｜はっち①(hatch) 舱口，升降口。 ケーブル｜けーぶる①⓪(cable) 电缆。 手すり｜てすり⓪③扶手。 掴み｜つかみ③ 真空｜しんくう⓪ 滞在｜たいざい⓪ 大気圏｜たいきけん③ パラシュート｜ぱらしゅーと③(parachute) 降落伞。 地球の上空じょうくう高度700キロ付近の宇宙空間で12日、アメリカの実業家ら4人を乗せた宇宙船のハッチが開き、宇宙服姿の2人が宇宙船の外に体を出す「船外活動」を行いました。国の宇宙機関に所属しない民間人が宇宙空間での船外活動を行うのは宇宙開発の歴史上初めてです。 9 月 12 日，在地球上空 700 千米附近的宇宙空间，美国的企业家等 4 人乘坐的宇宙飞船打开了舱门，身着宇航服的 2 人进行了将身体伸出了宇宙飞船的“舱外活动”。不属于国家宇宙部门的民间宇航员在宇宙空间进行舱外活动，这是宇宙开发历史上的首例。 アメリカの民間企業スペースXの宇宙船「クルードラゴン」は今月10日、民間人4人を乗せてフロリダ州にあるケネディ宇宙センターから打ち上げられ、地球をまわる軌道を飛行しています。 美国的民间企业 SpaceX 的宇宙飞船“龙飞船”在本月 10 日，搭载 4 名民间宇航员从佛罗里达州的肯尼迪航天中心发射，在围绕地球的轨道上飞行。 12日は宇宙船に乗っているアメリカのIT企業の創業者ジャレッド・アイザックマン氏ら2人が、宇宙船の外に出る「船外活動」を行いました。 12 日乘坐宇宙飞船的 IT 企业创业家贾里德·艾萨克曼等 2 人，进行了出舱的“舱外活动”。 日本時間の午後8時前、高度700キロ付近の宇宙空間で宇宙船のハッチが開くと、アイザックマン氏ら2人が順番に、スペースXが開発した宇宙服を着て宇宙船の外に体を出しました。 日本时间的下午 8 点前，高度 700 千米附近的宇宙空间，宇宙飞船的舱门一打开，艾萨克曼等 2 人就按顺序，身穿 SpaceX 开发的宇航服将身体伸出了宇宙飞船。 2人は宇宙船とケーブルでつながれた状態で、手すりをつかみながらそれぞれ数分間、宇宙空間に体を出し、宇宙服の状態の確認などを行いました。 2 人在与宇宙飞船保持电缆（生命维持系统）连接的状态下，握着扶手的同时分别在数分钟内，将身体伸向宇宙空间，进行了宇航服的状态确认等。 国の宇宙機関に所属しない民間人が宇宙空間での船外活動を行うのは宇宙開発の歴史上初めてです。 不属于国家宇宙部门的民间宇航员在宇宙空间进行舱外活动，这是宇宙开发历史上的首例。 今回の飛行はアイザックマン氏らが企画した「ポラリス計画」というプロジェクトの一環で、民間初の船外活動を行って新しく開発された宇宙服の性能を確かめるほか、通信用の人工衛星を使った実験などが行われる予定です。 本次的飞行是艾萨克曼计划的“北极星计划”中的一环，除了进行非官方的首次舱外活动、确认新开发的宇航服的性能外，还预计进行使用通信用的人工卫星的实验。 「ポラリス計画」有人での宇宙飛行を3回実施予定 “北极星计划”预计进行 3 次的载人宇宙飞行 今回の飛行計画はアメリカの実業家、ジャレッド・アイザックマン氏らが企画した宇宙開発プロジェクト「ポラリス計画」の一環として行われます。 本次的飞行是作为美国企业家艾萨克曼计划的“北极星计划”中的一环进行的。 このプロジェクトでは、有人での宇宙飛行をあわせて3回実施する予定です。 这个项目，预计进行 3 次的载人宇宙飞行。 今回はその1回目にあたり、アメリカの宇宙開発企業スペースXの宇宙船「クルードラゴン」にアイザックマン氏ら4人が乗って、宇宙空間でさまざまな活動を行う計画です。 本次是（其计划三回中的）第一回，计划艾萨克曼等 4 人乘坐美国的宇宙开发公司 SpaceX 的宇宙飞船“龙飞船”，在宇宙空间进行各种各样的活动。 計画では、宇宙船はアメリカ・フロリダ州にあるケネディ宇宙センターから打ち上げられたあと、高度およそ1400キロを通る軌道に入ります。 计划是，宇宙船从美国佛罗里达州的肯尼迪航天中心发射之后，进入高度达到约 1400 千米的轨道。 これは、およそ50年前、人類が地球と月を行き来したアメリカのアポロ計画以降では有人の宇宙船が地球から最も離れた場所を飛行したことになるということです。 这是大概 50 年前，人类往返月球的美国阿波罗计划之后的，载人宇宙飞船飞到的离地球最远的地方。 打ち上げから3日目には、高度700キロ付近でアイザックマン氏ともう1人の乗組員が船外活動を行う予定です。 预定在发射后的第 3 天，在高度 700 千亩附近艾萨克曼和另外一名机组成员进行舱外活动。 国の宇宙機関に所属しない民間人が宇宙空間での船外活動に成功すれば、宇宙開発の歴史上初めてのことになります。 如果（本次）非官方宇宙机构的民间宇航员在宇宙空间的舱外活动成功的话，这将是宇宙开发历史上的首例。 この時、宇宙船の内部も真空しんくう状態になるため、船外に出る2人に加えて船内に残る2人もスペースXが新しく開発した宇宙服を着用することになっています。 （舱外活动）的时候，宇宙飞船内部也将变成真空状态，出舱的 2 人机上船内剩余的 2 人都将穿着 SpaceX 新开发的宇航服。 その後、スペースXが打ち上げたインターネット通信用の人工衛星「スターリンク」を使った実験を行う予定です。 在这之后，预定进行使用 SpaceX 发射的网络通信用的人工卫星“星链”的实验。 宇宙船はおよそ5日間、宇宙空間に滞在たいざいし、打ち上げから6日目、宇宙船は大気圏たいきけんに突入してアメリカ・フロリダ州沖おきにパラシュートを使って着水ちゃくすいする予定です。 宇宙飞船大概会在宇宙空间滞留 5 天，在发生后的第 6 天，宇宙飞船会进入大气层，朝向美国佛罗里达州，使用降落伞降落到水面上。","link":"/2024/09/14/translate_news_nhk_20240912_k10014580571000/"},{"title":"日语翻译 - 新闻 - 千葉 我孫子 ひき逃げ死亡事件 80歳の容疑者を逮捕","text":"千叶县我孙子市，发生了肇事逃逸致人死亡事件，逮捕了 80 岁的嫌疑人 来源：NHK 日期：2024-09-13 08:49 链接：千葉 我孫子 ひき逃げ死亡事件 80歳の容疑者を逮捕 🌟 单词： 我孫子市｜あびこし 轢き逃げ｜ひきにげ⓪肇事逃逸。 部品｜ぶひん⓪零件。 自称｜じしょう⓪ ぶつかる｜ぶつかる⓪撞到，碰到。 経緯｜いきさつ① 11日、千葉県我孫子市で77歳の男性がひき逃げされて死亡した事件で、警察は県内の80歳の容疑者をひき逃げなどの疑いで逮捕しました。調べに対し、容疑を否認しているということです。 9 月 11 日，千叶县我孙子市发生了 77 岁的男性遭遇交通事故肇事逃逸死亡的事件，警察以交通肇事逃逸嫌疑逮捕了县内的 80 岁的嫌疑人。面对调查，嫌疑人进行了否认。 11日午後6時すぎ、我孫子市相島新田の国道沿いで、近くに住む福井憲男さん（77）が倒れているのが見つかり、その後、死亡しました。 在 11 日下午 6 点后，在我孙子市相岛新田的国道边，有人发现了住在附近的福井憲男先生倒在地上，之后，去世了。 警察は現場から黒っぽい車の部品が見つかったことなどから、ひき逃げ事件として捜査していました。 警察从现场发现了类似黑车的零件，之后将此事作为肇事逃逸事件进行了调查。 その結果、千葉県香取市かとりしの住宅で前方が壊れた車を見つけ、この家に住む自称じしょうアルバイトの小川誠容疑者（80）が事件に関わった疑いがあるとして13日、ひき逃げと過失運転致死ちしの疑いで逮捕しました。 结果是，在千叶县香取市的住宅前找到了损坏的车，住在这里的自称是打零工的嫌疑人小川誠因为和该交通事件有关的嫌疑，在 13 日被以交通肇事逃逸致人死亡的嫌疑而被逮捕了。 調べに対し、小川容疑者は「犬にぶつかった」などと、容疑を否認しているということです。 面对调查，嫌疑人小川说“之前撞到狗（导致车坏了）。”之类的进行了否认。 警察は詳しいいきさつ経緯を調べることにしています。 警察正在调查详细的事情经过。","link":"/2024/09/13/translate_news_nhk_20240913_k10014580751000/"},{"title":"日语翻译 - 新闻 - 台風13号 鹿児島 奄美大島で住宅の屋根が飛ぶなどの被害","text":"遭遇 13 号台风的灾害影响，鹿儿岛奄美大島上的住宅屋顶被卷走 来源：NHK 日期：2024-09-15 08:49 链接：千葉 我孫子 ひき逃げ死亡事件 80歳の容疑者を逮捕 🌟 单词： 屋根｜やね① 鹿児島｜かごしま 奄美大島｜あまみおおしま 住用町｜すみようちょう 平屋｜ひらや⓪ 暴風雨｜ぼうふうう③ 龍郷町｜たつごうちょう 沖合｜おきあい⓪海上，海面，海边。 運搬船｜うんぱんせん 座礁｜ざしょう⓪触礁，搁浅。 油｜あぶら⓪ 乗り上げる｜のりあげる④触礁，搁浅。 浅瀬｜あさせ⓪水浅的地方，浅滩。 曳航｜えいこう⓪拖船。 台風13号の影響で鹿児島県の奄美大島あまみおおしまでは、住宅の屋根が飛ばされるなどの被害が出ています。 受到台风 13 号的影响，在鹿儿岛的奄美大島，发生了房屋的屋顶被吹飞的灾害。 このうち、奄美市住用町すみようちょうでは、14日午後9時ごろ、木造平屋ひらや建ての住宅の屋根が強風によって半分以上飛ばされました。 当时，在奄美市住用镇 14 日下午 9 点左右，以木头搭建的一层平房的屋顶因为强风被吹走了一半以上。 住宅には70代の夫婦と30代の息子が3人で住んでいますが、屋根が飛ばされてからすぐに避難したため、いずれもけがはなかったということです。 虽然住宅有 70 岁的夫妇和 30 岁的儿子三人一起居住，但是因为屋顶被吹飞后迅速去避难，因此没有任何人受伤。 この住宅の70代の男性は、「一瞬のうちに暴風雨が来て屋根を飛ばしていった。強い風がずっと吹きっぱなしで台風は何度も経験しているが初めての体験で怖かった」と話していました。 这个房屋的 70 岁的男性（居住者）说：“一瞬间的功夫暴风雨来了吹飞了屋顶。虽然强风一直吹并且有几次遭遇台风的经验，但是首次经历（屋顶被吹飞）还是很恐怖的。” 奄美大島では、奄美市のほか龍郷町たつごうちょうなどでも強風によって屋根が飛ばされるなどの被害が確認されているということで、各自治体が調査を進めています。 在奄美大島区域，针对奄美市以外的龍郷町等是否也有因为强风屋顶被吹飞的受灾情况的确认，各区政府正在推进调查。 沖合に避難の運搬船うんぱんせん 風に流され座礁ざしょう 在海边避难的货运船 被风吹搁浅 古仁屋海上保安署によりますと、14日午後10時ごろ、奄美大島の瀬戸内町の沖合で、那覇市の会社が所有する土砂の運搬船「第七太海丸」の船長から「風に流され浅瀬に乗り上げた」と通報がありました。 据古仁屋海上保安署描述，14 日下午 10 点左右，在奄美大島区域的瀬戸内镇的沖合，有来自那覇市的公司所有的泥沙货运船「第七太海丸」的船长的报告：“被风吹到搁浅了。” 6人の乗組員にけがはなく、油あぶらの流出などはありませんでした。 6 名船员没有受伤，也没有油泄漏的事情。 また、船に土砂は積まれておらず、船体の向きも安定しているということです。 并且，船内没有堆积泥沙，船体的移动也没有问题。 船が乗りあげたのは、瀬戸内町瀬戸埼からおよそ100メートルの浅瀬あさせで、船は、台風13号の接近に伴い、避難してきたということです。 船体搁浅这件事情，是在濑户内町濑户埼约100米的浅滩上、由于伴随着 13 号台风的接近进行避难而导致的。 現場付近では、台風13号が暴風域を伴って最も接近した14日夜9時ごろ、31.1メートルの最大瞬間風速を観測していました。 在台风的暴风中心最接近的 14 日晚间 9 点左右，现场附近观测到（每秒）31.1 米的最大瞬时风速。 船を所有する会社は、今後、ほかの船でえい航する作業を進める方針だということです。 船所在的公司，正在制定之后由其他船进行拖船作业的方案。","link":"/2024/09/15/translate_news_nhk_20240915_k10014580571000/"},{"title":"日语翻译 - 新闻 - さいたま市 住宅に3人組の男が押し入り 財布など奪い逃走","text":"埼玉市，有男性三人组强行闯入他人住宅，抢夺钱包后逃走 来源：NHK 日期：2024-09-18 09:26 链接：さいたま市 住宅に3人組の男が押し入り 財布など奪い逃走 🌟 单词： 逃走｜とうそう⓪ 鈍器｜どんき① 脅す｜おどす⓪②恐吓，威吓。 強盗｜ごうとう⓪ 粘着｜ねんちゃく⓪ 縛る｜しばる② 物色｜ぶっしょく⓪ トレーナー｜とれーなー②⓪(trainer) 训练服，无帽卫衣。 手袋｜てぶくろ②手套。 痩せ形｜やせがた⓪清瘦，枯瘦。 18日未明、さいたま市の住宅に3人組の男が押し入り、女性2人を鈍器どんきのようなもので脅しおどし財布などを奪って逃げました。警察が強盗ごうとう事件として捜査しています。 18 日凌晨，有男性三人组强闯埼玉市的民宅，用钝器一样的东西威吓 2 位女性抢走钱包后逃走了。警察将此时作为强盗案件进行调查。 18日午前1時ごろ、さいたま市西区の住宅に3人組の男が窓ガラスを割って押し入り、鈍器のようなものを持ってこの家に住む80代と60代の女性を「金めの物を出せ」と脅しました。 18 日凌晨 1 点左右，有男性三人组打破窗户玻璃强行闯入埼玉市西区的住宅，拿着钝器一样的东西威胁住在那里的 80 岁和 60 岁的女性：“把值钱的东西拿出来。” 男らは女性2人の全身を粘着ねんちゃくテープのようなもので縛ったしばったうえ家の中を物色ぶっちょくし、財布などを奪って逃げたということです。 这些男性将 2 位女性用胶带之类的东西捆绑住，之后在家里翻找，抢夺了钱包等之后逃走了。 女性2人にけがはありませんでした。 2 位女性没有受伤。 逃げた3人はいずれも黒いニット帽をかぶった20代くらいの男で、▽このうち1人は身長が1メートル70センチほどで赤いトレーナーと黒い手袋を身に付けていて、▽もう1人は身長1メートル65センチほどで緑色のトレーナーを着ていたということです。▽あと1人は身長1メートル70センチほどでやせ型清瘦，枯瘦。だったということです。 逃走的 3 人都是戴着黑色针织帽的 20 岁左右的男性，其中一人身高 1 米 70，穿着红色的无帽卫衣、戴着黑色的手套，还有一人身高 1 米 65，穿着绿色的无帽卫衣。最后一人身高 1 米 70，很瘦。 現場は、JR川越線かわごえせんの指扇さしおうぎ駅から東に1キロほど離れた住宅街がいで、警察は、強盗事件として逃げた3人の行方を捜査しています。 现场在距离 JR 川越線的指扇站向东 1 千米远的住宅街，警察将此事作为强盗案件正在调查逃走 3 人的行踪。","link":"/2024/09/18/translate_news_nhk_20240918_k10014584511000/"},{"title":"日语翻译 - 新闻 - 中国 襲われた日本人学校の男子児童死亡 日本企業への影響も（第一部分）","text":"🕯 在中国，被袭击的日本学校的男孩死亡，对（在中）日本企业也有影响 来源：NHK 日期：2024-09-19 16:28 链接：中国 襲われた日本人学校の男子児童死亡 日本企業への影響も 🌟 单词： 児童｜じどう① 広東省｜かんとんしょう③ 通う｜かよう⓪ 刃物｜はもの① 総領事｜そうりょうじ 江蘇省｜こうそしょう 蘇州｜そしゅう 刺さる｜ささる② 哀悼｜あいとう⓪ 腹部｜ふくぶ⓪② 身柄｜みがら⓪ 拘束｜こうそく⓪ 中国南部 広東省かんとんしょうの※深センで日本人学校に通う10歳の男子児童が登校中に刃物はものを持った男に襲われた事件で、現地に駐在する日本の総領事そうりょうじは19日未明に男子児童が死亡したと明らかにしました。 在中国南部的广东省深圳市发生了去日本人学校上学的 10 岁男孩在途中被持有刀具的男性袭击的事件，驻扎在当地的日本的总领事于 19 日凌晨公布了男孩死亡。 中国ではおよそ3か月前のことし6月にも東部の江蘇省こうそしょう蘇州そしゅうで日本人学校のスクールバスが刃物を持った男に襲われ、日本人の親子がけがをする事件があり、現地では警戒が高まっていただけに衝撃が広がっています。 中国在大概 3 个月前的 6 月份，在东部的江苏省苏州市也发生了日本人学校的校车被持刀的中国男性袭击、日本人父母和子女受伤的事件，当地的提高了警戒，因此袭击（的范围）扩大了。 18日午前、中国 広東省の深センで、日本人の10歳の男子児童が保護者と一緒に日本人学校に登校していたところ、男に刃物で刺されてさされて病院に搬送されました。 18 日上午，在中国广东省深圳市，10 岁的日本男孩和监护人一起去日本人学校的时候，被男人用刀刺伤之后被送往了医院。 広東省広州に駐在する貴島善子総領事は19日朝、記者団に対して「男子児童は病院で治療を受けていましたが、19日未明、亡くなりました。心より哀悼あいとうの意をささげたい」と述べ、男子児童が死亡したことを明らかにしました。 驻扎在广东省广州市的貴島善子总领事在 19 日早晨，面对记者团说：“虽然男孩在医院里接受了治疗，但是在 19 日凌晨还是去世了。我从心底奉上哀悼之心。”，（同时）公布了男孩的死亡。 児童は腹部ふくぶを刺されて傷を負っていたということで、具体的な死因については、中国の当局が調査しているとしています。 孩童的腹部被刺受伤，关于具体的死因，中国当局还正在调查。 貴島総領事「一番に家族のケアを」 貴島总领事：“会尽全力关怀家属” 貴島総領事は「今回の事案の発生を受けて、引き続き中国側には日本人の安全確保のために尽くしてもらいたい。総領事館としても全力で対応していきたい」と述べました。 貴島总领事描述：“收到本次事件发生的消息之后，希望中方继续为确保日本人的安全尽心尽力。作为总领事馆也会尽全力应对。” そして「まずご家族のケアを一番に考えて対応していきたい」と述べ、日本人学校や深セン市政府とも連絡をとりながら対応していく考えを示しました。 之后表示：“首先会尽全力关怀受害者家庭”，同时还表示将考虑一边联络日本人学校和深圳市政府，一边进行后续应对。 容疑者は44歳の男 動機など不明 嫌疑人是 44 岁的男性，动机不明 地元の警察によりますと、容疑者は44歳の男で、その場で当局に身柄みがらを拘束こうそくされ、取り調べを受けているとみられますが、動機などについてはこれまでのところ、明らかになっていません。 据当地的警察描述，嫌疑人是 44 岁的男性，当场被逮捕并接受了提审调查，但是关于动机至今为止都没明确。 下一部分：日语翻译 - 新闻 - 中国 襲われた日本人学校の男子児童死亡 日本企業への影響も（第二部分）","link":"/2024/09/19/translate_news_nhk_20240919_k10014585361000_1/"},{"title":"日语翻译 - 新闻 - 中国 襲われた日本人学校の男子児童死亡 日本企業への影響も（第二部分）","text":"🕯 在中国，被袭击的日本学校的男孩死亡，对（在中）日本企业也有影响 来源：NHK 日期：2024-09-19 16:28 链接：中国 襲われた日本人学校の男子児童死亡 日本企業への影響も 上一部分：日语翻译 - 新闻 - 中国 襲われた日本人学校の男子児童死亡 日本企業への影響も（第一部分） 🌟 单词： 拘束｜こうそく⓪ 半袖｜はんそで⓪④ 大使｜たいし① 個別｜こべつ⓪ 北京｜ぺきん 憔悴｜しょうすい⓪ 申し入れる｜もうしいれる⑤⓪表明，提出意见。 要請｜ようせい⓪ 献花｜けんか① 手向ける｜たむける③ 添える｜そえる⓪②1. 添，附加，附上，配上；2. 伴随，陪同。 卑怯｜ひきょう② 「とても明るい子だった」 “（受害儿童）是非常开朗的孩子” 男子児童について関係者はNHKの取材に対し「とても明るい子どもだった」と話しています。 男孩子的相关者面对 NHK 的采访说：“他是非常开朗的孩子。” また、その場で拘束こうそくされた44歳の男については「目撃者の話では、背が高く、半袖はんそでのスポーツシャツとチノパン姿で帽子やサングラスなど顔を隠すものはなかった。男は、逃げることなくその場に立ち尽くしていて学校を警備していた地元の警察に取り押さえられていた」と話しています。 然后，针对在现场被拘捕的 44 岁的男性，说到：“目击者说，他身高很高，穿着半袖的运动衬衫和卡其裤，没有用帽子和太阳镜之类的遮挡面部。那个男人没有逃走而是一直站在现场，直到将学校戒备的地方警察将他逮捕。” 中国 日本の大使に「前科のある者による個別の事案」 中国方面向日本大使描述：“是有前科的人的个例。” 北京ぺきんに駐在する日本の金杉大使は19日現地入りし、男子児童の家族と面会したほか、深セン市の副市長と会談しました。 驻北京的日本的大使金杉先生在 19 日进入当地，和男孩的家庭成员会了面，除此之外还与深圳市的副市长进行了会谈。 このあと金杉大使は記者団に対し、家族の状況について「しょうすい憔悴しきっていた」と述べました。 之后金杉大使面对记者团，就受害者家庭的情况说到：“很憔悴。” そして中国外務省の孫衛東次官に電話で申し入れを行ったとしたうえで、事件について孫次官からは「前科のある者による個別の事案だ」と説明を受けたことを明らかにしました。 之后，他还表明：在与中国外务省的孙卫东次长通过电话进行了交谈的时候，针对此事从孙次官处获得了“这是有前科的人的个别事件。”的说明。 ただ、犯行の具体的な動機などについて説明はなかったということで、金杉大使は真相の究明と日本側への情報提供を引き続き求めていくとしています。 然后，由于没有关于犯罪的具体动机的说明，金杉大使正继续要求查明真相并向日方提供信息。 また、金杉大使は深セン市政府に対し、事件の再発防止と日本人の安全確保に向けた警備の強化などを強く要請したということです。 不仅如此，金杉大使面对深圳市政府，还强烈要求防止此类事件的再次发生和强化保障日本人安全的警备。 「深センは泣いています」地元の人々が献花に “深圳在哭泣”当地人们为此献花 児童が通っていた日本人学校や事件の現場には19日午後、地元の中国の人たちが次々と哀悼に訪れ、花をたむけていました。 19 日下午，受害儿童上学的日本学校也是案发现场，当地的中国人们相继到访哀悼，献上鲜花。 この中には「深センはあなたのために泣いています。あのひきょう者は深センの人々を代表していない」と日本語で書かれたメッセージが添えられているものもありました。 在这其中，也有添附着用日语写道：“深圳正在为你哭泣。那个卑劣无耻的人不能代表深圳的人们。”这样消息的。","link":"/2024/09/20/translate_news_nhk_20240919_k10014585361000_2/"},{"title":"日语翻译 - 新闻 - 中国 台湾から輸入の一部の農産品 関税免除措置の停止を発表","text":"中国大陆，宣布了对“从中国台湾进口的一部分农产品的关税免除措施”的停止措施 来源：NHK 日期：2024-09-19 09:22 链接：中国 台湾から輸入の一部の農産品 関税免除措置の停止を発表 🌟 单词： 台湾｜たいわん③ 農産品｜のうさんぴん 水産物｜すいさんぶつ 輸出品｜ゆしゅつひん 免除｜めんじょ① 品目｜ひんもく⓪ 妨げ｜さまたげ⓪ 見なす｜みなす⓪②1. 看作，认定为，认为，当作；2. 假设，看作。 大陸｜たいりく⓪① 反発｜はんぱつ⓪ 漁業｜ぎょぎょう① 民衆｜みんしゅう⓪ 資する｜しする②有助于，贡献。 恩恵｜おんけい⓪ 与党｜よとう①执政党。 中国政府は台湾から輸入する果物や野菜など一部の農産品のうさんぴんについて関税を免除してきた措置を停止すると発表し、台湾の頼清徳政権への圧力を強めるねらいがあるとみられます。 中国大陆就中国大陆政府从中国台湾进口的水果和蔬菜等一部分农产品，宣布了停止关税免除，此举被认为是对台湾赖清德政府的进一步施压。 中国政府は18日、台湾から輸入する果物や野菜、それに水産物など34種類の品目ひんもくについて、これまで実施してきた関税を免除する措置を今月25日から停止すると発表しました。 中国大陆政府于本月 18 日，宣布于本月 25 日停止对从台湾进口的水果、蔬菜以及水产品等 34 种品类至今为止试试的关税免除措施。 発表では、台湾が一方的に中国からの輸出品に対し差別的な制限措置をとり、中台の経済協力を妨げさまたげていると主張しています。 公告声称，中国台湾单方面对从中国大陆来的出口产品采取有差别（歧视性）的限制措施，妨碍了中台间的经济合作。 中国政府で台湾政策を担当する国務院台湾事務弁公室はコメントを発表し「農民や漁業者を含む多くの台湾同胞が民進党当局が推し進める『台湾独立』路線が極めて危険で有害なことを認識するよう望む」などとして中国が「台湾独立どくりつ派は」とみなす台湾の頼清徳政権をけん制してせいしています。 中国大陆政府中负责中国台湾政策的国务院台湾事务办公室，发表评论（通过此举）“希望农民和渔民在内的多数台湾同胞能认识到民进党当局正在推进的‘台湾独立’路线是非常危险且有害的。”来对被视为“台湾独立派”的台湾赖清德政府进行限制。 一方、台湾当局で対中国政策を担当する大陸たいりく委員会は声明を発表し、遺憾の意を示した上で「台湾の農民や漁業者ぎょぎょうしゃ、それに民衆みんしゅうの反感を買うだけで両岸関係の長期的な発展に資さない」と反発はんぱつしました。 另一方面，中国台湾当局负责中国大陆政策的大陆委员会发表声明，表示遗憾的同时反对称：“此举会招致台湾农民、渔民和广大民众的反感并妨碍两岸关系的长期发展。” 台湾では、中国の関税免除の恩恵おんけいを受けてきた果物農家は、与党・民進党の地盤と重なる南部に多く、中国には台湾の頼政権への圧力を強めるねらいがあるとみられます。 在中国台湾，受到中国关税免除恩惠措施的水果种植农民，多数处于与执政的民进党地盘重合的南部，因此此举被视为中国大陆对中国台湾赖政府的进一步施压。","link":"/2024/09/19/translate_news_nhk_20240919_k10014585511000/"},{"title":"日语翻译 - 新闻 - フィリピン人女性と日本人男性の間の子ども 支援団体が報告会","text":"支援菲律宾女性和日本男性的孩子的团体召开了报告会 来源：NHK 日期：2024-09-23 11:15 链接：フィリピン人女性と日本人男性の間の子ども 支援団体が報告会 🌟 单词： 渡航｜とこう⓪出国，航海。 訴える｜うったえる④③ チルドレン｜ちるどれん(children) 孩子们。 国籍｜こくせき⓪ 仲介｜ちゅうかい⓪ 肩代わり｜かたがわり③债务转移、更替。 貸付金｜かしつけきん⓪贷款。 返済｜へんさい⓪偿还，还债。 拘束｜こうそく⓪ 脅す｜おどす⓪② 搾取｜さくしゅ① 母語｜ぼご① 🌟 惯用句： 後を絶たない不断发生，络绎不绝。 フィリピン人女性と日本人男性の間に生まれた人たちなどを支援する団体による実態調査の報告会が開かれ、渡航時に借金を背負わされたり、雇用条件を理解しないまま就労するケースがあるとして対策の必要性が訴えられました。 由支援菲律宾女性和日本男性所生后代的团体召开了现状调查的报告会，对于存在出国时背负债务、不理解雇用条件就进行工作的例子，呼吁有（采取）对策的必要性。 NPO法人「JFCネットワーク」は、フィリピン人女性と日本人男性の間に生まれた「JFC＝ジャパニーズ・フィリピーノ・チルドレン」と呼ばれる人たちに対し、日本国籍の取得のための法的な支援などを行っていて、22日は日本への移住の過程で不当な扱いを受けていないかについての実態調査の報告会を都内で開きました。 NPO 法人“JFC 网络”对菲律宾女性和日本人男性所生的、被称为“JFC”即“日本人和菲律宾人的孩子”，进行合法获取日本国籍的支援，并在 22 日于都内召开了“往日本移居的过程中是否遭受了不当的待遇”的现状调查的报告会。 この中では、調査に協力した84人のうち、3分の1以上にあたる31人が来日の費用について「仲介ちゅうかい業者や就労先の会社などが肩代わりした」と回答したことが報告されました。 在会上报告了：参与调查的 84 人中，三分之一以上的 31 人关于来日本的费用回答了“中介和入职的企业做了债务转移”。 しかしこのうち30人は費用が貸付金かしつけきんとして返済へんさい義務をおわされ、返済総額の平均は42万円、最も高い人では180万円にのぼり、中には「返済せずに逃亡したら家族を拘束こうそくする」などと脅されるおどされるケースもあったということです。 但是在这其中有 30 人为贷款（因此）背负了还钱的义务，还款总额平均为 42 万日元，还款额最高的来到了 180 万日元。在这其中也有被威胁到“不还钱逃走的话就拘禁你的家人”的例子。 また、日本語の読み書きができない人も多い中、25人が雇用契約書が英語などに翻訳されていなかったと回答し、報告では、労働条件を理解しないまま就労するケースにつながっていると指摘されました。 然后，没法读写日语的人也很多，25 人被告知雇用合同没法翻译成英语之类的，报告还指出存在不理解劳动条件就入职的例子。 JFCネットワークの伊藤里枝子 事務局長は「搾取さくしゅ的な条件で働くなどのケースがあとをたたず、渡航前からのサポートや、母語ぼごで相談できる体制づくりなどが必要だ」と話しています。 JFC 网络的伊藤里枝子事务局长说：“在压榨的条件下工作的例子络绎不绝，有必要构建在出国前支援、使（他们）能够使用母语交谈的体制。”","link":"/2024/09/23/translate_news_nhk_20240923_k10014589521000/"},{"title":"日语翻译 - 新闻 - 車とバイク衝突 1人死亡1人重体 ひき逃げとして捜査 埼玉 川口","text":"埼玉县川口地区，汽车和摩托车相撞导致一人死亡一人重伤，警方在以肇事逃逸进行调查 来源：NHK 日期：2024-09-24 08:12 链接：車とバイク衝突 1人死亡1人重体 ひき逃げとして捜査 埼玉 川口 🌟 单词： 衝突｜しょうとつ⓪ ひき逃げ｜ひきにげ肇事逃逸。 原付きバイク｜げんつきばいく⑤轻骑，动力自行车，装有总排气量 50cc 以下发动机的两轮车。 映像｜えいぞう⓪ 23日夜遅く、埼玉県川口市の交差点で車とバイクが衝突し、バイクに乗っていた男性2人のうち、1人が死亡し、1人が意識不明の重体となっています。車は現場から走り去り、およそ1時間後に戻ってきたということで、警察はひき逃げ事件として捜査しています。 9 月 23 日深夜，在埼玉县川口市的十字路口汽车和摩托车相撞，两名乘坐了摩托车的男性一人死亡一人陷入意识不明的重伤状态。汽车先从现场逃走，大概 1 小时后折返回来，警察正将此事件作为肇事逃逸进行调查。 23日午後11時半ごろ、川口市前川の交差点で車と原付きバイクの衝突事故がありました。 23 日晚上 11 点半左右，在川口市前川区域的十字路口发生了车辆和轻量摩托车相撞的事故。 警察によりますと、現場にはバイクに乗っていた市内に住む男性2人が倒れていて、病院に搬送されましたが、このうち、17歳の建設作業員がおよそ1時間後に死亡し、16歳の高校生が意識不明の重体だということです。 据警察所述，现场两名乘坐摩托车的男性市民被撞倒，随后被送往了医院，不过在这之后 17 岁的建筑员工在大概 1 小时后死亡，16 岁的高中生陷入意识不明的重伤状态。 車は現場から走り去り、事故からおよそ1時間後に戻ってきたということです。 肇事车辆先从现场逃走，在事故发生大概 1 个小时后折返了回来。 警察はひき逃げ事件として、車に乗っていた2人の男性から事情を聴くとともに、周辺の防犯カメラの映像えいぞうを解析するなどして事故との関連について捜査しています。 警察将此事作为肇事逃逸案件，一边问询当时乘坐汽车的两名男性，一边分析周边的摄像头等来调查事故相关的信息。","link":"/2024/09/24/translate_news_nhk_20240924_k10014590271000/"},{"title":"日语翻译 - 新闻 - DMMビットコインに業務改善命令 不正流出問題受け 金融庁","text":"金融厅收到（资金）非法流出的问题，向 DMM 比特币下达了业务整改的命令 来源：NHK 日期：2024-09-26 18:24 链接：DMMビットコインに業務改善命令 不正流出問題受け 金融庁 🌟 单词： 相当｜そうとう⓪ 法律｜ほうりつ⓪ 徴求｜ちょうきゅう⓪ 適切｜てきせつ⓪ 権限｜けんげん③ 分散｜ぶんさん⓪ 最小限｜さいしょうげん 加える｜くわえる⓪③ 招く｜まねく② 厳粛｜げんしゅく⓪ 自主｜じしゅ⓪① 暗号資産の交換業を行う「DMMビットコイン」で480億円相当のビットコインが不正に流出した問題で、金融庁は会社に対し、システムリスクの管理態勢などに重大な問題があったとして業務改善命令を出しました。 由于进行加密资产的交换业务的 DMM 比特币公司发生了相当于 480 亿日元比特币非法流出的问题，金融厅以公司系统风险的管理态势等存在重大问题（为原因），向其发出了业务整改的命令。 「DMMビットコイン」ではことし5月、480億円相当のビットコインが不正に流出し、金融庁は法律にもとづいて会社に報告徴求命令を出し、原因の究明などを求めていました。 DMM 比特币在今年 5 月，非法流出了价值 480 亿日元的比特币，金融厅依法向公司发出了要求报告文件的命令，要求探明原因。 これについて金融庁は26日、不適切なシステムリスクの管理態勢が常態化していたほか、暗号資産の流出リスクへの対応にも重大な問題があったとして業務改善命令を出しました。 关于此事金融厅在 26 日，除了将不合适的系统风险的管理态势常态化以外，还因为（DMM 比特币公司）在加密资产流出风险的应对上也有重大的问题，发出了业务整改的命令。 金融庁によりますと、会社は、システムの開発や運用、安全管理などを行う権限けんげんを一部に集中させていたほか、顧客の暗号資産を管理するウォレットを複数設置して分散するなど、流出リスクを最小限さいしょうげんにするような対応を検討していなかったということです。 据金融厅所述，公司并没有探讨过“将系统的开发、运行和安全管理等权限集中于一部分人，或是将用以管理顾客加密资产的钱包设置多个并分散，以最小化流出风险。”这样的应对。 金融庁は命令で、こうしたリスク管理態勢の見直しに加えくわえ、巨額の不正流出を招いたまねいた経営責任の明確化も求めています。 金融厅通过命令，要求在重新修正这样的管理态势基础上，明确导致巨额资金非法流出的经营责任。 DMMビットコインは「業務改善命令を厳粛げんしゅくに受けとめ、引き続き改善および再発防止に取り組み、信頼回復に努めてまいります」とコメントしています。 DMM 表示：“会严格接受业务整改的命令，持续致力于整改和防止此类事件再次发生，努力让信用恢复。” 今回の問題を受けて、金融庁は暗号資産の交換業者でつくる業界団体に対し、流出リスクへの対応などを自主点検するよう要請しました。 受到这次问题的影响，金融厅包括对加密资产的交换行业从业者在内的业内团体，要求主动检查流出风险的应对等。","link":"/2024/09/27/translate_news_nhk_20240926_k10014593031000/"},{"title":"日语翻译 - 新闻 - パンダのリーリーとシンシン 中国へ 上野動物園で最後の観覧日","text":"大熊猫力力和真真将回到中国，上野动物园最后的参观日 来源：NHK 日期：2024-09-28 18:55 链接：パンダのリーリーとシンシン 中国へ 上野動物園で最後の観覧日 🌟 单词： 上野｜うえの 漂う｜ただよう③ 惜し｜あたらし 高血圧｜こうけつあつ④③ 竹｜たけ⓪1. 竹子；2. 竹制乐器。 予め｜あらかじめ⓪预先。 抽選｜ちゅうせん⓪抽签。 募集｜ぼしゅう⓪ 応募｜おうぼ⓪ 29日、中国に返還される東京 上野動物園のジャイアントパンダ「リーリー」と「シンシン」は28日、最後の観覧日を迎え、詰めかけた大勢のファンが別れを惜しあたらしみました。 29 日将返还给中国的上野动物园的大熊猫“力力”和“真真”于 28 日迎来了最后的参观日，数量众多的粉丝为分别而惋惜。 13年前の2011年2月に上野動物園にやってきたジャイアントパンダのオスの「リーリー」とメスの「シンシン」は、19歳と高齢で高血圧こうけつあつの治療なども必要なことから、29日、中国に返還されます。 13 年前的 2011 年 2 月来到上野动物园的大熊猫力力（雄性）和真真（雌性），已经 19 岁了再加上因为高龄导致的高血压需要治疗等，29 日将返还给中国。 最後の観覧日となった28日、動物園には大勢のファンが詰めかけ、開園の1時間以上前には列に並ぶ人が2000人を超え、これ以上は観覧ができないとして受け付けが締め切られました。 在最终参观日的 28 日，动物园聚集了大量的粉丝。距离开园时间还有 1 小时以上，排队的人就超过了 2000 人，由于不能再参观了，受付也被关闭了。 パンダ舎しゃでは、2頭が竹たけを食べたり、木によりかかったりしていて、訪れた人たちは写真を撮りながら「さようなら」とか「ありがとう」などと声をかけていました。 在熊猫馆，2 头大熊猫一会吃竹子，一会爬树，到来的人们一边拍照片一边说到：“再见！”、“谢谢你们！”等。 そして、最後の30分は混乱を避けるため、あらかじめ予め抽せんで選ばれた人たちが観覧しました。 之后，在最后 30 分钟为了避免混乱，（只提供给）预先通过抽签选出的人们进行参观。 200人の募集に対して、およそ61倍にあたる1万2000人余りの応募があったということで、抽せんに当たり3歳の子どもと一緒に来た母親は「最後を見届けることができて本当によかった」と話していました。 与募集 200 人相对的，是有 61 倍的 1 万 2000 多人参与了抽签。中了抽签的 3 岁的孩子与一起来的母亲说：“能送别他们的最后真的太好了。” また、抽せんに外れたファンも、観覧が終わったあとパンダ舎の周りに集まり、2頭との別れを惜しんでいました。 另外，没有被抽中的粉丝，在参观结束后依然聚集在熊猫馆的周围，为与 2 头大熊猫的分别感到惋惜。 2頭は29日未明にトラックで動物園をたち、その日のうちに中国に到着する予定です。 2 头大熊猫预定将于 29 日凌晨乘坐箱型货车离开，在当天中达到中国。 上野動物園 冨田副園長「2頭は明るい光をともしてくれた」 上野动物园的富田副园长说：“2 头大熊猫共同带来了光。” 最後の観覧を終え、上野動物園の冨田恭正副園長は「2頭は、東日本大震災やコロナ禍で暗い雰囲気が漂うただよう日本に明るい光をともしてくれた存在でした。きょうも本当に多くの人が好きでいてくれたんだと改めて感じ、心から感謝しています。あとは2頭を安全に中国に移送する一大ミッションをしっかり達成したい」と話していました。 最后的参观结束了，上野动物园的冨田恭正副院长说：“这两台大熊猫，是给因为东日本大地震和新冠疫情而阴云密布的日本带来光的存在。今天也有非常多喜欢大熊猫的人来了，再次从心底表示感谢。之后会好好完成将两头大熊猫安全地移送中国的重要任务。”","link":"/2024/09/29/translate_news_nhk_20240928_k10014594541000/"},{"title":"日语翻译 - 新闻 - 台風18号 3日昼ごろ台湾上陸へ 接近に伴い2人死亡 2人行方不明","text":"18 号台风 3 日白天在台湾登陆，随着它的接近 2 人死亡、2 人下落不明 来源：NHK 日期：2024-10-03 12:48 链接：台風18号 3日昼ごろ台湾上陸へ 接近に伴い2人死亡 2人行方不明 🌟 单词： 上陸｜じょうりく⓪ 接近｜せっきん⓪ 行方｜ゆくえ⓪1. 去向，目的地，下落，行踪；2. 将来。 通学｜つうがく⓪ 台北｜タイペー⓪ 閑散｜かんさん⓪闲散，冷清，清静。 低気圧｜ていきあつ③1. 低气压；2. 不高兴，不稳定。 台湾では台風18号の接近に伴って風と雨が強まり、これまでに2人が死亡し、2人の行方が分からなくなっています。台風は3日昼ごろ台湾南部に上陸する見通しで、台湾の気象当局は高波や強風に警戒するよう呼びかけています。 在台湾随着 18 号台风的接近，风雨变强，到目前为止（造成）2 人死亡、2 人下落不明。预计台风会在 10 月 3 日白天登陆台湾南部，台湾的气象当局正在呼吁警戒大浪和强风。 強い台風18号は、日本時間の3日午前9時の時点では台湾の南の海上でほとんど停滞ていたいしています。 强台风 18 号于日本时间 3 日上午 9 点，几乎在台湾南部的海上停滞了。 台湾の中央気象署によりますと、台風は3日昼ごろ、台湾南部に上陸する見通しで、接近に伴って各地で風と雨が強まっています。 据台湾的中央气象厅描述，预计台风会在 3 日白天登陆台湾南部，随着它的接近各地的风雨都会变强。 消防当局はこれまでに2人が死亡し、2人の行方が分からなくなっているほか、台湾各地で合わせて123人がけがをしたと発表しました。 消防当局也发布消息称，至今为止除了有 2 人死亡、2 人下落不明外，台湾各地总计还有 123 人受伤。 台湾のすべての県と市では2日に続いて、3日も出勤や通学つうがくを停止する措置がとられていて、台北の中心部では、ふだんは混み合うバス停や駅は閑散かんさんとしていました。 台湾的全部县市继 2 日之后，3 日也采取了停止上班和上学的措施。台北的中心区域，日常热闹拥挤的公交站和车站都很冷清。 台風は上陸したあと、勢力を徐々に弱め、熱帯低気圧に変わると予想されていますが、中央気象署は高波や強風に警戒するよう呼びかけています。 虽然预想台风在登陆后，势力会逐渐减弱而变成热带低气压，但是中央气象厅还是在呼吁警戒大浪和强风。","link":"/2024/10/03/translate_news_nhk_20241003_k10014599511000/"},{"title":"日语翻译 - 新闻 - 能登 地震と大雨の土砂災害を3D地図に ”複合災害に注意を”","text":"能登半岛，将地震和大雨带来的泥石流灾害用 3D 地图的方式来防范复合灾害 来源：NHK 日期：2024-10-05 13:14 链接：能登 地震と大雨の土砂災害を3D地図に ”複合災害に注意を” 🌟 单词： 能登｜のと 画像｜がぞう⓪ 上空｜じょうくう⓪ 立体｜りったい⓪ 土石流｜どせきりゅう③ 元日｜がんじつ⓪ 斜面｜しゃめん①⓪ 拡大｜かくだい⓪ 亀裂｜きれつ⓪ 崩壊｜ほうかい⓪ 緩む｜ゆるむ②1. 松，松弛；2. 松懈，松动；3. 缓和，放宽；4. 软化，变稀；5.（行市）疲软。 雪崩｜なだれ⓪ 能登半島地震とその後の記録的な大雨について、画像がぞう解析の専門家が上空じょうくうから撮影した写真などをもとに地震と大雨、それぞれで発生した土砂災害を解析し立体りったい地図にまとめました。 就能登半岛的地震和在这之后的破纪录的大雨，画像解析的专家给予从天上拍摄的照片，将地震、大雨和由于各种原因导致的泥石流灾害解析，并汇总成为立体的地图。 石川県輪島市町野町など、地震によって崩落ほうらくした下流かりゅう側で大雨によって崩れたり、土石流どせきりゅうのように流れたりと複合災害になっている状況が確認され、今後も注意が必要だと指摘しています。 确认了石川県輪島市町野镇等地区，（是否有）由于地震而土砂崩塌的下流方向，加上大雨的影响而崩溃（的情况），或是像泥石流那样复合灾害的情况。同时还指出了今后也需要注意。 東京大学大学院の渡邉英徳教授は、国土地理院が上空から撮影した写真などから元日がんじつの地震と先月21日の記録的大雨、それぞれの被害を把握できるよう土砂災害の状況を分析し、3Dで表示する地図を作成しました。 东京大学大学院的渡邉英徳教授，根据国土地理院从天上拍着的照片，分析了元旦的地震和上月 21 日的创纪录的大雨，为了能把握各自的受害情况，制作了用 3D 表示的地图。 このうち輪島市町野町では、地震によって斜面しゃめんが崩れたことを示す赤い色の下流側に大雨のあと、斜面崩落や土石流が起きたことを示す、青色の部分が広がっているところが複数、確認されました。 其中，在石川県輪島市町野镇，确认了用于本由于地震引起的山斜面滑坡的红色区域，因下了大雨后发生了山斜面崩落和泥石流灾害（而标记为）蓝色部分的、扩大的地方有多个。 地震で崩れた斜面と大雨で崩れた斜面が隣り合っているのは、珠洲市の日本海に面した地域でも確認され、渡邉教授は、元日の地震で斜面が崩れたり地盤じばんが弱くなったりしたところに大雨が降り、被害が拡大かくだいした可能性があると指摘しています。 由于地震而崩溃的斜面和由于大雨而崩溃的斜面相邻（的情况），在珠洲市面向日本海的地区也得到了确认。渡边教授指出：由于元旦的地震，斜坡崩塌或地基变弱的地方下了大雨，受灾可能扩大了。 また、輪島市稲舟町では元日の地震で住宅地に近い斜面に亀裂が入ったり、崩れたりしたあと大雨でさらに崩壊ほうかいが拡大しているとして、ほかの住宅地の斜面でも注意が必要だと指摘しています。 之后，还因为在輪島市稲舟镇由于元旦发生的地震和住宅地区相近的斜面产生了龟裂、奔溃，在这之后由于大雨崩溃进一步扩大了，而指出也需要注意其他的住宅地区的斜面。 渡邉教授は「すでに土砂崩れがあった地域だけでなく周辺でも地盤が緩んでゆるんでいるとみられ、今後、雨や雪が降ると、さらなる土砂崩れや雪崩なだれが起きるおそれがある。近くに住む方々はいつでも避難できるよう注意が必要だ」と話しています。 渡邉教授说：“不仅是已经发生了泥石流的区域，周边的区域看来地面也软化了。今后，如果下雨或下雪的话，有发生更严重的泥石流和雪崩的风险。周遭的居民有必要一直注意避难。”","link":"/2024/10/05/translate_news_nhk_20241005_k10014601811000/"},{"title":"日语翻译 - 新闻 - 認知症で行方不明の高齢者 QRコードで早期発見へ訓練 北海道","text":"北海道训练通过二维码及早发现由于认知障碍而行踪不明的老人 来源：NHK 日期：2024-10-05 19:17 链接：認知症で行方不明の高齢者 QRコードで早期発見へ訓練 北海道 🌟 单词： 繋ぐ｜つなぐ⓪1. 绑，系，套；2. 下狱，囚禁；3. 接起来；4. 维持，维系。&lt;/ 貼る｜はる⓪1. 粘，贴，糊；2. 钉上去。 帯広市｜おびひろし 配る｜くばる② 素早い｜すばやい③ 行方がわからなくなった認知症の高齢者などの早期発見につなげようと、衣服などに貼られたQRコード付きのシールをスマートフォンで読み取って個人を特定する訓練が5日、北海道帯広市おびひろしで行われました。 10 月 5 日，在北海道的带广市举行了为了及早发现行踪不明的有认知障碍的老人，通过手机读取贴在衣服上的带有二维码的贴纸来认定老人的训练。 北海道帯広市では、認知症やその疑いがある高齢者の家族などにQRコードが印刷されたシールを配るくばる取り組みを行っています。 在北海道的带广市，正在努力为有认知障碍和存疑者的家人发放印有二维码的贴纸。 QRコードをスマートフォンなどで読み取ると番号が表示され、それを警察に伝えることで個人情報がわかる仕組みで、行方がわからなくなった際にも素早くすばやく個人を特定し、早期発見につなげようというものです。 用智能手机读取二维码的话就会显示号码，通过将它传递给警察就能了解个人信息，即使是不知道行踪的时候，也能迅速确定个人，有助于及早发现（失踪的老人）。 この仕組みを活用してもらおうと5日、帯広市内の公園で訓練が行われました。 为了能让人活用这个功能，10 月 5 日在带广市的公园中进行了训练。 訓練にはおよそ50人が参加し、高齢者役の人を驚かせないように注意しながら声をかけ、QRコードを読み取って警察に連絡するまでの流れを確認していました。 有大约 50 人参加了训练，（他们）确认了以不惊扰扮演老人的人的方式进行提醒，同时呼喊他们，然后读取二维码并联络警察的流程。 参加した50代の女性は「QRコードがあるととてもいいと思います。知らない人どうしなので声をかけるのは難しいですがこれからは声をかけるようにしていきたい」と話していました。 参加活动的 50 岁的女性说：“有二维码真的是太好了。虽然要和不认识的人打招呼很难，但是今后希望能这么做。” 帯広市地域福祉課の齋藤周平課長は「冬になるとこれまで以上に発見の遅れが命に関わるので、QRコードをつけているお年寄りがいたら困っているかもしれないと思って気にかけてほしい」と話していました。 带广市地区福利科的齋藤周平科长说：“到了冬天的话，发现会比平日晚，这是性命攸关的事情，希望能让大家意识到：是带有二维码的老人的话他们可能正处于困境中。”","link":"/2024/10/06/translate_news_nhk_20241005_k10014601961000/"},{"title":"日语翻译 - 新闻 - いすみ鉄道 脱線 枕木の腐食が一因か 10月末の運転再開目指す","text":"夷隅市铁路的脱轨，枕木腐蚀是其中一个原因，目标是 10 月末重新开放路线运行 来源：NHK 日期：2024-10-07 18:25 链接：いすみ鉄道 脱線 枕木の腐食が一因か 10月末の運転再開目指す 🌟 单词： 枕木｜まくらぎ③ 腐食｜ふしょく⓪ 大多喜｜おおたき 後ろ｜うしろ⓪ レール｜れーる⓪1. (rail) 轨，钢轨，轨道；2. 横条，横杆，扶手，栏杆；3. 事先的准备。 記者会見｜きしゃかいけん③ 頻度｜ひんど① 千葉県のいすみ鉄道は先週の脱線事故の原因は枕木まくらぎの腐食ふしょくが一因だったとみられるとして、全線で枕木の点検などを行い、10月末の運転再開を目指すと発表しました。 千叶县夷隅市铁路发表称：由于枕木腐蚀是脱轨事故的原因之一，将进行全线的枕木检查，目标是 10 月末重新开放路线运行。 千葉県のいすみ市と大多喜おおたき町を結ぶいすみ鉄道では、10月4日に列車が脱線する事故があり、その後の調査で車両が停止したすぐ後ろうしろで左側のレール1本が外側に横倒しよこだおしとなったことがわかっています。 连接千叶县的夷隅市与大多喜镇的铁道，在 10 月 4 日发生了列车脱轨的事故。通过之后的调查发现：车辆停止之后，很快左侧的铁轨就横到了外侧。 7日、いすみ鉄道は、古竹孝一社長などが記者会見きしゃかいけんを行い、脱線が起きた区間に枕木が劣化している場所があったことを明らかにしました。 7 日夷隅市铁路方由古竹孝一社長召开了记者见面会，明确了脱轨发生的区间内枕木已经劣化的事情。 そのうえで、枕木の腐食が事故の一因だったとみられるという見方を示し、会社は今後、全線で枕木の点検などを行い、10月末の運転再開を目指すとしています。 在此基础上，还表明了看起来枕木的腐蚀是事故的原因之一的见解，并表示今后会进行全线的枕木的检查，目标是 10 月末恢复运营。 いすみ鉄道では2013年に枕木の腐食が原因で脱線事故が起きていて、古竹社長は「利用者にはご迷惑をおかけしておわび申し上げます。安全確認が取れた状態での再開を目指すとともに、点検の頻度ひんどなど安全対策についても見直しを進めたい」と述べました。 夷隅市铁路在 2013 年就曾发生过由于枕木腐蚀导致的脱轨事故，古竹社长表示：“对乘客表示非常抱歉。以确定安全状态地重新开放运营的同时，也会推进重新评估（提高）检查的频率等安全对策。”","link":"/2024/10/07/translate_news_nhk_20241007_k10014603371000/"},{"title":"日语翻译 - 新闻 - ネットのひぼう中傷 やわらかい表現変換や注意喚起の機能開発","text":"将网络上的诽谤中伤转换为柔和的表现或是提醒注意的功能正在开发 来源：NHK 日期：2024-10-08 06:09 链接：ネットのひぼう中傷 やわらかい表現変換や注意喚起の機能開発 🌟 单词： 誹謗｜ひぼう⓪ 表現｜ひょうげん③ 喚起｜かんき① 興味きょうみを喚起する。 トラブル｜とらぶる②1. (trouble) 纠纷，纠葛纷争麻烦；2. 故障。 候補｜こうほ① 花嫁はなよめの第一候補。 防ぐ｜ふせぐ② 搭載｜とうさい⓪ アプローチ｜あぷろーち1. (approach) 接近，靠近，联系；2. 探讨，研究。 閲覧｜えつらん⓪ 該当｜がいとう⓪符合，适合，相当。 傾向｜けいこう⓪ インターネット上でひぼう中傷のトラブルが課題となる中、IT企業の間で、文章を投稿する前にやわらかい表現の文章を変換の候補こうほとして表示したり、注意喚起したりする機能の開発が進んでいます。 将网络上的诽谤中伤的问题作为课题的背景下，IT 企业之间正在推进开发文章投稿前将更柔和表现形式的文章作为候补显示，或是提醒注意的功能。 このうち文字入力アプリ「Simeji」を開発した企業は、表現が強く、誤解されやすい文章の投稿を防ごうふせごうと、ことし8月から新たな機能を搭載とうさいしました。 在这之中开发了文字输入 APP Simeji 的企业，想要防止言辞激烈、容易误解的文章的投稿，从今年 8 月开始搭载上了新的功能。 例えば、「だからなに？」と打つと、「なるほどね、それからどうしたいの？」とやわらかい表現の文章が変換の候補として表示されるほか、注意喚起も行います。 举个例子，输入“所以呢？”的话，不止“原来是这样啊，那么后面你准备怎么办呢？”这样的更柔和形式的文章会作为变换后的候补进行显示，还会提醒注意。 アプリの運用を担当する古谷由宇さんは「文章を打つ一番最初の部分でユーザーにアプローチできるので、送る前に気付くことのできるきっかけを作りたい」と話していました。 负责 APP 使用方面的古谷由宇君说：“因为可以通过打出文章的最开始的部分来接近用户，所以我们希望创造一个契机，让他们在发送之前能够注意到。” このほかLINEヤフーは配信されたニュースに閲覧えつらん者がコメントする際、文章の内容によって注意喚起のメッセージを出す機能を9月に追加しました。 除此之外，LINE APP 也在 9 月追加了读者在评论通知的新闻时，根据文章的内容不同显示引起注意的消息的功能。 入力されたコメントが投稿される前に、AIが該当がいとうする表現を抽出して表現を見直すよう促す仕組みです。 （这个功能是）在提交输入的评论之前，AI 将响应的（不当）表达抽取出来并推荐修改的功能。 総務省が設置するインターネット違法・有害情報相談センターによりますと、ひぼう中傷を含めたトラブルに関する相談件数は、昨年度1年間で6400件余りと増加傾向けいこうにあり、IT企業の間でこうした被害を減らすための開発の動きが相次いでいます。 据总务省设置的网络违法有害信息咨询中心描述：与包含诽谤中伤问题相关的咨询去年 1 年间发生了 6400 件并且有增加的趋势，IT 企业间为了减少这样的危害相继进行功能开发。","link":"/2024/10/08/translate_news_nhk_20241008_k10014603481000/"},{"title":"日语翻译 - 新闻 - 横浜 市管理のすべての公園で来年4月から喫煙禁止へ","text":"横滨市管理的所有公园从明年 4 月开始将禁止吸烟 来源：NHK 日期：2024-10-09 05:44 链接：横浜 市管理のすべての公園で来年4月から喫煙禁止へ 🌟 单词： 受動｜じゅどう⓪ 喫煙｜きつえん⓪ この程｜このほど②1. 最近；2. 这回，这次。 子育て｜こそだて② 条例｜じょうれい⓪ 可決｜かけつ⓪通过。 有数｜ゆうすう⓪有数，屈指可数，为数不多。 罰則｜ばっそく⓪ 過料｜かりょう过失罚款。 仮設｜かせつ⓪1. 临时设置，临时安设；2. 假设，假定。 答弁｜とうべん①答辩，回答。 受動じゅどう喫煙を防ぐふせぐため、観光名所の山下公園など横浜市が管理するすべての公園で来年4月から喫煙を禁止することがこのほど正式に決まりました。 为了防止被动吸烟，观光胜地的山下公园等横滨市管理的所有公园最近正式决定从明年 4 月开始禁止吸烟。 横浜市は、「子育てこそだてしたいまち」の実現に向けて、受動喫煙することなく安全に遊べる公園にしようと、喫煙を禁止する条例じょうれいの改正案を先月開会した議会に提出し、このほど可決かけつされました。 横滨市为了实现“想要孕育孩子的城市”（这一目标），在上月召开的议会上，作为“打造没有被动吸烟的可以安全游玩的公园”（其中一环），提出了禁止吸烟的条例，最近这个条例通过了。 対象となるのは市が管理するおよそ2700か所の公園すべてで、市内有数ゆうすうの観光名所の「山下公園」や「港の見える丘おか公園」なども含まれています。 （禁烟）对象时市政府管理的所有大约 2700 所公园，市内为数不多的观光胜地“山下公园”和「港の見える丘公園」等也被包含在内。 喫煙が禁止されるのは来年4月1日からで、違反した場合の罰則ばっそくは5万円以下の過料となります。 禁止吸烟是从明年 4 月 1 日开始的，届时违反的话会处以 5 万日元的过失罚款。 市は今後、対象となる公園に看板を設置したり、SNSを活用したりして事前に広く周知したいとしています。 横滨市在今后，会在作为禁烟对象的公园设置看板，活用社交媒体在事前进行广泛宣传。 一方、多くの人が訪れる大規模なイベントが公園で行われる際に隠れて吸うケースを防ぐため、仮設かせつの喫煙所を設けることを検討するということです。 另一方面，为了防止公园举行来宾众多的大规模活动时（有人）偷偷吸烟，也正在研讨设置临时的吸烟所（的方案）。 議会の答弁とうべんで、横浜市の山中竹春市長は「禁煙を条例で明確に位置づけて多くの子どもが集まる公園で望まない受動喫煙をなくし、誰もが安全で安心して遊び、快適に過ごすすごす環境を実現していく」と述べていました。 在议会的问答上，横滨市的山中竹春市长表示：“会通过禁烟条例明确地指定位置，在孩子们聚集的公园让不被期望的被动吸烟行为消失，实现无论是谁都能安全、安心地游玩、快乐地度过时光的环境。”","link":"/2024/10/09/translate_news_nhk_20241009_k10014604891000/"},{"title":"日语翻译 - 新闻 - 日米豪印4か国の共同訓練 インド近海で始まる","text":"日本、美国、澳大利亚和印度 4 国在印度近海开始共同军演 来源：NHK 日期：2024-10-10 05:12 链接：日米豪印4か国の共同訓練 インド近海で始まる 🌟 单词： 日にち米べい豪ごう印いん 共同｜きょうどう⓪ 連携｜れんけい⓪ 進出｜しんしゅつ⓪进入，打入；挤进；参加；向……发展，进展。 ベンガル湾｜ベンガルわん孟加拉湾。 護衛艦｜ごえいかん②护卫舰。 駆逐艦｜くちくかん驱逐舰。 巡洋艦｜じゅんようかん⓪巡洋舰。 潜水艦｜せんすいかん④潜水艇。 中将｜ちゅうじょう 増す｜ます⓪ クアッド｜くあっど(Quad, Quadrilateral Security Dialogue)四边安全对话是美国、日本、印度和澳大利亚之间的战略对话，强调对“自由开放的印度-太平洋的共同目标和实现”。 首脳｜しゅのう⓪ 念頭｜ねんとう⓪心头，心上。 インド近海で、日本の海上自衛隊とアメリカ、オーストラリア、インドの海軍による共同訓練が始まり、4か国の連携れんけいを強化し、海洋進出しんしゅつの動きを強める中国をけん制するねらいがあるとみられます。 在印度近海上，日本的海上自卫队和美国、澳大利亚以及印度的海军将开始共同训练，此举被视为强化 4 国的连同协作，以限制正进一步强化海洋发展动作的中国。 インド国防省によりますと、海上自衛隊とアメリカ、オーストラリア、インドの海軍による共同訓練「マラバール」が、8日、インド近海のベンガル湾わんで始まりました。 据印度国防部表示，由日本海上自卫队、美国、澳大利亚和印度海军构成的共同训练“马拉巴尔”于 10 月 8 日在印度近海的孟加拉湾开始。 訓練は今月18日まで行われ、海上自衛隊の護衛艦ごえいかん「ありあけ」のほか、各国の駆逐艦くちくかんや巡洋艦じゅんようかんなどが参加して対潜水艦せんすいかん戦などの演習を行い、連携を確認するということです。 训练将到本月 18 号为止，除了海上自卫队的护卫舰以外，各国的驱逐舰和巡洋舰也将参加并进行对潜水艇作战的演习，来确认连同协作。 9日行われた記者会見で、インド海軍の中将ちゅうじょうは「世界の安全保障や経済の安定のために、インド太平洋地域の重要性はさらに増している」と述べ、訓練の意義を強調しました。 在 9 号的记者见面会上，印度海军的中将说到：“为了保障世界的安全和经济的安定，印度太平洋地区的重要性正在进一步增加。”，强调了训练的意义。 共同訓練は1990年代にアメリカとインドが始め、その後、日本とオーストラリアが加わりました。 联合演习于 1990 年代由美国和印度开始，之后，日本和澳大利亚也加入了。 訓練によって4か国の連携を強化し、海洋進出の動きを強める中国をけん制するねらいがあるとみられます。 此举被通过训练强化了 4 国的连同协作，以限制正进一步强化海洋发展动作的中国。 「クアッド」と呼ばれる日本とアメリカ、オーストラリア、インドの4か国は先月、アメリカで首脳しゅのう会合かいごうを開き、中国を念頭ねんとうに海洋安全保障協力を強化していく方針を確認したばかりです。 被成为“四边”的日本、美国、澳大利亚和印度 4 国于上月，刚刚在美国举行了首脑会议，确认了重视中国、继续强化海洋安全保证协同的方针。","link":"/2024/10/10/translate_news_nhk_20241010_k10014605801000/"},{"title":"日语翻译 - 新闻 - コンビニ越しの富士山撮影スポット 危険な横断ふせぐ柵増設","text":"越过便利店拍摄富士山的地点，设置了防止危险的横穿马路行为的栅栏 来源：NHK 日期：2024-10-11 05:37 链接：コンビニ越しの富士山撮影スポット 危険な横断ふせぐ柵増設 🌟 单词： 河口湖町｜かわぐちこまち富士河口湖町，所在地：山梨県南都留郡。 横断｜おうだん⓪ 防護柵｜ぼうごさく コンビニエンスストア｜こんびにえんすすとあ(convenience store) 方便商店，便利店。 絶つ｜たつ① 歩道｜ほどう⓪人行道。 中旬｜ちゅうじゅん⓪ マナー｜まなー①(manner) 礼貌，规矩符合礼仪的举止和态度。 🌟 惯用句： 後を絶たない｜あとをたたない①不断发生，络绎不绝。 富士河口湖こ町のコンビニエンスストア越しに富士山を撮影できることで人気となった場所で、写真を撮ろうと無理な道路の横断おうだんをする人が相次いで危険だとして、町は横断を防ぐための防護柵ぼうごさくを増やしました。 在富士河口湖镇由于可以透过便利店拍摄富士山而具有人气的地方，由于想要拍摄照片而不合理地横穿道路的人一个接一个非常危险，因此镇上增加了防止很穿马路的防护栏。 富士河口湖町にあるコンビニ周辺では、店の上に富士山が乗ったような写真が撮影できるとSNSで話題になったことから多くの外国人観光客などが訪れ、交通量の多い道路を横断するなどの迷惑行為が後を絶たず、町はことし5月、店の向かいの歩道ほどう沿いに富士山を見えなくする幕まくを設置しました。 在富士河口湖镇的便利店的周边，由于能拍摄处富士山坐落于店的上方的照片而成为社交媒体的话题，很多的外国官方客前来参观，横穿交通量大的道路的迷惑行为不断发生，镇上于今年 5 月，在店对面的人形横道沿线可以看见富士山的地方设置了帷幕。 その後、町は「大きなトラブルはなくなった」として、8月中旬ちゅうじゅん以降に幕を外しましたが、再び訪れる人が増えて、道路の危険な横断が確認されているということです。 在这之后，镇上由于“大的麻烦已经消失了。”而于 8 月中旬以后撤走了帷幕，然后来访的人们再次增多了，又确认出现了危险地横穿道路的事情。 今月2日にNHKが取材した際にも道路を横断する人が相次ぎ、近くの駐車場に無断で車を止める人も見られました。 本月 2 号 NHK 取材的时候，也发生了相继有人横穿道路的情况，还发现了附近的停车场将车乱停的人。 こうした状況を受け、町は10日、すでに設置されている防護柵ぼうごさくの西側の危険な横断が見られる場所に新たに5メートルの柵を設置しました。 受到这种情况的影响，镇上于 10 月 10 日，在已经设置的防护栏的西边、被发现又危险的横穿马路情况的地方设置了 5 米的新护栏。 作業員は4つの穴を掘ったあと、防護柵を差し込んで固定していました。 施工员挖了 4 个洞之后，将防护栏插入并固定了。 富士河口湖町の担当者は「いちばんひどい時に比べるとマナーが悪い観光客は減少げんしょうしている。様々な対策を講じて再び幕を設置しなくても済むようにしていきたい」と話しています。 富士河口湖镇的负责人说：“很最严重的时候相比的话，行为不好的观光者的数量正在减少。我们将讨论各样的对策，以期望在不设置帷幕的情况下解决问题。”","link":"/2024/10/11/translate_news_nhk_20241011_k10014606831000/"},{"title":"日语翻译 - 新闻 - 過労死白書 “芸術や芸能分野 長時間労働の傾向”明らかに","text":"过劳死白皮书明确艺术和表演领域，有（过于）长时间劳动的倾向 来源：NHK 日期：2024-10-11 12:55 链接：過労死白書 “芸術や芸能分野 長時間労働の傾向”明らかに 🌟 单词： 白書｜はくしょ① 閣議｜かくぎ① 大綱｜たいこう⓪ 拘束｜こうそく⓪ ハラスメント｜はらすめんと②(harassment) 折磨，骚扰，扰乱。 パワー･ハラスメント｜ぱわー・はらすめんと(power harassment) 职场暴力，职权骚扰。 殴る｜なぐる② 蹴る｜ける① 叩く｜たたく② 怒鳴る｜どなる② 削減｜さくげん⓪ フリーランス｜ふりーらんす④②无所属，无固定单位，自由合同，自由职业。 ことしの過労死白書が11日に公表され、芸術や芸能分野に従事する人へのアンケートでほかの業種に比べて長時間労働の傾向にあることが明らかになりました。 今年的过劳死白皮书在 11 日发表，，明确了从事艺术和表演领域的人的调查问卷，与其他的工种相比，有（更）长时间劳动的倾向。 11日に閣議かくぎ決定された過労死白書では、法律に基づく過労死防止に向けた大綱たいこうの中に重点業種としてことし追加された「芸術・芸能分野」について調査や分析が行われました。 于 11 日在内阁会议中被敲定的过劳死白皮书中，基于法律对防止过劳死的纲要中作为重点工种的、今年才追加的“艺术表演领域”进行了调查和分析。 それによりますと、この分野に従事する488人に実施したアンケートで、▽1週間当たりの拘束こうそく時間が「過労死ライン」に相当する週60時間以上と回答した人の割合わりあいが35.2％に上り、ほかの業種に比べて長時間労働の傾向にあることが分かりました。また、▽1か月当たりの休日数は「6日以下」が52.6％、▽1日の平均的な睡眠時間は「6時間未満」が41.2％でした。 据（白皮书）描述，在这个领域从事工作的 488 人的调查问卷中，▽ 回答每周被限制（工作）的时间与“过劳死生活”相当有一周 60 小时以上的人高达 35.2%，与其他的工种相比有（更）长时间劳动的倾向。然后，▽ 每月的休息日在“6 天以下”的占了 52.6%，▽ 一天的平均睡眠“不足 6 小时”的占了 41.2% そして、仕事の関係者からのハラスメントについて「傷つくことを言われた」と回答した人が42.0％、「殴られたなぐられた、蹴られたけられた、たたかれた叩かれた、または、どなられた怒鳴られた」が22.3％などとなりました。 然后，就从工作相关方那里受到骚扰回答“被说了伤人的话”的人有 42.0%，而“被殴打、被踢、被敲和被迁怒”的人有 22.3%。 厚生労働省は「長時間労働の削減さくげんに向けた対策を進めるとともに、芸術や芸能分野ではフリーランスで働く人も多いので、11月に施行されるフリーランスの人たちを保護する法律を周知し、過労死などの防止に取り組んでいきたい」としています。 厚生劳动省正在应对“推进减少长时间劳动的对策，并且由于艺术和表演领域的无合同工作者很多，会广泛告知将于 11 月实行的保护无合同劳动者的法律，努力防止过劳死之类的情况发生。”","link":"/2024/10/12/translate_news_nhk_20241011_k10014607191000/"},{"title":"日语翻译 - 新闻 - 長崎高校生平和大使が核兵器廃絶へ署名活動平和の実現を訴え","text":"长崎高中生和平（举行）目标废弃核武器的署名活动来呼吁实现和平 来源：NHK 日期：2024-10-13 18:15 链接：長崎高校生平和大使が核兵器廃絶へ署名活動平和の実現を訴え 🌟 单词： 核兵器｜かくへいき③ 廃絶｜はいぜつ⓪ 被団協｜ひだんきょう日本原水爆被害者団体協議会的略称。 託す｜たくす② スイス｜すいす瑞士。 国連｜こくれん⓪联合国。 長崎の高校生平和大使が核兵器の廃絶に向けた署名活動を行い、ことしのノーベル平和賞に日本被団協が選ばれたことを受けて、改めて平和な世界の実現を訴えました。 长崎的高中生和平大使举行了以废弃核武器为目标的署名活动，同时受到今年诺贝尓和平奖选中日本原水爆被害者团体协会的影响，呼吁重新实现和平的世界。 署名活動を行ったのは長崎の高校生平和大使など、県内の高校生7人です。 举行署名活动的是，长崎的高中生和平大使在内的县内的 7 名高中生。 高校生平和大使は毎週日曜日に核兵器の廃絶を求める署名活動を行っていて、13日は、日本被団協がノーベル平和賞に選ばれてから初めて活動を行いました。 高中生和平大使目前每周日都在进行寻求废弃核武器的署名活动，10 月 13 日进行了日本被团协被诺贝尔和平奖选中之后的首次活动。 生徒たちは「核兵器の廃絶を願う思いを私たちに託してください」などと、協力を呼びかけていました。 学生们正呼吁（寻求帮助）：“请将废弃核武器的愿望托付给我们。” 母親と一緒に署名した男の子は、「戦争も武器もない世界になってほしいです」と話していました。 和母亲一起署名的男孩子说：“想要世界变成没有战争和武器的。” 集まった署名は、来年8月にスイスにある国連のヨーロッパ本部に届けられることになっています。 收集来的署名，将于来年 8 月送往处于瑞士的联合国欧洲总部。 高校生平和大使で被爆3世の大原悠佳さんは「受賞が決まり、私たちが受賞したかのようにとてもうれしかったです。長崎を最後の被爆地にできるかどうかは、今を生きている私たちにかかっているので、県民の方は核廃絶に向けて一緒に声を上げてほしい」と話していました。 高中生和平大使，同时也是核爆受害者第三代人的大原悠佳君说：“很高兴我们获奖了。长崎能否成为最后的核爆受灾地，是跟现在生活着的我们息息相关的。希望县民们也能以废止核武器为目标一起发声。”","link":"/2024/10/13/translate_news_nhk_20241013_k10014608911000/"},{"title":"日语翻译 - 新闻 - スペースX 宇宙船試験飛行でロケット部を発射台に回収 初成功","text":"SpaceX 在宇宙飞船试验飞行中，首次成功将火箭部分回收至发射台 来源：NHK 日期：2024-10-14 08:00 链接：スペースX 宇宙船試験飛行でロケット部を発射台に回収 初成功 🌟 单词： ロケット｜ろけっと②(rocket) 火箭。 火星｜かせい⓪ 掴む｜つかむ② 噴射｜ふんしゃ⓪ 降下｜こうか①1. 降落，降下，下降；2. 下达（命令）。 大気圏｜たいきけん③ 探査｜たんさ① 月面｜げつめん⓪ 焦点｜しょうてん① アメリカの企業スペースXが月や火星かせいへの飛行も想定して開発している大型宇宙船の試験飛行が行われ、再利用を目指すロケット部分を発射台でつかんでつかんで回収することに初めて成功しました。 美国的企业 SpaceX 预定飞往月球和火星而开发的大型宇宙飞船，进行了试验飞行，并且首次成功（实现）以再利用为目标的、将火箭部分通过发射台抓住的回收（工作）。 アメリカの宇宙開発企業スペースXは、将来、月や火星への飛行も想定した大型宇宙船「スターシップ」の開発を進めています。 美国的宇宙飞船企业 SpaceX，持续推进预定将来飞往月球和火星的大型宇宙飞船“星舰”。 13日、この宇宙船の試験飛行が行われ、アメリカ南部テキサス州にある発射台から無人で打ち上げられました。 13 日进行了这个宇宙飞船的试验飞行，（飞船）从美国南部的德克萨斯州的发射台以无人的形式发射了。 宇宙船は、大型ロケットを含めると高さがおよそ120メートルあり、打ち上げからおよそ3分後にロケットが切り離されました。 宇宙船将大型火箭包含在内的话高度约为 120 米，在发射后的大约 3 分钟后火箭（和宇宙飞船）脱离了。 高さおよそ70メートルのロケットは切り離されたあと、エンジンを噴射ふんしゃしながら打ち上げられた発射台を目指して降下こうかし、発射台にある2本のアームでつかまれて停止しました。 高度约为 70 米的火箭在分离之后，一边喷射燃料一边以发射的发射台为目标下降，被发射台的两根手臂捕获后停了下来。 スペースXによりますと、ロケットは最終的に再利用を目指していて、この方式での回収に初めて成功したということです。 据 SpaceX 描述，火箭的最终目标是回收再利用，也是首次通过这种方式在回收这件事上取得了成功。 一方の宇宙船は、宇宙空間に到達したあと大気圏たいきけんに突入し、打ち上げからおよそ1時間後、予定していた海上に着水したということです。 另一边的宇宙飞船，再达到宇宙空间后突入大气层，再发射的大约 1 小时后，降落到了预定的海面上。 スターシップの試験飛行は今回が5回目で、前回は、目標としていた宇宙船の地球への帰還を初めて実現しています。 本次是星舰的试验飞行的第五回，上一回（星舰）首次实现了宇宙飞船回到地球的目标。 スターシップは、アメリカが進める国際月探査たんさプロジェクト「アルテミス計画」で宇宙飛行士を乗せて月面げつめんに着陸することを想定していますが、開発の遅れも指摘されていて、いつ実用化されるかが焦点しょうてんとなっています。 虽然星舰将通过美国推进的国际月球调查计划“阿耳忒弥斯计划”搭载宇航员登陆月球表面，但是被指出了开发迟缓，什么时候可以（真正）实用化正成为关注焦点。","link":"/2024/10/14/translate_news_nhk_20241014_k10014609191000/"},{"title":"日语翻译 - 新闻 - NASA 木星の衛星に向け新探査機打ち上げ 生命維持可能か調査へ","text":"NASA 向木星的卫星发射新的探查机，目的是调查维持生命的可能性 来源：NHK 日期：2024-10-15 07:31 链接：NASA 木星の衛星に向け新探査機打ち上げ 生命維持可能か調査へ 🌟 单词： 探査｜たんさ① エウロパ(Europa) 欧罗巴，木卫二。 クリッパー1. (clipper) 割草机；2. 剪刀；3. 快速帆船，快速飞艇。 エウロパ・クリッパー欧罗巴快船。 パネル(panel) 覆う｜おおう②⓪ 液体｜えきたい⓪ 搭載｜とうさい⓪ 地球以外に生命を維持できる環境が存在するか確かめるため、NASA＝アメリカ航空宇宙局は、木星の衛星「エウロパ」に向けて新しい探査機を打ち上げました。 为了确认地球以外是否存在能够维持生命的环境，NASA 即美国航空航天局向木星的卫星“木卫二”发生了新的探查机。 14日、アメリカ・フロリダ州にあるケネディ宇宙センターから打ち上げられたのは、NASAの探査機「エウロパ・クリッパー」です。 14 日于美国佛罗里达州的肯尼迪航天中心发射的是，NASA 的探查机“欧罗巴快船”。 探査機は太陽電池パネルを広げたときの幅がおよそ30メートル、重さがおよそ6トンで、木星の周辺をまわりながら、木星の衛星「エウロパ」の周囲を50回ほど通過し、詳しい調査を行うことになっています。 探查机的太阳能电池板展开时的宽度大概为 30 米，整体重大约 6 吨。它环绕木星周边的同时，将通过木星卫星“木卫二”的周围 50 次，并进行详细的调查。 衛星エウロパは月よりもやや小さく、表面が氷に覆われておおわれていますが、これまでの観測でその下には、液体えきたいの水が存在している可能性が指摘されています。 卫星欧罗巴与月亮相比稍稍小了点，虽然表面被冰覆盖了，但是至今为止的观测，指出了冰面下存在液体水的可能性。 このため探査機は搭載とうさいしているさまざまな観測機器を使って、エウロパの表面の氷の下に液体の水が存在するか確かめたり、どのような物質があるか分析したりして、地球以外に生命を維持できる環境が存在するか調べる計画です。 因此这个计划是：使用探查机搭载的各种各样的观测机器，确定欧罗巴的表面冰层下是否存在液体水，并分析存在什么样的物质，以调查地球以外是否存在可以维持生命的环境。 NASAによりますと探査機が木星の周辺に到達するのは、6年後の2030年で、2031年にはエウロパの本格的な観測が始まる予定だということです。 据 NASA 描述，探查机达到木星周边（的时间点）是 6 年后的 2030 年，并预定在 2031 年开始真正地观测欧罗巴。","link":"/2024/10/15/translate_news_nhk_20241015_k10014609751000/"},{"title":"日语翻译 - 新闻 - 中国のパンダ2頭 米首都ワシントンに到着「パンダ外交の再開」","text":"中国的两头熊猫达到美国首都华盛顿，熊猫外交的再启动 来源：NHK 日期：2024-10-16 09:09 链接：中国のパンダ2頭 米首都ワシントンに到着「パンダ外交の再開」 🌟 单词： 米｜べー美国。 首都｜しゅと①② チャーター機｜ちゃーたーき包机。 四川｜しせん① 隔離｜かくり①⓪ 大統領｜だいとうりょう③总统。 訪中｜ほうちゅう⓪ 象徴｜しょうちょう⓪ 国家主席｜こっかしゅせき④ 貿易｜ぼうえき⓪ 大国｜たいこく⓪ ライバル｜らいばる①(rival) 对手，敌手，情敌。 🌟 惯用句： まれに見る｜まれにみる④奇特；非凡的；少见的，单数的；异常的；单一的。 アメリカの首都ワシントンの動物園に中国から貸し出されたパンダ2頭が到着しました。この動物園では、1年近く前に中国に返還されて以降、パンダがいない状況が続いていただけに、アメリカのメディアは「パンダ外交の再開だ」と伝えています。 两头从中国借出的熊猫达到了美国首都华盛顿的动物园。正是由于这个动物园在近 1 年前归还中国后，没有熊猫的状况持续至今，因此（此事）也被美国的媒体传达为“熊猫外交的再启动”。 ワシントンの国立動物園によりますと、中国から貸し出されたジャイアントパンダ2頭は、チャーター機「パンダ・エクスプレス」で中国の四川しせん省を出発し、15日、到着しました。 据华盛顿的国立动物园描述，从中国借出的 2 头大熊猫，搭乘专机“熊猫快递”号从中国四川省出发，于 15 日到达。 到着したのは、いずれも3歳のオスの「バオリー」とメスの「チンバオ」で、隔離かくりの期間を経て来年1月24日から一般に公開される予定です。 到达的两头大熊猫分别的三岁雄性“宝力”和三岁雌性“青宝”，经过隔离的时期后，将从明年 1 月 24 日开始进行面向普通人的开放参观。 この動物園へのパンダの貸し出しは1972年のニクソン大統領だいとうりょうの訪中ほうちゅうをきっかけに始まり、50年以上にわたって米中の友好関係の象徴しょうちょうとされてきましたが、米中関係が悪化するなか、去年、親子3頭が返還されて以降は1年近く、パンダがいない状況が続いていました。 向这个动物园进行熊猫借出（的行为）是以 1972 年美国尼克松总统访中为契机开始的，历经五十多年都被作为中美友好关系的象征。然而中美关系处于恶化中，去年 3 头亲子熊猫被返回后的将近 1 年，（动物园）都保持着没有熊猫的状况。 しかし、去年11月に習近平国家主席こっかしゅせきがアメリカのサンフランシスコを訪問した際、パンダを再び貸し出すことに前向きな考えを示し、その後、今回の2頭をアメリカに送ることが決まりました。 然而，去年 11 月国家主席习近平访问美国旧金山的时候，表示了再次借出熊猫的前瞻性考量。在这之后，决定了这次送出两头熊猫的决定。 CNNテレビは「パンダ外交の再開は、貿易ぼうえきや技術などをめぐり緊張が高まっていた大国たいこくのライバル関係においてまれに見る明るい話題だ」と伝えています。 CNN 电视台将此事传达为：“熊猫外交的再启动，是处于围绕贸易和技术等高度紧张的大国敌对关系中，少有的充满希望的事情。”","link":"/2024/10/16/translate_news_nhk_20241016_k10014610601000/"},{"title":"日语翻译 - 新闻 - アマゾン 原発開発に関わる企業に投資 AI拡大で電力確保の動き","text":"Amazon 投资开发原子能相关的企业，有因为 AI 产业扩大而确保电力的动向 来源：NHK 日期：2024-10-17 09:41 链接：アマゾン 原発開発に関わる企業に投資 AI拡大で電力確保の動き 🌟 单词： 原発｜げんぱつ⓪1. 原子能发电；2. 原发（肿瘤，症状等）由病因直接或初次表现出来。 急増｜きゅうぞう⓪ 原子炉｜げんしろ③原子反应堆。 小型｜こがた⓪ 供給｜きょうきゅう⓪ 調達｜ちょうたつ⓪ スリーマイル島（美国）三里岛。 三里岛核泄露事故，通常简称“三里岛事件”，是1979年3月28日发生在美国宾夕法尼亚州萨斯奎哈纳河三里岛核电站的一次部分堆芯熔毁事故。 賄う｜まかなう③1. 供给饭食；2. 供给，提供，供应，筹措；3. 维持；4. 处理。 アメリカのIT大手アマゾンは、原発の開発に関わる企業に対して投資を行うと発表しました。グーグルも同様の発表をしたばかりで、IT大手は、AI＝人工知能の利用拡大で消費電力が急増する中、安定した電力を確保する動きを強めています。 美国的 IT 大企业 Amazon 公布了将针对开发原子能的企业进行投资的行为。Google 也才刚刚发布一样的消息。IT 大公司在 AI（人工智能）的利用扩大导致电力消耗急剧增加的过程中，正有加强确保稳定电力供应的动作。 アマゾンは16日、次世代型の原子炉げんしろとされる小型こがたモジュール炉「SMR」の開発を手がける複数の企業に対して投資を行うと発表しました。 Amazon 于 16 日，发布了对多个着手开发被视为次世代反应炉的模块反应堆“SMR”企业的投资行为。 このうちアメリカの企業「Xエナジー」にも投資が行われ、この企業によりますと、アマゾンなどからあわせておよそ5億ドル、日本円にしておよそ750億円の投資を受けるということです。 在这其中美国的企业 X-energy 也将被投资，据这个企业所述，从 Amazon 等企业加起来总共受到 5 亿美元，折合将近 750 亿日元的投资。 アマゾンは、ワシントン州やバージニア州でも、エネルギー大手などと契約を締結し、小型モジュール炉の開発プロジェクトを進める計画です。 Amazon 计划在华盛顿州和弗吉尼亚州，与能源大企业等签订合约，持续推进小型核反应炉的开发计划。 アメリカでは、AIの利用拡大でデータセンターの消費電力が急増していて、グーグルも今月14日、原発の開発を進める企業から電力を調達すると発表したほか、先月にはマイクロソフトが東部にあるスリーマイル島原発から電力の供給きょうきゅうを受けることが明らかになりました。 在美国，由于 AI 的利用扩大导致数据中心的电力消耗急剧增加，除了 Google 与本月 14 日发布将从推进开发原子能的公司筹措电力资源以外，上个月微软也明确将从处于美国东部的三里岛核电厂获取电力供给。 IT各社は、これまで推進してきた再生可能エネルギーの活用だけではまかない賄いきれず、原発による安定した電力を確保する動きを強めています。 IT 各公司不完全满足于至今为止推进的再生能源的活用，正在加强通过原子能开发来确保稳定电力的举措。","link":"/2024/10/17/translate_news_nhk_20241017_k10014611641000/"},{"title":"日语翻译 - 新闻 - アマゾン 中国 日本人学校の男児死亡事件1か月 中国側が説明の意向示す","text":"中国的日本人学校男童死亡事件发生一个月后，中方展现出发表声明的意向 来源：NHK 日期：2024-10-18 05:13 链接：中国 日本人学校の男児死亡事件1か月 中国側が説明の意向示す 🌟 单词： 男児｜だんじ① 刃物｜はもの① 適切｜てきせつ⓪ 拭う｜ぬぐう②⓪1. 擦掉，拭去，揩掉；2. 消除，洗刷。3. 做某事后装作若无其事，假装不知。 中国で日本人学校の男子児童が登校中に刃物はものを持った男に襲われ、死亡した事件が起きてから18日で1か月となる中、日中の外務省幹部が北京で会談しました。中国側は、司法手続きの中で事件の真相を解明し、日本側に説明する機会を設ける意向を示したということです。 从 9 月 18 日中国发生日本人学校的男童在上学路上被持刀男子袭击导致死亡的事件到现在的 1 个月中，中日双方的外务省干部在北京做了会谈。中方表明了在司法程序下解开事件的真相，并设立了向日方说明机会的意向。 中国南部の深センで9月、日本人学校に通うかよう10歳の男子児童が登校中に刃物を持った男に襲われ、死亡した事件が起きてから18日で1か月となります。 从中国南部的深圳市于 9 月 18 日发生的去日本人学校上学的男童在路上被持刀男性袭击，导致死亡的事件已经 1 个月了。 こうした中、外務省の岩本桂一領事局長が17日、中国外務省を訪れ、※トウ励邓励次官などと会談しました。 在这之中，外务省的岩本桂一领事局长于 17 日访问了中国外交部，并与邓励等副部长进行了会谈。 この中で岩本局長は、中国側に対して▼再発防止策につなげるための事実の解明や、▼SNS上での事実に基づかない悪質で反日的な投稿の取り締まりなどを求めました。 过程中岩本局长要求中方：说明带有防止再发生策略的事实情况、监管约束社交媒体上不基于事实的恶劣的反日信息。 これに対し、中国側は司法手続きの中で真相解明を果たし、適切な形で日本側に説明する機会を設ける意向を示したということです。 针对要求，中方表示了在司法程序下解开事件真相，并设立了向日方说明机会的意向。 また、SNS上の投稿については、特に法律に違反する可能性があるものへの対応をとっていく考えを示したということです。 然后，（中方）还表明了针对社交媒体上的信息，尤其是可能违反法律的那些会进行对应的想法。 中国各地の日本人学校では、中国当局とも協力し警備が強化されていますが、事件の背景の説明がない中、現地の日本人の間からは「動機が不明のままでは対策がとれない」といった声も聞かれ、安全への不安が拭えぬぐえない状況が続いています。 虽然中国各地的日本人学校都在于中国政府一起协作加强警力，但是在没有关于事件背景说明的当下，从当地的日本人们之间还会听到“因为不知道动机所以无法采取行动”的声音，对人生安全的不安无法消除的状况还在持续。","link":"/2024/10/18/translate_news_nhk_20241018_k10014612441000/"},{"title":"日语翻译 - 新闻 - 賃上げ 人材確保に向け7％程度表明する企業も 動き広がるか","text":"为了保留人才表明 7% 程度的涨薪，企业的这种行为正在蔓延 来源：NHK 日期：2024-10-21 05:59 链接：賃上げ 人材確保に向け7％程度表明する企業も 動き広がるか 🌟 单词： コールセンター｜こーるせんたー④(callcenter) 呼叫中心，客户服务中心。 手当｜てあて①补助，津贴。 春闘｜しゅんとう①春季要求提高工资的斗争。 ホールディングス｜ほーるでぃんぐす⑥(Holdings) 株式会社，控股公司。 連合｜れんごう⓪联合，联盟。 組合｜くみあい⓪1. 合伙；2. 扭打；3. 工会。 上乗せ｜うわのせ⓪追加，另加。 企業の間では人材の確保などに向けて、7％程度の高い賃上げを早期に表明する動きも出てきています。今後、中小企業を含めて高い賃上げの動きが広がるかが焦点となります。 在企业间为了确保人才（不流失）等，正出现提前表明高达 7% 涨薪等的动向。往后中小企业包含在内的、高涨薪行为蔓延的这件事情，正在成为焦点。 家電量販店のノジマは、来年1月から従業員およそ3000人に対しベースアップを実施するとともに、さらに店舗やコールセンターなどで働く従業員には4月しがつから1か月当たり最大さいだい2万5000円の手当を新たに設けることを決めました。 家电量贩店野岛电器不仅从明年 1 月开始对大约 3000 名员工实施基础薪资上涨，更决定从 4 月开始的每个月，对在店铺和呼叫中心等工作的员工，新设立最高 2 万 5000 日元的津贴。 ベースアップは3年連続で、新たな手当も受け取る従業員は平均7％程度の賃上げとなります。 连续 3 年基础薪资上涨、收到新的津贴的员工将（综合）涨薪 7%。 会社は早期の賃上げの表明で人材の確保につなげたいとしています。 公司表明早期的涨薪，是想要带来留住人才（的效果）。 来年の春闘しゅんとうでは、サントリーホールディングスが先月、ベースアップも含めて7％程度の賃上げを行う方針を明らかにするなど、今後、高い水準の賃上げが実現するかが課題となっています。 关于来年的春斗，三得利控股公司在上个月明确了将实行含基础薪资在内 7% 涨薪的方针等行为，今后，会将如何实现高水准的涨薪作为课题。 連合れんごうは、来年の春闘で定期昇給分を含めて5％以上の賃上げを要求するとともに中小企業の労働組合くみあいについてはさらに上乗せうわのせして、6％以上の賃上げを要求する方針で、大企業だけでなく中小企業にまで広がるかも焦点となっています。 工会不仅要求在来年的春斗（进行）包含定期涨薪在内（达到）5% 以上的涨薪，关于中小企业的劳动工会还（设立了）更高的、6% 以上涨薪的要求。因此不仅是大企业，（涨薪的行为）蔓延到中小企业的这件事，正在成为焦点。","link":"/2024/10/21/translate_news_nhk_20241021_k10014614571000/"},{"title":"日语翻译 - 新闻 - 南西諸島～東日本 23日にかけ大気不安定 落雷や突風などに注意","text":"西南诸岛到东日本，在 23 日大气处于不稳定状态，主力落雷和突然刮起的强风 来源：NHK 日期：2024-10-22 06:44 链接：南西諸島～東日本 23日にかけ大気不安定 落雷や突風などに注意 🌟 单词： 諸島｜しょとう① 大気｜たいき① 突風｜とっぷう⓪ 低気圧｜ていきあつ③ 南西｜なんせい⓪ 竜巻｜たつまき⓪ 北東｜ほくとう⓪ 辺り｜あたり①1. 附近，周围；2. 大约，上下，左右，差不多。 積乱雲｜せきらんうん③ 兆し｜きざし⓪1. 萌芽；2. 兆头，预兆。 頑丈｜がんじょう坚固的，牢固的。 季節外れ｜きせつはずれ 低気圧などの影響で南西諸島から東日本では、23日にかけて大気の状態が非常に不安定になる見込みで、気象庁は落雷や竜巻たつまきなどの激しい突風や急な強い雨に注意するよう呼びかけています。 由于低气压等的影响，预测西南诸岛到东日本于 23 日大气都非常不稳定。气象厅正在呼吁注意落雷、龙卷风等突然刮起的强风和暴雨。 気象庁によりますと、高気圧の縁へりをまわって流れ込む暖かく湿った空気の影響で南西諸島や西日本では、大気の状態が非常に不安定になり、雷かみなりを伴った激しい雨が降っているところがあります。 据气象厅描述，受到围绕高气压的边缘流入的暖湿空气的影响，在西南诸岛和西日本，大气在状态变得非常的不稳定，存在伴随着雷电降下暴雨的地区。 また、22日夜から23日にかけて、前線を伴った低気圧が発達しながら日本海を北東ほくとうへ進む見込みで、南西諸島から東日本では雷を伴った非常に激しい雨や激しい雨が降るところがある見込みです。 还有，从 22 日夜间岛 23 日，预计伴随着锋线的低气压会一边变强一边沿着日本海向东北前进，（同时还能）预测从西南诸岛到东日本存在伴随雷电降下大暴雨或暴雨的地区。 気象庁は、落雷や竜巻たつまきなどの激しい突風や急な強い雨に注意するよう呼びかけています。 气象厅正在呼吁注意落雷、龙卷风等突然刮起的强风和暴雨。 あたり辺りが急に暗くなったり、冷たい風が吹いたりするなど、発達した積乱雲せきらんうんが近づく兆しきざしがある場合は頑丈がんじょうな建物の中に移動するなど安全を確保してください。 又是周围突然变暗了，又是刮起了冷风等，如果有这些强大的积乱云靠近的征兆，请采取移动到坚固的建筑中等行为保障自身安全。 また、22日は西日本から北日本にかけて広い範囲で気温が上がり、日中の最高気温は▽熊本くまもと市で29度、▽鹿児島かごしま市、長崎市、福岡市で28度、▽佐賀さが市、和歌山わかやま市、大阪市で27度、▽宮崎みやざき市、高知市、松山市などで26度と、25度以上の夏日となるほか、▽東京の都心とうしんで24度、▽仙台市で22度、▽札幌市さっぽろで21度などと予想されています。 还有，在 22 日从西日本到北日本大范围气温上升，一天中的最高气温预测如下：▽ 熊本市 29 度▽ 鹿儿岛市、长崎市和福冈市 28 度▽ 佐贺市、和歌山市和大阪市 27 度▽ 宫崎市、高知市和松山市等 26 度，成了超过 25 度的夏天▽ 东京市中心 24 度▽ 仙台市 22 度▽ 札幌市 21 度 季節外れの暑さとなるところもある見込みで体調管理に注意してください。 预计有些地方会出现不合季节的炎热天气，请注意身体健康管理。","link":"/2024/10/22/translate_news_nhk_20241022_k10014615481000/"},{"title":"日语翻译 - 新闻 - 衆院選 医療や年金など社会保障制度のあり方めぐり活発な論戦","text":"众议院围绕医疗和年金等的社会保障制度展开了激烈的论战 来源：NHK 日期：2024-10-23 06:13 链接：衆院選 医療や年金など社会保障制度のあり方めぐり活発な論戦 🌟 单词： 選挙｜せんきょ① 構築｜こうちく⓪ 国民皆保険｜こくみんかいほけん⑦ 基礎｜きそ①② 受給｜じゅきゅう⓪ 底上げ｜そこあげ⓪ 払拭｜ふっしょく⓪ 存続｜そんぞく⓪继续存在，永存，长存。 低所得｜ていしょとく 衆議院選挙せんきょは終盤戦に入りました。選挙戦では医療や年金など社会保障制度のあり方をめぐり、各党による活発な論戦が行われています。 众议院选举进入了最终战。选举战围绕医疗和年金等社会保证制度的方面，由各党进行激烈的论战。 自民党は、全世代型の社会保障を構築こうちくし、国民皆かい保険は堅持しつつ、「年収の壁」を見直して働き方に関わらない中立な社会保険制度にするとしています。 自民党着力于构建全年龄的社会保障制度，持续坚持所有国民加入保险，重新评估年收的壁垒并进行与工作无关的中立的社会保障制度。 また、年金制度は、被用者として手厚い給付を受けられる人を増やし、基礎きそ年金の受給じゅきゅう額の底上げそこあげも図るなどとしています。 不仅如此，就年金制度，还意图增加作为被用工方的（能够）获取更多补助的人，并提高年金的发放额。 立憲民主党は、「マイナ保険証」の利用率が低迷する中、国民の不安が払拭ふっしょくされるまでは、いまの保険証を存続そんぞくさせるほか、社会保険料負担の上限額を見直し、富裕層に応分の負担を求めるとしています。 立宪民主党在「マイナ保険証」的利用率低迷的情况下，为了彻底消除民众的不安，除了继续保持现有的保险证以外，还在重新评估社会保险负担的上限额度，以求让富裕阶层负担匹配的部分。 年金制度では、低所得ていしょとくの高齢者の年金に一定額を上乗せして給付する制度を設けるとしています。 就年金制度，正在采取针对低收入的高龄者的年金，进行一定程度的提升支付的制度。 …… 对政治不感兴趣不翻了 🤦‍","link":"/2024/10/23/translate_news_nhk_20241023_k10014616221000/"},{"title":"日语翻译 - 新闻 - 飛び込み営業でリフォーム詐欺未遂疑い 会社役員ら逮捕 愛知","text":"涉嫌借推销进行房屋改建欺诈未遂，爱知县逮捕了一些公司职员 来源：NHK 日期：2024-10-23 20:31 链接：飛び込み営業でリフォーム詐欺未遂疑い 会社役員ら逮捕 愛知 🌟 单词： リフォーム｜りふぉーむ②(reform) 重制，改建。 詐欺｜さぎ①欺诈，诈骗。 未遂｜みすい⓪ 名古屋｜なごや 屋根｜やね①1. 蓬盖；2. 屋顶，屋脊。 騙し取る｜だましとる欺骗，诈骗，骗取。 千種区｜ちくさく 稲沢市｜いなざわし 特定商取引法｜とくてーしょーとりひきほー 認否｜にんぴ①承认与否认。 動画｜どうが⓪ 名古屋なごやのリフォーム会社の役員らが住宅を飛び込み営業で訪れ、「屋根が腐ってくさっている」などとうそを言って工事代金の名目で金をだましとろうとしたとして、詐欺未遂などの疑いで警察に逮捕されました。 由于名古屋的房屋改建公司的员工在别人家进行推销业务时，说类似“屋檐正在腐朽”之类的谎话片然后用工程贷款的名目骗取金钱，而被警察以欺诈未遂的嫌疑逮捕。 逮捕されたのは、名古屋市のリフォーム会社の役員、加藤大輝容疑者（33）ら合わせて5人です。 被逮捕的是名古屋内房屋改建公司的职员加藤大輝等总共 5 名嫌疑人。 警察によりますと、容疑者らは去年9月、名古屋市千種ちくさ区の住宅を訪れ、「屋根が腐っている」などとうそを言って、工事代金の名目で140万円をだまし取ろうとしたほか、ことし5月にも稲沢いなざわ市の住宅で同様の手口で150万円余りをだまし取ろうとしたとして、詐欺未遂と特定商取引法違反の疑いが持たれています。 据警察所述，嫌疑人于去年 9 月在名古屋千种区的住宅推销时说了“屋檐正在腐朽”等谎话，以工程贷款的名义骗取了 140 余万日元。除此之外在今年 5 月，还用同样的借口在稲沢市的住宅骗取了 150 多万日元，因此有欺诈未遂和违反「特定商取引法」的嫌疑。 5人の認否は明らかにされていません。 并未公开 5 人承认与否。 警察によりますと、被害者側が不審に思って消費生活センターに相談するなどし、契約を解除していたということです。 据警察描述，被害者方面觉得可以然后于消费生活中心进行了咨询，解除了合约。 警察は、今回とは別のケースで容疑者らが営業に使っていたとみられる動画どうがを押収していて、この動画で、屋根の一部がもともと壊れていたかのように見せていたとみられるということです。 警察没收了本次和其他案例中嫌疑人在推销中使用的视频，在视频中可以看到屋檐的一部分已经坏了。 警察はほかにも被害がないか捜査しています。 警方正在调查是否还有其他受害者。","link":"/2024/10/24/translate_news_nhk_20241023_k10014617281000/"},{"title":"日语翻译 - 新闻 - G20閉幕 共同声明 “世界経済 下振れリスク高まっている”","text":"G20 峰会闭幕，共同声明表示“世界经济下行的风险正在增高” 来源：NHK 日期：2024-10-25 06:33 链接：G20閉幕 共同声明 “世界経済 下振れリスク高まっている” 🌟 单词： 閉幕｜へいまく⓪ 軟着陸｜なんちゃくりく③ 共同｜きょうどう⓪ 保護｜ほご① 滲む｜にじむ②1. 渗出；2. 反映出；3. 渗入。 中でも｜なかでも①尤其，其中尤以…… 彼女は中でも特に出来る。 抑制｜よくせい⓪ 下支え｜したざさえ⓪下限。 軸｜じく②核心，中心。 各国｜かっこく①⓪ 焦点｜しょうてん① 下振れ｜したぶれ 紛争｜ふんそう⓪ 間近｜まぢか①⓪临近，接近；跟前，眼前。 迫る｜せまる② 掛け合う｜かけあう③⓪1. 交涉，谈判；2. 相当于，对应。 貿易｜ぼうえき⓪ 促す｜うながす⓪③ 途上国｜とじょうこく 気候｜きこう⓪ アメリカのワシントンで開かれていたG20＝主要20か国の財務相・中央銀行総裁会議が日本時間の25日朝閉幕へいまくしました。世界経済については、ソフトランディング＝軟着陸なんちゃくりくの見通しを持っているという認識で一致したものの、共同きょうどう声明ではリスクが高まっていると指摘し、なかでも尤其。行き過ぎた保護ほご主義によって経済的な分断が生じることに警戒感をにじませました。 在美国华盛顿召开的 G20（主要的 20 国的财务官、中央银行总裁会议）于日本时间 20 日早上闭幕。关于世界经济，一致认为带有软着陆的前景，但是联合声明页指出了风险正在增高，尤其对因过度的保护注意而产生的经济上的分裂表现出了警惕。 今回のG20は、欧米などが物価の抑制よくせいから利下げによる景気の下支えに軸じくを移す中、世界経済に関する各国の認識やこの先の安定に向けてどのように協調していくかが焦点となりました。 本次的 G20，以欧美等国从抑制物价转为降低利率来支撑经济（的情况下），各国对世界经济的认识以及如何协调实现未来的稳定成为焦点。 最終日の25日に行われた世界経済の見通しに関する議論では、各国が「ソフトランディング＝軟着陸についてよい見通しを持っている」という認識で一致しました。 于最后一天 25 日举行的关于世界经济前景的讨论上，各国就“有软着陆的前景”的认识保持了一致。 ただ、議論の成果をまとめた共同声明では「高い不確実性の中でいくつかの下振れしたぶれリスクが高まっている」と指摘し、各地の戦争や紛争ふんそうに加えくわえ、経済的な分断が世界経済の安定にとってリスクになりかねないと懸念を示しました。 然后，汇总了议论成果的共同声明指出了“在高不确定情况下经济多少下降的风险正在增高”，还展示了再加上各地的战争和纷争（的影响），经济上的分裂可能会对世界经济的安定造成风险。 今回のG20はアメリカ大統領選挙がまぢか間近に迫るせまる中での開催となりましたが、かつて高い関税をかけ合うなど貿易政策をめぐる米中の対立が世界経済のリスクになったことも踏ふまえ、行き過ぎた保護主義が再び広がることに警戒感をにじませた形です。 虽然本次的 G20 是在美国总统大选临近的情况下召开的，但是鉴于之前围绕高关税谈判等贸易政策的中美对立对世界经济造成的影响，还是（需要）对过度的保护注意的再次蔓延带有警惕。 加藤財務大臣は会議のあとの会見で「自由貿易がわが国経済であり世界経済の成長を促してきている。経済的な分断の要素が広がっていくことになれば経済の下振れリスクになりかねない」と述べました。 加藤财务大臣在会议后的见面会上说：“自由贸易正在促进包含我国经济在内的世界经济成长。如果经济上分裂的因素蔓延的话，（就）有导致经济下行的风险。” このほか、会議では途上国による気候変動対策を支援するため世界銀行などの「国際開発金融機関」の機能強化についても意見が交わされました。 除此之外，会议上还就为了支援各发展中国家气候变化对策的、强化世界银行等国际开发金融机关的功能交换了意见。","link":"/2024/10/25/translate_news_nhk_20241025_k10014618421000/"},{"title":"日语翻译 - 新闻 - 島根原発2号機の再稼働に向け 原子炉に核燃料を入れる作業開始","text":"为了岛根核能发电二号机器的再启动，开始向核反应堆加注核燃料的作业 来源：NHK 日期：2024-10-28 16:21 链接：島根原発2号機の再稼働に向け 原子炉に核燃料を入れる作業開始 🌟 单词： 島根県｜しまねけん③ 原子｜げんし① 核燃料｜かくねんりょう 上旬｜じょうじゅん⓪ 松江市｜まつえし 講じる｜こうじる⓪③1. 讲说；2. 谋求，寻求，想出措施等；3. 讲和；4. 采取。 建屋｜たてや②⓪ 沸騰水型炉｜ふっとうすいがたろ 東北｜とうほく⓪ 女川｜おながわ 着実｜ちゃくじつ⓪扎实，牢靠，稳健。 中国電力は、ことし12月に計画している島根しまね原子力発電所2号機の再稼働に向け、28日午後、原子炉に核燃料かくねんりょうを入れる作業を開始しました。作業は1週間程度かかる見通しで、その後検査などを行って問題がなければ、12月上旬にも原子炉を起動することにしています。 中国电力为了再次启动预计于今年 12 月（工作的）岛根核能发电站的二号机器，于 28 日下午开始了向反应堆加注核燃料的工作。预计作业会花费 1 周，之后进行检查等如果没有问题的话，12 月上旬会启动反应堆。 松江まつえ市にある島根原発2号機は、2012年以降運転を停止していますが、中国電力は安全対策工事を講じたうえで、ことし12月の再稼働を計画しています。 坐落于松江市的岛根核能发电二号机，虽然在 2012 年之后停止了运行，但是中国电力已经采取了安全措施，并计划于今年 12 月再去启动。 それに向けて、原子炉に核燃料を入れる作業を28日午後1時から開始したと発表しました。 为此，（公司）发布了从 28 日下午 1 点开始向反应堆加注核燃料的作业。 原子炉建屋たてやの中にあるプールに保管されている560体の核燃料を、水の中で1体ずつ移動させて原子炉内に入れていくということで、すべての作業が終わるまでには1週間程度かかる見通しです。 （作业内容是）将保存在核反应堆建筑水池中的 560 根核燃料棒，使用水包裹一个一个移动到核反应堆中。预计所有的工作结束花费 1 周时间。 その後検査などを行って問題がなければ、12月上旬に原子炉を起動することにしています。 如果之后进行检查后没有问题的话，决定于 12 月上旬重启核反应堆。 島根原発2号機は、事故を起こした東京電力の福島第一原発と同じ沸騰ふっとう水型すいがたと呼ばれるタイプで、このタイプで再稼働するのは、29日、原子炉を起動する予定の東北とうほく電力の女川おながわ原発2号機に続き2基目になる見通しです。 岛根核能发电站的二号机器，是和发生事故的东京电力的福岛第一核电厂一样的、被沉稳给沸腾水型类型的（发电设备），这个类型机器的再启动，预计将是继 29 日启动的东北电力的女川核能发电所二号机器之后的第二台。 中国電力は「安全確保を第一に、再稼働に向けた一つ一つの準備を着実ちゃくじつに進めてまいります」とコメントしています。 中国电力公司表示“将以确保安全作为首位，一个一个稳定地推进为了再启动的准备工作。”","link":"/2024/10/28/translate_news_nhk_20241028_k10014621791000/"},{"title":"日语翻译 - 新闻 - 宇宙飛行士の月面探査 着陸候補地9か所に絞り込む NASA","text":"NASA 针对宇航员的月球表面探查，筛选出了 9 个着陆候补地 来源：NHK 日期：2024-10-29 09:16 链接：宇宙飛行士の月面探査 着陸候補地9か所に絞り込む NASA 🌟 单词： 候補地｜こうほち③ 絞り込む｜しぼりこむ④1. 拧，榨；2. 锁定，限定，检索。 南極｜なんきょく⓪ 飲み水｜のみみず⓪ 探る｜さぐる⓪ 相手の腹を探る。 資源｜しげん① 継続｜けいぞく⓪ 火星｜かせい⓪ 見据える｜みすえる⓪③着眼于。 据える｜すえる⓪ NASA＝アメリカ航空宇宙局は、再来年を目標に進めている、宇宙飛行士による月面探査について、着陸の候補地を9か所に絞りしぼり込んだと発表しました。 NASA（美国国家航空航天局）发布了正在以后年为目标前进，就通过宇航员进行月面探测（的行动），已经筛选除了 9 个着陆候补地的事情。 候補地となる月の南極なんきょく付近は、氷が存在する可能性が指摘されていて、確認されれば、将来、飲み水みずなどに利用できるか探るさぐる計画です。 作为候补地的月球南极附近，被指出有存在冰的可能性，如果确认了的话，将来可以探索能否将其作为饮用水利用的计划。 NASAは国際月探査プロジェクト「アルテミス計画」で、再来年9月を目標に宇宙飛行士が月面に降り立つミッションを計画しています。 NASA 正在计划的任务是：通过国际月球探查计划“阿耳忒弥斯计划”，以后年 9 月为目标，让宇航员在月球表面降落。 これについてNASAは28日、宇宙飛行士が着陸を目指す月面の候補地を9か所に絞り込んだと発表しました。 就此 NASA 于 28 日公布筛选出了 9 个宇航员目标着陆的候补地。 候補地は、探査を行った際、資源しげんなどに関する新しい発見が得られる見込みがあるかや、安全に着陸できるかなどを検討して決めたということです。 候补地是探讨了是否预测可以在执行探索的时候有新的资源等相关的发现，并且可以安全着陆之后定下的。 月の南極付近には水が氷の状態で存在している可能性が指摘されていて、確認されれば、将来、飲み水や燃料として利用できるか、宇宙飛行士が探る計画です。 广泛指出月球的南极附近，有可能水以冰的形式存在，如果确认了的话将来是否可以用作饮用水和燃料，宇航员正在探索这个计划。 アルテミス計画をめぐっては日本はことし4月、アメリカ側と月面探査に関する取り決めに署名し、NASAが日本人宇宙飛行士に2回にわたり月面に着陸する機会を提供することなどが盛り込まれました。 围绕“阿耳忒弥斯计划”，日本于今年 4 月与美国方面在关于月面探查的协定上签字，加入了 NASA （需要）提供搭载 2 次日本宇航员着陆月球表面机会（的协议）。 アルテミス計画では、再来年以降も継続して月面の探査が行われる予定で、将来的には火星かせいの有人探査も見据えてすえています。 阿耳忒弥斯计划预定在后年以后继续进行月球表面的探查，还着眼于将在进行火星上的载人探查任务。","link":"/2024/10/29/translate_news_nhk_20241029_k10014622481000/"},{"title":"日语翻译 - 新闻 - 中古スマホ販売台数 6年連続過去最高更新へ 民間調査会社予測","text":"民间调查公司预测，二手手机的销售台数将连续第 6 年创下历史新高 来源：NHK 日期：2024-10-30 09:06 链接：中古スマホ販売台数 6年連続過去最高更新へ 民間調査会社予測 🌟 单词： 中古｜ちゅうこ⓪① 価格｜かかく⓪① 高止まり｜たかどまり③居高不下。 端末｜たんまつ 用途｜ようと① 今年度の中古スマートフォンの販売台数が6年連続で過去最高を更新するという見通しを民間の調査会社が公表しました。部材費の上昇による新製品の価格かかくの高止まりなどで中古端末たんまつへの需要が高まっているとしています。 民间的调查公司发表了今年度的二手手机销售数量将连续（第）6 年刷新历史最高记录的预测。由于配件费用上升导致新产品的价格居高不下，因此对二手手机的需求正在变高。 民間の調査会社「MM総研」は、端末の販売事業者などを調査した結果、今年度1年間の中古スマートフォンの販売台数は、315万台になると予測しています。 民间的调查公司“MM总研”根据调查手机销售从业人员等的结果，预测今年度的二手手机销售台数向达到 315 万台。 昨年度の販売台数は272万8000台で、今年度はおよそ42万台上回って、6年連続で過去最高を更新する見通しだとしています。 去年度的销售台数为 272 万 8000 台，预测今年大约会多 42 万台，连续 6 年更新过去最高的记录。 また、スマホ販売の全体に占める中古の割合は昨年度の9.7％から今年度は10.8％に増える見込みだということです。 并且，还预计占手机销售总量的二手（销售）比例将从去年度的 9.7% 增加至今年度的 10.8%。 調査会社は部材費の上昇などの影響で新製品の価格が高止まりしているほか、用途ようとに応じて複数の端末を使いたいという需要が高まっていることなどを理由にあげています。 调查公司除了由于材料费上涨等影响，新产品的价格居高不下以外，还给出了为了应对（不同）用途想要使用多个手机的需求逐渐增高的理由。 調査会社の横田英明研究員は「スマホが発売されてから、十数年がたち、発売当時と比べて進化の度合いが小さくなってきている。いわゆる『1円スマホ』に対する規制が強化されたことも中古への需要の背景にある」と話していました。 调查公司的横田英明研究员说：“从智能手机销售开始已经过去了十余年，但是和当时相比，进化的程度越来越小。换言之对于‘一元手机’的规范制约也成为了对二手手机需求的背景。”","link":"/2024/10/30/translate_news_nhk_20241030_k10014623191000/"},{"title":"日语翻译 - 新闻 - 日銀 きょう2日目の金融政策決定会合 政策金利を据え置くか","text":"日银，今天开始举行为期 2 天的金融政策决定会议，或许会维持利息政策不变 来源：NHK 日期：2024-10-31 05:11 链接：日銀 きょう2日目の金融政策決定会合 政策金利を据え置くか 🌟 单词： 日銀｜にちぎん⓪ 動向｜どうこう⓪ 慎重｜しんちょう⓪ 据え置く｜すえおく③④⓪ 先行き｜さきいき⓪将来，前途。 大統領｜だいとうりょう③ 控える｜ひかえる③②1. 等待；2. 在旁边等；3. 拽住；4. 面临；5. 打消念头。 余裕｜よゆう⓪ 日銀にちぎんは31日、2日目となる金融政策決定会合を開き、当面の政策を決定、公表します。日銀は利上げを検討する上でアメリカ経済の動向どうこうを重視するとしていますが、当面は慎重しんしょうに見極めるべきだという意見が多く、今回は政策金利を据え置くとみられます。 日银将于 10 月 31 日召开为期 2 天的金融政策决定会议，决定并公布眼前的政策。虽然日银在探讨提高利率方面采取重视美国经济的动向的行为，但是“应该慎重地看透当前形式”的意见也很多，被认为本次会维持政策利率不变。 日銀は31日、金融政策決定会合の2日目の議論を行い、当面の金融政策を決定、公表します。 日银于 31 日将举行了为期 2 天的金融政策决定会议，决定并公布眼前的政策。 日銀が利上げを検討する上で最近重視しているアメリカ経済をめぐっては、経済指標が市場の予想を上回るケースが多くなっています。 围绕日银在探讨提高利率方面围绕最近正在重视的美国经济，经济指标超过市场预期的例子正在变多。 ただ、植田総裁は先週、訪問先のワシントンで「先行きに対して楽観論が少し広がりつつある気がしている」と述べたほか、日銀内でも大統領選挙を控えひかえアメリカの経済は当面、慎重に見極めるべきだという意見が多くなっています。 不过，植田总裁于上周在访问目的地华盛顿表示“我认为前景逐步变得些许乐观”。但是日银内部认为面对总统选举，应该着眼当前、慎重地观察美国经济的意见正在变多。 さらに植田総裁は会見などで「時間的な余裕はある」と繰り返し述べていて、日銀は今回政策金利を据え置くとみられます。 之后植田总裁在见面会等回复“时间还足够”，被认为日银本次会维持政策利率不变。 一方、市場関係者の間では今月行われた衆議院選挙で政治情勢が不透明になっているとして、今後日銀は利上げを進めにくくなるのではないかという観測も出ています。 另一方面，由于本月举行的众议院选举导致政治形式变得不透明，市场关系方也提出了今后日银可能难以推进利率上升的猜测。 会合のあと行われる会見で、植田総裁がアメリカ経済の分析に加えて、この先の利上げに向けてどのような見通しを示すのかが焦点です。 目前的焦点时：在会议之后举行的见面会，植田总裁对美国经济的分析和对未来加息的前景（判断）。","link":"/2024/10/31/translate_news_nhk_20241031_k10014624461000/"},{"title":"日语翻译 - 新闻 - 自転車 酒気帯び運転疑いで2人逮捕 今月1日から罰則対象に","text":"作为本月 1 日开始的处罚对象，2 人因为醉酒骑自行车被逮捕 来源：NHK 日期：2024-11-04 07:33 链接：自転車 酒気帯び運転疑いで2人逮捕 今月1日から罰則対象に 🌟 单词： 酒気｜しゅき①② 帯びる｜おびる②⓪ 酒気を帯びる。带酒气；有醉意。 罰則｜ばっそく⓪ 路肩｜ろかた⓪ 乗用車｜じょうようしゃ③ 衝突｜しょうとつ⓪ 呼気｜こき① 検出｜けんしゅつ⓪ 懲役｜ちょうえき⓪徒刑。 科す｜かす①判刑，处刑。 自称｜じしょう⓪ 今月1日に施行された改正道路交通法で新たに罰則の対象となった自転車の酒気帯び運転の疑いで3日夜、福岡県と沖縄県であわせて2人が逮捕されました。警察は新たな罰則を周知するとともに、交通ルールを守って自転車を利用するよう呼びかけています。 作为本月 1 日实施的改正道路交通法中成为新的处罚对象的酒后骑自行车，福冈县和冲绳县共计 2 人因此嫌疑于 3 日夜晚被逮捕。警察将新的处罚条例广而告之的同时，还呼吁遵守交通规则使用自行车。 警察によりますと3日午後10時ごろ、福岡市中央区で事故のため路肩ろかたに停車していた軽乗用車にじょうようしゃ自転車が衝突しょうとつしました。 据警察所述，再 3 日下午 10 点左右，再福冈市中央区由于事故，自信车撞上了停在路边的小轿车。 現場にいた警察官が確認したところ、自転車に乗っていた住所不定・無職の28歳の容疑者から酒の臭いがしたため検査を行った結果、呼気こきから基準値の2倍近いアルコールが検出けんしゅつされ、酒気帯び運転の疑いでその場で逮捕しました。 现成的警官确认之后，由于从骑自信车的无固定居所、无业的 28 岁嫌疑人身上闻到了酒味，因此做了检查，结果是从呼气检测出了将近 2 倍基准值的酒精，（骑行者）因为醉骑的嫌疑被当场逮捕。 また沖縄県石垣いしがき市では3日午後10時ごろ、ライトをつけずに自転車に乗っていた住所不詳、45歳の自称じしょう建築作業員を警察官が呼び止め、呼気から基準値を上回るアルコールが検出されたため、その場で逮捕したということです。 还有冲绳县石垣市于 3 日晚上 10 点左右，警察官将骑车不带灯的、住所不明的自称 45 岁建筑作业员的人叫停，由于从他的呼气中检出了超过基准值的酒精，现场进行了逮捕。 11月1日に施行された改正道路交通法では、これまで罰則の対象外だった自転車の酒気帯び運転について、3年以下の懲役ちょうえきまたは50万円以下の罰金が科かされることになりました。 11 月 1 日实行的改正道路交通法，关于至今为止都是处罚对象以外的酒后骑自行车，将处以 3 年以下的徒刑或者 50 万日元以下的罚款。 警察は新たな罰則を周知するとともに、交通ルールを守って自転車を利用するよう呼びかけています。 警察将新的处罚条例广而告之的同时，还在呼吁遵守交通规则使用自行车。","link":"/2024/11/04/translate_news_nhk_20241104_k10014628541000/"},{"title":"日语翻译 - 新闻 - スペイン 洪水発生から1週間 捜索続く 200人以上が死亡","text":"西班牙洪水发生已经一周，搜救继续，确认 200 人以上死亡 来源：NHK 日期：2024-11-05 06:19 链接：スペイン 洪水発生から1週間 捜索続く 200人以上が死亡 🌟 单词： スペイン西班牙。 難航｜なんこう⓪1. 困难的航程，难以航行；2. 难以进展，迟迟不进。 犠牲者｜ぎせいしゃ② バレンシア州巴伦西亚。 排水｜はいすい⓪ 押しつぶす｜おしつぶす压碎。 貯まる｜たまる③积存，积攒。 積む｜つむ⓪1. 堆积，积累；2. 装载；3. 积累，积攒，积蓄。 交通網｜こうつうもう③交通网。 寸断｜すんだん⓪ 200人以上が死亡したスペイン東部の洪水は5日で発生から1週間です。被災地は今も浸水している場所も多く、行方不明者の捜索活動は難航しています。 11 月 5 日距离导致 200 人死亡的西班牙东部洪水已经过了一周时间。受灾地目前处于浸水状态的地方依然很多，搜索失踪者的活动难以推进。 スペイン東部では、バレンシア州を中心に10月29日から30日にかけて記録的な大雨による洪水が発生し、地元メディアによりますと、死亡が確認された人はこれまでに217人にのぼっているほか、行方がわからない人も多いことから犠牲者ぎせいしゃはさらに増える可能性が指摘されています。 西班牙东部以巴伦西亚州为中心于 10 月 29 日到 30 日由于破纪录的大雨导致发生了洪水，据当地媒体描述，至今为止被确认死亡的人数已经上升至了 217 人，除此之外指出由于失踪人数众多，遇难者有进一步增多的可能性。 被災地では地下の駐車場などで今も大量の水がたまっている場所もあり、消防などはポンプを使って排水作業を行っているほか、押しつぶされたり壊れたりした車両を1台1台確認するなど、厳しい状況での捜索を強いられています。 受灾地的地下停车场等，目前仍存在积存大量水的地方，消防人员不仅要使用泵进行排水作业，还要对被压坏或损坏的车辆一辆一辆进行确认，在严峻的状况下进行搜索。 4日には水や食料をのせたトラックなどを積んだスペイン軍の艦船がバレンシアの港に到着しました。 10 月 4 日搭载装有水和食物卡车等的西班牙军队的舰船到达了巴伦西亚州的港口。 被災地は道路や鉄道への被害で交通網もうが寸断すんだんされ、支援が十分に行き渡っていない地域もあり、住民の間からはスペイン政府やバレンシア州当局の対応に不満や怒りの声もあがっています。 由于前往受灾地道路和铁道的损坏，交通网被破坏了，仍然存在支援无法完全达到的地区，居民之间对西班牙政府和巴伦西亚地区当局应对措施不满的怨气正在上升。","link":"/2024/11/05/translate_news_nhk_20241105_k10014629181000/"},{"title":"日语翻译 - 新闻 - 転職市場でも賃金上昇傾向 多くの企業が中途採用強化で","text":"即使是转职市场也有薪资上涨的倾向，多数企业采取扩充聘用有工作经验的人的方式 来源：NHK 日期：2024-11-06 06:41 链接：転職市場でも賃金上昇傾向 多くの企業が中途採用強化で 🌟 单词： 賃金｜ちんぎん①工资；薪金，薪水；报酬。 中途採用｜ちゅうとさいよう应届录用以外的录用；录用有工作经验的人。 人手｜ひとで⓪ 獲得｜かくとく⓪ リクルート｜りくるーと③(recruit) 征募，征聘，发掘（人才），招聘，招募，就职面试。 提示｜ていじ①⓪出示，提出。 即戦力｜そくせんりょく③现有战斗力，立即作战的能力。 人手不足を背景に多くの企業が中途採用を強化していることから、転職市場でも賃金が上昇する傾向が見られます。 由于在人手不足的背景下，多数企业扩充聘用有工作经验的人，即使是转职市场也能看到有薪资上升的倾向。 企業の間では中途採用を強化する動きが出ていますが、獲得かくとく競争が激しく必要な人員を確保できない企業が多くなっています。 虽然企业之间出现了扩充聘用有工作经验的人的动向，但是争取人才竞争激烈，导致没法确保必要人员（补充）的企业变多了。 こうした中、ことし7月から9月までにリクルートが自社の転職支援サービスを使った人たちの転職の前と後の年収を比べたところ、全体の36.1％が1割以上増え、統計のある2002年以降もっとも高くなったということです。 对比了在这其中今年 7 月到 9 月的时间段内使用了自己公司的转职支援服务的人转职前后的年收之后，全体转职人员的 36.1% 提升了 10% 以上的薪资，是从有统计开始的 2002 年之后最高的（一年）。 業種別にみると、IT系エンジニアが41.3％ともっとも高く、営業職が36.9％、事務系専門職が34.7％などとなっています。 从行业分类来看的话，IT 系程序员为 41.3% 最高，营业职位为 36.9%，事务系专门职位为 34.7%。 またパーソルキャリアによりますと、ことし4月から9月までに自社の転職支援サービスを使った20代の転職後の平均年収は414万円と、転職前に比べて18万円増えたということです。 并且据太阳职业描述，今年 4 月到 9 月中使用了自己公司转职支援服务的 20 到 30 岁的人，转职后的平均年收为 414 万日元，与转职前相比增加了 18 万日元。 30代では転職後の平均年収が494万円と6万円増え、40代では562万円と10万円減っていますが、いずれの年代でも高水準の年収を提示ていじされる人の割合は増えていて、即戦力の人材を中心に賃金が上昇する傾向が見られます。 30 多岁的人转职后的平均年收是 494 万日元，增加了 6万日元，40 多岁是 562 万日元，相比减少了 10 万日元。不过无论是哪个年代，被给出高水准薪资的人的占比增加了，看起来有以有能力的人才为中心（对象）提升薪资水平的倾向。 パーソルキャリアの桜井貴史doda編集長は「どのようなスキルを伸ばす必要があるか会社の外にも目を向けることが大事になる。転職後のやりがいなど、未来の自分のキャリアもイメージしながら転職を考える必要がある」と話しています。 太阳职业的桜井貴史doda总编说：“（要考虑）应该提升哪方面的技能（的话），将目光放到公司外（的世界）也很重要。有必要想象着转职后的价值、未来自己的职业生涯，同时考虑转职的事情。”","link":"/2024/11/06/translate_news_nhk_20241106_k10014629971000/"},{"title":"日语翻译 - 新闻 - 富士山 初冠雪を気象台が発表 130年前の観測開始から最も遅く","text":"气象台公布了富士山首次开始积雪，是从 130 年前开始观测的最迟的 来源：NHK 日期：2024-11-07 07:40 链接：富士山 初冠雪を気象台が発表 130年前の観測開始から最も遅く 🌟 单词： 初冠雪｜はつかんせつ③每年山顶平均气温最高日过后，第一次在山顶发现冰雪堆积的现象。 山頂｜さんちょう⓪ 甲府市｜こうふし 目視｜もくし① 積雪｜せきせつ⓪ 積もる｜つもる②⓪ 麓｜ふもと③山脚，山麓。 薄っすら｜うっすら③微微地，隐约地。 独自｜どくじ⓪① 初雪｜はつゆき⓪ 宣言｜せんげん③ 富士山で7日朝、初冠雪はつかんせつが観測されました。平年より1か月余り遅れ、130年前に統計を取り始めてから最も遅い観測となりました。 于 7 日早上在富士山观测到了首次积雪。和常年相比晚了 1 个多月，（本次观测）是从 130 年开始统计的最迟的。 富士山の初冠雪は、山頂さんちょうからおよそ40キロ離れた甲府市こうふしの甲府地方ちほう気象台から職員が目視もくしで積雪せきせつの状況を確認し、発表しています。 富士山的首次积雪，是在距离山顶大约 40 千米远的甲府市的甲府地方气象台，工作人员通过目视确认积雪的情况，然后公布的。 気象台によりますと、7日午前6時ごろ、富士山の山頂付近に雪が積もっているのを確認したため、初冠雪が観測されたと発表しました。 据气象台描述，在 7 日早上 6 点左右，因为确认到了富士山的山顶附近雪堆积了，而发布了观测到首次积雪。 ことしの初冠雪は平年の10月2日から36日遅い観測となりました。 今年的首次积雪被观测到与往年的 10 月 2 日相比晚了 36 天。 また、これまでで最も遅かった昭和30年と平成28年の10月26日よりも遅く、130年前の明治27年に統計を取り始めてから最も遅い観測となりました。 还有，（本次观测）比到目前为止最迟的昭和 30 年和平成 28 年的 10 月 26 日还要迟，是从 130 年前的明治 27 年由记载开始的最迟的观测。 ふもと山脚，山麓。の富士吉田市では市職員が撮影した写真をもとに分析した結果、山頂にうっすら微微地，隐约地。と雪が積もっているのを確認し、6日に独自どくじの「初雪はつゆき化粧宣言せんげん」を発表していました。 在山脚下的富士吉田市，市政府员工基于拍摄的照片分析之后，确认了山顶上微微积雪的情况，在 6 日肚子发布了“宣布（富士山）有初雪装点”。","link":"/2024/11/07/translate_news_nhk_20241107_k10014631141000/"},{"title":"日语翻译 - 新闻 - カピバラ親子が露天風呂に入る姿が人気 静岡 伊東の動物公園","text":"在静冈伊东的动物公园，卡皮巴拉亲子进入露天澡池的姿势极具人气 来源：NHK 日期：2024-11-11 08:58 链接：カピバラ親子が露天風呂に入る姿が人気 静岡 伊東の動物公園 🌟 单词： 露天｜ろてん露天；室外。 伊東｜いとう 伊豆｜いず 仲睦まじい｜なかむつまじい亲密，和睦感情好。 飼育｜しいく⓪ 時期｜じき① 次々｜つぎつぎ② 湯船｜ゆぶね① 細める｜ほそめる③使细，弄细。 寛ぐ｜くつろぐ③1. 舒畅，轻松愉快，惬意，松快地休息；2. 不拘礼节，随便。 南瓜｜かぼちゃ⓪ ゆず｜ゆず①柚子。 神奈川｜かながわ 静岡県伊東市の動物公園では、カピバラの親子が仲むつまじく露天風呂に入る姿が人気を集めています。 静冈县的伊东市动物园，卡皮巴拉亲子亲密地进去露天澡池的姿态正聚集大量人气。 伊東市の「伊豆いずシャボテン動物公園」では50年以上前からカピバラを飼育しいくしていて、毎年、寒くなるこの時期じきに専用の露天風呂を設けています。 伊东市的“伊豆仙人掌公园”从 50 多年前就开始饲养卡皮巴拉，每年变得寒冷的同时期，都会设置专用的露天澡池。 風呂に湯が張られると、9月以降に生まれた赤ちゃんを含め、カピバラの親子が次々つぎつぎと湯船ゆぶねに入って、気持ちよさそうに目を細めてくつろいで寛いでいました。 澡池里的热水涨起来后，包括 9 月以后诞生的小宝贝，卡皮巴拉亲子一个个地进入澡盆，看起来很舒服地将眼睛眯成一条线享受。 伊豆特産で小さいかぼちゃ南瓜ほどの大きさの「鬼ゆず」が湯に入れられると、観光客は「鬼ゆず」にじゃれるカピバラの愛らしい姿を撮影していました。 将伊豆特产的、和小南瓜一样大的“鬼柚子”放入热水里之后，参观者就会拍摄和“鬼柚子”玩耍的卡皮巴拉的可爱姿态。 神奈川かながわから来た5歳の女の子は「お風呂に入ったところがかわいかったです。気持ちよさそうでした」と話していました。 从神奈川来的 5 岁的女孩子说：“（卡皮巴拉）进入澡池的时候非常可爱，看起来很舒服的样子。” 飼育員の林優樹さんは「小さい子だったり、大きな大人のカピバラがゆっくりのんびりとお風呂に入っている姿を見ることができますので、ぜひお越しください」と話していました。 饲养员林优树说：“可以看到小的、大的成年的卡皮巴拉慢悠悠地无忧无虑地进去澡池的姿态，请一定再来！” カピバラの露天風呂は、来年4月まで続けられます。 卡皮巴拉的露天澡池，将持续到明年 4 月。","link":"/2024/11/11/translate_news_nhk_20241111_k10014634511000/"},{"title":"日语翻译 - 新闻 - 韓国 北朝鮮ICBM ロシアから技術支援受けた可能性を指摘","text":"韩国指出北朝鲜的洲际弹道导弹有从俄罗斯接受技术支援的可能性 来源：NHK 日期：2024-11-11 22:26 链接：韓国 北朝鮮ICBM ロシアから技術支援受けた可能性を指摘 🌟 单词： 北朝鮮｜きたちょうせん⑤ 大陸間弾道ミサイル｜たいりくかんだんどうみさいる洲际弹道导弹。 ミサイル｜みさいる②导弹。 級｜きゅう 与党｜よとう①1. 执政的政党，执政党；2. 志同道合的伙伴。 国会｜こっかい⓪ 軍事｜ぐんじ① 派遣｜はけん⓪ 北朝鮮きたちょうせんが先月発射したICBM＝大陸間弾道ミサイル級きゅうのミサイルについて、韓国の国防当局は、通常、発射前に行われるエンジンの実験が確認されていないなどとして、ロシアから技術支援を受けた可能性を指摘しました。 关于北朝鲜在上个月发射的 ICBM 洲际弹道导弹级别的导弹，韩国当局指出由于没有确认一般发射前（会做）的引擎实验，（北朝鲜）有接收俄罗斯技术支援的可能性。 これは、韓国の与党よとう 国民の力の国会こっかい議員が11日、韓国国防省の国防情報本部の分析結果として明らかにしました。 上述的事情，是韩国的执政党“国民力量党”的国会议员于 11 日，作为韩国国防部中的国防信息总部的分析结果公布的。 それによりますと、北朝鮮が先月末に発射実験に成功したとする、ICBM＝大陸間弾道ミサイル級の「火星19型」について、改良型ではなく、新型のミサイルと判断したということです。 据描述，判断北朝鲜在上个月末发射成功的、ICBM 洲际弹道导弹级别的“火星 19 号”，并非改良型号，而是新型的导弹。 さらに、北朝鮮は通常、新型の弾道ミサイルの発射前にエンジンの実験を行いますが、ことし3月を最後に、固体こたい燃料のエンジンの実験は確認されていないとしています。 更进一步的是，北朝鲜通常在新型弹道导弹发生前会进行引擎实验，但是在今年 3 月以后，（北朝鲜）没有进行过固态燃料的引擎实验。 そして、国防情報本部は具体的な情報はないとしたうえで「『宇宙技術分野の協力』という名目で、北がロシアから、弾道ミサイルに転用できる技術支援を受けている可能性も排除できない」との見方を示したとしています。 然后，国防信息总部由于没有得到具体的信息，表明了“不能排除北朝鲜以‘宇宙技术领域的帮助’的名义，接受了来自俄罗斯的、可以运用于弹道导弹的技术的可能性。”的看法。 韓国政府などは、北朝鮮がウクライナへの軍事ぐんじ侵攻を続けるロシアに対して軍の部隊を派遣はけんする見返りとして、ICBMなど軍事技術の支援を求める可能性を指摘していて、関係国が動向を注視しています。 韩国政府等指出了北朝鲜作为向持续军事进攻侵犯乌克兰的俄罗斯派遣军队的回报，有可能要求了 ICBM 等军事技术的支援。相关国家将持续关注后续动向。","link":"/2024/11/12/translate_news_nhk_20241111_k10014635481000/"},{"title":"日语翻译 - 新闻 - 通信各社 宇宙や空での通信インフラ構築に向けた実証実験 加速","text":"各通信公司正在加速（进行）为了在宇宙和天空中构筑通信基础设施的实证实验 来源：NHK 日期：2024-11-11 22:26 链接：通信各社 宇宙や空での通信インフラ構築に向けた実証実験 加速 🌟 单词： インフラ｜いんふら⓪(infrastructure) 基本建设，基础设施形成生产或生活基础的构筑物；基础设施。 施設｜しせつ①② 構築｜こうちく⓪构筑，建筑。 衛星｜えいせい⓪ 航空機｜こうくうき③ 手がける｜てがける③1. 亲自动手；2. 亲自照料，亲自照管，亲自培养。 電波｜でんぱ① アンテナ｜あんてな⓪(antenna) 天线。 山間部｜さんかんぶ⓪ 成層圏｜せいそうけん平流层，同温层。 大規模だいきぼな災害に備えて、通信各社の間で衛星えいせい通信網もうとスマートフォンとの直接の通信や、無人の航空機こうくうきを使った「空飛ぶ基地局」といった宇宙や空での通信インフラの構築に向けた実証実験が加速しています。 为了防备大规模的灾害，各通信公司间正在加速进行为了在宇宙和天空中构筑卫星通信网和智能手机之间直接通信的、无人的飞行器使用的被称为“天空基站”的通信基础设施的实证实验。 このうちKDDIは、先月アメリカの宇宙開発企業・スペースXが手がける衛星通信網「スターリンク」とスマートフォンの間で直接、メッセージの通信を行う実証実験に成功したと発表しました。 在这其中 KDDI 发布了上个月美国宇宙开发企业 SpaceX 亲自研发的星链和手机之间直接进行信息通信的实证实验成功了的信息。 スターリンクは、これまでも衛星の電波でんぱを中継する専用のアンテナを通じて、地上の基地局がカバーしていない山間部さんかんぶや海上での通信のほか、災害で基地局が壊れた際などに活用されています。 星链到目前为止，通过中继卫星电波的专用天线，在地上基站无法覆盖的山中和海上，还有由于灾害导致地上基站坏掉的时候被广泛运用。 会社は、今回の実験で簡易に通信が行えるとして、年内にサービスの提供を始めたいとしています。 公司由于在本次的实验中（确认了）能够简单地通信，正在决定年内开始提供服务。 このほか「HAPS」と呼ばれる無人の航空機を使った通信サービスについても実証実験が進んでいます。 除此以外，关于被称为“HAPS”的无人机使用的通信服务，也在推进实证实验。 ソフトバンクは、開発している大型の機体が成層圏せいそうけんの飛行に成功したと先月発表したほか、NTTドコモも再来年の商用化に向けて取り組んでいて、大規模な災害に備えて宇宙や空での通信インフラの構築に向けた開発の動きが相次いでいます。 软银在上月发发布了开发的大型机体在平流层成功飞行的消息，除此以外，NTT DOCOMO 为了后年的商用化也在努力，为了防备大规模的灾害、目标是在宇宙和天上构筑通信基础设施的开发动作相继发生。","link":"/2024/11/13/translate_news_nhk_20241113_k10014636591000/"},{"title":"日语翻译 - 新闻 - 京都で保管の蒸気機関車 解体の危機も 新たな展示場所へ出発","text":"在京都保管的蒸汽机车，有被解体的危机，向新的展示场所出发 来源：NHK 日期：2024-11-14 05:15 链接：京都で保管の蒸気機関車 解体の危機も 新たな展示場所へ出発 🌟 单词： 与謝野町｜よさのちょう 蒸気｜じょうき① 閉鎖｜へいさ⓪ 大正｜たいしょう⓪大正(大正天皇嘉仁的年号)大正元年为公元1912年(年号（1912.7.30～1926.12.25）。明治の後，昭和の前。大正天皇の代。) 北部｜ほくぶ① 加悦｜かや京都府北西部，与謝野町の地名。 愛好家｜あいこうか クラウドファンディング(crowdfunding) 众筹。 修繕｜しゅうぜん⓪ トレーラー｜とれーらー②⓪(trailer) 拖车。 危機｜きき①② 京都府与謝野町よさのちょうの施設で保管されていた100年ほど前の蒸気じょうき機関車が、施設の閉鎖へいさに伴い、13日、千葉県の新たな展示場所に向けて出発しました。 在京都府与謝野镇的设施中保管着的 100 年前的蒸汽机车随着设施的关闭，13 日向着千叶县新的展示场所出发。 大正たいしょうから昭和にかけて京都府北部ほくぶの各地を結んだ「加悦鉄道」を走っていた、100年ほど前に作られた国産の蒸気機関車は、与謝野町で展示されていましたが、4年前に施設が閉鎖されたことから、一時は解体される恐れがありました。 （该机车）从大正开始到昭和的期间内，运行在连接京都府北部各地的“加悦铁道”上，虽然（作为）100 年前造出来的国产整齐机车，一直在与謝野镇上展示，但是由于 4 年前设施被关闭了，一度有被解体的风险。 しかし、鉄道愛好家たちがクラウドファンディングで、修繕しゅうぜんや新しい展示先への移動の費用、およそ1000万円を集めたことから、12月から千葉県いすみ市内の施設で展示されることになり、13日、トレーラーに乗せられ、関係者に見送られながら出発しました。 然后，由于铁道爱好者们通过众筹，募集了（用以）修缮和移动到新的展示场地的大约 1000 万日元，从 12 月开始机车将在千叶县的「いすみ」市内的设施展出。13 号机车由拖车搭载，在相关人士的目送中出发。 クラウドファンディングを行った佐瀬賢太郎さんは「見捨てたくなかったので、多くの人の支援をもらえ嬉しかったです。千葉で機関車の姿を見るのが楽しみです」と話していました。 进行众筹的佐瀬賢太郎说：“由于不忍舍弃，收到众多人士的支援非常高兴。很期待在千叶看到机车。”","link":"/2024/11/14/translate_news_nhk_20241114_k10014637841000/"},{"title":"日语翻译 - 新闻 - 「高額療養費制度」上限額引き上げる方向で検討 厚労省","text":"厚生劳动省探讨提升“高额疗养费制度”（患者承担）的上限额 来源：NHK 日期：2024-11-15 06:05 链接：「高額療養費制度」上限額引き上げる方向で検討 厚労省 🌟 单词： 療養｜りょうよう⓪1. 疗养，养病。 患者｜かんじゃ⓪ 抑える｜おさえる③② 軽減｜けいげん⓪ 審議会｜しんぎかい③ 与野党｜よやとう⓪ 医療費が高額になった患者かんじゃの自己負担ふたんを一定額に抑えるおさえる「高額療養費制度」について、厚生労働省は上限額を引き上げる方向で検討を始めました。国全体の医療費が増加する中、現役世代の保険料負担を軽減けいげんするねらいがあります。 关于将高额医疗费患者的自己承担费用设定在一定数值的“高额疗养费制度”，厚生劳动省开始探讨提高其上限额度。在全国全体人民医疗费增加的背景下，很难减轻现在工作一代的保险金负担。 「高額療養費制度」は、高額な治療を受けた場合に、患者の負担が重くならないように、年齢や年収に応じて毎月の医療費の自己負担に上限額を設け、それを超えた分が払い戻される仕組みです。 “高额疗养费制度”是：在接受高额的治疗的时候，为了不让患者的负担变重，基于其年龄和年收设定每个自己负担医疗费用的上限额度，超过上限的部分返还。 現在の上限額は、70歳未満では5つの区分に分かれていて、年収が最も少ない区分では3万5400円、年収が最も多い区分では25万2600円程度などとなっています。 现在的上限额，没满 70 岁会分为 5 个区间，年收最少的区间是 3 万 5400 日元，年收最多的区间是 25 万 2600 日元。 これについて厚生労働省は、医療費が増加する中、患者の自己負担を今より増やすことで現役世代の保険料負担を軽減しようと、上限額を引き上げる方向で検討を始めました。 就此厚生劳动省为了在医疗费增加的背景下，通过对比当前现状增加患者自己的负担额度、以减轻现在工作一代的保险金负担，开始探讨提高上限额度。 年収が少ない区分については、自己負担が大きくならないように引き上げ幅を調整する方向です。 针对年收少的区间，为了不增加其自身负担，会调整上涨的幅度。 厚生労働省は、近く審議会しんぎかいで本格的に議論を始め、年内にも具体的な引き上げ額や実施時期などを決定したい考えですが、患者の自己負担が重くなるため与野党よやとうから反発が出ることも予想されます。 厚生劳动省考虑最近在审议会开始正式的讨论，并决定在年内定下具体的上涨额度和执行日期，不过由于会增加患者自己的负担，预测会有来自在野党的反对。","link":"/2024/11/15/translate_news_nhk_20241115_k10014638981000/"},{"title":"日语翻译 - 新闻 - JR函館線で貨物列車が脱線 けが人なし 復旧急ぎ原因調査へ","text":"JR 函馆线发生了货物列车脱轨的事故，没有人员受伤，急于恢复而进行原因调查 来源：NHK 日期：2024-11-16 10:09 链接：JR函館線で貨物列車が脱線 けが人なし 復旧急ぎ原因調査へ 🌟 单词： 函館｜はこだて ブレーキ｜ぶれーき②(brake) 1. 制动器，车闸，刹车；2. 阻碍，制止。 作動｜さどう⓪ コンテナ｜こんてな①⓪(container) 容器；周转容器；周转箱；集装箱。 名古屋市｜なごやし ターミナル｜たーみなる①(terminal) 1. 终点站；2. 终端；3. 接头。 札幌｜さっぽろ⓪ 長万部｜おしゃまんべ 運輸｜うんゆ① 管内｜かんない① 大沼郡｜おおぬまぐん 洞爺湖｜とうやこ 室蘭市｜むろらんし 動作｜どうさ① 軸｜じく② 🌟 惯用句： 運転見合わせ暂时不能和平时一样通行。 通常通り運転することをいったんやめて、状況の成り行きを見守ることなどを意味する語。電車やバスなどの交通機関が悪天候や災害などによって運行を一時中断することを指す場合が多い。 北海道森町の函館はこだて線で16日未明、走行中の貨物列車が脱線して停止しました。けが人はいませんでしたが、函館線は現場付近で運転を見合わせていて、運転再開の見通しは立っていないということです。 16 日凌晨在北海道森町的函馆线上，行驶中的货物列车脱轨然后停下来了。虽然没有受伤的人，但是无法驾车到函馆线脱轨现场，因此无法预见重新开放线路（的时间）。 JR貨物によりますと、16日午前1時40分ごろ、森町の函館線で走行中の貨物列車の非常ブレーキ紧急制动器。が作動さどうし、運転士が確認したところ、貨車が脱線していたということです。 据 JR 货物公司所述，在 16 日上午 1 点 40 分左右，在森町的函馆线上行驶列车的紧急制动器启动了，驾驶员确认了之后，（发现）原来是火车脱轨了。 貨物列車はコンテナを載せて名古屋市の名古屋貨物ターミナル駅から札幌さっぽろ市の札幌貨物ターミナル駅に向かう途中で、機関車を含めた21両編成のうち貨車の部分の5両が脱線しました。けが人はいませんでした。 货物列车搭载了集装箱在从名古屋市的名古屋货物车站前往札幌市札幌货物车站的途中，由包含机车头在内的总计 21 节中的 5 节货车部分脱轨了，没有人无人受伤。 この影響で、函館線は森駅と長万部おしゃまんべ駅の間で運転を見合わせています。 受此影响，函馆线在森站和长万部站之间暂停运行。 運転再開の見通しは立っていないということで、札幌と函館を結ぶ特急列車は16日は終日運転を見合わせたり、折り返し運転をしたりすることにしています。 由于无法预测重新开放线路，连接札幌和函館到特快列车 16 日整天都无法运行，只能决定折返。 事故を受けて国の運輸うんゆ安全委員会は、鉄道事故調査官2人を16日、現地げんちに派遣し、脱線の詳しい原因を調べる予定です。 受到事故影响，国家运输安全委员会预定于 16 日将 2 名铁道事故调查员派往当地，调查脱轨的详细原因。 JR北海道の管内かんないでは、2013年に函館線の大沼おおぬま駅構内で貨物列車の脱線事故が起きたほか2017年にも洞爺湖とうやこ町の室蘭むろらん線で貨物列車が脱線するなど、貨物列車の脱線事故が相次いで発生しています。 在 JR 北海道的管辖范围内，除了 2013 年在函馆线的大沼站内发生了货物列车的脱轨事件意外，在 2017 年洞爺湖镇的室蘭线货物列车页脱轨了，货物列车脱轨的事件相继发生。 鉄道事故調査官を現地に派遣 運輸安全委 运输安全委员会向当地派遣了铁道事故调查员 国土交通省によりますと、脱線したJR貨物の車両は機関車1両と貨車20両のあわせて21両編成で、非常ブレーキが動作どうさしたため運転士が停車させたところ、貨車5両が進行方向右側に脱線していたと会社から報告があったということです。 据国土交通省描述，收到的报告说：脱轨的 JR 货物车辆由一节车头和 20 节货车共计 21 节组成，由于紧急制动器工作，驾驶员将车辆停止后，5 节货车向行驶方向的右侧脱轨了。 脱線していたのは、12両目の2軸じく、15両目の1軸、17両目の4軸すべて、19両目の2軸、20両目の1軸だということです。 脱轨的是：第 12 节的 2 个车轴、第 15 节的 1 个车轴、第 17 节的 4 个车轴、第 19 节的 2 个车轴和第 20 节的 1 个车轴。 この事故を受け、国の運輸安全委員会は、鉄道事故調査官2人を現地に派遣し、脱線の詳しい原因を調べる予定です。 受到事故影响，国家运输安全委员会预定于 16 日将 2 名铁道事故调查员派往当地，调查脱轨的详细原因。","link":"/2024/11/16/translate_news_nhk_20241116_k10014640301000/"},{"title":"日语翻译 - 新闻 - あすにかけ北日本は平地でも積雪のおそれ 交通影響に十分注意","text":"明天北日本即使是平地恐怕也会积雪，请万分注意对交通的影响 来源：NHK 日期：2024-11-18 06:52 链接：あすにかけ北日本は平地でも積雪のおそれ 交通影響に十分注意 🌟 单词： 真冬｜まふゆ⓪ 並み｜なみ⓪1. 并列，排列；2. 普通，一般，平常；3. [接尾]并列，与……同样的程序。 上空｜じょうくう⓪ 積雪｜せきせつ⓪ 北陸｜ほくりく⓪ 山沿い｜やまぞい⓪ タイヤ｜たいや⓪(tire) 轮胎。 凍結｜とうけつ⓪ 冷え込み｜ひえこみ⓪骤冷，气温急剧下降。 真狩村｜まっかりむら 八甲田山｜はっこうださん 酸ヶ湯温泉｜すかゆおんせん 冬型ふゆがたの気圧配置が強まり、上空じょうくうにこの時期としては強い寒気が流れ込む影響で全国的に気温が下がり、北日本では19日にかけて、平地でも雪が積もるおそれがあります。今シーズン初めての積雪せきせつになるところもある見込みで交通への影響に十分注意してください。 由于冬季型气压分布增强，（并且）上空也在这个期间有强冷的寒气流入的影响，全国性地发生了温度下降。北日本在 19 日，即使是平地也有雪堆积的可能性。因为预测有这个季节的首次剞劂，因此请万分注意对交通的影响。 気象庁によりますと日本付近は冬型の気圧配置となっていて、上空にはこの時期としては強い寒気が流れ込んでいます。 据气象厅描述，日本附近产生了冬季型气压分布，上空在这个期间也流入了强冷的寒气。 このため北海道や東北、それに北陸ほくりくでは雪が降っているところがあります。 因此，另一方面北海道和东北地区、还有北陆地区将会降雪。 19日にかけて北海道から北陸にかけての日本海側では山沿いを中心に雪が降り、北日本では平地でも積もるところがある見込みです。 在 19 号，从北海道到北陆地区的日本沿海地区，预计沿山将会降雪，（同时）在北日本即使是平地也会积雪。 今シーズン初めての積雪せきせつとなるところもある見込みで、雪が予想されている地域では冬用ふゆようタイヤやチェーンを装着するなどして、路面の凍結とうけつや交通への影響に十分注意してください。 由于预测到将成为这个季节的首次积雪，在预计会降雪的地区，请采取使用冬季用轮胎或链条等的行为，万分注意路面的冻结对交通的影响。 また、冷え込みひえこみ’も強まり、午前5時までの最低気温は▽北海道真狩村まっかりむらでマイナス4.1℃、▽青森県八甲田山はっこうださん系の酸ヶ湯すかゆでマイナス3.6℃、▽岩手県盛岡市で4.5℃などとなっています。 还有，骤冷增强，截至早上 5 点的最低气温▽北海道真狩村最低将为 4.1 度▽青森県八甲田山系的酸ヶ湯最低将为 3.6 度▽岩手県盛岡市最低将为 4.5 度 17日の最高気温は▽静岡市で25.8℃、▽東京の都心で23.8℃など広い範囲で季節外れの暖かさとなりましたが、20日はつかにかけて気温が大幅に下がり、真冬並みの寒さになるところもある見込みです。 17 号的最高气温▽ 静冈市为 25.8 度▽ 东京的市中心为 23.8 度虽然大范围会变得不像这个季节的温暖，但是预计在 20 日气温会大幅下降，变得犹如隆冬的寒冷。 体調管理にも注意してください。 请注意身体。","link":"/2024/11/18/translate_news_nhk_20241118_k10014641591000/"},{"title":"日语翻译 - 新闻 - 成田空港「ブラインド訓練」12月に初実施へ 災害時の対応確認","text":"成田机场将在 12 月初首次实施“盲训”，以确认灾害发生时的应对措施 来源：NHK 日期：2024-11-19 05:43 链接：成田空港「ブラインド訓練」12月に初実施へ 災害時の対応確認 🌟 单词： 成田空港｜なりたくうこう ターミナル｜たーみなる①(terminal) 1. 站点；2. 终端。 ブラインド｜ぶらいんど⓪(blind) 百叶窗，遮光帘。 実践｜じっせん⓪1. 实行，实践；2. 根据某种理论或主义实际行动。 テナント｜てなんと⓪(tenant) 借地人，租房人楼房、公寓等的租借使用人。 シナリオ｜しなりお⓪(scenario) 剧本，脚本。 スタッフ｜すたっふ②(staff) 1. 负责干部，干部，职员,班底；2. 工作人员；3. 材料，原料。 多言語｜たげんご 手当て｜てあて①1. 准备，预料；2. 处置，救助；3. 报酬，工资；4. 补贴，津贴。 立ち会う｜たちあう③到场，在场，会同，出席，参加以证人、参考人和监督者的身份临场。 抽出｜ちゅうしゅつ⓪ 日本を訪れる外国人旅行客が増加する中、大地震など災害時の対応を確認するため、多くの外国人が利用する成田なりた空港のターミナルで内容を事前に明かさない「ブラインド訓練」を、来月初めて実施することになりました。 随着来访日本的外国旅客增加，为了确认大地震之类灾害时的应对，将会于下个月月初在众多外国游客使用的成田机场的站点实施事前明确内容的“盲训”。 成田空港では、ことし6月までの半年間に国際線を利用した外国人が初めて1000万人を超えるなど増加傾向が続き、大地震が発生した際の避難経路の周知など、対応が課題になっています。 在成田机场，截至今年 6 月的半年间，使用了国际线路的外国人首次突破 1000 万人，并且还有持续增加的趋势，广泛告知大地震发生时的避难路线等对应错误，正在成为难题。 成田空港会社は、大地震が発生した際の対応を確認する実践じっせん訓練を行う必要があるとして、航空会社やターミナル内のテナントなどに協力を呼びかけ、詳しい内容やシナリオ剧本，脚本。を事前に明かさない「ブラインド訓練」を来月上旬に実施することを決めました。 成田机场公司，由于（认为）有进行用以确认大地震发生时的对应措施的实际的训练，航空公司决定呼吁站点内商家的协助，在下个月上旬实施事前明确详细的内容和脚本的“盲训”。 訓練には航空会社のスタッフやテナントの従業員などあわせて100人ほどが参加し、外国人旅行客の避難誘導を多言語たげんごで行うほか、けが人の手当てなどを行う予定で、専門家が立ち会って対応が十分かどうかチェックするということです。 训练将有航空公司的工作人员和站内商家的从业人员等总计 100 人参加，除了将外国旅客的避难引导用多语言进行以外，还预定进行对受伤人员的处理，并由专家到场确定应对措施是否充足。 成田空港のターミナル内で「ブラインド訓練」を行うのは今回が初めてで、成田空港会社によりますと、過去には高知空港や釧路くしろ空港で実施されたものの、国内の大規模な空港では例がないということです。 在成田机场的站点内进行“盲训”，这次是第一次，据成田机场公司描述，虽然过去在高知机场和釧路机场实施过，但是并美誉在国内大机场（实施）的例子。 成田空港会社は「訓練で課題を抽出ちゅうしゅつして改善につなげ、災害対応力の向上に努めたい」としています。 成田航空公司正在“想要随着通过训练将问题找出并改善，提升灾害应对能力”。","link":"/2024/11/19/translate_news_nhk_20241119_k10014642471000/"},{"title":"日语翻译 - 新闻 - バルト海 海底の通信ケーブル 切断や損傷が相次ぐ 当局が捜査","text":"波罗的海，相继发生海底通信光缆被切断或损害的事件，当局开始调查 来源：NHK 日期：2024-11-20 09:08 链接：バルト海 海底の通信ケーブル 切断や損傷が相次ぐ 当局が捜査 🌟 单词： バルト海｜ばるとかい波罗的海。 北欧｜ほくおう⓪ ケーブル｜けーぶる①⓪(cable) 1. 电缆；2. 缆，缆绳，钢缆。 切断｜せつだん⓪ 損傷｜そんしょう⓪ 沿岸｜えんがん⓪ スウェーデン｜すうぇーでん(Sweden) 瑞典。 工作｜こうさく⓪ 露わ｜あらわ リトアニア｜りとあにあ⓪(Lithuania) 立陶宛。 制限｜せいげん③ 名指し｜なざし ハイブリッド｜はいぶりっど(hybrid) 混合。 天然ガス｜てんねんがす⑤天然气。 パイプライン｜ぱいぷらいん④(pipeline) 输油管。 ノルドストリーム｜るどすとりーむ⑥(Nord Stream) 北溪天然气管道。 北欧ほくおうのバルト海で海底の通信ケーブルが切断せつだんされたり損傷したりしているのが相次いで見つかり、沿岸えんがんのスウェーデンなどの当局が捜査を始めました。ドイツの国防相は破壊工作こうさくの可能性が高いという見方を示し、ロシアへの警戒感をあらわにしています。 相继在北欧的波罗的海发现海底的通信光缆被切断或是损害，沿岸的瑞典等当局已经开始了调查。德国的国防官表示是破坏行动的可能性很高，同时展现出了对俄罗斯的警戒感。 ドイツとフィンランドの両政府は18日、両国を結ぶバルト海の海底通信ケーブルが切断されているのが見つかったと発表しました。 德国和法国两政府于 18 日发表了发现连接两国的波罗的海海底通信光缆被切断的信息。 バルト海ではその前日にもスウェーデンとリトアニアを結ぶ海底通信ケーブルに損傷が見つかり、リトアニア国内のインターネット通信が制限されるなどの影響が出ています。 在波罗的海前些日子也发现连接瑞典和立陶宛的海底通信电缆被损伤，而出现了立陶宛国内网络通信受到限制的影响。 ともに復旧には2週間程度かかる見通しで、相次ぐ被害を受けスウェーデンとフィンランドの当局が近くを航行していた船などの捜査を始めました。 预计总共进行修复需要 2 周时间，相继受到损害的瑞典和法国当局已经开始对附近航行的船只等进行搜索。 これについて19日、ドイツのピストリウス国防相は「ケーブルが誤って切断されたとは誰も信じていない。破壊工作だと想定する必要がある」と述べ、名指しなざしは避けながらも、非軍事的手段も組み合わせて相手国を混乱させる「ハイブリッド攻撃」をしかけているとされるロシアへの警戒感をあらわにしました。 对此 19 日德国的国防官 Pistorius 表示“光缆被不小心切断是谁都不会相信的，有必要将其想定为破坏行动”。虽然没有指名道姓，但是表现除了对开始着手采取非军事手段努力让对方国家陷入混乱的“混合攻击”的俄罗斯的警戒感。 バルト海では、おととし天然ガスのパイプライン「ノルドストリーム」で爆発が起き、捜査が続いていますが、いまも誰が関与したのか真相は明らかになっていません。 波罗的海前年发生了北溪天然气运输管道爆炸的事件，虽然持续进行调查，但是现在也没有公开与谁有关的真相。","link":"/2024/11/20/translate_news_nhk_20241120_k10014643741000/"},{"title":"日语翻译 - 新闻 - 北海道 函館 正月向けのかずのこ 加工が最盛期","text":"在北海道的函馆，面向正月的“干青鱼子”迎来了加工的最忙期 来源：NHK 日期：2024-11-21 05:05 链接：北海道 函館 正月向けのかずのこ 加工が最盛期 🌟 单词： 最盛期｜さいせいき③ 鰊｜にしん鲱鱼，青鱼。 子孫繁栄｜しそんはんえい③ 縁起物｜えんぎもの⓪ おせち料理｜おせちりょうり④年菜，节日食物。 塩漬け｜しおづけ⓪④ 箱詰め｜はこづめ⓪ 豊漁｜ほうりょう⓪（捕鱼）丰收，渔获量大。 仕入れ｜しいれ⓪买进，购买；采购，采办，采买。 コリコリ｜こりこり①1. （咬东西时发出的）咔哧咔哧响；2. 硬邦邦。 首都圏｜しゅとけん② ことしも残り1か月余りとなり、北海道の函館市では正月向けの「かずのこ」の加工が最盛期さいせいきを迎えています。 今年还剩下 1 个多月，北海道的函馆市正迎来面向正月的“干青鱼子”加工最忙的时期。 にしんの卵「かずのこ」は、子孫しそん繁栄の願いを込めた縁起物えんぎものとして正月のおせち料理年菜，节日食物。に使われます。 青鱼的卵“干青鱼子”作为祈祷子孙繁荣的吉祥物将被使用在正确的节日料理中。 函館市古川町にある水産加工会社では、正月向けの需要が高まるこの時期に「かずのこ」の加工が最盛期を迎えています。 函馆市古川镇的水产加工公司，正迎来迎正月需求高涨、在这个时期内“干青鱼子”加工的最忙期。 加工場では20日も、6人の従業員が塩漬けしおづけにした「かずのこ」を大きさごとに分け、丁寧に箱詰めはこづめしていました。 加工厂在 20 日，6 名工人也将腌渍之后的“干青鱼子”按大小分类，小心地装了箱。 この水産加工会社では、アメリカなど海外産のにしんを中心に原料に使っていましたが、ことしは豊漁ほうりょうが続く北海道産のにしんの仕入れを増やしたことで、円安の影響はほとんど受けず、かずのこの価格は例年並みなみだということです。 这个水产加工公司，虽然之前都是以美国等海外产的青鱼作为主要原料使用，但是今年增加了对持续渔获丰收的北海道青鱼的采购，因此几乎没有受到日元贬值的影响，干青鱼子的价格和往年持平。 水産加工会社の松田一徳社長は「北海道ではコリコリとしたおいしいかずのこがたくさんとれているので、北海道や全国の人たちに食べてもらいたい」と話していました。 水产加工公司的松田一徳社长说：“北海道盛产有嚼劲、美味的干青鱼子，想要让北海道和全国的人都吃到。” 「かずのこ」の加工は12月中旬まで続き、首都圏しゅとけんや関西などに向けて出荷されます。 “干青鱼子”的加工将持续到 12 月中旬，之后将向首都圈和关西等地发货。","link":"/2024/11/21/translate_news_nhk_20241121_k10014645041000/"},{"title":"日语翻译 - 新闻 - 精神障害になったとして労災と認められた管理職など 過去最多","text":"今年由于精神问题被认定为工伤的管理人员，是迄今为止最多的 来源：NHK 日期：2024-11-22 07:03 链接：精神障害になったとして労災と認められた管理職など 過去最多 🌟 单词： 啓発｜けいはつ⓪ 月間｜げっかん⓪ 最多｜さいた⓪ 未遂｜みすい⓪ 追い込まれる｜おいこまれる③ 共同｜きょうどう⓪ きちっと｜きちっと②1. 整整齐齐地，干干净净地；规规矩矩地，准确地；2. 正好，正巧，正合适。 疲労｜ひろう⓪ 蓄積｜ちくせき⓪ カウンセリング｜かうんせりんぐ①②(counseling) 劝告，忠告，辅导，咨导。 今月は「過労死等防止啓発けいはつ月間げっかん」です。仕事が原因で精神障害になったとして労災と認められた企業の管理職などは、昨年度52人と過去最多となりました。専門家は「部下の働き方改革を進めなくてはいけない一方で、求められる仕事は減らず、プレッシャーがかかっている」と指摘しています。 本月是“促进防止过劳死月”，由于工作原因导致精神问题而被认定是工伤的企业管理职位人员，去年度为最多的有 52 人。专家指出“一方面必须推进部下工作方式的改革，另一方面被要求做的工作量也不会减少，压力很大”。 厚生労働省によりますと、昨年度、仕事の強いストレスが原因でうつ病などの精神障害になったとして労災と認められた人は過去最多の883人でした。 据厚生劳动省藐视，去年度由于工作压力太大原因导致抑郁症等精神问题而被认为是工伤的人数，是迄今为止最多的，有 883 人。 このうち、企業の管理職などにあたる「管理的職業」は52人に上り、前の年度の37人から15人増えこちらも過去最多でした。 在这其中，承担企业管理职位的管理人员上升到了 52 人，从去年的 37 人增加了 15 人这也是历年最多的。 また、自殺に追い込まれた人は未遂みすいも含めて15人で、前の年度から4人増加しました。 还有，被逼入绝境自杀包含自杀未遂的有 15 人，对比上一年度增加了 4 人。 管理職の労災について、日本精神科産業医協会で共同きょうどう代表理事を務める渡辺洋一郎医師は「部下の労働時間を減らさなくてはいけないが、自分の仕事量は減っていない。トップから『働き方改革を推進しろ、だけど業績は上げろ』と指示されて、プレッシャーがかかっている」と述べました。 关于管理岗的工伤，供职于日本精神产业医科协会的共同代表理事的渡辺洋一郎医师表示：“虽然必须减少部下的劳动时间，但是自己的工作量却不会减少。被领导指示‘推进工作方法改革吧！同时提升业绩吧！’，非常有压力。” 対策として「会社側は管理職についても時間管理をきちっとする。疲労ひろう蓄積ちくせき度のチェックリストなどを定期的につけてもらい、一定の点数以上であれば必ず健康管理室のところに相談にいくような仕組みをつくることが大切だ」と述べて、管理職向けの相談やカウンセリング体制の整備の必要性を指摘しています。 作为对策还描述“作为公司方面也要好好地对管理职位进行时间管理。采取定期地给他们带去疲劳累积度确认明细，如果超过了一定分数以上必须前往健康管理室进行交谈的努力非常重要。”，指出有必要针对管理岗位准备交谈和劝导策略。","link":"/2024/11/22/translate_news_nhk_20241122_k10014645851000/"},{"title":"日语翻译 - 新闻 - 働く高齢者の労災防止対策 企業の努力義務へ 厚労省が方針","text":"企业需要努力制定预防高龄劳动者工伤的对策，厚生劳动省将制定方针 来源：NHK 日期：2024-11-22 21:18 链接：働く高齢者の労災防止対策 企業の努力義務へ 厚労省が方針 🌟 单词： 低下｜ていか⓪ 労使｜ろうし①劳动者和雇佣者。 努力義務｜どりょくぎむ要求努力达成而非强制。 段差｜だんさ⓪①1. 高低平面的差异；2. 等级差别。 ハード面｜はーどめん①硬件设施、条件。 通院｜つういん⓪（经常或定期）到医院去。 上る｜のぼる⓪ 両立｜りょうりつ⓪两立，并存。 働く高齢者が増えるなか、厚生労働省は企業に対して身体機能の低下ていかなどに配慮した職場環境の改善や作業の管理を努力義務とする方針を示しました。 在工作的老人增加的背景下，厚生劳动省表示，企业有义务努力改善工作环境和管理工作，以应对身体机能下降等问题。 これは厚生労働省で22日に開かれた労使などでつくる審議会で示されました。 这是厚生劳动省在 22 日召开的劳动者和雇佣者组成的审议会上表示的。 それによりますと働く高齢者が増えるなか、労働災害によるけがや病気で死亡したり4日以上休んだりした60歳以上の人が去年、労働者全体の29.3％を占めて年々、割合が高まっています。 据此描述，工作的老人增加的背景下，由于劳动受伤或疾病死亡或休息 4 天以上的 60 岁的人，占全体劳动者的 29.3%，并且这个比例每年还在增加。 高齢者は、若い世代と比べると労働災害の発生率が高く、休業する期間も長くなる傾向があることから厚生労働省は、企業に対して身体機能の低下などに配慮した職場環境の改善や作業の管理を努力義務とする方針です。 由于老人与年轻人相比工作受伤的发生率更高，也更有延长休息时间的倾向。厚生劳动身希望企业努力改善工作环境和管理工作，以应对（高龄工作者）身体机能的下降。 具体的には、職場の段差をなるべく減らすといったハード面の改善や筋力の低下を考慮した作業内容の見直しなどが対策として検討されているということです。 具体来说，要将改善能够尽量减少职场差异的硬件设施、重新制定考虑肌肉能力下降的工作内容等作为对策进行探讨。 また22日の審議会では通院しながら働く人がおととし、労働者全体の40.6％に上るのぼるなか、企業に対して治療と仕事の両立を支援するための必要な措置を努力義務とする方針も示されました。 还有在 22 日等审议会上，还表示了：在前年经常去医院等劳动者上升到了全体劳动者的 40.6% 的背景下，企业需要努力采取必要的措施对（劳动者的）治疗和工作两方面进行支援。 厚生労働省は法律の改正に向けて、これらの方針を年明けにも報告書として取りまとめたいとしています。 厚生劳动省为了修正法律，将在明年年初将这些方针汇总成为报告书。","link":"/2024/11/23/translate_news_nhk_20241122_k10014647081000/"},{"title":"日语翻译 - 新闻 - 東海道新幹線 ダイヤの乱れ続く 2時間以上の遅れも","text":"东海岛新干线，时刻表延误的情况持续，列车将晚 2 小时以上 来源：NHK 日期：2024-11-23 17:12 链接：東海道新幹線 ダイヤの乱れ続く 2時間以上の遅れも 🌟 单词： ダイヤ乱れ｜だいやみだれ时刻表延误。 ダイヤル｜だいやる⓪(dial) 1. 调谐度盘，刻度盘；2. 号码盘，拨号盘。 名古屋｜なごや 上り線｜のぼりせん高速公路的上线。 下り線｜くだりせん高速公路的下线。 運休｜うんきゅう⓪停开，停驶，停车。 本数｜ほんすう③ 図る｜はかる②图谋，策划，谋求。 電光｜でんこう⓪电光，闪电，电灯光。 掲示板｜けいじばん⓪1. 布告牌，公告牌；2. 电子公告牌，电子传告栏。 東海道新幹線は、23日朝、車両の点検作業のため一部の区間で運転を見合わせました。この影響で夕方になっても2時間以上遅れる列車が出るなどダイヤの乱れが続いています。 东海道新干线于 23 日早晨由于检查作业的原因，一部分范围内运行停止。受此影响，即使是到了傍晚也持续着存在晚了超过 2 小时以上列车的时刻表延误情况。 JR東海によりますと、23日午前8時ごろ、東海道新幹線の新大阪発東京行きの「のぞみ210号」で異常を知らせる表示が出たため、京都駅を出発したあと停止しました。 据 JR 东海描述，在 23 日上午的 8 点左右，由于在东海道新干线的从新大阪出发前往东京的「のぞみ210号」检查出了异常，因此从京都站出发之后停了。 この車両の点検作業のため、東海道新幹線は新大阪駅と名古屋なごや駅の間の上りのぼり線で運転を見合わせ、午前9時半ごろには運転を再開しましたが、夕方になってもダイヤの乱れが続いています。 由于车辆的检查作业，东海道新干线路线上的新大阪站到名古屋站中的高速公路的上线无法行驶了，虽然在上午 9 点半左右恢复了行驶，但是直到傍晚时刻表延误的情况依旧持续。 特に遅れは上り線を中心に続いていて、午後4時半時点で上り線では2時間以上遅れている列車もあります。 延误尤其以高速公路的上线为中心持续，在下午 4 点半时高速公路的上线依然有延误 2 小时以上的列车存在。 JR東海では、東海道新幹線を10本程度運休うんきゅうするなど運転本数を減らして遅れの解消を図っているということで「ホームページや駅の電光でんこう掲示板けいじばんなどで最新の情報を確認してほしい」としています。 由于 JR 东海在东海道新干线上通过停运 10 辆列车等减少列车数量的行为来借此希望消除延误的情况，因此（希望）“大家在主页和电子告示牌等确认最新的信息。”","link":"/2024/11/24/translate_news_nhk_20241123_k10014647531000/"},{"title":"日语翻译 - 新闻 - 警視庁 任期付き職員を民間から採用 サイバー犯罪捜査体制強化","text":"警察从民间任用带有任期的职员，为了强化电子犯罪调查体制 来源：NHK 日期：2024-11-25 05:08 链接：警視庁 任期付き職員を民間から採用 サイバー犯罪捜査体制強化 🌟 单词： サイバー｜さいばー①(cyber) 电脑的，网络上的。 選考｜せんこう⓪选拔，选用。 若干｜じゃっかん⓪少许，一些，多少，若干。 最先端｜さいせんたん③ 精通｜せいつう⓪ セキュリティー｜せきゅりてぃー②(security) 安全防卫，防御。 口述｜こうじゅつ⓪ 携わる｜たずさわる④参与，参加，从事，有关系。 被害が深刻化するサイバー犯罪などの捜査体制強化につなげるため、警視庁は来年4月、2年間の任期付きの職員を、「警部」として採用することを決め、25日から選考の受付を始めます。警視庁が任期付きの警察官を民間から採用するのは初めてだということです。 为了强化针对危害变大的电子犯罪的调查体制，警视厅决定于来年四月，聘用 2 年任期的职员作为「警部」人员，从 25 日开始选拔的预约。这是警视厅首次从民间聘用带有任期的警察官。 警視庁が25日から選考の申し込みを受け付けるのは、生活安全部サイバー犯罪対策課の職員若干名です。 警视厅从 25 开始接受预约加入选拔的是，生活安全部电子犯罪对策课的若干名（职位）。 サイバー犯罪の被害が深刻化する中、最先端さいせんたんの技術に精通せいつうした人材を民間から登用することで、捜査体制の強化を図ります。 在电子犯罪危害变大的背景下，（警视厅）希望通过从民间录用精通最前沿技术的人才，强化调查体制。 受験資格があるのは、情報処理の高度な知識や技能を認定する国家資格や、それに相当する資格を持ち、民間のサイバーセキュリティ部門やシステム関連部門などで大卒の場合は10年以上、高卒の場合は14年以上の職務経験がある人です。 有考试资格的是：拥有被认定的信息处理高级知识或技能的国家资格的、或是有相应（等级）资格的，在民间的信息安全部门或信息系统相关部门大学毕业后工作了 10 年以上的，如果是高中毕业的话工作了 14 年以上的人。 任用期間は来年4月1日からの2年間で、書類による1次いっじ選考と口述こうじゅつによる2次選考があり、「警部」の階級かいきゅうで採用するということです。 任用期限是从明年 4 月 1 日开始的 2 年，如果通过了第一轮的书面考试和第二轮的面试，将被任用为「警部」阶级的人员。 警視庁が任期付きの警察官を民間から登用するのは今回が初めてで、警視庁は「捜査にも携わりたずさわり、警察官でしかできない経験が得られるのではないか。定年まで働くことを前提ぜんていにした中途採用とは異なり、警察で得た知見を再び民間に戻って生かすこともできる」として、広く応募を呼びかけています。 这是警视厅首次从民间聘用带有任期的警察官，警视厅正在广泛呼吁：“会带有调查工作，这是只有警察官才能获取的经验！这和以工作到退休为前提的社会招聘不同，是能带着警察的见解再回到社会的。” 申し込みの受付は25日から12月9日までです。 预约申请从 25 日开始到 12 月 9 日为止。","link":"/2024/11/25/translate_news_nhk_20241125_k10014648341000/"},{"title":"日语翻译 - 新闻 - 名古屋市営バス 運賃支払うシステム障害 すべてのバスで復旧","text":"名古屋市营公交，车费支付系统故障，目前所有公交都已恢复 来源：NHK 日期：2024-11-25 05:08 链接：名古屋市営バス 運賃支払うシステム障害 すべてのバスで復旧 🌟 单词： 市営｜しえい⓪ 乗客｜じょうきゃく⓪ 決済｜けっさい①结算，结帐，清帐。 始発｜しはつ⓪ 所有｜しょゆう⓪ 料金箱｜りょうきんばこ③ 目立つ｜めだつ②显眼，显著，引人注目。 名古屋市営しえいバスの一部の車両で乗客じょうきゃくが運賃を支払うシステムに障害が起きて起動せず、市営バスはシステムが復旧するまで乗客が料金の決済けっさいをしなくても乗車できるよう対応しました。 在名古屋市营的一部分公交车辆上，乘客用以支付车费的系统发生了问题而没有启动，市营公交到系统恢复为止通过让乘客不付钱也能乘车的方式进行了应对。 バスの運行には影響がなく、午後7時ごろにすべてのバスで復旧したということです。 并没有对公交的运行造成影响，在下午 7 点左右所有的公交（的支付系统）都恢复了。 名古屋市交通局によりますと25日の始発しはつから、名古屋市営バスの一部の車両で、乗客が運賃を支払うシステムに障害が起きて起動せず、料金を支払うことができなくなりました。 据名古屋市交通局描述：从 25 日开始，在市营的一部分公交车辆上，乘客用以支付车费的系统发生了问题而没有启动，使得无法支付费用。 所有しょゆうするおよそ1000台のバスのうち781台で障害が起き、およそ4万人の乗客から運賃を受け取れなかったとみられるということです。 被认为拥有的大约 1000 台公交中的 781 台发生了问题，使得无法从大约 4 万名乘客收取车费。 バスの運行には影響がなく、市営バスはシステムが復旧するまでは乗客が料金の決済をしなくても乗車出来るよう対応しました。 对公交的运行没有影响，市营公交一直到系统恢复为止，都采取了不收乘客的钱也能让他们乘车的方式进行对应。 乗客には「料金箱りょうきんばこに不具合があったので、次回の乗車時にお支払い下さい」などと車内で呼びかけ、目立った混乱はなかったということです。 在车内对乘客呼吁“投币箱目前有问题，请在下次乘车时进行支付！”，并没有特别的混乱情况。 名古屋市交通局はシステム障害が起きたバスの点検作業を進め、システムは午後7時ごろにすべてのバスで復旧したということです。 名古屋市交通局持续对发生系统问题的公交进行检查作业，系统在下午 7 点左右在所有的公交上恢复了正常。","link":"/2024/11/26/translate_news_nhk_20241125_k10014648551000/"},{"title":"日语翻译 - 新闻 - セブン＆アイHD 中間持ち株会社の株式入札 住商などが参加検討","text":"7&amp;I 控股进行了中间持股公司的股票投标，住友商社等参与了探讨 来源：NHK 日期：2024-11-27 06:05 链接：セブン＆アイHD 中間持ち株会社の株式入札 住商などが参加検討 🌟 单词： 束ねる｜たばねる③ 売却｜ばいきゃく⓪ 住友商事｜すみともしょうじ ⑤ ファンド｜ふぁんど①(fund) 资金，基金。 イトーヨーカ堂｜いとよかどう伊藤洋华堂。 統括｜とうかつ⓪①总括，总合，归拢一起。 ドラッグストア｜どらっぐすとあ⑥(drugstore) 杂货店，药品店。 首都圏｜しゅとけん② 相乗効果｜そうじょうこうか 兆｜ちょう① 買収｜ばいしゅう⓪ 主力｜しゅりょく⓪① セブン＆アイ・ホールディングスは、コンビニ以外の事業を束ねるたばねる中間持ち株会社の株式を一部売却ばいきゃくしようとしていますが、大手商社の住友すみとも商事やアメリカの投資ファンドなどが入札手続きへの参加を検討していることがわかりました。入札は28日にも締め切られ、セブン＆アイは売却先の選定を進める方針です。 7&amp;I 控股准备将管理便利店以外事务的中间持股公司的股票卖出一部分，大商社住友商事和美国的投资基金探讨了参与投标的事情。投标会在 28 日截至，7&amp;I 将会推进选定买方。 セブン＆アイ・ホールディングスは、業績の不振が続くスーパーの「イトーヨーカ堂どう」のほか、雑貨店やレストランなどコンビニ以外の事業を統括とうかつする中間持ち株会社「ヨーク・ホールディングス」を設立し、株式の半分以上を売却する方針です。 7&amp;I 控股设立了囊括除业绩持续不振的超市“伊藤洋华堂”，还有杂货店和饭店等便利店以外事业的中间持股公司「ヨーク・ホールディングス」，并计划售卖一半以上的股票。 関係者によりますと、この株式の入札手続きはあすにも締め切られる予定で、大手商社の住友商事やアメリカの投資ファンド「KKR」などが参加を検討していることがわかりました。 据相关者描述，这个股票的投标手续预定将于明天结束，已经知晓了大商社住友商事和美国的投资基金 KKR 参与了探讨。 住友商事は食品スーパーの「サミット」やドラッグストアの「トモズ」を抱えていることから、首都圏しゅとけんなどに店舗網を持つイトーヨーカ堂などとの相乗そうじょう効果を見込んでいるものとみられます。 由于住友商事拥有食品超市「サミット」和杂货店「トモズ」，因此广泛预计会和在首都圈拥有店铺网的伊藤洋华堂产生化学作用。 一方、セブン＆アイは、カナダのコンビニ大手「アリマンタシォン・クシュタール」から7兆ちょう円規模の買収ばいしゅう提案を受けるなか、主力しゅりょくのコンビニ事業に注力する方針で、入札内容を慎重に検討した上で売却先の選定を進めることにしています。 另一方面，7&amp;I 由于从加拿大便利店大公司 Alimentation Couche-Tard 的 7 兆日元规模的购买提案，因此计划将主要助力主力的便利店事业，将在慎重考虑投标内容的基础上推进对买家的选择。","link":"/2024/11/27/translate_news_nhk_20241127_k10014650591000/"},{"title":"日语翻译 - 新闻 - “経営の神様” 松下幸之助がAIに パナソニックHD","text":"松下控股将“经营的神”松下幸之助通过 AI 还原 来源：NHK 日期：2024-11-28 06:58 链接：“経営の神様” 松下幸之助がAIに パナソニックHD 🌟 单词： パナソニック｜ぱなそにっく(Panasonic) 松下。 松下幸之助｜まつしたこうのすけ 研究所｜けんきゅうじょ⓪ 共同｜きょうどう⓪ 生前｜せいぜん⓪ 著作物｜ちょさくぶつ③ 口元｜くちもと⓪1. 嘴边，嘴角；2. 嘴形，说话时嘴的形状。 薫陶｜くんとう⓪熏陶，熏染。 示唆｜しさ①暗示，示意，启发。 継承｜けいしょう⓪ “経営の神様”と呼ばれたパナソニックホールディングスの創業者、松下幸之助まつしたこうのすけを再現したAI＝人工知能が開発されました。 将被称为“经营的神”的松下控股公司的创立者松下幸之助再现的 AI（人工智能）被开发出来了。 このAIは、パナソニックとPHP研究所けんきゅうじょなどが“経営の神様”と呼ばれた松下幸之助の理念を次の世代に伝えようと、共同きょうどうで開発しました。 这个 AI 是松下和 PHP 研究所等为了将被称作“经营的神”的松下幸之助的理念传达给后世而共同开发的。 生前せいぜんの音声や、著作物ちょさくぶつ、講演での発言など、大量のデータをAIに学習させることで、幸之助の考え方や話し方を再現したとしています。 正在通过让 AI 学习其生前的声音、著作、在演讲上的发言等大量的数据，而再现幸之助的想法和讲话方式。 AIは、質問を受けると学習したデータをもとに回答を作成して、70代の頃の声で答え、画面に映る幸之助の表情が変わったり口元くちもとが動いたりします。 AI 如果收到问题的话，会基于学习了的数据创建答复，并用 70 岁的时候的声音回答，同时画面上幸之助的表情也会变化嘴巴也会动。 例えば、「AIの導入で人手はいらなくなるのか」と尋ねると、「AIの導入が進むことで人手がいらなくなるというのは一面の真実ではありますが、それがすべてではないんですわ。むしろ、新たな価値を創造することができると信じております」などと答えていました。 例如，如果问“是不是导入了 AI 就不需要劳动力了？”的话，它会回答“AI 的出现意味着我们不再需要更多的劳动力，这是一方面的事实，但这并不是全部。相反，我相信我们可以创造新的价值。”之类的。 このAI、グループ内の研修などで活用されるということです。 这个 AI 被广泛用于组内的研修等。 パナソニックなどは「松下幸之助の薫陶くんとうを受けた人物が年々少なくなる中、『幸之助なら、どのような経営判断を行うか』など、より深い経営面での示唆しさを提供することのできるAIを目指していきたい」としています。 松下等正决定：“在受到过松下幸之助的熏陶的人年年减少的背景下，希望创造出能够提供比‘如果是幸之助的话，会做出怎样的经营判断呢？’这样更深层次经营层面启发的 AI。” 松下幸之助の孫「実写かなと思うほど」 松下幸之助的孙子表示“感觉就像照片” 松下幸之助の孫で、パナソニックホールディングスの元副会長、松下正幸特別顧問は、AIについて「実写かなと思うほどで、懐かしく思い出しました。本人が見たらびっくりしそうですが、このAIを種に、ビジネスが出来るのではないかと、発想したかもしれないです。幸之助の理念の継承けいしょうに、役立つように使ってもらいたい」と話していました。 松下幸之助的孙子，同时也是松下控股原来的副会长松下正幸特别顾问就 AI 表示：“看起来就像照片，让我很怀念。如果你亲眼所见，你可能会感到惊讶，但是你可能会想，也许我们可以用 AI 做生意。想要让它继承幸之助的理念，发挥作用为人们使用。”","link":"/2024/11/28/translate_news_nhk_20241128_k10014651871000/"},{"title":"日语翻译 - 新闻 - 広島 原爆資料館 若い世代に向けた新たな展示を整備へ","text":"广岛的原子弹资料馆，将为年轻一代准备新的展示（内容） 来源：NHK 日期：2024-11-29 01:07 链接：広島 原爆資料館 若い世代に向けた新たな展示を整備へ 🌟 单词： 原爆｜げんばく⓪ サミット｜さみっと①(summit) 西方七国首脑会议最高级会议。 上半期｜かみはんき③ 訪れる｜おとずれる④ 人混み｜ひとごみ⓪ 平方｜へいほう⓪ バーチャルリアリティー虚拟现实。 広島市の原爆げんばく資料館で、入館者が増加し混雑が課題となるなか、市は、平和学習で訪れるおとずれる修学旅行生などに落ち着いた環境で被爆の実相を知ってもらいたいと、若い世代に向けた新たな展示を整備する方針を固めました。 在广岛的原子弹资料馆，由于参观者的增加和拥挤逐渐成为问题，广岛市制定了：想要给因和平学习而来访的修学旅行生以安静的环境来了解受原子弹伤害的真相，和针对年轻一代准备新的展示（方案、内容）的方针。 広島市の原爆資料館では、G7広島サミット以降の外国人旅行者の増加などで来館者が大幅に増え、今年度は上半期かみはんきで118万人余りと、過去最多さいただった前年度を上回るペースとなっていて、館内の混雑が大きな課題となっています。 广岛市的原子弹资料馆，在 G7 广岛峰会后由于外国旅行者的增加等原因，来馆里参观的人大幅增加，今年上半年又 118 万余人，有将已经创下最多人数的去年超过的速度，馆内的拥挤正在成为大问题。 こうした中、資料館の運営団体が実施したアンケート調査では、修学旅行で訪れた学校から「見学者が多すぎて見たい場所で立ち止まれなかった」とか「人混みひとごみで、はぐれない别走散。ようにするのが精いっぱいで、ゆっくり見学できなかった」といった声が寄せられ、市では対応を検討していました。 在这其中，在资料馆的运营团队实施的问卷调查中，从因为修学旅行而来访的学校收到了“参观者太多了，因此没法在想参观的地方驻足停留”和“人太多了，为了不走散就已经精疲力竭了，没法休闲地进行参观。”的声音，广岛市正在检讨应对措施。 この結果、市は、修学旅行生などに、より落ち着いた環境で被爆の実相を知ってもらいたいと、若い世代に向けた新たな展示を整備する方針を固めたことが関係者への取材でわかりました。 结果是，通过和关系方的了解，明白了广岛市制定了想要给因和平学习而来访的修学旅行生以安静的环境来了解受原子弹伤害的真相，和针对年轻一代准备新的展示（方案、内容）的方针。 市では、資料館の地下の会議室などになっている500平方へいほうメートル余りのスペースを活用する計画で、具体的な展示内容は、VR＝バーチャルリアリティーの活用も含め、今後、議論していく予定だということです。 广岛市今后将活用包含通过将资料馆地下的会议室等 500 多平的地方，具体的展示内容包含通过虚拟现实等的利用在内，预订在之后进行讨论。","link":"/2024/11/29/translate_news_nhk_20241129_k10014653131000/"},{"title":"日语翻译 - 新闻 - 皇居「乾通り」 秋の一般公開が始まる 12月8日まで","text":"皇居乾街开始秋天的对外公开，截止 12 月 8 日为止 来源：NHK 日期：2024-11-30 12:04 链接：皇居「乾通り」 秋の一般公開が始まる 12月8日まで 🌟 单词： 皇居｜こうきょ① 乾通り｜いぬいどおり 青空｜あおぞら③ 紅葉｜もみじ① 宮内庁｜くないちょう② 堀｜ほり⓪1. 护城河；2. 沟，渠。 コントラスト｜こんとらすと④①(contrast) 对比，对照。 皇居こうきょの「乾通りいぬいどおり」の一般公開が30日から始まり、青空あおぞらのもと大勢の人たちが並木道なみきみちを歩き、紅葉もみじを楽しんでいます。 皇居中的乾街从 30 日开始对外公开，再加上蓝天（天气好），大量的人来到林荫道散步，享受红叶。 「乾通り」は、皇居の中を通り抜けるおよそ600メートルの並木道で、8種類70本のモミジが植えられています。 乾街是通往皇居的大约 600 米的林荫道，种植有 8 种合计 70 颗红叶树。 午前9時に坂下門で入場が始まると、待っていた人たちが次々と皇居内に入っていきました。 上午 9 点在皇居门口入场一开始，等待的人们就一个接一个进入皇居内。 宮内庁くないちょうによりますと、ことしは秋になっても暑い日が続いたことから、乾通りの木々の葉は色づき始めたところだということです。 据宫内厅描述，由于今年到了秋天也持续炎热的原因，乾街的树木的叶子颜色才刚刚开始变红。 訪れた家族連れや外国人観光客などは、ゆっくりと散策しながら、写真を撮るなどして楽しんでいました。 来访的一家人和外国观光客，一边悠闲地散步，一边拍照享受其中。 去年までイギリスに留学していたという茨城県の27歳の女性は、海外と日本の違いに触れ、「お堀ほりがあってきれいな紅葉が見られるところなど、日本の美しさがあらわれているなと思いました」と話していました。 到去年为止还在英国留学的茨城県的 27 岁女性，接触了国外和日本的不同之后，说：“有护城河，可以看到红叶，我觉得这表现出了日本的美丽。” 東京 中央区の60歳の男性は、「ふだんは入れない場所に入れるのは珍しいので毎年、訪れています。ことしはこれから色づきが進むと思いますが、コントラスト对照。がきれいでした」と話していました。 （居住于）东京中央区的 60 岁男性说：“由于能够进入平时无法进入的地方，这个机会弥足珍贵，因此每年都会来。今年从现在开始叶子才变红，这种反差也很美。” アメリカから新婚旅行で訪れた女性は、「さまざまな木々の紅葉が見られてとても美しかったですし、風景も気に入りました」と話していました。 从美国来新婚旅行的女性说：“能看到各种树木的红叶非常美丽，也很喜欢这样的风景。” 一般公開は、12月8日までの9日間実施され、午前9時から午後3時まで入場することができ、予約は必要ないということです。 面向公众公开将在到 12 月 8 日为止的 9 天内实施，可以从上午 9 点到下午 3 点入场，无需预约。","link":"/2024/11/30/translate_news_nhk_20241130_k10014654411000/"},{"title":"日语翻译 - 新闻 - マンション“投資より居住目的の人に”不動産会社に新たな動き","text":"为了让公寓提供给居住目的的人而不是投资目的的人，不动产公司采取新的行动 来源：NHK 日期：2024-12-02 07:33 链接：マンション“投資より居住目的の人に”不動産会社に新たな動き 🌟 单词： マンション｜まんしょん①(mansion) 高级公寓。 新築｜しんちく⓪1. 新建，新盖翻盖，重盖；2. 新建的房屋。 居住｜きょじゅう⓪ 豊島区｜としまく 板橋区｜いたばしく 分譲｜ぶんじょう⓪分开出售，分成一部分一部分地出售，分售。 防ぐ｜ふせぐ② 公共性｜こうきょうせい⓪ マンション価格が上昇し投資や転売目的の取り引きが増える中、不動産会社の中には実際に住みたい人が購入しやすい物件を用意する新たな動きも出ています。 在高级公寓价格上升，并成为投资和倒卖对象、交易量上升的背景下，不动产公司中正在出台为了让真的想住的人更方便地买入房产的新的措施。 新築しんちくマンションの価格の上昇が続く中、投資や転売目的の取り引きが増えることで居住きょじゅうを目的にした購入が難しくなることが懸念されています。 在新建公寓的价格持续上涨的背景下，由于以投资和倒卖为目的的交易持续增多，广泛担忧以居住为目的的购买正变得困难。 こうした中、住友不動産は、東京・豊島区としまくと板橋区いたばしくの分譲ぶんじょう中のタワーマンションで、購入後5年間は転売を防ぐふせぐための特約を設けました。 在这其中，住友不动产对东京豊島区和板橋区分售的塔楼，设立了为了防止购入后的五年间转卖的特别条约。 正当な理由がなく短期間で転売された場合は、最初の分譲の契約を取り消す仕組みで、実際に住みたい人が購入しやすくするための対応だということです。 通过如果房子没有正当理由却在短时间内被转卖的话，就取消当初的分售合同的方式，（这是）为了让真正想居住的人购入变得更便宜的对应措施。 住友不動産の中村貴彦さんは「再開発で作られた公共性こうきょうせいの高い物件でもあるので投機的な目的ではなく、住むことを目的にした人に提供したい」と話していました。 住友不动产的中村貴彦君说：“因为（公寓）是通过再开发所构建的公共性高的房产，因此想提供给不是以投机为目的、而是真正以居住为目的的人。” また、野村不動産は、ことし10月から販売を始めたさいたま市のタワーマンションで、購入の申し込みができるのは1つの名義で2つの部屋までとしています。 还有，野村不动产在从今年 10 月开始出售的埼玉市的塔楼，正在实施“少于等于 2 套房产的个人才有资格购买”的措施。 多くの人たちが申し込めるようにする対応で、特に住まいとしての需要が高い地域でこうした動きが広がるか注目されます。 为了让更多的人能来申请，尤其是在住房需求很高的低于，这样的措施是否会扩大引人注目。","link":"/2024/12/02/translate_news_nhk_20241202_k10014655341000/"},{"title":"日语翻译 - 新闻 - ナスダック株価指数 最高値更新 ハイテク関連銘柄など買い注文","text":"纳指刷新（最近的）最高值，高科技股票相关的买单增多 来源：NHK 日期：2024-12-03 08:03 链接：ナスダック株価指数 最高値更新 ハイテク関連銘柄など買い注文 🌟 单词： 銘柄｜めいがら⓪1. 品种；2. 商标，牌子。 指数｜しすう② ハイテク｜はいてく⓪(high-tech) 高科技。 先行き｜さきいき⓪1. 将来，前途；2. 将来的行情，行情的前景。 小幅｜こはば⓪ 為替｜かわせ⓪ 連邦｜れんぽう⓪ 台前半｜だいぜんはん 2日のニューヨーク株式市場は、ハイテク関連の銘柄を中心に買い注文が広がり、ナスダックの株価指数などが最高値を更新しました。 2 号的纽约股市，以高科技相关的股票为中心的买单增多，纳斯达克指数等刷新了最高值。 ニューヨーク株式市場は、アメリカ経済の先行きへの期待感などを背景にIT大手や半導体関連の銘柄を中心に買い注文が広がったことで、ナスダックの株価指数は先週末と比べておよそ1％上昇し、およそ3週間ぶりに最高値を更新しました。 纽约股市，在对美国经济前景抱有期待感的背景下，以 IT 大企业和半导体等相关股票为中心的买单增多，纳指和上周末相比上涨了大约 1%，刷新了最近三周的最高值。 また、主要な500社の株価で算出する「S＆P500」の株価指数も小幅こはばに上昇し、最高値を更新しました。 并且，通过主要的 500 个公司的股价算出的“S＆P500”股价指数也小幅上涨，刷新了最高值。 市場関係者は「EVメーカーの『テスラ』の株価が大きく上昇したほか、年末商戦への期待感から『アマゾン』などにも買い注文が入った」と話しています。 市场相关者说：“除了马斯克的特斯拉股价大幅上涨以外，由于对年末商战的期待感，对亚马逊等的买单也多了。” 一方、ニューヨーク外国為替かわせ市場では、アメリカのFRB＝連邦れんぽう準備制度理事会が今月の会合で利下げに踏み切るという観測などを背景にドルを売って円を買う動きが進み、円相場は一時1ドル＝149円台前半をつけ、およそ1か月半ぶりの円高水準となりました。 另一方面，在纽约的外汇市场，在预测美国的 FRB 会在这个月的会议上落实利率下降政策的背景下，卖出美元买入日元的动作增多，在外汇市场一度达到 1 美元等于 149 日元，成为大约 1 个半月以来的日元最高价格。","link":"/2024/12/03/translate_news_nhk_20241203_k10014656621000/"},{"title":"日语翻译 - 新闻 - 全国のコメ事業者らが意見交換会“さらに価格上昇の可能性も”","text":"在全国大米从业者参加的意见交换会上，（有人）表示“价格有进一步上涨的可能性” 来源：NHK 日期：2024-12-04 06:40 链接：全国のコメ事業者らが意見交換会“さらに価格上昇の可能性も” 🌟 单词： 米｜こめ②稻米，大米。 集荷｜しゅうか⓪① 卸売｜おろしうり⓪③卸货贩卖，在商品流通过程中，介于制造、采收(生鲜食品)和零售之间的中介行业。 高値｜たかね② 増す｜ます⓪ 収穫量｜しゅうかくりょう ⑤ 全国のコメの取り引きに関わる事業者や団体の意見交換会が開かれ、参加者からはコメの価格は今後さらに上昇する可能性があるという見方も示されました。 全国的大米交易相关从业者和团体的意见交换会召开了，与会者表示预测今后大米的价格有进一步上涨的可能性。 農林水産省で開かれた意見交換会には生産者や集荷しゅうか団体、それに卸売おろしうり業者などの担当者が出席しました。 农林水产省召开的意见交换会，有生产者、集中采购团体和销售从业者等的责任人出席。 ことしの新米は高値たかねでの取り引きが続いていて、10月の相対取引価格はすべての銘柄の平均で去年の同じ月より57％上昇し、2か月連続で過去最高を更新しています。 今年新米持续在高价进行交易，10 月取所有品牌平均价格的相对交易价格比去年同月上升了 57%。联系两个月刷新历史最高值。 参加者からは「販売するコメを農家から集める業者間の競争が厳しい」などの意見が出て、今後、価格はさらに上昇する可能性があるとの見方も示されました。 与会者表示：“负责将销售的大米从农户处收集的从业者，他们之间的竞争非常激烈”，并且展示除了今后价格有可能会进一步上涨的见解。 また別の参加者からは「コメの生産を続けるための価格の上昇は消費者にとっては負担が増すますことになる」として価格の上昇による消費の落ち込みを懸念する意見も出ていました。 然后别的参与者表示由于“为了将大米的生产继续下去的价格上涨行为，会加重消费者的负担”，因此担忧价格的上涨会带来消费的低迷。 農林水産省はことしの主食用しゅしょくようのコメの収穫しゅうかく量は去年より18万トン余り増えると予想していて、年末を前にコメの価格に対する注目はしばらく続きそうです。 农林水产省预测今年主食用的大米的收成将比去年多 18 万吨，在年底之前，对大米价格的关注可能会持续一段时间。","link":"/2024/12/04/translate_news_nhk_20241204_k10014657551000/"},{"title":"日语翻译 - 新闻 - 米大手自動車メーカーGM 中国事業関連で50億ドル超の損失計上","text":"美国大型汽车制造商通用汽车，统计了在中国市场的事业上损失了超过 50 亿美元 来源：NHK 日期：2024-12-05 06:11 链接：米大手自動車メーカーGM 中国事業関連で50億ドル超の損失計上 🌟 单词： ゼネラル・モーターズ(General Motors) 通用汽车。 損失｜そんしつ⓪ 合弁｜ごうべん⓪ 閉鎖｜へいさ⓪ 持続｜じぞく⓪ 収益｜しゅうえき⓪① 立て直し｜たてなおし⓪重整，复兴；革新。 中西部｜ちゅうせいぶ 建設｜けんせつ⓪ 減速｜げんそく⓪ 激化｜げきか①⓪ 迫る｜せまる② アメリカの大手自動車メーカーのGM＝ゼネラル・モーターズは、中国での事業に関連し、50億ドル、日本円で7500億円を超える損失そんしつを計上することを明らかにしました。中国では現地のEV＝電気自動車メーカーなどとの競争が激しくなり、赤字が続いていたということです。 美国的大型汽车制造商通用汽车，发布了在中国的事业相关方面，计算除了超过 7500 亿日元的损失的事情。与中国当地的电动汽车制造商间的竞争愈发激烈，赤字将会持续。 これはGMが4日に開示した資料で明らかにしたもので、中国で事業を展開する現地企業との合弁ごうべん会社の価値の見直しや、工場の閉鎖へいさなどの費用として合わせて50億ドル、日本円で7500億円を超える損失を計上するとしています。 这是通用汽车在 4 日公开的资料中表明的。计算出：（通过）修正与在中国当地开展事业当地企业的合并公司的价值，加上关闭工厂之类的费用，总计损失了超过 50 亿美元，约 7500 亿日元。 中国では、現地のEVメーカーなどとの競争が激しくなり、赤字が続いていたということです。 在中国，与当地的电动汽车制造商间的竞争愈发激烈，赤字将会持续。 会社は「持続じぞく可能で収益しゅうえき力の高い事業にするために、合弁を組む現地企業と協力して中国事業の立て直しに取り組んでいる」とコメントしています。 公司评论道“为了创造处有可能持续并且收益能力强的事业，正在努力和合并的当地企业合作，重整在中国的事业。” このほかGMは、アメリカ中西部ちゅうせいぶミシガン州に建設けんせつしていたEV向けの電池工場について、協業する韓国の大手電池メーカー、LGエナジーソリューションに売却する方針を明らかにするなど、アメリカでのEV市場の減速や中国での競争の激化げきかを背景に戦略の見直しを迫られてせまられています。 除以以外，关于在美国中西部密西根洲建设的面向新能源的电池工厂，明确了卖给合作的韩国大型电池制造商 LG 能源解决方案的事情，在美国的新能源市场减速和中国（市场）的竞争白热化的背景下，迫切需要重新制定战略。","link":"/2024/12/05/translate_news_nhk_20241205_k10014659031000/"},{"title":"日语翻译 - 新闻 - 先端半導体の国産化目指すラピダスにIPA通じ出資の案検討 政府","text":"政府正在探讨对以国产化尖端半导体为目标的 Rapidus 公司，通过 IPA 进行出资的提案 来源：NHK 日期：2024-12-05 20:26 链接：先端半導体の国産化目指すラピダスにIPA通じ出資の案検討 政府 🌟 单词： 先端｜せんたん⓪ 国産｜こくさん⓪ ラピダスRapidus 公司。 行政｜ぎょうせい⓪ 株主｜かぶぬし②⓪ 呼び水｜よびみず⓪1. 泵的启动水；2. 诱因，起因。 兆｜ちょう① 補助｜ほじょ① 所管｜しょかん⓪ 啓発｜けいはつ⓪启发，启迪，启蒙对人们没有意识到的事情或不足之处进行教诲并使明白。 育成｜いくせい⓪ 担う｜になう② 詰める｜つめる②1. 塞满，填满；2. 缩小，缩短；3.（热心地）继续做，持续做；4. 节约，简省；5. 深究。 妥当｜だとう⓪ 先端半導体の国産化を目指すラピダスに対し、政府は、独立行政ぎょうせい法人の「IPA＝情報処理推進機構」を通じて出資する案を検討していることが分かりました。政府が実質的な株主かぶぬしとなることで民間からの投資の呼び水にしたい考えです。 政府正在探讨针对以国产化尖端半导体为目标的 Rapidus 公司，通过独立行政法人的 IPA（推荐信息处理机构）进行出资的案件。被认为通过让政府成为实际的股东来促成来自民间的投资。 政府は、先月、閣議決定した経済対策で、半導体やAIの分野に対し、2030年度までに合わせて10兆ちょう円以上の補助ほじょや金融支援などを行う方針を明らかにしています。 政府通过在上个月的内阁会议上决定的经济策略，明确了到 2030 年末，针对半导体和 AI 领域总计会进行 10 兆日元以上的辅助和经济援助等行为。 関係者によりますと、このうちラピダスに対しては、経済産業省が所管しょかんする独立行政法人「IPA＝情報処理推進機構」を通じて出資する案が検討されていることが分かりました。 据相关人士表示，在这其中，正在探讨对 Rapidus 公司通过独立行政法人的 IPA（推荐信息处理机构）进行出资的案件。 IPAは、情報セキュリティーに関する啓発けいはつ活動や、デジタル人材の育成いくせいなどを担ってになってきましたが、今回、新たな役割が追加されることになります。 IPA 一直以来都是承担信息安全相关的启发活动或培养数字人才的工作，在这次被追加了新的职能。 政府は、これまでラピダスの工場建設などに最大9000億円余りの支援を決めていますが、今回、独立行政法人を通じて出資し、実質的な株主となることで、民間からの投資の呼び水にしたい考えです。 由于政府目前决定对 Rapidus 的工厂建设投入最多超 9000 亿日元的经济援助，因此被认为（政府）这次通过独立行政法人进行出资而成为实际的股东，是为了促进来自民间的投资。 政府は、来年度予算案にも出資に必要な費用を盛り込む方針で、今後、具体的な出資額を詰めるとともに、必要な法案を来年の通常国会に提出することにしていますが、ラピダスに対する国の関与が一段と強まるだけに予算の妥当だとう性や有効性がより問われることになります。 政府决定也在来年度的预算案中加入出资所必需的费用，随着今后确定出具体的出资额度，同时在来年向国会提出必要的法案。随着国家对 Rapidus 的参与力度加大，预算的充足性和有效性将进一步受到质疑。","link":"/2024/12/06/translate_news_nhk_20241205_k10014659801000/"},{"title":"日语翻译 - 新闻 - 米 連邦控訴裁判所「TikTok」禁止する法律差し止め訴え 退ける","text":"美国联邦法院驳回了取消对 TikTok 禁止法律对控诉 来源：NHK 日期：2024-12-07 06:41 链接：米 連邦控訴裁判所「TikTok」禁止する法律差し止め訴え 退ける 🌟 单词： 動画｜どうが⓪ 連邦｜れんぽう⓪ 控訴｜こうそ① 訴える｜うったえる④③ 退ける｜しりぞける④ 漏えい｜ろうえい 憲法｜けんぽう① 正に｜まさに① アメリカで成立した動画どうが共有アプリ「TikTok」を禁止する法律をめぐり、アメリカの連邦れんぽう控訴こうそ裁判所は、TikTok側が法律の差し止めを求めた訴えうったえを退けしりぞけました。1月19日までに中国の親会社がアメリカ事業を売却しなければ、アプリでの配信などが禁止されることになります。 围绕对在美国成立的短视频共享应用程序 TikTok 的禁止，美国的联邦法院驳回了 TikTok 方对依法禁止其活动行为的控诉。如果到 1 月 19 日为止中国的母公司还没有卖出美国的事业的话，将禁止其在美国进行发布（视频）活动。 TikTokをめぐって、アメリカでは、中国側への情報漏えいろうえいの懸念などから、中国の親会社、バイトダンスがアメリカでの事業を売却しなければアプリを禁止する法律がことし4月に成立しました。 围绕 TikTok，美国由于担心其相中国方面泄漏情报，因此在今年 4 月设立了“中国的母公司字节跳动如果不将在美国的事业出售的话，将禁止其应用程序”的法律。 TikTok側は、この法律が表現の自由を侵害し、憲法けんぽうに違反しているとして差し止めを求める訴えを起こしていましたが、連邦控訴裁判所は6日、訴えを退けました。 TikTok 方虽然发起了“这个法律侵害了言论自由，违反了宪法”的申请停止禁止行为的控诉，但是联邦法院于 6 日驳回了申诉。 この理由について裁判所は、「アメリカ政府が敵対的な外国から表現の自由を守り、国民のデータを収集する能力を制限しようとする法律だ」として、憲法と照らしあわせても問題がないとしています。 关于理由，法院称：“（这是）美国政府为了针对敌对的外国守护言论自由，同时限制其收集国民数据能力的法律”，因此和宪法相符，没有问题。 これを受けて、期限となっている1月19日までにバイトダンスがアメリカ事業を売却しなければ、アプリが禁止されることになります。 受此影响，如果到了作为期限的 1 月 19 日，字节跳动还没有出售他们在美国的事业的话，应用程序将被禁止。 TikTok 連邦最高裁判所で争う姿勢を示す TikTok 展示了将在联邦最高法院进行抗争的姿态 アメリカの連邦控訴裁判所の決定を受け、TikTokは6日、声明を発表しました。 收到美国联邦法院的决定后，TikTok 在 6 日发表了声明。 この中では、「最高裁判所にはアメリカ人の言論の自由を守ってきたという確立された歴史的実績があり、今回の憲法をめぐる重要な問題でもまさに同じことを期待する」として、連邦最高裁判所で争う姿勢を示しています。 在这其中，说到：“美国的最高法院，有确定的、一直以来守护美国人言论自由的历史成绩，期待本次围绕宪法的重要问题和以前一样得到相同回应”，展示出了在联邦法院进行抗争的姿态。","link":"/2024/12/07/translate_news_nhk_20241207_k10014661141000/"},{"title":"日语翻译 - 新闻 - 1日に摂取する野菜の量 過去最少に 平均250gあまり 厚労省調査","text":"据厚生劳动省调查，（国民）1 天中摄取蔬菜的量是过去最少的，平均只有 250 克 来源：NHK 日期：2024-12-08 06:08 链接：1日に摂取する野菜の量 過去最少に 平均250gあまり 厚労省調査 🌟 单词： 摂取｜せっしゅ① 下回り｜したまわり⓪ 健康作り｜けんこうづくり 定める｜さだめる③ 減少｜げんしょう⓪ 脳卒中｜のうそっちゅう③ 心疾患｜しんしっかん 疾患｜しっかん⓪ 低減｜ていげん⓪ 1日に摂取せっしゅする野菜の量が去年、平均で250グラムあまりと、国が示す目標値を100グラムほど下回りしたまわり、統計を取り始めて最も少なくなったことが厚生労働省の調査でわかりました。 一天中摄入的蔬菜的量，去年平均为 250 多克，比国家公布的目标值少了 100 克左右，根据厚生劳动省的调查，这是有统计以来的最低值。 厚生労働省は、去年11月、全国の男女およそ5300人を対象に食生活の状況などを調査しました。 厚生劳动省在去年 11 月以全国近 5300 名男性和女性作为对象，调查了他们的饮食生活。 このうち、1日に摂取する野菜の量は男性の平均が262.2グラム、女性の平均が250.6グラムで、男女を合わせると256グラムとなりました。 在这其中，1 天中摄取蔬菜的量，男性平均为 262.2 克，女性平均为 250.6 克，综合为平均 256 克。 これは、今の方法で調査を始めた2001年以降で最も少なく、5年間で1割近く減っています。 这是从使用现在方法开始调查的 2001 年以后，最少的一次，（平均值）在 5 年间减少了近 1 成。 厚生労働省は国民の健康作りけんこうづくりのため、1日あたりの野菜の摂取量の目標を350グラムに定めてさだめていますが、それに100グラムほど足りない結果となりました。 厚生劳动省为了国民的身体健康，指定交易了一天中蔬菜的目标摄入量为 350 克，然而这个（平均值）少了近 100 克。 また年齢別では、男女ともに20代の摂取量が最も少なく、男性は230.9グラム、女性は211.8グラムで、1日350グラムの目標値に達しているのは、男性が19.1％、女性は11.6％にとどまっています。 然后根据年龄做划分，男性女性都是 20 多岁的一代摄入最少，男性为 230.9 克，女性为 211.8 克，要达到一天 350 克的目标值，男性还差 19.1%，女性还差 11.6%。 厚生労働省は野菜の価格が上昇していることも摂取量が減少げんしょうする要因の1つではないかとした上で、「野菜を食べると脳卒中のうそっちゅうや心疾患しっかんなどのリスクを低減ていげんできるので、できるだけ摂取量を増やしてほしい」と呼びかけています。 厚生劳动省考虑到蔬菜价格上涨也可能是摄入量减少的一个原因，呼吁“吃蔬菜的话能够降低心脑血管疾病和心脏病的风险，请尽量多吃蔬菜。”","link":"/2024/12/08/translate_news_nhk_20241208_k10014660811000/"},{"title":"日语翻译 - 新闻 - 通信各社 携帯端末など中古電子機器回収の動き 素材再利用も","text":"各通信公司出现了回收手机等二手电子设备的动向，或作为素材再次利用 来源：NHK 日期：2024-12-09 07:19 链接：通信各社 携帯端末など中古電子機器回収の動き 素材再利用も 🌟 单词： 中古｜ちゅうこ⓪① 機器｜きき①② 素材｜そざい⓪ 端末｜たんまつ⓪ 付与｜ふよ①授予，给予，赋予。 レアメタル｜れあめたる③(raremetal) 稀有金属。 希少｜きしょう⓪ 視野｜しや① アフターマーケット(aftermarket) 配件市场。 中古ちゅうこの電子機器ききの活用や素材の再利用を進めようと、通信各社の間で、携帯端末たんまつやパソコンなどをポイントの付与ふよや買い取りを通じて回収する動きが出てきています。 作为想要推进二手电子产品的活用和作为素材进行再利用的措施，各通信公司之间出现了通过赋予积分和购买回收手机和电脑等的动向。 このうちNTTドコモは、12月2日から都内にある一部の携帯電話の販売店で、携帯端末のほか、パソコンやゲーム機などを回収し、製品の種類に応じて自社のポイントを付与する実証実験を行っています。 在这其中，NTT DOCOMO 从 12 月 2 日开始，在都内的一部分手机售卖店中，开始实践“回收不止手机还有电脑和游戏机等，然后根据产品的种类赋予自己公司的积分”的实验。 これまでも、不要になった携帯端末を回収していますが、対象の製品を広げてポイントも付与することで、より多くの機器を回収しようというねらいです。 迄今为止虽然也在收集不要了的手机，然而（本次）通过扩大回收产品的范围并赋予积分的行为，旨在回收更多设备。 回収した機器は、中古品として販売するなど活用を検討していくとしています。 将回收回来的机器作为二手产品售卖之类的活用方案，正在持续探讨。 アフターマーケットビジネス部の浅見晶戦略・企画担当課長は「将来は、レアメタルなど希少きしょうな資源の循環も視野しやに入れていきたい」と話していました。 配件市场商业部门的战略计划担当科长浅見晶说：“想要在未来将稀有金属等稀少资源的循环也带入大众视野。” このほか、ソフトバンクは、不要になったパソコンやサーバーなどをグループ会社が企業などから買い取っていて、通信各社の間で、中古の電子機器の活用や素材の再利用に向けた動きが出てきています。 除此以外，软银集团公司也从企业等收购不要的电脑和服务器之类的，各通信公司之间，已经开始出现活用二手电子设备和将其作为素材再利用的动向。","link":"/2024/12/09/translate_news_nhk_20241209_k10014661991000/"},{"title":"日语翻译 - 新闻 - 成田空港 外国からの人材確保に向け検討会 関係機関が意見交換","text":"成田机场，在为了引入外国人才的研讨会上，相关机关交换了意见 来源：NHK 日期：2024-12-09 19:00 链接：成田空港 外国からの人材確保に向け検討会 関係機関が意見交換 🌟 单词： ハンドリング｜はんどりんぐ④(handling) 处理。 人手｜ひとで⓪ 急激｜きゅうげき⓪ 顕著｜けんちょ① 滑走路｜かっそうろ③ 煩雑｜はんざつ⓪ 空港で航空機の地上での誘導や荷物の積み降ろしなどを行う「グランドハンドリング地勤。」の人手ひとでが不足する中、外国からの人材の確保について話し合う検討会が9日、成田空港で開かれ、関係機関が受け入れ体制について意見を交わしました。 在机场飞机的地面阶段进行引导和装卸行李的地勤人员，处于人手不足的情况，在这个背景下，于 9 日召开了关于（如何）确保来自外国的人才的探讨会，相关机关就（人才）引进制度交换了意见。 成田空港では、コロナ禍のあと航空需要が急激きゅうげきに回復して「グランドハンドリング」の人手不足が顕著けんちょになっていて、今後、3本目の滑走路かっそうろが新設されることもあってさらなる人手の確保が課題となっています。 成田机场在新冠疫情（结束）后，航班需求急速恢复，导致地勤人手不足（的问题）变得更加急迫。今后，新的第三条跑道设立后，（如何）确保人手足够愈发会成为问题。 こうしたことを受けて成田空港会社は9日、外国からの人材の確保に向けた検討会を開き、グランドハンドリングを担ううなう企業5社や自治体などの関係者が参加しました。 受此影响成田机场公司于 9 日召开了关于确保来自外国的人才的研讨会，负责地勤的 5 家公司和地方政府等相关方参加了此会议。 会議では、企業側から、外国からの人材の受け入れをめぐって、空港近くの住宅が少ないことや、生活面での行政の手続きが煩雑はんざつなことなどが課題になっていることが説明されました。 在会议上，企业方围绕引入外国的人才，表示机场周边的住宅又少、生活方面的行政的手续又繁琐，这些都成了阻力。 また、成田市からは、外国からの人材が増える一方で、地域のコミュニティーに関われていない現状などについて報告されました。 然后，成田市政府方面表示虽然来自外国的人才会增加，但是现状是这些人并没有和当地社区产生关联。 成田空港会社は今後も定期的に会議を開き、具体的な対策を決めることにしています。 成田机场决定今后会定期召开会议，以制定出具体的对策。 成田空港会社戦略企画室の片山敏宏室長は、「地域と一体となって外国人が暮らしやすい受け入れ体制を作っていきたい」と話していました。 成田机场公司的战略企划室的片山敏宏室长说：“想要制定让外国人能融入社区、生活得更容易的引入策略。”","link":"/2024/12/10/translate_news_nhk_20241209_k10014662831000/"},{"title":"日语翻译 - 新闻 - 副業や兼業する人の割増賃金ルール見直しへ 環境整備ねらい","text":"重新制定从事副业、兼职的劳动者的补贴规定，有创造（新的）环境的意向 来源：NHK 日期：2024-12-11 05:30 链接：副業や兼業する人の割増賃金ルール見直しへ 環境整備ねらい 🌟 单词： 副業｜ふくぎょう⓪ 兼業｜けんぎょう⓪③ 割増｜わりまし⓪ 深夜｜しんや① 定める｜さだめる③ 細か｜こまか②③ 副業や兼業けんぎょうをする人には本業の労働時間と通算して割増わりまし賃金が支払われるルールですが、厚生労働省の研究会はこの通算の労働時間の管理が企業側の負担となっているとして廃止する案を示しました。ルールの見直しで副業や兼業に取り組みやすい環境を整備するねらいがあります。 虽然现状有“做副业和兼职的人，需要将其与本业的劳动时间算在一起然后被支付补贴资金”的规定，但是厚生劳动省的研究会认为这样对劳动时间统计的管理正在成为企业方面的负担，因此展示了废止它的提案。有重定规则并创造更容器从事副业、兼职环境的意向。 労働基準法では1日8時間、週40時間の法定労働時間を超えた場合や深夜しんやや休日に働かせた場合、企業は労働者に対して一定の割増賃金を支払わなければならないと定めてさだめています。 根据劳动基准法，超过 1 天 8 小时、一周 40 小时的法定劳动时间，或是让员工在深夜和休息日工作的话，企业需要对劳动者支付一定的补贴工资。 これは副業や兼業をする人にも適用され、現状は、企業側が本業と副業・兼業先の労働時間をして割増賃金を支払っています。 这对从事副业和兼职的人也适用，现状是，企业方面需要将本业、副业和兼职的劳动时间算在一起支付补贴。 このため、通算の労働時間を1日ごとに細かこまかく管理する必要があり、企業から大きな負担で副業や兼業を受け入れるのが難しいという声が上がっていました。 因此，统计的劳动时间需要细化到每一天进行管理，出现了（因为）对企业来说是很大的负担从而难以接受副业和兼职的声音。 厚生労働省の研究会は、企業の負担を減らして副業や兼業に取り組みやすい環境を整備しようと、10日開かれた会合で割増賃金について通算の労働時間の管理を廃止する案を示しました。 在厚生劳动省的研究会上，为了创造出减轻企业的负担并让副业和兼职更容易的环境，10 号召开的会议上，关于补贴工资，展示了废止对通算劳动时间进行管理的提案。 一方で、働く人の健康を確保するため労働時間の合計を1か月や1年の単位で把握するルールは引き続き、必要だとしています。 另一方面，广泛认为“为了确保劳动者的健康，继续将劳动的总时间用月和年为单位进行把控”是必要的。 研究会は年度内に報告書をまとめる予定で、その後、厚生労働省は労使が参加する審議会にこの案を示し、割増賃金の新たな支払い方法などについて議論していくことにしています。 研究会预定在今年度汇总出报告书，之后厚生劳动省会在劳动者参加的审议会上展示，继续讨论补贴工资新的支付方式等。","link":"/2024/12/11/translate_news_nhk_20241211_k10014664321000/"},{"title":"日语翻译 - 新闻 - 暗号資産の交換行う「コインチェックグループ」ナスダック上場","text":"从事虚拟资产交换业务的 CoinCheck Group 在纳斯达克上市 来源：NHK 日期：2024-12-12 06:01 链接：暗号資産の交換行う「コインチェックグループ」ナスダック上場 🌟 单词： 上場｜じょうじょう⓪ 次期｜じき① 大統領｜だいとうりょう③ 掲げる｜かかげる⓪1. 悬，挂，升起，举起，打着；2. 撩起，挑，掀；3. 刊登，载，登载；4. 提出，揭出，指出。 証券｜しょうけん⓪① 子会社｜こがいしゃ② 式典｜しきてん⓪ 歓声｜かんせい⓪ 突破｜とっぱ⓪① 獲得｜かくとく⓪ 暗号資産の交換業などを手がける「コインチェックグループ」が11日、ニューヨーク株式市場のナスダックに上場じょうじょうしました。トランプ次期じき大統領だいとうりょうが暗号資産の取引環境の整備などを掲げるかかげる中、今後、業界では上場を目指す動きが広がる可能性もあります。 从事加密资产交换业务的 CoinCheck Group 于 11 日在纽约股市的纳斯达克上市。在特朗普总统提出整顿加密资产的交易环境的背景下，今后业界可能广泛将以上市作为目标。 ナスダックに上場したのは、日本のネット証券しょうけん大手「マネックスグループ」の子会社こがいしゃで、暗号資産の交換業などを手がける「コインチェックグループ」です。 本次在纳斯达克上市的是，日本大型在线证券交易摩乃科斯证券公司的子公司、参与加密资产交易业务的 CoinCheck Group。 11日は、ニューヨーク中心部にあるナスダックで記念の式典しきてんが行われ、会社関係者は歓声かんせいをあげて上場を祝いました。 11 号在纽约中心的纳斯达克举行了纪念的庆典，与会者线上欢呼庆祝上市。 アメリカのトランプ次期大統領が暗号資産の取り引きをめぐる環境整備を掲げてきたことなどが好感され、代表的な暗号資産の1つであるビットコインの価格は、12月には初めて10万ドル、日本円でおよそ1500万円を突破とっぱしました。 针对美国的特朗普作为下位总统提出整顿加密资产的交易环境的行为，（大家）广泛（表示）好感，（因此）作为代表的虚拟货币的比特币的价格，在 12 月初突破 10 万美元，合日元大概为 1500 万。 式典のあと、マネックスグループの松本大会長は「暗号資産やブロックチェーンは世界的に展開するビジネスで、上場を契機に、人材の獲得かくとくやほかの会社の買収を進めていきたい。この数年間、アメリカは暗号資産に関してはやや慎重だったが今は、それが変化してきたので上場のタイミングとしてはベストだ」と話していました。 庆典之后，摩乃科斯证券公司的松本总会长说：“虚拟资产和区块链是在世界范围内开展的商业，我们想以上市为契机，持续推进人才的获取和对其他公司的收购。在过去的几年。美国对加密资产都稍稍有些谨慎，但现状变了，因此是上市的最好时机。” 暗号資産関連の会社の間では上場を目指す動きが広がる可能性もありますが、アメリカでの環境整備などが着実に進むかが今後の焦点となりそうです。 虽然加密资产关联的公司可能广泛将以上市作为目标，但是美国的环境整顿等是否能够真正进行下去，似乎还将成为今后的焦点。","link":"/2024/12/12/translate_news_nhk_20241212_k10014665421000/"},{"title":"日语翻译 - 新闻 - 自宅で大麻草栽培か 12日施行の規制法違反で会社員逮捕 名古屋","text":"在名古屋，由于在自己的住宅种植大麻违反了 12 日实施的限制法，公司员工被逮捕 来源：NHK 日期：2024-12-12 22:00 链接：自宅で大麻草栽培か 12日施行の規制法違反で会社員逮捕 名古屋 🌟 单词： 大麻｜たいま① 栽培｜さいばい⓪ 大麻草｜たいまそう 所持｜しょじ① 麻薬｜まやく⓪ 自宅で大麻たいまを栽培さいばいしたなどとして、名古屋市の41歳の会社員が、12日に施行された大麻草たいまそう栽培規制法などに違反した疑いで警察に逮捕されました。 由于在自己的住宅栽培大麻等原因，名古屋 41 岁的公司员工涉嫌违反 12 日实施的大麻栽培限制法案而被警察逮捕。 逮捕されたのは、名古屋市南区の会社員、饒辺浩二容疑者（41）です。 被逮捕的是，名古屋市南部的公司员工饒辺浩二。 警察によりますと、12日午前、自宅で営利目的で大麻草1本を栽培し、少量の大麻を所持しょじしたとして、12日に施行された大麻草栽培規制法と改正麻薬まやく取締法に違反した疑いが持たれています。 据警察描述，由于他在自家住宅以盈利为目的栽培了一株大麻，同时持有少量大麻，因此在 12 日上午因其涉嫌违反 12 日当日实施的大麻栽培限制法案和修订麻药取缔法而被逮捕。 大麻草の栽培をしているような画像がSNS上に投稿されているのが見つかり、警察が自宅を捜索したところ、栽培中の大麻草、合わせて39本と、大麻を吸うのに使うとみられるパイプなどが見つかったということです。 找到了看上去是在栽培大麻的、被上传到社交媒体的画像，经过警察在他住宅的搜索，还找到了总计 39 株种植中的大麻，还有看上去是用以吸食大麻的烟斗。 警察によりますと、調べに対し容疑を認めているということです。 据警察所述，面对调查嫌疑人都承认了。","link":"/2024/12/13/translate_news_nhk_20241212_k10014666691000/"},{"title":"日语翻译 - 新闻 - “北朝鮮 IT技術者使い不正に収入得る”米司法当局 14人を起訴","text":"由于“北朝鲜的 IT 技术员获取不正当收入”，美国当局起诉了 14 人 来源：NHK 日期：2024-12-14 06:30 链接：“北朝鮮 IT技術者使い不正に収入得る”米司法当局 14人を起訴 🌟 单词： 北朝鮮｜きたちょうせん⑤ 偽る｜いつわる③ 受注｜じゅちゅう⓪接受订货。 拠点｜きょてん⓪ 動員｜どういん⓪ 罪｜つみ① 氷山｜ひょうざん① 厳格｜げんかく⓪ アメリカの司法当局は、北朝鮮きたちょうせんが国籍などを偽ったいつわったIT技術者を使ってアメリカの企業などからリモートワークの仕事を受注じゅちゅうし、およそ6年間で少なくとも8800万ドルを不正に得ていたとして、北朝鮮国籍の14人を起訴しました。 美国的当局，北朝鲜使用隐瞒了国籍的 IT 技术人员从美国的企业等接受远程工作的订单，从而在大约 6 年间获得至少 8800 万美元的不正当收入，因此起诉了北朝鲜国籍的 14 人。 起訴状などによりますと、中国とロシアに拠点きょてんを置く北朝鮮のフロント企業2社は、IT技術者少なくとも130人を動員どういんし、国籍などを偽ってアメリカの企業や団体からリモートワークの仕事を受注して、その収益を北朝鮮側に送金していたということです。 据起诉书描述，2 家在中国和俄国设立据点的服务公司，动员了至少 130 名 IT 技术人员，伪造了国籍从美国的企业和团体接受远程工作的订单，再将收益送回北朝鲜方面。 去年までのおよそ6年間で少なくとも8800万ドル、日本円で135億円余りを不正に得ていたとして、司法当局は12日、フロント企業の代表など北朝鮮国籍の14人をアメリカによる制裁措置違反などの罪つみで起訴したと発表するとともに、最高500万ドルの報奨金をつけて情報提供を呼びかけています。 由于他们到去年为止的 6 年前至少获得了 8800 万美元，合 135 亿日元的不正当收入，司法当局在 12 日发布了声明说：由于违反美国制定的制裁措施法案，已经起诉了服务公司代表等北朝鲜国籍的 14 名人员。同时公布 500 万美元的报酬金，呼吁提供信息。 これらの企業はIT技術者を組織内で「IT戦士」と呼び、ボーナスや賞品で業績を競きそわせていたということで、司法当局は北朝鮮の核兵器やミサイル開発の資金源になっている可能性を指摘しています。 这些企业将 IT 技术人员在组织内部称为 IT 战士，再通过奖金和奖品让他们竞争业绩，（因此）司法当局指出他们将成为北朝鲜的核武器和导弹开发的资金源。 FBIの捜査官は「これは氷山ひょうざんの一角にすぎない。北朝鮮政府は毎日、アメリカ企業に対して同じ手口を実行するために、何千人ものIT技術者を訓練し、配備している」として、リモートワークの従業員の審査しんさなどを厳格げんかくにするよう、企業に注意を呼びかけています。 FBI 的调查员表示：“这只不过是冰山一角。北朝鲜为了对美国的企业实施同样的手段，每天都在训练数千名 IT 技术人员并进行配置。”，因此呼吁企业多加注意，对参与远程工作的人员进行更严格的审查。","link":"/2024/12/14/translate_news_nhk_20241214_k10014667841000/"},{"title":"日语翻译 - 新闻 - 長崎の被爆者 朝長さん “核兵器廃絶に若い世代欠かせない”","text":"长崎的原子弹受害者朝長先生表示：“核武器的废止缺不了年轻一代的努力” 来源：NHK 日期：2024-12-14 19:48 链接：長崎の被爆者 朝長さん “核兵器廃絶に若い世代欠かせない” 🌟 单词： 被団協｜ひだんきょう 朝長万左男｜ともながまさお 廃絶｜はいぜつ⓪ 登壇｜とうだん⓪ 締約｜ていやく③ オブザーバー｜おぶざーばー③(observer) 列席会议的观察员，旁听人，评论员，观察家。 日本被団協ひだんきょう＝日本原水爆被害者団体協議会のノーベル平和賞の授賞式に出席した長崎の被爆者で医師の朝長万左男さんが福岡市内で講演し、核兵器の廃絶はいぜつには若い世代の力が欠かせないと期待を寄せました。 出席了日本原子弹受害者协会诺贝尔和平奖授奖仪式的、同时也是长崎的核弹受害者兼医生的朝長万左男先生在福冈市内进行了演讲，表示核武器的废止缺不了年轻一代的努力，并对此寄予期待。 被爆による人体への影響を長年研究してきた、長崎の被爆者で医師の朝長万左男さんは、ノルウェーの首都しゅとオスロで行われた日本被団協のノーベル平和賞の授賞式に出席し、現地で若者との対話集会にも参加しました。 一直以来长年研究核爆对人体影响的、长崎的核弹受害者兼医生的朝長万左男先生，出席了在挪威首都奥斯陆举行的、对日本原子弹受害者协会的诺贝尔和平奖颁奖仪式，并在当地参加了和年轻人的对话集会。6 朝長さんは14日、帰国してから初めて、福岡市内で開催された講演会に登壇とうだんしました。 朝長先生于 14 日，也是回国后的首次，在福冈市举行的演讲会上登台演讲。 この中で朝長さんは「すばらしい授賞式だった。スピーチで感動したのは、被爆者が繰り返し原爆について話す理由を、核兵器をこのままにしておくと人類の未来が危ないからだとした点だ」と述べました。 在这过程中，朝長先生表示：“授奖仪式非常棒。演讲中令人感动的是，核爆受害者反复谈论原子弹的理由是，如果放任核武器不管，人类的未来就危险了。” また、若者との交流については「核兵器のない世界の実現のためには、若者の世代に責任があるとオスロの若者たちに伝えたら、素直に受け止めてもらえた。これから若者の活動が非常に重要になる」と話し、核兵器の廃絶には若い世代の力が欠かせないと期待を寄せました。 并且针对关于与年轻人的交流这件事，表示：“‘为了实现没有核武器的世界，年轻一代责任重大’，当我对奥斯陆的年轻人传达这样的观点后，他们一下子就接受了。从今往后年轻人的行动将变得愈发重要。”，核武器的废止缺不了年轻一代的努力，并对此寄予期待。 講演を聞いた60代の男性は「核兵器をなくすためのプロセスが大切だと思う。日本政府には、せめて核兵器禁止条約の締約ていやく国会議にオブザーバー参加してほしい。講演を聞いて、世論を動かさないといけないと思った」と話していました。 听了演讲的 60 岁男性说：“为了废止核武器，我认为流程是很重要的。想要日本政府哪怕只是以旁听（都要去）参加缔结废止核武器条约的国际会议。我听了演讲，觉得必须要动摇舆论。”","link":"/2024/12/15/translate_news_nhk_20241214_k10014668191000/"},{"title":"日语翻译 - 新闻 - 日銀 18日から金融政策決定会合 追加の利上げは","text":"日银将从 18 号开始召开金融政策会议，预计将追加利率上调 来源：NHK 日期：2024-12-16 02:49 链接：日銀 18日から金融政策決定会合 追加の利上げは 🌟 单词： 概ね｜おおむね⓪梗概，概要；大概，大约，大致。 通商｜つうしょう⓪ 前後｜ぜんご① 仮に｜かりに⓪1. 暂时；2. 假设。 日銀は今週18日から金融政策を決める会合を開きます。市場関係者の間では日銀は今回か次の会合で追加の利上げに踏み切るのではないかという見方も出ていますが、日銀内では賃上げの動きが広がるかやアメリカのトランプ次期大統領の政策の影響を見極めるべきという意見も多く、慎重に検討するとみられます。 日银将从本周的 18 号开始召开制定金融政策的会议。虽然市场关系者中有预测“在这次和下次的会议上回进行追加的利息上调”，但是也有很多意见表示日银内部广泛在提高工资、还会受到美国下一任总统政策的影响，要慎重考虑。 日銀は今月18日から2日間、金融政策決定会合を開きます。 日银将从本月 18 号开始，召开为期 2 天的金融政策决定会议。 日銀は経済と物価が見通しどおりに推移すれば追加の利上げを検討する方針を示していて、市場関係者の間では最近の企業業績や物価などのデータから今回か来月の会合で追加の利上げを決めるのではないかという観測が出ています。 由于日银表示，如果经济和物价按预期发展的话，会讨论进一步的利率上调，因此市场相关者根据企业业绩和市场物价推测“会在这个月或下个月决定追加利息上调”。 日銀内でも経済と物価の動きについてはおおむね見通しどおりに推移しているという見方が多くなっています。 日银内部关于经济和物价的动向，认为大概也会按预想发展的人也正在变多。 一方、来年の春闘などで中小企業を含めことしと同じ程度の水準の賃上げが広がるかどうかや、トランプ次期大統領の経済政策や通商つうしょう政策が経済に与える影響を見極めるべきだという意見があります。 另一方面，（需要考虑）在明年的春斗上是否会与包含中小企业（涨薪）在内的今年上涨一样的薪水，同时还应该预测美国下任总统特朗普的经济政策和商贸政策会给经济带来的影响，这些意见也存在。 さらに、円相場はこのところ1ドル＝150円前後ぜんごの水準が続き、物価を急速に押し上げるリスクは大きくないといった意見も一部に出ています。 并且，还有一部分意见表示“日元汇率在这个时间点持续维持在 1 美元等于 150 日元左右的水准，物价急速上涨的风险正在变大”。 仮にかりに今回の会合で追加の利上げに踏み切る場合、ことし3月、7月に続き1年に3回の政策変更となり、日銀としては今の経済や物価の動きが崩れないかどうかも含めて今後の対応を慎重に議論するとみられます。 如果在这次的会议上，决定追加利率上调的话，那么加上今年 3 月、7 月就 1 年 3 回变更政策了，预计日银将慎重讨论包括当前经济和物价走势是否不会崩溃在内的今后应对措施。","link":"/2024/12/16/translate_news_nhk_20241216_k10014668721000/"},{"title":"日语翻译 - 新闻 - 高校生が模擬株式会社を設立 出資金で開発の商品販売会 秋田","text":"在秋田市举行了“高中生模拟成立有限公司，通过股金开发的商品”的贩卖会 来源：NHK 日期：2024-12-17 06:54 链接：高校生が模擬株式会社を設立 出資金で開発の商品販売会 秋田 🌟 单词： 設立｜せつりつ⓪ 出資金｜しゅっしきん⓪股金，资本。 賑わい｜にぎわい⓪③热闹，繁华。 南通｜みなみどおり 秋田小町｜あきたこまち①①秋田小町大米。 ブレンド｜ぶれんど⓪(blend) 混合，搀和。 入浴剤｜にゅうよくざい⓪ 実践｜じっせん⓪ 高校生が模擬的に株式会社を設立せつりつし、出資金しゅっしきんで開発した商品の販売会が15日に秋田市で開かれ、買い求める多くの人でにぎわいました。 15 号在秋田市开展了“高中生模拟成立有限公司，然后通过股金开发商品”的销售会，来买的人很多非常热闹。 販売会は、高校生に会社の経営について興味を持ってもらおうと、キャリア教育などの事業を行う横手市の法人が開き、秋田市南通みなみどおりの会場には参加した秋田高校や秋田北高校、それに秋田南高校から10の店舗が並びました。 销售会是因为高中生对公司的经营等有兴趣，而由进行职业教育等（工作）的横手市的法人召开的。在秋田市南通镇上的会场上，有来参加（活动）的秋田高校、秋田北高校和秋田南高校的 10 个店铺。 店舗では、高校生が開発に取り組んだあきたこまち秋田小町大米。の米粉こめこを使ったお菓子や秋田杉すぎの香りをブレンドした入浴剤にゅうよくざいなど、地域の特色を生かした商品が販売されたほか、高校生が勉強の相談に応じる学習塾も出店されました。 开设的店铺，高中生除了贩卖努力开发的、使用秋田小町大米的米粉制作的糕点，和混入秋田杉香气的入浴剂等发挥地区特色的商品，还开设了应对高中生学习的顾问性质的学习私塾。 生徒たちは、模擬的に株式会社を設立して株式を発行したり、投資家に事業説明をしたりして、ことしの夏から会社の経営について学んできたということです。 学生们又是模拟设立有限公司发行股票，又是向投资家进行事业说明，从今年夏天开始就一直学到于公司经营相关的知识。 秋田北高校1年生の女子生徒は「お金のやり取りや接客は難しかったですが、将来の役に立つよい経験ができました」と話していました。 秋田北高校 1 年纪的学生说：“虽然挣钱和接待客人都很难，但是获得了在将来会发挥用场的经验。” イベントを企画した法人の奥真由美代表理事は「学校では実践じっせん的なキャリア教育の場が少なくなっているので、こうした機会を通じて主体的に動く力を発揮してほしい」と話していました。 规划活动的法人奥真由美代表理事说：“由于学校中进行真实的职业教育的地方正在变少，因此想要通过这样的机会（让学生）发挥主观能动性。”","link":"/2024/12/17/translate_news_nhk_20241217_k10014669601000/"},{"title":"日语翻译 - 新闻 - 日本証券業協会 野村証券に3000万円の過怠金命じる方針","text":"日本证券协会决定命令野村证券缴纳 3000 万日元的过失金 来源：NHK 日期：2024-12-17 21:33 链接：日本証券業協会 野村証券に3000万円の過怠金命じる方針 🌟 单词： 過怠金｜かたいきん⓪ 命じる｜めいじる⓪③ 経営陣｜けいえいじん高层领导。 勧告｜かんこく⓪ 課徴金｜かちょうきん附加税。 納付｜のうふ⓪① 戒告｜かいこく⓪ 不祥事｜ふしょうじ② 証券最大手の「野村証券」が日本国債の先物取引で価格を不正に操作していた問題で「日本証券業協会」は会社に対する処分として過怠金かたいきん3000万円の支払いを命じるめいじる方針を固めました。経営陣けいえいじんが主導して再発防止を進めるよう勧告かんこくも行う方針です。 关于日本最大的证券公司野村证券对日本国债期货交易进行不正常的价格操纵的问题，日本证券界协会决定作为对该公司的处分，命令其缴纳 3000 万日元的过失费用。劝告高层领导主导的促进防止再次发生（一样事件）的行为也将进行。 「野村証券」をめぐっては3年前、トレーダーが自社の資金を使った日本の長期国債の先物取引で価格を不正に操作したとして、ことし10月に金融庁から課徴金かちょうきんの納付のうふを命じる処分を受けました。 围绕野村证券（还发生过）3 年前交易员对使用自己公司资金的日本国债期货交易进行不正常的价格操纵，因此在今年 10 月从金融厅接受了（被命令）缴纳附加税的处分。 関係者によりますと、これについて業界団体の日本証券業協会も金融商品取引法に違反していると判断し、会社に対する処分として過怠金かたいきん3000万円の支払いを命じる方針を固めました。 据关系人士所述，商会团体判断此事违反了金融商品交易交易法，决定对公司处以命令其缴纳 3000 万日元过失金的处分。 また、経営陣が主導して再発防止を進め実施状況を報告するよう勧告も行う方針です。 并且还将建议由管理层主导，以防止再次发生，并报告实施情况。 日本証券業協会は18日にも処分を公表する見通しです。 预计日本证券界协会也将在 18 日公布处分。 この問題をめぐっては先物取引を手がける大阪取引所が6000万円の過怠金を支払うよう命じたほか、東京証券取引所も戒告かいこくの処分を行っています。 围绕这个问题，除了命令参与交易的大阪交易所支付 6000 万日元的过失金以外，还对东京证券交易所进行了警告的处分。 野村証券では、この問題のほかにも営業職だった社員が強盗ごうとう殺人未遂みすいと放火ほうかの罪で起訴されるなど顧客の信頼を揺るがす不祥事ふしょうじが相次いでいます。 野村证券除了这个问题，还相继发生着营业员（被起诉）强盗杀人未遂和放火等、动摇着客户信赖的丑闻。","link":"/2024/12/18/translate_news_nhk_20241217_k10014670971000/"},{"title":"日语翻译 - 新闻 - 埼玉 深谷 特産の「深谷ねぎ」 出荷最盛期","text":"在埼玉的深谷市，迎来特产深谷大葱的出货最忙时期 来源：NHK 日期：2024-12-19 06:34 链接：日埼玉 深谷 特産の「深谷ねぎ」 出荷最盛期 🌟 单词： 深谷市｜ふかやし ヘクタール｜へくたーる③(hectare) 公顷，1公亩的100倍之意土地面积的单位。 栽培｜さいばい⓪ 冷え込み｜ひえこみ⓪骤冷，气温急剧下降。 収穫｜しゅうかく⓪ 皮｜かわ② 猛暑｜もうしょ① 団欒｜だんらん⓪团栾，团圆，团聚人们聚在一起欢度时光。 全国有数ゆうすうのねぎの産地、埼玉県深谷市ふかやしで、特産の「深谷ねぎふかやねぎ」の出荷が最盛期さいせいきを迎えています。 在全国有名的大葱产地埼玉県深谷市，正迎来特产深谷大葱出货最忙的时期。 深谷市は、水はけのよい土地をいかして、およそ450ヘクタールでねぎを栽培さいばいする全国有数の産地です。 深谷市是活用排水良好的土地的、种植了约 450 公顷大葱的全国有名的（大葱）产地。 特産の深谷ねぎは、本格的な冷え込みひえこみとともに甘みあまみが増すこの時期に出荷の最盛期を迎えていて、明戸地区の畑では、生産者が機械を使って掘り出していました。 作为特产的深谷大葱，在这个时期随着气温骤降而积攒甜度，迎来出货最忙的时期，在明户地区的田里，种植者使用机械将其挖掘出来。 作業場では、収穫しゅうかくしたねぎの皮かわをむいて箱に詰める作業に追われていました。 之后在作业场所，会追加将收获的大葱的皮去除后装箱的作业。 ことしは夏の猛暑もうしょの影響で一部で細いねぎがあったものの、12月に入ってからの冷え込みで、例年と変わらない太さと甘さがあるねぎに仕上がっているということです。 虽然今年受到夏天炎热的影响出现了一部分细的大葱，但是进入 12 月以来气温骤降，和往年一样生产除了饱满的、甘甜的大葱。 生産者の澤野政明さんは「鍋料理などに使ってもらって、家族だんらん団欒で楽しく食べてもらいたいです」と話していました。 作为种植者的澤野政明先生或：“想要将其用在锅物料理中，和家人们团聚在一起开心地享用。” 深谷ねぎの出荷は、1月まで続きます。 深谷大葱的出货将持续到 1 月底。","link":"/2024/12/19/translate_news_nhk_20241219_k10014671791000/"},{"title":"日语翻译 - 新闻 - 北海道 岩見沢 市職員が「豪雪パトロール」 雪の事故防止へ","text":"北海道岩見沢市的市区职员进行“大雪巡逻”来防止事故 来源：NHK 日期：2024-12-20 05:12 链接：北海道 岩見沢 市職員が「豪雪パトロール」 雪の事故防止へ 🌟 单词： 積雪｜せきせつ⓪ 落雪｜らくせつ⓪ 豪雪｜ごうせつ⓪ 大雪｜おおゆき⓪ 暖房｜だんぼう⓪ 雪庇｜せっぴ⓪①雪檐。 平年の3倍近い積雪せきせつとなっている北海道岩見沢市では、落雪らくせつなどによる雪の事故を防ごうと、市の職員がひとり暮らしの高齢者などの住宅を回って注意を呼びかける「豪雪ごうせつパトロール」が行われています。 在积雪靠近往年三倍（深度）的北海道岩見沢市，市镇府职员为了防止降雪导致的事故，正在进行来往独居老人住宅并提醒注意的“大雪巡逻”行动。 この冬、大雪おおゆきが続く岩見沢市では平年の3倍近い積雪となっていて、落雪などによる雪の事故を防ごうと、市の職員がひとり暮らしの高齢者や障害のある人の住宅を回って注意を呼びかける「豪雪パトロール」が19日から行われています。 这个冬天，持续下大雪的岩見沢市的积雪有往年的三倍，为了防止降雪导致的事故，市镇府职员从 19 日开始进行往返于独居老人和有不便的人士并提醒注意的“大雪巡逻”行动。 20日までに市内の1730世帯を訪問する予定で、職員は屋根の雪庇せっぴがせり出していないかや、暖房だんぼうの排気口が雪に埋まっていないかなどを確認していました。 预定到 20 日为止访问市辖区内的 1730 户，市镇府职员正在确认（各家）屋檐的雪檐是不是伸出来了，供暖设备的排气口有没有被雪掩埋。 また、今後さらに積雪があった場合に落雪に注意するよう呼びかけたり、玄関先の除雪を行ったりしていました。 然后，今后会进一步，在有积雪的情况下提醒注意降雪，并清扫玄关前的雪。 90代の女性は「市の職員がパトロールをしてくれて助かりました」と話していました。 90 岁的婆婆说：“市政府职员进行巡逻帮到大忙了。” パトロールを行った岩見沢市の職員の葛西理さんは「高齢の方が多いので、除雪で体を痛めたりすることがないよう体に気をつけてくださいと伝えるようにしています」と話していました。 进行巡逻的岩見沢市的职员葛西理说：“由于高龄者众多，我试着告诉他们要注意身体，不要因为除雪而伤到身体。”","link":"/2024/12/20/translate_news_nhk_20241220_k10014672521000/"},{"title":"日语翻译 - 新闻 - 固定電話 通信事業者変更「番号ポータビリティー」来月開始へ","text":"从下个月开始，固话号码可以变更通信公司的“号码可迁移性” 来源：NHK 日期：2024-12-23 06:59 链接：固定電話 通信事業者変更「番号ポータビリティー」来月開始へ 🌟 单词： 双方向｜そうほうこう③ ポータビリティー｜ぽーたびりてぃー④(portability) 可移植性。 この程｜このほど②1. 最近；2. 这回，这次，这一次。 指針｜ししん⓪ 電話番号を変えずに通信事業者を双方向そうほうこうに変更できる「番号ポータビリティー」が来月から固定電話でも始まります。 能在不改变电话号码的情况下双向改变用户和通信公司的“号码可迁移性”将在下个月从固话号码开始。 固定電話の「番号ポータビリティー」は2001年に始まりましたが、NTT東日本と西日本からほかの通信事業者に変更する場合に限って行われています。 虽然固话号码的“号码可迁移性”是从 2001 年开始的，但是仅限于变更为来自 NTT 东日本和西日本的其他的通信公司。 このほど固定電話サービスを提供する事業者18社の間でシステムの改修などが行われ、来月から携帯電話と同じように双方向での番号ポータビリティーができるようになります。 最近，提供固定电话服务的 18 家运营商之间进行了系统改造，从下个月开始就能提供像手机一样的双向号码迁移。 総務省は、利用者にとって番号を変えることなく割安なサービスに乗りかえることができるようになるほか、事業者の間の公正な競争を促すことにもつながるとしています。 总务省不仅让消费者能够在不更改号码的情况下享受更便宜的服务，还顺带促进了从业者之间公正的竞争。 実施に合わせて総務省は、事業者向けの指針ししんの案をまとめ、利用者が他社に移ることを引き止めることや、他社に移る際の手数料などを不当に高額に設定することなどを禁止する方向で検討しています。 随着实施进行，总务省汇总了针对从业者的方针案件，以禁止“阻碍消费者向其他公司迁移”和“向其他公司迁移的时候设定高昂的费用”为方向展开研讨。 一方、一部の地域では、他社への移行に制約があるケースもあるということで、各社は利用者に対して、ホームページなどで情報を確認してほしいとしています。 另一方面，由于在一些地区还存在向其他公司的迁移有条款制约情况，各公司希望消费者能在公司主页等地方进行信息确认。","link":"/2024/12/23/translate_news_nhk_20241223_k10014675611000/"},{"title":"日语翻译 - 新闻 - トヨタ 中国にEV＝電気自動車の新工場建設を検討","text":"丰田探讨在中国建立新的电车工厂 来源：NHK 日期：2024-12-24 05:04 链接：トヨタ 中国にEV＝電気自動車の新工場建設を検討 🌟 单词： 高級｜こうきゅう⓪ 用地｜ようち① 迫る｜せまる② 三菱｜みつびし② 撤退｜てったい⓪ 閉鎖｜へいさ⓪ トヨタ自動車が中国の上海にEV＝電気自動車を生産する新たな工場の建設を検討していることがわかりました。高級こうきゅう車ブランドのEVを中心に生産する計画だということです。 获悉丰田汽车正在探讨在中国上海建立新的电车工厂。计划主要以高级汽车品牌为重心进行生产。 関係者によりますと、トヨタは、中国の上海に用地ようちの取得を進めてEVを生産する新たな工場を建設することを検討していて、稼働開始は早ければ2027年ごろになる見通しだということです。 据关系人士描述，丰田正在探讨推进在中国上海获得用地并建立新的生产电车的工厂，预计开工最早在 2027 年左右。 トヨタは2035年に世界全体で高級車ブランド「レクサス」の新車をすべてEVにする計画を打ち出していて、新工場では「レクサス」を中心に生産する計画だということです。 丰田发布了在 2035 年将世界上的、所有旗下高级车品牌雷克萨斯的新车都变成电车的计划，因此新工厂也将以雷克萨斯作为生产重心。 中国市場でEVの普及が続き、価格競争も激しくなる中で、エンジン車が中心の日本メーカー各社は販売の落ち込みが続き、生産体制の見直しを迫られています。 在中国市场上的电车持续普及、价格竞争也日渐激烈的背景下，以汽油车为中心的日本各制造公司的销售业绩日渐低迷，生产体制的重整迫在眉睫。 三菱みつびし自動車工業が2023年10月に中国からの撤退てったいを決めたほか、2024年に入って日産自動車とホンダが一部の工場を閉鎖へいさするなど、影響が広がっています。 除了三菱汽车在 2023 年 10 月决定从中国退出，进入2024年之后日产汽车和本田关闭了部分工厂等，影响正在扩大。 トヨタも2024年1月から10月までの中国での販売台数は141万台余りと、2023年の同じ時期を9.3％下回っていて、トヨタとしては、新工場建設によってEVシフトが急速に進む中国で巻き返しを図りたいねらいがあるものとみられます。 丰田从 2024 年 1 月到 19 月再中国的贩卖辆数为 141 万多台，对比 2023 年的同期下降了 9.3%。（此举被视为）丰田希望通过建立新工厂重返电车急速发展的中国并扭转局面。","link":"/2024/12/24/translate_news_nhk_20241224_k10014677041000/"},{"title":"日语翻译 - 新闻 - 熊本など 外国人エンジニアのビザ取得要件緩和へ 人手不足懸念","text":"熊本县等担忧人手不足，放宽外国工程师的签证条件 来源：NHK 日期：2024-12-24 21:47 链接：熊本など 外国人エンジニアのビザ取得要件緩和へ 人手不足懸念 🌟 单词： 雇い｜やとい② 緩和｜かんわ⓪ 官邸｜かんてい⓪ 諮問｜しもん⓪咨问，咨询，咨议。 北九州市｜きたきゅうしゅうし ドローン｜どろーん②(drone) 无人机。 細かい｜こまかい③ 政府は半導体工場の進出などを念頭に人手不足が懸念されるとして、熊本県などで外国人エンジニアを雇いやといやすくするため、ビザの取得要件を緩和かんわすることになりました。 政府担忧半导体工厂的引进之后会人手不足，因此熊本县为了让雇用外国工程师更加容易，将签证的获取条件放宽。 政府は24日、総理大臣官邸かんていで、地域を限って大胆だいたんな規制緩和などを行う国家戦略特区の諮問しもん会議を開き、32件の事業の認定が報告されました。 政府于 24 日，在总理大臣官邸召开了就“（设立）国家战略特区来进行特定地区的大胆的条件放宽策略”的咨询会议，会上报告了对 32 个行业的认定。 このうち熊本県と、福岡市、北九州きゅうしゅう市では台湾の半導体大手TSMCの工場の進出などを念頭に、人手不足が懸念されるとして、外国人エンジニアなどを雇いやすくするため、ビザの取得要件を緩和するとしています。 其中，熊本县、福冈市、北九州市考虑到台湾大型半导体公司 TSMC 的工厂进驻等，担心人手不足，为了便于雇用外国工程师等，将放宽签证的取得条件。 また▽北海道では、銀行がGX＝グリーントランスフォーメーション関連事業に出資しやすくなるほか▽石川県加賀市などでは、自動運転やドローンなどの実証実験を行う際に、手続きがワンストップでできるようになります。 并且▽ 在北海道，银行对绿色发展相关事业的投资将变得更加容易，▽ 除此以外，在石川县加贺市，在进行自动驾驶和无人机的实验时，手续将变得一次就能完成。 会議で石破総理大臣は「地域の課題を起点とする規制改革を大胆に進めていく中で、特区は重要だ。地域の期待によりきめ細かくこまかく応えることができる制度となるよう検討を進めてほしい」と述べました。 在会议上石破总理大臣说到：“在以地区的问题作为起点大胆推进制度改革的情况中，特区是非常重要的。希望大家能推进探讨出更能细致地满足地方期待的制度。”","link":"/2024/12/25/translate_news_nhk_20241224_k10014678201000/"},{"title":"日语翻译 - 新闻 - 東京都立中央図書館 旧「こどもの城」周辺へ移転の方向性示す","text":"都政府展示了将东京都立中央图书馆移动到旧的孩子城周边的想法 来源：NHK 日期：2024-12-25 21:32 链接：東京都立中央図書館 旧「こどもの城」周辺へ移転の方向性示す 🌟 单词： 老朽化｜ろうきゅうか⓪ 周辺｜しゅうへん⓪ 有栖川宮｜ありすがわのみや 劇場｜げきじょう⓪ 老朽化ろうきゅうかが進んでいる東京 港区の都立中央図書館について、都は渋谷区の旧「こどもの城しろ」を含む周辺の都有地へ移転する方向性を示しました。 对于持续老化的东京都立图书馆，都政府表示想往包含旧的孩子城周边的都政府所有地转移。 25日、渋谷区の子どもの文化交流施設、旧「こどもの城」や旧青山病院を含む周辺しゅうへん都有地の活用方法について有識者が集まって検討する会がオンラインで開かれました。 25 日，就如何使用旧涉谷区孩子们的文化交流设施，（还有）包括旧的孩子城和旧青山医院的周边的都政府所有地，有识之士们聚集并在线上召开了探讨会。 この中で、都側からは建設から50年を超えて老朽化が進んでいる港区の有栖川宮ありすがわのみや記念公園にある都立中央図書館についてこの地区に移転する方向性が示されました。 在这其中，都政府侧表示想将建立超过 50 年的、持续腐朽的坐落于港区有栖川宮纪念公园的都立中央图书馆迁移到这个地方。 新たな図書館には、調査や研究といった従来の役割だけでなく、交流や創造活動を生み出す機能を持たせたいとしています。 同时表示新的图书馆，将不仅局限于调查和研究等一直以来的功能，还希望诞生出交流和创造活动等的功能。 また、この地区にデジタル技術に対応した1200席規模の新たな劇場げきじょうを整備し、子どもが、芸術文化に触れる機会を設けたいとしています。 并且还希望在这个地方准备使用了数字技术的 1200 个席位规模的新的剧场，为孩子们创造接触艺术文化的机会。 25日の検討会では反対意見はなく、都はこの方向性をさらに具体化させることにしています。 25 日的研讨会上没有反对意见，都政府正在将目标方向具体化。","link":"/2024/12/26/translate_news_nhk_20241225_k10014678891000/"},{"title":"日语翻译 - 新闻 - 11月の有効求人倍率 全国平均で1.25倍 前の月と同じ水準","text":"11 月的有效招聘倍数为全国平均 1.25 倍，和之前的月份保持了相同水准 来源：NHK 日期：2024-12-27 08:55 链接：11月の有効求人倍率 全国平均で1.25倍 前の月と同じ水準 🌟 单词： 物価高｜ぶっかだか③ 就業｜しゅうぎょう⓪ 卸売｜おろしうり⓪③卸货贩卖，在商品流通过程中，介于制造、采收（生鲜食品）和零售之间的中介行业。 小売｜こうり⓪零售。 宿泊｜しゅくはく⓪ 注視｜ちゅうし⓪ 11月の有効求人倍率は全国平均で1.25倍で、前の月と同じ水準となり、厚生労働省は「働き方改革の影響で運輸業では求人を増やす動きがあるが、物価高ぶっかだかの影響で建設業や製造業では求人を減らす動きがある」としています。 11 月的有效招聘倍数为全国平均 1.25 倍，和之前的月份保持了相同水准，厚生劳动省正表示：“受到劳动方法改革的影响，虽然出现了运输业招聘增多的动向，不过由于高物价的影响，建造业和制造业出现了招聘减少的动向。” 厚生労働省によりますと、仕事を求めている人1人に対して何人の求人があるかを示す有効求人倍率は、11月、全国平均で1.25倍となり、前の月と同じ水準でした。 据厚生劳动省描述，展示 1 个求职人员有几个招聘岗位的有效招聘倍数，在 11 月为全国平均 1.25 倍，和之前的月份保持了相同的水准。 都道府県別の有効求人倍率を就業しゅうぎょう地別でみると、最も高いのは福井県で1.91倍、次いで、山口県が1.66倍、香川県が1.62倍となりました。 如果按就职地点看各都道府县的有效招聘倍数的化，最高的是福井县有 1.91 倍，之后是山口县的 1.66 倍和香川县的 1.62 倍。 また、最も低いのは北海道で1.05倍で、大阪府で1.07倍、福岡県が1.08倍となりました。 然后，最低的是北海道的 1.05 倍，大阪府的 1.07 倍和福冈县的 1.08 倍。 新規求人を産業別にみると、去年の同じ月に比べて、「運輸業、郵便業」で2.0％、「卸売おろしうり業、小売こうり業」で0.9％増加しました。 如果将新增招聘按产业划分来看的话，和去年的同月相比，运输业和快递业增加了 2.0%，批发和零售业增加了 0.9%。 一方で、「宿泊しゅくはく業、飲食サービス業」で12.2％、「教育、学習支援業」で6.4％の減少となりました。 另一方面，酒店业和餐饮服务业减少了 12.2%，教育和学习支援行业减少了 6.4%。 厚生労働省は「ことし4月から時間外労働の上限規制が始まり働き方改革の影響を受けている運輸業では求人を増やす動きがある。その一方で建設業や製造業では物価高の影響で原材料費が上がり、求人を減らす動きが出ていて、今後の動向に注視ちゅうしが必要だ」とコメントしています。 厚生劳动省表示：“受到今年 4 月开始的对工作时间外的劳动进行限制的劳动方式改革的影响，运输业出现了招聘增多的动向。另一方面建筑业和制造业受到物价上涨的影响，原材料费用增多，出现了招聘减少的动向，今后还需要继续保持关注。”","link":"/2024/12/27/translate_news_nhk_20241227_k10014680161000/"},{"title":"日语翻译 - 新闻 - ChatGPT 手がける「オープンAI」 新たな営利企業が事業主導へ","text":"开发 ChatGPT 的 OpenAI 将以新的盈利企业主导事业 来源：NHK 日期：2024-12-28 08:54 链接：ChatGPT 手がける「オープンAI」 新たな営利企業が事業主導へ 🌟 单词： 統治｜とうち① 巨額｜きょがく⓪ 子会社｜こがいしゃ② 重視｜じゅうし①⓪ 追求｜ついきゅう⓪ 慈善｜じぜん⓪ 存続｜そんぞく⓪ 生成AIのChatGPTを手がけるアメリカの「オープンAI」は、非営利の組織が統治とうちする構造を見直し、新たな営利企業が事業の運営などを主導する方針を明らかにしました。巨額きょがくの資金を集めやすくして開発を加速かそくするねらいです。 着手生成式 AI ChatGPT 的美国公司 OpenAI，重整其由非盈利组织统治的结构，明确了以全新的盈利企业（形象）主导事业的运营。目标是更轻松地筹集巨额资金来加速开发。 オープンAIは2015年に安全なAI開発を目指す非営利の研究機関として設立され、現在は非営利の組織が営利部門の子会社こがいしゃを統治する特殊な構造となっています。 OpenAI 是于 2015 年以安全的 AI 开发作为目标成立的非盈利性质的研究机构，现在的组织结构是：非盈利的组织部分统治盈利部门的子公司的特殊的结构。 オープンAIは27日、非営利の組織に代わって公益こうえき性を重視じゅうしした形の新たな営利企業が、事業の運営などを主導する方針を明らかにしました。 OpenAI 在 27 日明确了：将使用新的、重视公益的盈利企业替代非盈利的组织来主导事业的运行。 これによって株主などの利益を追求ついきゅうするとともに、競合他社と同じように資金を調達できるようになるとしています。 决定通过这种方式追求利益的同时，变得和其他竞争公司一样能够调遣资金。 一方、非営利の組織は健康や科学などの分野での慈善じぜん活動を継続する形で存続するということです。 另一方面，非盈利的组织将以在健康和科学等领域从事慈善活动等形式继续存续下去。 今回の見直しは巨額の資金を集めやすくして開発を加速するねらいで、オープンAIは「使命を果たし続けるためにも、想像していたより多くの資金を調達する必要がある」としています。 本次的重整是以更方便地筹集资金来加速开发为目的的，OpenAI 表示“为了继续完成使命，有必要筹集比想象的更多的资金”。","link":"/2024/12/29/translate_news_nhk_20241228_k10014681701000/"},{"title":"日语翻译 - 新闻 - 学校給食費の全国での無償化 通常国会でも論点に","text":"无偿化全国范围内的学校伙食费，将在通常国会上成为争论焦点 来源：NHK 日期：2024-12-30 04:11 链接：学校給食費の全国での無償化 通常国会でも論点に 🌟 单词： 恩恵｜おんけい⓪ 速やか｜すみやか② 子育｜こそだて⓪ 一律｜いちりつ⓪ 困窮｜こんきゅう⓪ 乏しい｜とぼしい③1. 缺乏，不足，缺少；2. 贫穷，贫乏，贫困。 財源｜ざいげん⓪③ 維新｜いしん① 学校給食費の全国での無償化について、政府は、給食を提供していない学校の子どもに恩恵おんけいが及ばないなど課題は少なくないとして、丁寧に検討を進める方針です。一方、立憲民主党などは速やかすみやかな実施を主張していて、2025年の通常国会こっかいでも論点となりそうです。 就对全国范围的学校伙食费进行无偿化的事情，政府由于无法将恩惠波及到不提供伙食的学校等不少问题，（认为）需要进一步仔细检讨。另一方面，立宪民主党等则主张尽快实施，似乎将在 2025 年的通常国会上作为争论焦点。 学校給食費をめぐり、文部科学省は、子育てこそだて支援や格差対策などの観点から全国での無償化を求める声があるのを踏まえ、課題を整理しました。 围绕学校伙食费，文部科学省基于由于支援孩子养育和价差对策等原因而来自全国的对无偿化的诉求，整理了问题。 この中では、▽給食を提供していない学校に通うケースを含め、給食を食べていない児童じどう・生徒がおよそ61万人いて、一律いちりつに無償化しても、すべての人に恩恵が及ばないと指摘しています。 在这当中，▽ 既有不提供伙食的学校的案例，同时也有大概 61 万不吃学校伙食的儿童、学生，如果一律进行无偿化的话，无法将恩惠波及到所有人。 また、▽生活困窮こんきゅう世帯は基本的にすでに無償化されているため、格差是正ぜせいの観点も乏しいとぼしいのに加え、▽少なくとも4800億円余りの安定財源ざいげんが必要になるなどとしています。 然而，▽ 由于现在对生活贫困的一代基本（已经）完全无偿化，纠正价差的观点也有点站不住脚，▽ 并且最少也需要 4,800 亿日元的稳定的经济来源。 石破総理大臣は「公平性をどう図るかという課題はある。きちんと解決したときに次の段階に移行する」と述べていて、政府としては、一連の課題を踏まえ、丁寧に検討を進める方針です。 石破総理大臣说到：“有如何实现公平性的问题，完全地解决好之后会进入下个阶段”，作为政府，进行的是基于一系列的问题，仔细地持续讨论的方针。 一方、立憲民主党と日本維新いしんの会、国民民主党の3党は、先の臨時国会に、公立の小中学校などの給食費を無償化する法案を共同で提出するなど、速やかな実現を求めていて、2025年の通常国会でも論点になりそうです。 另一方面，立宪民主党、日本维新会和国民民主党三党在之前的临时国会上，共同提出无偿化公立中小学校等的伙食费的法案，并且追求迅速实现，似乎将在 2025 年的通常国会上成为争论焦点。","link":"/2024/12/30/translate_news_nhk_20241230_k10014682481000/"},{"title":"日语翻译 - 新闻 - 次世代の車の競争でカギ握るソフトウエア開発が本格化","text":"作为次世代汽车竞争关键的软件开发被规范化 来源：NHK 日期：2025-01-06 07:46 链接：次世代の車の競争でカギ握るソフトウエア開発が本格化 🌟 单词： 握る｜にぎる⓪ 本格化｜ほんかくか⓪规范化。 燃費｜ねんぴ⓪① エンターテインメント｜えんたーていんめんと⑤(entertainment) 娱乐，演艺，余兴。 搭載｜とうさい⓪ カーナビ｜かーなび⓪(carnavigation) 汽车导航（系统）。 次世代の車の競争でカギを握るにぎるとされる、車の性能をアップデートできるソフトウエアの開発が日本の自動車メーカーの間で本格化しています。 被当作次世代的汽车竞争关键的、能够提升车辆性能的软件开发，正在被日本的汽车制造商们规范化。 車を購入したあともソフトウエアを更新することで、燃費ねんぴ性能や安全機能などを高められる「SDV」＝ソフトウエア・デファインド・ビークルは、次世代の車の競争でカギを握るとされています。 在车辆购入之后，通过更新软件，提升燃料性能和安全功能的 SDV 被作为次世代汽车竞争的关键。 この分野ではアメリカのテスラや中国の新興しんこうメーカーなどが先行し、自動運転から車内のエンターテインメントまで幅広い分野で実用化が始まっています。 在这个领域，美国的特斯拉和中国的新兴制造商率先开始从自动驾驶到娱乐设备、实用化多个领域。 こうした動きに対抗するため、日本メーカーも開発を本格化させていて、トヨタ自動車はことし、車載用の基本ソフトを世界で展開する車に搭載とうさいする計画です。 为了对抗这种行为，日本制造商也将开发正式化，丰田汽车将于今年在世界范围内为车辆搭载基本的车载软件。 この基本ソフトはさまざまな機能を追加できるのが特徴で、まずは生成AIとカーナビを連動させた道案内の機能を導入することにしています。 这个基本的软件拥有能够追加各种各样能力的特征，并且首先决定引入使生成式 AI 和汽车导航联动的指路功能。 また経営統合に向けて本格的な協議に入ったホンダと日産自動車は、ソフトウエアの分野で研究開発機能を一体化して開発力を高めるほか、ホンダは来年から世界で展開する電気自動車に自社開発の基本ソフトを搭載する計画です。 还有为了统合经营二引入规范协议的本田和日产汽车，除了将研究开发功能一体化来提高开发能力，本田还计划从明年开始在射界范围内为电车搭载自己公司研发的基本软件。 このほかスズキも、資本提携を結ぶトヨタやスタートアップ企業とも連携して開発を進めています。 并且铃木也与有资本提携的丰田和创业公司联动（来）推进开发。 ただ、ソフトウエアの開発には巨額の投資が必要なうえ、収益を確保するためにも、より多くの車に搭載する必要があることから、異業種の参入も含めて自動車メーカーの間で競争が激しくなっています。 然后，由于软件的开发需要巨额的投资，为了确保收益，需要在尽量多的汽车商搭载软件，由于有其他行业的参与，汽车制造商之间的竞争也在变得激烈。","link":"/2025/01/06/translate_news_nhk_20250106_k10014685511000/"},{"title":"日语翻译 - 新闻 - AIの半導体開発やデータセンター整備など 日本企業3社が協業へ","text":"在 AI 的半导体开发和数据中心构建等方面，日本的 3 家公司将协作 来源：NHK 日期：2025-01-08 21:49 链接：AIの半導体開発やデータセンター整備など 日本企業3社が協業へ 🌟 单词： 担う｜になう② 合意｜ごうい⓪① 海外勢｜かいがいぜい海外投资者。 AI＝人工知能をめぐる開発が世界で加速する中、半導体メーカーの「ラピダス」など日本の企業3社が、AIの情報処理を担う半導体の開発やデータセンターの整備などで協業していくことで基本合意ごういしたと発表しました。 在全球加速围绕 AI（人工智能）开发的背景下，半导体制造商 Rapidus 等三家日本企业，发布了达成协议今后在负担 AI 信息处理的半导体开发和数据中心构建方面互相协作。 基本合意したのは、▽半導体メーカーの「ラピダス」と▽AI向けの半導体の設計を手がける「プリファードネットワークス」それに、▽データセンターなどを運営する「さくらインターネット」です。 达成协议的是，▽ 半导体的制造商 Rapidus，▽ 从事 AI 方面半导体设计的 Preferred Networks，▽ 运营数据中心的樱花网络。 3社は、AIの情報処理を担う半導体の設計や製造、それにデータセンターの整備などで協業していくとしています。 三家公司决定在负担 AI 信息处理的半导体开发和数据中心构建方面互相协作。 AI＝人工知能の普及に伴って、半導体やデータセンターの需要が拡大する一方、国際情勢の変化に伴う半導体の供給リスクや電力不足の懸念が高まっています。 随着 AI 的普及，一方面对半导体和数据中心的需求扩大，另一方面随着国际形式的变化，半导体供应的风险和对电力不足的担忧也在增长。 3社は、高い情報処理能力を持つ半導体の開発や、省電力のデータセンターの整備など、各社の強みを生かして協業するとしています。 三家公司决定在开发拥有高性能的半导体和构建省电的数据中心方面，发挥各自的优势通力合作。 AIビジネスを支える半導体やデータセンターは、アメリカを中心に海外勢が先行していて、今回の協業が日本の競争力強化につながるか注目されます。 支撑 AI 业务的半导体和数据中心，一直都是以美国为中心，国外走在先列，本次的协作广泛被视作将为日本带来竞争力的增强。","link":"/2025/01/09/translate_news_nhk_20250108_k10014688341000/"},{"title":"日语翻译 - 新闻 -「＜バレー＞日本勝利で会場に『ハイキュー！！』テーマ曲＝中国ファン『次元を超えた』と興奮」","text":"排球比赛中，日本队胜利之后在会场播放《排球少年》的主题曲，中国粉丝兴奋表示：“跨越了次元壁！” 来源：Record China 日期：2024-08-02 15:30 链接：＜バレー＞日本勝利で会場に「ハイキュー！！」テーマ曲＝中国ファン「次元を超えた」と興奮 🌟 单词： 五輪｜ごりん⓪ ネタバレ｜ねたばれ⓪泄露，揭秘，曝光，剧透，预先透露的剧情。 古舘春一氏｜ふるだてはるいち 小柄｜こがら⓪ 身長｜しんちょう⓪ 宮城県｜みやぎけん③ 烏野｜からすの 魅了｜みりょう⓪ 初戦｜しょせん⓪ 投稿｜とうこう⓪ 情熱的｜じょうねつてき⓪ 熱血｜ねっけつ⓪ 大王｜だいおう⓪ エピソード｜えぴそーど①③1. 故事中的插曲，插话；2. 趣闻，轶事，花絮。 最終話｜さいしゅうわ 2024 年 7 月 31 日、パリ五輪バレーボール男子で日本がアルゼンチンに勝利した際、会場でテレビアニメ「ハイキュー！！セカンドシーズン」第 2 クールのテーマ曲「FLY HIGH！！」が流れたことが、中国でも話題になっている。（本記事はネタバレを含みます） 2024 年 7 月 31 日巴黎奥运会排球男子赛上，日本队赢下阿根廷队的时候，会场播放了动漫《排球少年》第二季的主题曲《FLY HIGH！！》的事情，也成为了中国的热点话题。（本报道含有剧透） 「ハイキュー！！」は、古舘春一氏ふるだてはるいちの漫画が原作。体格が小柄こがらな主人公・日向翔陽（ひなたしょうよう）が高校バレーのテレビ中継を見かけた際に低身長ていしんちょうながら活躍する宮城県立烏野からすの高校の選手に魅了され、同校どうこうに進学。天才セッター・影山飛雄（かげやまとびお）ら烏野高校のバレー部員と共に全国大会を目指す日々を描く物語。 《排球少年》的原作是古馆春一的漫画，描述了：体格较小的主人公日向翔阳在看高效排球赛的电视转播时，被矮个子却十分活跃的宫城县立乌野高校的选手所吸引，进入了同样的学校就读，之后和天才选手影山飞雄等乌野高校的排球队员一起以参加全国大赛为目标的日常故事。 中国の SNS・微博（ウェイボー）で約 44 万人のフォロワーを持つブロガーは、「日本が初戦でアルゼンチンに勝利した後、会場では『ハイキュー！！』の曲『FLY HIGH！！』が流れた。本当に鳥肌が立った」と投稿とうこう。すると、中国のファンからは「情熱的じょうねつてき！！」「本当に泣きそうだああ」「なんてことだああああ、夢のようだ！」「昨日見て興奮こうふんしすぎて死にそうだった」「うわあ…次元を超えた感じ。音楽が流れた瞬間、鳥肌が立ちまくった」「熱血度 × 80％ の勝利後に『ハイキュー！！」の音楽が流れたら、熱血度 × 1000000％」などと、コメントが集まった。 在中国微博上拥有 44 万粉丝的博主，发了博文：“日本初战对阵阿根廷胜利后，会场播放了《排球少年的》的 BGM《FLY HIGH！！》，真的鸡皮疙瘩都起来了！”。之后，中国的粉丝们陆续评论：“激动！”、“感动得快要哭了啊啊”、”我的天啊，简直像梦一样！“、”昨天看到快激动死了！“、”哇！感觉跨越了次元，音乐播放的时候鸡皮疙瘩都起来了。“、”本来热血度只有 80%，胜利后放了《排球少年》的音乐，热血度 1000000％“。 また、「（敵チームのキャラクターである）及川徹（おいかわとおる）がアルゼンチンチームにいるように見えるからこそ、より興奮する！」「本当に次元の壁が破れた。漫画では、日向と影山が日本代表としてオリンピックに出場し、反対コートには大王（及川）がいる」などと、原作漫画の最終話にて日向や影山が東京五輪に日本代表として出場し、アルゼンチンに帰化した及川と対戦したエピソードと重ねるファンも見られた。 然后，“正是因为及川徹（对方队伍的角色）看起来像是阿根廷队的一员，更加兴奋了！”、“真的打破了次元壁，在漫画中日向和影山代表日本参加了奥运会，对手就是及川。”等待，在原作漫画的最终话，日向和影山代表日本参加东京奥运会，与加入阿根廷籍的及川进行对战队的故事也被粉丝们看到了。","link":"/2024/08/08/translate_news_record_china_b938130-s25-c50-d0201/"},{"title":"日语翻译 - 公司简讯 - 【佐川急便】2024 年 7 月　自治体との協定締結のお知らせ　「包括連携協定」2 件、「災害協定」4 件","text":"【佐川急便】2024 年 7 月与地方政府签订协定的通知：《总体合作协定》2 件、《灾害协定》4 件 来源：SG 日期：2024-08-08 链接：【佐川急便】2024年7月 自治体との協定締結のお知らせ 「包括連携協定」2件、「災害協定」4件 🌟 单词： 締結｜ていけつ⓪指国家签订条约和协定等，缔结。 包括｜ほうかつ⓪ インフラ｜いんふら⓪(infrastructure) 基本建设，基础设施形成生产或生活基础的构筑物。 ノウハウ｜のうはう①(know-how) 技能，本事，窍门。 双方｜そうほう①双方，两方。 定める｜さだめる③1. 决定，选定；2. 规定，制定；3. 平定，平静，放松；4. 平定，镇定；5. 奠定。 ニュースリリース 新闻发布 ＳＧホールディングスグループの佐川急便株式会社は、自治体と「包括連携協定」を2件、「災害協定」を4件締結しましたのでお知らせします。 SG 控股集团的佐川急便有限公司，就与地方政府签订了 2 条《总体合作协定》、4 条《灾害协定》的事情进行通知。 佐川急便は、社会インフラを担うになう企業として佐川急便で保有するリソースやノウハウを活用し、地域経済の活性化や持続可能な社会の実現に向けた活動を積極的に取り組んでいます。その一環いっかんとして、自治体と佐川急便が双方の強みやリソースを生かし、さまざまな連携事業を推進する中で課題解決を目指す「包括連携協定」や、災害発生時における支援物資の管理や輸配送等の支援について定めた「災害協定」を締結しています。また、官民かんみん一体となって地域課題に取り組む「ＳＡＧＡＷＡタウンサポート※」を全国の自治体へ展開しています。 佐川急便作为承担了社会基础建设的企业，活用所拥有的资源和本领，积极地投身于活跃地方经济和实现可持续发展的社会。作为其中的一环，签订了能使地方政府和佐川急便使双方的强项和资源发挥作用、推进各种各样的合作事业中的“致力于问题解决的《总体合作协定》”和“规定灾害发生时期救援物资的管理和运输配送等的《灾害协定》”。并且，将官民一体致力于解决地区问题的“SAGAWA 城市支持”想全国的地方政府进行开展。 今後も佐川急便は、自治体と連携することで、多様なサービスの創出そうしゅつ、持続可能な暮らしやすいまちづくりと地域活性化を目指し、社会的課題の解決・改善に取り組んでまいります。 今后、佐川急便也会通过和地方整合合作，创造出多样的服务，以创造出可持续发展且适合生活的城市和活跃地区作为目标、致力于解决和改善社会的问题。","link":"/2024/08/29/translate_newsrelease_detail_2024_0808_2294/"},{"title":"日语翻译 - 影评 - 「葬送のフリーレン（TVアニメ動画）」（第一部分）","text":"《葬送的芙莉莲》的影评 By take_0(ゼロ) 来源：あにこれ 作者：take_0(ゼロ) 日期：2024-07-31 链接：「葬送のフリーレン（TVアニメ動画）」 🌟 单词： なじみ深い｜なじみぶかい⑤熟悉 優越感｜ゆうえつかん④ ちらほら｜ちらほら①1. 星星点点地，稀稀落落地这里那里都有一点的样子；2. 不时地渐渐地时时发生状。 仄々｜ほのぼの③1. 温暖；2. 朦胧，模糊，隐约。 冷める｜さめる②1. 变冷，凉；2. 降低，减退。 厳か｜おごそか②庄严，严肃，肃穆，庄重，郑重威严。 フラット｜ふらっと②(flat) 平的，平坦的。 味気ない｜あじきない④乏味，没意思，无聊是「あじけない」较陈旧的说法。 矛盾｜むじゅん⓪ 緻密｜ちみつ⓪ 知己｜ちき①② 富む｜とむ① 途轍もない｜とてつもない⑤ 異名｜いみょう⓪ 語る｜かたる⓪ 曰く｜いわく⓪① 葬り去る｜ほうむりさる 見事｜みごと①1. 美丽，好看；2. 漂亮，卓越，地道，精彩，巧妙；3. 完全，彻底。 アニメ化の発表の際から話題になっていた作品。原作も追っているので、個人的には連載当初から知っているので、気持ちの上ではなじみ深くなじみぶかく、なんなら「最初から知っているんだぜ」的な優越感もちらほら。 《葬送的芙莉莲》是从动画化的发表开始就成为了话题的作品。因为我之前就在追原作漫画，并且还是从连载初期就知道这部作品的，很熟悉，甚至有“我从一开始就知道”的优越感。 原作での、ほのぼのというか、のんびりというか、どこか冷めたさめた感じといおうか、厳かおごそかささえ感じるフラットな感じといおうか、何となく感じるあたたかさといおうか、 原作的那种温暖、那种悠闲、那种有些冷淡的感觉、那种连庄严都能感觉到的安稳的感觉、总觉得有些温暖的感觉、 なんとも言えない、作品の持つ独特の雰囲気をアニメ作品の中で上手くうまく表現できていたと思う。「味気ないとか淡々としている」と受け止める人が居ても仕方ないとは思う。 不知道怎么说，我认为在动画作品中很好地表现了作品具有的独特氛围。即使有觉得“平淡无味”的人那也没办法。 個人的感想として、あえて、矛盾したことを言わせてもらえれば・・・ 作为个人的感想，如果非要让我说写自我矛盾的话： 「おもしろいのか、おもしろくないのか解らないぐらい、おもしろい」 “到了不知道作品有趣还是无趣的地步，这本身就很有趣。” さらに言えば、 更进一步说： 「おもしろいのかどうかも、よくわかってはいない」 “也不知道是否有趣。” アホな感想で申し訳ない。 很抱歉，有这种笨蛋想法。 なので、他のレビュワーさんの様に緻密ちみつな分析も、知己ちきに富んだとんだ考察もできはしないのだけれども、上の☆評価でとてつもない魅力を持つ作品であることは評価しておきたい。 因此，虽然不能像其他的评论家一样进行细致的分析、或是富有见解地考察，但还是想通过上面的 ☆ 评价这是部具有巨大魅力的作品。 作品中でフリーレンの異名について魔物の口から語られ、タイトル回収された場面があった。 作品中关于芙莉莲的外号，有从魔物的口中说出，回收标题的场面。 曰くいわく「歴史上で最も多くの魔族を葬り去ったほうむりさった魔法使い。葬送のフリーレン。私の嫌いな天才だ」 说到：“历史上消灭魔族最多的魔法使。葬送的芙莉莲。我讨厌的天才。” なるほど、見事なタイトル回収。 原来如此，近乎完美的标题回收。 下一部分：日语翻译 - 影评 - 「葬送のフリーレン（TVアニメ動画）」（第二部分）","link":"/2024/08/13/translate_review_14239_01_01/"},{"title":"日语翻译 - 影评 - 「葬送のフリーレン（TVアニメ動画）」（第二部分）","text":"《葬送的芙莉莲》的影评 By take_0(ゼロ) 来源：あにこれ 作者：take_0(ゼロ) 日期：2024-07-31 链接：「葬送のフリーレン（TVアニメ動画）」 上一部分：日语翻译 - 影评 - 「葬送のフリーレン（TVアニメ動画）」（第一部分） 🌟 单词： 数多｜あまた① 数多く｜かずおおく③ 類似｜るいじ⓪ 死者｜ししゃ①② 弔う｜とむらう③1. 吊丧，吊唁吊慰；2. 祭奠，祭祀，为死者祈冥福。 少なからず｜すくなからず④⑤1. 很多，不少，不小，非常；2. 经常。 受け止める｜うけとめる④⓪1. 接住，挡住；2. 阻止，防止，阻击；3. 理解，认识。 強引｜ごういん⓪1. 强行；强制；硬干，蛮干。 巫山戯る｜ふざける③ でもね、私の個人的な所感では、やはり別の意味もあるのだと信じています。 但是啊，我个人的感受，相信（葬送的芙莉莲的标题）应该是别的意义的。 よく言われますが、 人们常说： 「人は肉体的に死んでも覚えていてくれる人がいる限り、決して死ぬことは無い・・・」 “人虽然肉体上死亡了，但是只要还有记着他们的人，就绝对还没有逝去……” 数多あまたの作品の中で類似るいじの事が言われています。そして、これは事実であり、多くの人にとっての希望でもあります。 众多的作品中都讲了类似的事。然后，这（不仅）是事实，对于很多人来说也是希望。 「葬送」とは死者ししゃと最後の別れをし、送り出すことの意だそうです。 “葬送”看起来表示：和死者做最好的告别，送走他们这件事。 文字通り数多くの魔物を倒し、彼の地へ送り出したという意味とバッチリ一致します、ぐうの音も出ません。 像文字描述的“打倒数量众多的魔物、把他们送回自己该在地方”的意思完全一致，毫无疑问。 ですが、死者を弔うとむらうという意味も少なからず持っているように私は受け止めています。(強引ごういんですねｗ勝手に自分の解釈にもっていきますｗ) 因此，在我看来，也有不少悼念死者的意思。（有点牵强 😂 擅作主张地带着自己的解释 😂） そして、フリーレンのこの物語の中ではヒンメルをはじめ、ハイター、そして今はまだ生せいあるものの、フリーレンの命の長さを考えれば、必ず別れが訪れるおとずれる者たちが多く登場します。 然后，芙莉莲的这个故事以辛美尔为首、海塔、还有虽然现在还活着，但是考虑到芙莉莲生命的长度，一定会迎来离别的角色。 きっと人を知りたいと思ったその日からの、様々な出会いをフリーレンは記憶し、語ってかたっていくことになるのでしょう。それは、出会った人を弔いながらも、生かし続けていくことに他なりません。 芙莉莲一定会记住从想要了解他人的那天开始的、各种各样的相遇，并将这些流传下去。这就是一遍悼念相遇的人、一边延续他们的生命。 今の物語の中で、私たちがヒンメルを、カッコイイと思ったり、優しいと思ったり、いい奴と思ったり、ふざけた奴と思ったりしていることで証明されています。あたかも、生きているのと同じように心を動かされているのです。 在现在的故事中，我们认为欣梅尔是一个很酷的家伙，一个很善良的家伙，一个很好的家伙，一个很顽皮的家伙，这些都证明了这一点。就像他们还活着一样而被感动了。 下一部分：日语翻译 - 影评 - 「葬送のフリーレン（TVアニメ動画）」（第三部分）","link":"/2024/08/18/translate_review_14239_01_02/"},{"title":"日语翻译 - 影评 - 「葬送のフリーレン（TVアニメ動画）」（第三部分）","text":"《葬送的芙莉莲》的影评 By take_0(ゼロ) 来源：あにこれ 作者：take_0(ゼロ) 日期：2024-07-31 链接：「葬送のフリーレン（TVアニメ動画）」 上一部分：日语翻译 - 影评 - 「葬送のフリーレン（TVアニメ動画）」（第二部分） 🌟 单词： 物悲しい｜ものがなしい⓪⑤悲伤的，悲哀的。 可哀想｜かわいそう④令人同情的，令人怜悯的，招人同情的。 銀河｜ぎんが① ポエミー｜ぽえみー诗篇 素直｜すなお① 力量｜りきりょう⓪ 稀有｜けう① 気になる｜きになる③1. 挂心，担心，惦记，挂念，在意；2. 产生兴趣，有意，想要。 「ヒンメルならそうした・・・」 “如果是辛美尔的话会这么做……” 死して尚なお、人を動かす力を持つ人は、生きている人以上です。 虽然已经去世了，但是还有打动人的力量的人，那么就还活着。 きっとフリーレンは今作こんさくや、続く物語の中でのエピソードが終わった後も長くそうした世界を生きていくのだと想像したとき、少し物悲しく、少し可哀そうで、少し羨ましく思いましたｗ。 当我想象“芙莉莲在现在的作品中、或接下来的故事中的小插曲结束后，一定还会在那个世界活很久。”，有点悲伤、有点同情，又有点羡慕 😂。 そうした中、永遠えいえんの時の中を生き続ける女性に既に出会っていたことを思い出しました。(もちろんアニメの中での話です) 在这过程中，我想起了与还永远活在时间里的女性的相遇。（当时是动漫里的。） 私が少年だったころ、鉄道で旅をした(気になっていた)メーテルという女性ですｗ。あの「銀河鉄道999」の中で、既に永遠の時間の中で生きていく辛さや悲しみ、希望というものをみていたような気がしています。 我还是少年的时候，遇见的是通过铁路旅行的梅黛儿 😂。在《银河铁道 999》中，我似乎已经看到了在永恒的时间中活下去的辛酸、悲伤和希望。 あの時・・・ 那个时候…… 「・・・・・そして 少年は大人になる。」のナレーションと共に大人になったオッサンが、今再び、似たような感覚を覚えてしまいました。 “然后，少年成长为男人。”和这旁白一起成为大人的大叔，现在，又产生了相似的感觉。 「そして、おっさんはフリーレント共に再び旅に出る・・・」そんな気にさせてくれるアニメでした。 “然后，大叔和芙莉莲一起再次启程。”《葬送的芙莉莲》是让我感受到这样感觉的动漫。 いや～～～、だいぶ気持ち悪いっすねェｗこんなポエミーなレビューｗ。 不！好恶心啊 😂这种诗一样的评论 😂 とは言え、思った事は素直に書いておきたいので書いておきます。 不过，（只是）因为想把想到的事不隐晦地写出来所以写了。 作品の持つ雰囲気、製作側の力の入れよう、作品の持つ力量りきりょうと投入されるリソースが高い次元で完成した稀有けうな作品であると思います。 我认为《葬送的芙莉莲》是一部作品所具有的氛围、制作方的投入、作品所具有的力量和投入的资源都在很高的层次上完成的稀有作品。 当然、続きも気になるところですが。 当然，我也会继续关注。 続きが作成されれば、機会を作って是非とも視聴したい作品です。 如果有续作的话，是一定要找机会看的作品。 素晴らしい稀有な雰囲気、魅力をもった作品と評価をいたします。 我评价它是非常优秀的、稀有的、带有独特气氛和魅力的作品。","link":"/2024/08/20/translate_review_14239_01_03/"},{"title":"日语翻译 - 杂志文章 -【子どものタイプ別勉強法】人によって違う脳タイプを知って伸ばすことから始める（第一部分）","text":"【根据孩子的类型而定的学习法】从知晓各人的大脑类型不同并发展它们开始…… 来源：Fujisan.co.jp 日期：2024-06-05 链接：【子どものタイプ別勉強法】人によって違う脳タイプを知って伸ばすことから始める 🌟 单词： 我武者羅｜がむしゃら⓪冒失，鲁莽；不顾前后；有勇无谋。 促す｜うながす⓪③ 内科医｜ないかい 度合｜どあい⓪程度。 神経｜しんけい① 細胞｜さいぼう⓪ 形成｜けいせい⓪ 系統｜けいとう⓪ 伝達｜でんたつ⓪ 聴覚｜ちょうかく①⓪ 漠然｜ばくぜん⓪含混，模糊；笼统；暧昧。 ヒント｜ひんと①(hint) 暗示，启发，启示，提示。 働き出す｜はたらきだす开始工作。 🌟 惯用/短句： とは言え｜とはいえ虽说……可是…… ともいわれる据说，听说。 脳は、人によってタイプが違うって、知っていましたか？そして、そのタイプごとに、適したてきした勉強法は変わってくるのです。逆に、脳のタイプに合わない勉強法だと、やればやるほど勉強嫌いになる可能性も。お子さんの脳に合った勉強法を教えてもらいました。 各人的大脑类型不同，你知道吗？然后根据大脑类型不同，适合的学习法也会改变。反之、使用和大脑类型不同的学习法的话，做得越多越有可能变得讨厌学习。它们（上述概念）教会了我适合孩子大脑的学习法。 成績を上げるためにはガムシャラ冒失，鲁莽；不顾前后；有勇无谋。に勉強する必要がある。そう考える人もたくさんいることでしょう。 为了提升成绩必须一个劲地学习。这么想的人有很多吧。 たしかに実際問題として入試でよい点数を取るためには、きちんとテスト勉強をしないといけません。とはいえそこに至るまで、たとえば小学生のうちなら、まずは脳そのものを成長させることがより大事だと考えています。子供たちの脳は、ものすごいスピードで成長していきます。その成長をさらに促すために取るべきトレーニングというものもあります。 确实作为实际问题，为了在入学考试上取得好的成绩，不认认真真应试学习是不行的。话虽如此，在此之前，例如在小学生中，我认为首先最重要的事情是让大脑本身成长。孩子们的大脑，会以惊人的速度成长。还有一些培训可以进一步促进这种成长。 私は脳内科医として、30 年以上も人の脳を見てきました。脳には、その人の経験が記憶されており、次にどうしたらよいかを選ぶためのヒントがあります。つまり、脳は人によって発達の度合いやタイプが違うのです。脳には個性があるのです。その個性に合わせた脳のトレーニングがあり、個性に合わせた勉強法があります。 我作为脑内科医生，看了 30 年以上的人脑。大脑会记录着一个人的经历，并提示我们选择下一步该怎么做。也就是说，脑子因为人不同发达程度和类型也都不同。大脑是有个性的。 個性に合わせた勉強法の話の前に、脳について少し説明しましょう。 在讲适合个性的学习法之前，让我简单介绍一下大脑。 人間の脳には 1,000 億個を超えるともいわれる神経細胞があり、「見る」「聞く」「体を動かす」など同じうな働きをする神経細胞ごとに集団を形成しています。その神経細胞群を私は「脳番地」と呼んでいます。人間の脳全体では 120 もの脳番地がありますが、私はその中で似たような働きを持つ脳番地をまとめて、八つの代表的系統に分類しています。 人类的大脑里据说有超过 1,000 亿个神经细胞，神经细胞按照“看”、“听”、“动”等行动的功能形成集团。我称那样的神经细胞群为“脑领域”。虽然人类的大脑里有 120 个“脑领域”，但是我汇总其中有相似功能的，分类了 8 个有代表性的系统。 思考や判断に関係する「思考系脳番地」、感性や社会性に関係する「感情系脳番地」、話したり伝えたりすることに関係する「伝達系脳番地」、体を動かすことに関係する「運動系脳番地」、耳で聞くことに関係する「聴覚系脳番地」、目で見ることに関係する「視覚系脳番地」、物事や言葉を理解するのに関係する「理解系脳番地」、覚えたり思い出したりすることに関係する「記憶系脳番地」です。 （分别是）关乎思考和判断的“思考系脑领域”、关乎感性和社会性的“感情系脑领域”、关于说话和表达的“传达系脑领域”、关乎运动的“运动系脑领域”、关于听的“听觉系脑领域”、关乎看的“视觉系脑领域”、关于理解事物和语言的“理解系脑领域”、关于记忆和回忆的“记忆系脑领域”。 この中で、小学生のうちに主に発達していくのは、「伝達系」「運動系」「聴覚系」「視覚系」の四つです。この四つが活発に働き出すことで、ほかの「思考系」「感情系」「理解系」「記憶系」も発達していきます。そこで、まずはベースとなる四つを成長させることに注力したいものです。 在这其中，在小学生阶段主要发达的“传达系”、“运动系”、“听觉系”和“视觉系”四个脑领域。通过这四个活跃工作，会让剩下的“思考系”、“感情系”、“理解系”和“记忆系”也变发达。因此，我想首先需要助力让作为基础的四个脑领域成长。 脳番地には、それぞれ伸ばすべき方法があります。漠然と脳トレをするのではなく、脳番地ごとにトレーニングをすることで、理想の脳へと近づけることができます。 有各种各样的方法让脑领域成长。不能模糊地进行大脑训练，（只有）通过根据脑领域不同进行针对训练，才能使其接近理想的大脑。","link":"/2024/08/12/translate_zasshi_bunsyou_%E5%AD%90%E3%81%A9%E3%82%82%E3%81%AE%E3%82%BF%E3%82%A4%E3%83%97%E5%88%A5%E5%8B%89%E5%BC%B7%E6%B3%95/"},{"title":"为 Twikoo 静态网站评论系统配置邮件通知功能（使用 Mailgun 的免费发信额度）","text":"前言虽然早早配置了 Twikoo 评论系统，但是一直没有配置邮件通知功能。今天翻了下之前的文章检查错误的时候，偶然发现了用户一个月前的留言 🤦 虽然回复了但是恐怕帮不到他了，加个评论通知功能防止再发生一样的问题吧。 方案概述 注册 Mailgun 账号并绑定域名 获取 Mailgun 的 SMTP 信息 配置 Twikoo 评论系统的邮件通知功能 测试邮件通知功能是否正常 设置 Mailgun 的发信上限 操作步骤一、注册 Mailgun 账号并绑定域名官方网址：Mailgun查看价格可以看到 Mailgun 提供了免费的、每天 100 封邮件的发信额度，对于个人博客来说绰绰有余： 需要注意的是，免费额度需要绑定信用卡，如果你没有信用卡的话，可以在这里创建：WildCard并且我推荐虚拟信用卡的还有一个原因是可以很好地控制限额，避免被刷后的损失。 注册完账号后，我们需要绑定域名，这里我绑定的是我的博客域名 senjianlu.com，具体操作如下： 之后按照给定的 DNS 信息验证域名即可： 点击右上角的 Verify 按钮，等待验证通过即可： 二、获取 Mailgun 的 SMTP 信息该域名发信的 SMTP 在 Send -&gt; Sending -&gt; Domains 中的对应域名下：进入域名相关页后，再点击 SMTP credentials 即可查看到 SMTP 的相关信息，默认创建了一个 postmaster 用户：点击 Reset Password 重置并保存密码，就得到完成的 SMTP 信息了： SMTP Server: smtp.mailgun.org SMTP Port: 587 SMTP Username: postmaster@senjianlu.com SMTP Password: aaaaabbbbbbbbbb-ccdd-eexxxxxxx 使用 Python 写个 Demo 测试下是否可以正常发信： 1234567891011121314151617181920212223242526272829303132import smtplibfrom email.mime.text import MIMETextfrom email.header import Header# 邮件内容msg = MIMEText('Hello, this is a test email.', 'plain', 'utf-8')msg['Subject'] = Header('这是一封内部测试邮件', 'utf-8')# 为了符合 Google 新的安全策略，发信方和收信方必须是同一个域名下的邮箱msg['From'] = 'postmaster@senjianlu.com'msg['To'] = '测试邮件接收者'# 发信方信息subject = 'Test Email'smtp_server = 'smtp.mailgun.org'smtp_port = 587smtp_user = 'postmaster@senjianlu.com'smtp_password = 'aaaaabbbbbbbbbb-ccdd-eexxxxxxx'# 收信方信息to_addrs = ['test@gmail.com', 'test@163.com', 'test@qq.com']# 发信try: server = smtplib.SMTP(smtp_server, smtp_port) server.starttls() server.login(smtp_user, smtp_password) server.sendmail(smtp_user, to_addrs, msg.as_string()) print('Send email successfully.')except Exception as e: print('Failed to send email:', e)finally: server.quit() 这里请使用尽量多个邮件接收者。无论如何，我们在这一步只需要确定 Mailgun 的 SMTP 信息是正确的即可。 确定信息正确，收到邮件后即可开始下一步： 三、配置 Twikoo 评论系统的邮件通知功能进入博客评论模块，点击右上角的设置图标：选择配置管理：配置邮件通知：之后保存即可。可以发送邮件测试一下： 四、测试邮件通知功能是否正常1、配置管理员邮箱当其他用户评论时，管理员邮箱会收到邮件通知： 2、测试用户发布评论 3、测试回复评论 五、设置 Mailgun 的发信上限在 Mailgun 的控制台选择 Manage Account：Account details之后设置 Custom Message Limit：值是单月的发信上限，可以根据自己的需求设置：最小值是 1000，我这里就设置了 1000。 结束。","link":"/2024/11/10/twikoo_mailgun_smtp/"},{"title":"Ubuntu 20.04 从官方源安装最新的 Docker","text":"前言Ubunut 20.04 默认 apt 中的 Docker 版本过旧，不支持部分特性。因此在整体构建环境时都倾向于从官方源安装最新的 Docker。记录一下各命令。 操作步骤1、更新 apt 包索引1sudo apt-get update 2、安装必备的软件包以允许 apt 通过 HTTPS 使用存储库： 1sudo apt-get install ca-certificates curl gnupg lsb-release 3、添加 Docker 官方版本库的 GPG 密钥12sudo mkdir -p /etc/apt/keyringscurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg 4、设置存储库1echo &quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null 5、安装 Docker12sudo apt-get updatesudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin 6、检查下 Docker 版本1docker -v 版本高于直接安装的 Docker： 12sudo apt updatesudo apt install docker.io docker-compose 结束。","link":"/2024/09/13/ubuntu2004_docker_latest/"},{"title":"Ubuntu 20.04 下部署 Zabbix Agent 2","text":"前言记录一下各命令。 操作步骤参考：Download and install Zabbix 一、引入 Zabbix 源123wget https://repo.zabbix.com/zabbix/6.4/ubuntu/pool/main/z/zabbix-release/zabbix-release_6.4-1+ubuntu20.04_all.debdpkg -i zabbix-release_6.4-1+ubuntu20.04_all.debapt update 二、安装 Zabnbix Agent 21apt install zabbix-agent2 zabbix-agent2-plugin-* 如果出现 zabbix-agent2 : Depends: libssl1.1 (&gt;= 1.1.1) but it is not installabl 错误，大概率是你系统版本不对，请前往 Download and install Zabbix 选择对应系统版本的源再安装一次。 三、修改配置文件1vi /etc/zabbix/zabbix_agent2.conf 为 Server 和 ServerActive 添加 Zabbix Server 的外网 IP 或内网 IP： 123Server=127.0.0.1, 1.2.3.4, 10.10.10.1ServerActive=127.0.0.1, 1.2.3.4, 10.10.10.1 四、重启 Zabbix Agent2123systemctl restart zabbix-agent2# 设置开机启动systemctl enable zabbix-agent2","link":"/2024/09/26/ubuntu2004_zabbix_agent/"},{"title":"Ubuntu 24.04 下安装桌面环境并进行远程连接","text":"前言想在 Ubuntu 24.04 服务器上安装下 Steam，但是似乎需要图形化界面。而由于一般云服务器厂商都是提供的 server 版本，因此需要安装下桌面环境。 方案概述 安装 X Window System 安装 GNOME 的显示管理器 gdm3 安装 Ubuntu 桌面 安装 GNOME 依赖包 安装 Xrdp 服务 进行远程连接 操作步骤一、安装 X Window System 关于 X Window System： X 窗口系统（X Window System，也常称为 X11 或 X，天窗口系统）是一种以位图方式显示的软件窗口系统。最初是 1984 年麻省理工学院的研究，之后变成 UNIX、类 UNIX、以及 OpenVMS 等操作系统所一致适用的标准化软件工具包及显示架构的运作协议。 123sudo susudo apt updateapt-get install -y x-window-system-core 二、安装 GNOME 的显示管理器 gdm3 关于 gdm3： gdm3 是 GNOME 显示管理器 (GNOME Display Manager) 的缩写，它是 GNOME 桌面环境的默认显示管理器，负责提供图形化的登录界面，并在用户成功验证后启动GNOME 会话。 1apt-get install -y gdm3 出现下面错误的时候不要紧张： gdm.service is not active, cannot reload. 之后重启就能解决这个问题。 三、安装 Ubuntu 桌面1apt-get install -y ubuntu-desktop 四、安装 GNOME 依赖包1apt-get install -y gnome-panel gnome-settings-daemon metacity nautilus gnome-terminal 五、安装 Xrdp 服务安装： 12sudo apt updatesudo apt install xrdp 启动： 12sudo systemctl start xrdpsudo systemctl enable xrdp 之后重启： 1reboot 六、进行远程连接我是 Mac 系统，因此使用的是 Microsoft Remote Desktop 进行远程连接。之后还需要按照提示配置下桌面：看一眼监控，在什么都没运行的情况下，CPU 和内存就已经占用超过一半了：后续再升级配置吧，总之算是成功了。 如果在后续的登陆中，出现下面的错误的话： Sorry, password authentication didn’t work. Please try again. 则需要修改下 /etc/pam.d/gdm-autologin 和 /etc/pam.d/gdm-password 文件： 1vi /etc/pam.d/gdm-autologin 12# 注释掉下面这行# auth requied pam_succeed_if.so user != root quiet success 1vi /etc/pam.d/gdm-password 12# 注释掉下面这行# auth requied pam_succeed_if.so user != root quiet success 参考资料： Linux：腾讯云轻量应用服务器搭建Ubuntu图形界面并配置远程连接","link":"/2025/08/30/ubuntu2404_install_desktop_and_vnc/"},{"title":"搭建 VMess + WebSocket + TLS 节点并通过 Nginx 进行伪装分流","text":"前言久违地接触点新事物，尝试使用 acme 申请 TLS 证书，搭建一个 VMess + WebSocket + TLS + Web 的节点。 方案概述 域名解析到对应的节点服务器上。 使用官方的安装脚本安装 V2Ray。 使用 acme 申请 TLS 证书。 配置 VMess + WebSocket + TLS 节点。 通过 Nginx 建立伪装网站。 操作步骤一、域名解析前往域名托管处操作。 二、安装 V2Ray官方脚本仓库：v2fly/fhs-install-v2ray运行脚本后，不需要进行任何其他操作，V2Ray 在安装后也不会启动： 1bash &lt;(curl -L https://raw.githubusercontent.com/v2fly/fhs-install-v2ray/master/install-release.sh) 三、申请 SSL 证书1234567891011# 安装所需软件apt-get install curlapt-get install socat# 安装 acmecurl https://get.acme.sh | sh# 添加软链接ln -s /root/.acme.sh/acme.sh /usr/local/bin/acme.sh# 切换 CA 机构acme.sh --set-default-ca --server letsencrypt# 申请证书acme.sh --issue -d $your_domain --standalone -k ec-256 确保你在 V2Ray 安装完成后再进行下一步证书安装过程，否则你没有 /usr/local/etc/v2ray 这个目录： 12# 安装证书acme.sh --install-cert -d $your_domain --ecc --key-file /usr/local/etc/v2ray/server.key --fullchain-file /usr/local/etc/v2ray/server.crt --reloadcmd &quot;systemctl restart v2ray&quot; 四、配置 VMess + WebSocket + TLS 节点需要更新的配置文件为 /usr/local/etc/v2ray/config.json： 1vi /usr/local/etc/v2ray/config.json 配置文件参考： 节点服务在 18388 端口 只监听来自 127.0.0.1 的请求 用户 ID 为 UUID 形式，最好通过 v2ray uuid 命令重新生成。 节点路径为 /download，后续会被 Nginx 分流。 1234567891011121314151617181920212223242526272829303132{ &quot;log&quot;: { &quot;loglevel&quot;: &quot;warning&quot; }, &quot;inbounds&quot;: [ { &quot;port&quot;: 18388, &quot;listen&quot;:&quot;127.0.0.1&quot;, &quot;protocol&quot;: &quot;vmess&quot;, &quot;settings&quot;: { &quot;clients&quot;: [ { &quot;id&quot;: &quot;76a9f1b5-2fe2-4715-ba0d-e4b0d66ae30e&quot;, &quot;alterId&quot;: 64 } ] }, &quot;streamSettings&quot;: { &quot;network&quot;: &quot;ws&quot;, &quot;wsSettings&quot;: { &quot;path&quot;: &quot;/download&quot; } } } ], &quot;outbounds&quot;: [ { &quot;protocol&quot;: &quot;freedom&quot;, &quot;settings&quot;: {} } ]} 如果你不想分流的只想搭建一个简单的 TCP + TLS 节点的话，可以使用下面的配置： 12345678910111213141516171819202122232425262728293031323334353637{ &quot;log&quot;: { &quot;loglevel&quot;: &quot;warning&quot; }, &quot;inbounds&quot;: [ { &quot;port&quot;: 8443, &quot;protocol&quot;: &quot;vmess&quot;, &quot;settings&quot;: { &quot;clients&quot;: [ { &quot;id&quot;: &quot;76a9f1b5-2fe2-4715-ba0d-e4b0d66ae30e&quot;, &quot;alterId&quot;: 64 } ] }, &quot;streamSettings&quot;: { &quot;network&quot;: &quot;tcp&quot;, &quot;security&quot;: &quot;tls&quot;, &quot;tlsSettings&quot;: { &quot;certificates&quot;: [ { &quot;certificateFile&quot;: &quot;/usr/local/etc/v2ray/server.crt&quot;, &quot;keyFile&quot;: &quot;/usr/local/etc/v2ray/server.key&quot; } ] } } } ], &quot;outbounds&quot;: [ { &quot;protocol&quot;: &quot;freedom&quot;, &quot;settings&quot;: {} } ]} 客户端配置，以 Surge 为例： 修改完配置，重启下服务： 12systemctl daemon-reloadsystemctl restart v2ray 如果启动失败的话，需要修改下 v2ray.service 的启动用户： 1vi /etc/systemd/system/v2ray.service 从 nobody 修改为 root： 1234...[Service]User=root... 参考：systemctl 启动v2ray 失败，命令行启动正常。。。 五、通过 Nginx 进行伪装、分流没有 Nginx 的话先安装： 1apt-get install nginx Nginx 的配置文件编辑 /etc/nginx/nginx.conf 即可： 1vi /etc/nginx/nginx.conf 在 http 配置段内增加： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152server { listen 80; # 修改为你的域名 server_name $your_domain; rewrite ^(.*)$ https://${server_name}$1 permanent;}server { listen 443 ssl; listen [::]:443 ssl; # 修改为你的域名 server_name $your_domain; ssl_certificate /usr/local/etc/v2ray/server.crt; ssl_certificate_key /usr/local/etc/v2ray/server.key; ssl_session_timeout 1d; ssl_session_cache shared:MozSSL:10m; ssl_session_tickets off; ssl_protocols TLSv1.2 TLSv1.3; ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384; ssl_prefer_server_ciphers off; # 伪装网址 location / { proxy_pass https://www.hostloc.com; proxy_ssl_server_name on; proxy_redirect off; sub_filter_once off; sub_filter &quot;www.hostloc.com&quot; $server_name; proxy_set_header Host &quot;www.hostloc.com&quot;; proxy_set_header Referer $http_referer; proxy_set_header X-Real-IP $remote_addr; proxy_set_header User-Agent $http_user_agent; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto https; proxy_set_header Accept-Encoding &quot;&quot;; proxy_set_header Accept-Language &quot;zh-CN&quot;; } # 分流到 V2Ray 服务 location /download { proxy_redirect off; proxy_pass http://127.0.0.1:18388; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; }} 之后重启下 Nginx： 12nginx -s reloadservice nginx restart 访问下域名，如果打开（跳转到）目标的伪装网站：并且访问分流的路径返回 Bad Request：就说明节点服务端启动成功了。 客户端配置，以 Surge 为例（注意端口为 443，路径为 /download）： 六、进阶操作1. 开启 TCP BBR 加速12345# 修改系统变量echo net.core.default_qdisc=fq &gt;&gt; /etc/sysctl.confecho net.ipv4.tcp_congestion_control=bbr &gt;&gt; /etc/sysctl.conf# 保存生效sysctl -p 确实是否生效： 1sysctl net.ipv4.tcp_available_congestion_control 2. 定时更新证书和重启服务原博文没有提到，但是在使用 acme.sh --install-cert 安装证书的时候其实就已经做了： 12# 安装证书acme.sh --install-cert -d $your_domain --ecc --key-file /usr/local/etc/v2ray/server.key --fullchain-file /usr/local/etc/v2ray/server.crt --reloadcmd &quot;systemctl restart v2ray&quot; 我们指定了 --reloadcmd &quot;systemctl restart v2ray&quot; 证书更新的时候重启 V2Ray，这就会使得新证书被正确使用。 参考文章： 节点搭建系列(5)：深入浅出VMESS+WS+TLS+WEB原理与搭建 基于nginx搭建v2ray服务端配置vmess+tls+websocket完全手册","link":"/2024/09/12/vmess_ws_tls_web/"},{"title":"Windows10 安装 OpenSSH 并在 Mac 系统上基于 VSCode Remote 进行远程连接开发","text":"前言有些应用只有 Windows 版本，而我的主要开发机器又是 Mac，所以需要连接到 Windows 进行远程开发。 方案概述 Windows10 安装 OpenSSH 配置 OpenSSH VSCode Remote 远程连接 Windows10 配置 VSCode Remote 代理 操作步骤一、Windows10 安装 OpenSSH从开始菜单打开 设置 , 然后选择 应用和功能 , 这里就有一个 管理可选功能 的选项：点击之后便可以看到一个可选功能, 选择 OpenSSH 服务器 即可（注意并非是红框框出的，而是偏下的那个）： 新版的 Windows10 默认已经安装了 OpenSSH，如果你找不到相关选项，可以直接跳过这一步。 之后需要使用 Windows PowerShell（管理员） 运行命令： 输入下面命令确认 Client 和 Server 的状态： 1Get-WindowsCapability -Online | ? Name -like 'OpenSSH*' 输出应该是类似的结果： 1234Name : OpenSSH.Client~~~~0.0.1.0State : NotPresentName : OpenSSH.Server~~~~0.0.1.0State : NotPresent NotPresent 表示未安装，接下来安装 Client 和 Server： 1234# 安装 OpenSSH ClientAdd-WindowsCapability -Online -Name OpenSSH.Client~~~~0.0.1.0# 安装 OpenSSH ServerAdd-WindowsCapability -Online -Name OpenSSH.Server~~~~0.0.1.0 安装完成后再次运行上面的命令，输出应该是类似的结果： 1234Name : OpenSSH.Client~~~~0.0.1.0State : InstalledName : OpenSSH.Server~~~~0.0.1.0State : Installed 二、配置 OpenSSH首先启动 OpenSSH 服务： 1Start-Service sshd 然后设置 OpenSSH 服务为自动启动： 1Set-Service -Name sshd -StartupType 'Automatic' 最后确认一下防火墙是否是放开的： 1Get-NetFirewallRule -Name *ssh* OpenSSH-Server-In-TCP 的 Enabled 状态为 True 即可： 三、VSCode Remote 远程连接 Windows10最新版的 VSCode 已经内置了 Remote - SSH 插件，可以直接使用。如果没有的话，可以在插件商店搜索 Remote - SSH 安装：添加连接，选择右侧的配置或者加号：添加如下配置即可： 123Host Windows10 HostName 192.168.1.11 User $your_username 四、配置 VSCode Remote 代理Mac 中内置了 nc 命令，可以使用 nc 命令作为代理： 我这里有跑在 6153 端口的 Socks5 代理，所以使用 nc -X 5 -x 127.0.0.1:6153 %h %p 作为代理。 1234Host Windows10 HostName 192.168.1.11 User $your_username ProxyCommand nc -X 5 -x 127.0.0.1:6153 %h %p Windows 系统通过 VSCode Remote 连接其他系统的话，代理配置可以参考：【归档文章】VS Code 使用需要认证的 SOCKS5 代理通过 Remote - SSH 连接远程服务器进行开发 参考资料： Mac 使用 VS Code 配合 Remote Development 插件连接 Windows 远程服务器 ssh命令之ProxyCommand选项","link":"/2024/11/02/windows10_openssh_vscode_remote/"},{"title":"WordPress 表结构描述与 OneNav 一为导航新建网址实际生成的表数据","text":"前言之后 steam.cash 导航站的网址一定是通过脚本自动抓取和添加的，因此必须要分析 WordPress 的表结构和 OneNav 操作对表的实际影响。需要注意的是，本文仅仅做了对 OneNav 导航添加 分类 和 网址 相关的分析。自定义网址、评论和主题相关的操作均不涉及，我也推荐将这些极度个性化的操作只在页面端实施。OneNav 一为导航主题版本为 V4.1810。 WordPress 与 OneNav 的表结构描述一、WordPress 官方文档：zh-cn:数据库描述 WordPress 自身拥有 11 张表，它们支撑起了 WordPress 最基础的功能，包括文章编辑、发布、评论和用户操作等。 稍作解释： wp_comments：保存对文章的评论的信息。 ❌ 导航添加 分类 和 网址 不涉及。 管理 &gt; 评论 &gt; 评论 wp_commentmeta：保存评论的元数据（特征信息）。 ❌ 导航添加 分类 和 网址 不涉及。 管理 &gt; 评论 &gt; 评论 wp_links：保存于网址相关的信息。 ❌ 看起来似乎和导航主题的 网址 概念匹配，但实际没有关系。 管理 &gt; 网址 &gt; 添加管理 &gt; 网址 &gt; 编辑 wp_options：保存设置的各项及其值。 ❌ 导航添加 分类 和 网址 不涉及。 管理 &gt; 设置 &gt; 常规管理 &gt; 设置 &gt; 撰写管理 &gt; 设置 &gt; 阅读管理 &gt; 设置 &gt; 讨论管理 &gt; 设置 &gt; 隐私管理 &gt; 设置 &gt; 固定网址管理 &gt; 设置 &gt; 杂项管理 &gt; 外观 &gt; 小工具 wp_postmeta：保存发布用的对象的元数据（特征信息），包含描述、网址、查看数和收藏数等。 ✅ 导航中的一个 网址 实际上是 WordPress 中的一篇文章，因此导航添加 分类 和 网址 涉及该表。 管理 &gt; 文章 &gt; 添加管理 &gt; 页面 &gt; 添加 wp_posts：保存各种发布用的对象的数据，包含标题、内容和状态等。而展示目录的时候，也会使用到该表。 ✅ 导航添加 分类 和 网址 涉及该表。 管理 &gt; 文章 &gt; 添加管理 &gt; 文章 &gt; 编辑管理 &gt; 页面 &gt; 添加管理 &gt; 页面 &gt; 编辑管理 &gt; 媒体 &gt; 添加管理 &gt; 媒体 &gt; 媒体库 wp_terms：保存文章的分类和 Tags。 ✅ 导航添加 分类 和 网址 涉及该表。 管理 &gt; 文章 &gt; Tags管理 &gt; 文章 &gt; 分类管理 &gt; 网址 &gt; 网址分类管理 &gt; 文章 &gt; 添加管理 &gt; 文章 &gt; 编辑管理 &gt; 文章 &gt; 添加管理 &gt; 文章 &gt; 编辑 wp_term_relationships：保存与与文章有关的分类。 ✅ 导航添加 分类 和 网址 涉及该表。 涉及操作与 wp_terms 表相同。 wp_term_taxonomy：保存分类和 Tags 的属性，比如描述和父子结构等。 ✅ 导航添加 分类 和 网址 涉及该表。 涉及操作与 wp_terms 表相同。 wp_usermeta：保存每个用户的元数据（特征信息）。❌ 导航添加 分类 和 网址 不涉及。 管理 &gt; 用户 wp_users：用户列表。❌ 导航添加 分类 和 网址 不涉及。 管理 &gt; 用户 综上，我们只需要关注 wp_posts、wp_postmeta、wp_terms、wp_term_relationships 和 wp_term_taxonomy 即可。 二、OneNav 表结构原文件等可以到我整理的仓库获取：senjianlu/steamcash OneNav 新增了 6 张表，来支撑导航需要的功能。 wp_io_custom_term：与 OneNav 主题中商城有关的表。 ❌ 导航添加 分类 和 网址 不涉及。 管理 &gt; 商城数据 wp_io_custom_url：与 OneNav 主题中商城有关的表。 ❌ 导航添加 分类 和 网址 不涉及。 管理 &gt; 商城数据 wp_io_pay_order：与 OneNav 主题中商城有关的表。 ❌ 导航添加 分类 和 网址 不涉及。 管理 &gt; 商城数据 wp_io_custom_messages：可能是与 OneNav 主题中商城有关的表。虽然可能也和其他内部消息推送功能相关，不过我在长久使用后它内部依然没有新增数据。 ❌ 导航添加 分类 和 网址 不涉及。 管理 &gt; 商城数据 wp_io_views：存储 网址 的点击、访问次数等。 ✅ 导航添加 分类 和 网址 涉及该表。 管理 &gt; 网址 wp_termmeta：存储 分类 的元数据（特征信息），包含 SEO 信息和其下 网址 的展示方式等。 ✅ 导航添加 分类 和 网址 涉及该表。 管理 &gt; 网址 &gt; 网址分类 综上，我们只需要关注 wp_io_views 和 wp_termmeta 即可。 OneNav 一为导航新建网址实际生成的表数据 OneNav 导航站的大致数据结构： 123456789站点- 目录 1（父） - 目录 a（子） - 网址百度 - 网址 Google - 目录 b（子）- 目录 2（父）...... 一、新建目录（父） 相关表：wp_terms、wp_termmeta、wp_term_taxonomy 和 wp_term_relationships。只方便理解，暂时不会将该功能写入脚本。 1、新建测试用的目录（父） 2、带来的新的数据 wp_terms 表 term_id name slug term_group 7 表数据判断用目录（父） table_data_check_for_path_parent 0 最重要就是 term_id，它是这个目录的唯一标识符。 wp_termmeta 表 meta_id term_id meta_key meta_value 22 7 _term_order 99 23 7 seo_title SEO 自定义标题 24 7 seo_metakey SEO 自定义关键词一、关键词2 25 7 seo_desc 自定义描述。 另起一行。 26 7 card_mode default 27 7 columns_type custom 28 7 columns a:5:{s:2:”sm”;s:1:”3”;s:2:”md”;s:1:”4”;s:2:”lg”;s:1:”5”;s:2:”xl”;s:1:”6”;s:3:”xxl”;s:1:”7”;} meta_id 应该是自增 ID。 wp_term_taxonomy 表 term_taxonomy_id term_id taxonomy description parent count 7 7 favorites 表数据判断用目录（父）的描述。另起一行。Home of Emoji Meanings ? ???? 0 0 term_taxonomy_id 官方标记了它为自增 ID：term_taxonomy_id bigint(20) unsigned NOT NULL auto_increment,，它的值与 term_id 并不总是相同，需要区分对待：term_taxonomy_id vs term_id。而 description 在表数据中虽然显示有问题（可能是我 MySQL GUI 的问题），但是实际在 WordPress 中表示是好的，后续在脚本编写的时候也会克服这个问题。 wp_term_relationships 表 object_id term_taxonomy_id term_order 虽然单纯创建目录（父）不会新增数据，但这里还是提一下 object_id 将是作为 网址 的 WordPress 文章的 post_id，而 term_taxonomy_id 则是上面 wp_term_taxonomy 表的主键。 3、配置项与表字段的映射关系 WordPress 页面配置项 对应表字段 备注 例子 名称 wp_terms.name 别名 wp_terms.slug 父级分类目录 wp_term_taxonomy.parent 没有父目录的时候为 0 描述 wp_term_taxonomy.description 排序 wp_termmeta 表中 meta_key 为 _term_order 的行 自定义标题 wp_termmeta 表中 meta_key 为 seo_title 的行 SEO设置（可留空） 设置关键词 wp_termmeta 表中 meta_key 为 seo_metakey 的行 SEO设置（可留空） 自定义描述 wp_termmeta 表中 meta_key 为 seo_desc 的行 SEO设置（可留空） 网址卡片样式 wp_termmeta 表中 meta_key 为 card_mode 的行 自定义选项 网址列数 wp_termmeta 表中 meta_key 为 columns_type 的行、wp_termmeta 表中 meta_key 为 columns 的行 自定义选项 其他字段： wp_terms.term_id：创建目录的时候自动生成。 wp_terms.term_group：目录（父）没有再上级的目录，因此为 0。 wp_term_taxonomy.taxonomy：总为固定值 favorites。 wp_term_taxonomy.count：目录中的网址个数。 二、展示目录（父） 相关表：wp_posts、wp_postmeta 和 wp_term_relationships。只方便理解，暂时不会将该功能写入脚本。 1、展示测试用的目录（父）添加至菜单，之后保存： 2、带来的新的数据 wp_posts 表 ID post_author post_date post_date_gmt post_content post_title post_excerpt post_status comment_status ping_status post_password post_name to_ping pinged post_modified post_modified_gmt post_content_filtered post_parent guid menu_order post_type post_mime_type comment_count 27 1 2024-10-12 14:21:54 2024-10-12 06:21:54 表数据判断用目录（父）的描述。 另起一行。 Home of Emoji Meanings ? ???? publish closed closed 27 2024-10-12 14:21:54 2024-10-12 06:21:54 0 https://steam.cash/?p=27 4 nav_menu_item 0 虽然乍一看都能明白数据来源，但是基本都是从其他表中检索而来，同时还伴有 menu_order 这种需要检索对应数据进行重新排序生成的值。因此可以预见的是展示目录功能使用 Python3 来实现会比较复杂，顺位最后。 wp_postmeta 表 meta_id post_id meta_key meta_value 192 27 _menu_item_type taxonomy 193 27 _menu_item_menu_item_parent 0 194 27 _menu_item_object_id 7 195 27 _menu_item_object favorites 196 27 _menu_item_target 197 27 _menu_item_classes a:1:{i:0;s:0:””””;} 198 27 _menu_item_xfn 199 27 _menu_item_url 204 27 menu_ico iconfont icon-category 205 27 open 206 27 purview 0 wp_term_relationships 表 object_id term_taxonomy_id term_order 27 4 0 这里的 object_id 是上一张 wp_posts 表的 ID，而 term_taxonomy_id 则大概率为 4。原因是与表中的这条数据有关： term_taxonomy_id term_id taxonomy description parent count 4 4 nav_menu 0 0 OneNav 用其管理所有需要展示的分类，而一般你需要新建一个目录（它的 term_taxonomy_id 将自增为 3），再进行展示操作，OneNav 自动新建数据，自增为 4。 三、新建目录（子） 相关表：wp_terms、wp_termmeta、wp_term_taxonomy 和 wp_term_relationships。数据与目录（父）基本一致。只方便理解，暂时不会将该功能写入脚本。 1、新建测试用的目录（子） 2、带来的新的数据 wp_terms 表 term_id name slug term_group 8 表数据判断用目录（子） table_data_check_for_path_child 0 wp_termmeta 表 meta_id term_id meta_key meta_value 29 8 _term_order 50 30 8 seo_title 子的自定义标题 31 8 seo_metakey 子的自定义关键词一、关键词2 32 8 seo_desc 子的自定义描述。 另起一行。 33 8 card_mode min 34 8 columns_type custom 35 8 columns a:5:{s:2:”sm”;s:2:”10”;s:2:”md”;s:1:”9”;s:2:”lg”;s:1:”8”;s:2:”xl”;s:1:”7”;s:3:”xxl”;s:1:”6”;} wp_term_taxonomy 表 term_taxonomy_id term_id taxonomy description parent count 8 8 favorites 表数据判断用目录（子）的描述。 另起一行。 Home of Emoji Meanings ? ???? 7 0 这里指定了父目录，因此 parent 为 7。 wp_term_relationships 表 object_id term_taxonomy_id term_order 四、展示目录（子） 相关表：wp_posts、wp_postmeta 和 wp_term_relationships。只方便理解，暂时不会将该功能写入脚本。 1、展示测试用的目录（子） 2、带来的新的数据 wp_posts 表 ID post_author post_date post_date_gmt post_content post_title post_excerpt post_status comment_status ping_status post_password post_name to_ping pinged post_modified post_modified_gmt post_content_filtered post_parent guid menu_order post_type post_mime_type comment_count 28 1 2024-10-12 14:52:49 2024-10-12 06:52:49 表数据判断用目录（子）的描述。 另起一行。 Home of Emoji Meanings ? ???? publish closed closed 28 2024-10-12 14:52:49 2024-10-12 06:52:49 7 https://steam.cash/?p=28 5 nav_menu_item 0 这里指定了父目录，因此 post_parent 为 7。 wp_postmeta 表 meta_id post_id meta_key meta_value 207 28 _menu_item_type taxonomy 208 28 _menu_item_menu_item_parent 27 209 28 _menu_item_object_id 8 210 28 _menu_item_object favorites 211 28 _menu_item_target 212 28 _menu_item_classes a:1:{i:0;s:0:””””;} 213 28 _menu_item_xfn 214 28 _menu_item_url 216 28 menu_ico iconfont icon-category 217 28 open 218 28 purview 0 wp_term_relationships 表 object_id term_taxonomy_id term_order 28 4 0 五、新建网址 相关表：wp_posts 和 wp_postmeta。 1、新建测试用的网址（在子目录中） 2、带来的新的数据 wp_posts 表 ID post_author post_date post_date_gmt post_content post_title post_excerpt post_status comment_status ping_status post_password post_name to_ping pinged post_modified post_modified_gmt post_content_filtered post_parent guid menu_order post_type post_mime_type comment_count 29 1 2024-10-12 15:04:43 0000-00-00 00:00:00 自动草稿 auto-draft open closed 2024-10-12 15:04:43 0000-00-00 00:00:00 0 https://steam.cash/sites/29.html 0 sites 0 30 1 2024-10-12 15:11:54 2024-10-12 07:11:54 正文信息。另起一行。&lt;a href=””https://steam.cash/sample-page&quot;&quot;&gt;示例页面 测试用的新网址（子目录中） publish open closed %e6%b5%8b%e8%af%95%e7%94%a8%e7%9a%84%e6%96%b0%e7%bd%91%e5%9d%80%ef%bc%88%e5%ad%90%e7%9b%ae%e5%bd%95%e4%b8%ad%ef%bc%89 2024-10-12 15:11:54 2024-10-12 07:11:54 0 https://steam.cash/sites/30.html 0 sites 0 wp_postmeta 表 meta_id post_id meta_key meta_value 224 30 views 0 225 30 _down_count 0 226 30 _like_count 0 227 30 _star_count 0 228 30 _user_purview_level all 229 30 _edit_last 1 230 30 _edit_lock 1728717031:1 231 30 _seo_title 232 30 _seo_metakey 233 30 _seo_desc 234 30 sidebar_layout default 235 30 _sites_type sites 236 30 _goto 0 237 30 _wechat_id 238 30 _is_min_app 239 30 _sites_link https://google.com 240 30 _spare_sites_link a:1:{i:0;a:3:{s:10:””spare_name””;s:4:””Bing””;s:9:””spare_url””;s:16:””https://bing.com&quot;&quot;;s:10:&quot;&quot;spare_note&quot;&quot;;s:30:&quot;&quot;这是 Bing 的跳转链接。””;}} 241 30 _sites_sescribe 这是 Google 的跳转链接。另起一行。 242 30 _sites_language zh,en 243 30 _sites_country 中国 244 30 _sites_order 0 245 30 _thumbnail https://image.senjianlu.com/blog/icon.png 246 30 _sites_preview https://image.senjianlu.com/blog/2024-10-10/onenav.png 247 30 _wechat_qr 248 30 _down_version 249 30 _down_size 250 30 _down_url_list 251 30 _dec_password 252 30 _app_platform 253 30 _down_preview 254 30 _down_formal 255 30 _screenshot 256 30 buy_option a:7:{s:8:””buy_type””;s:4:””view””;s:5:””limit””;s:3:””all””;s:8:””pay_type””;s:5:””money””;s:10:””price_type””;s:6:””single””;s:9:””pay_title””;s:0:””””;s:9:””pay_price””;s:1:””0””;s:5:””price””;s:1:””0””;} wp_term_taxonomy 表 term_taxonomy_id term_id taxonomy description parent count 8 8 favorites 表数据判断用目录（子）的描述。 另起一行。 Home of Emoji Meanings ? ???? 7 1 更新了子目录的 count，将其加一从 0 变成了 1。父目录的不会跟着变化。 wp_term_relationships 表 object_id term_taxonomy_id term_order 30 8 0 term_taxonomy_id 是子目录的 term_taxonomy_id 为 8。 3、配置项与表字段的映射关系 WordPress 页面配置项 对应表字段 备注 例子 网址分类 wp_term_relationships 表中 object_id 为对应 post_id 的行 标题 wp_posts.post_title 正文 wp_posts.post_content 链接 wp_postmeta 表中 meta_key 为 _sites_link 的行 备用链接地址（其他站点） wp_postmeta 表中 meta_key 为 _spare_sites_link 的行 一句话描述（简介） wp_postmeta 表中 meta_key 为 _sites_sescribe 的行 站点语言 wp_postmeta 表中 meta_key 为 _sites_language 的行 站点所在国家或地区 wp_postmeta 表中 meta_key 为 _sites_country 的行 排序 wp_postmeta 表中 meta_key 为 _sites_order 的行 拖动排序的情况下无法更改，一直为 0 LOGO，标志 wp_postmeta 表中 meta_key 为 _thumbnail 的行 网站预览截图 wp_postmeta 表中 meta_key 为 _sites_preview 的行 公众号二维码 wp_postmeta 表中 meta_key 为 _wechat_qr 的行 其他字段： wp_posts.id：自增。 wp_posts.post_name：Url 编码后的标题。 wp_posts.uid：&quot;https://steam.cash/sites/{}.html&quot;.format(id) 形式的值。 wp_postmeta 表中 meta_key 为 _edit_lock 的行：前面的值是秒级的时间戳，&quot;{}:1&quot;.format(str(int(time.time()))) 形式的值。","link":"/2024/10/12/wordpress_data_modeler_onenav/"},{"title":"OneNav 一为导航新建目录与导航网址","text":"前言没有怎么使用过 WordPress，一为主题也是第一次使用，实际操作并记录下流程。为后续 Python3 脚本的编写铺路。OneNav 一为导航主题版本为 V4.1810。 方案概述 新建父目录并展示 新建子目录并展示 新建网址并填写信息 操作步骤 官方文档：收录你的第一个网址 这里拿全知猪的 PromptPerfect 站点标签作为目标案例： OneNav 导航站的大致数据结构： 123456789站点- 目录 1（父） - 目录 a（子） - 网址百度 - 网址 Google - 目录 b（子）- 目录 2（父）...... 一、新建父目录并展示 目标案例的父目录名是 AIGC 办公平台，权重是最高的排在首位。 1、新建目录首先建立这个父目录，进入 网址 ➡️ 网址分类 页面，输入响应的信息：然后拉到最下方，点击 添加新网址目录：之后就能看到目录被创建在右侧了： 2、展示目录 刚刚我们建立的目录，属于 网址分类目录 种类。 进入 工具 ➡️ 菜单 页面，点击右上角的 显示选项 按钮，将搜索条件的下拉框打开： 确保界面元素相关搜索条件中，起码勾选了 网址分类目录 和 APP/资源分类目录；而高级菜单属性条件中，起码勾选了 网址目标 和 CSS 类： 勾选的同时就会进行检索。勾选完成后往下翻一点，就可以看到 网址分类目录 这个待添加的菜单项了，选择 查看所有，然后勾选刚刚新建的目录，点击 添加到菜单：这里目录如果位置不对的话，你可以编辑它的排序（约小越靠前，排序相同的情况下越早创建约靠前），或者直接拉住拖动：保存后回到主页，就能看到这个目录了： 二、新建子目录并展示1、新建目录 目标案例的子目录名是 AI提示词，权重是最高的排在首位。 子目录创建与父目录大致相同，唯一不同的是新建的时候要指定下父目录： 2、展示目录添加流程是一样的，但是后续需要拖动，将子目录放置到父目录下做展示：保存后回到主页确认下： 三、新建网址并填写信息1、新建网址 目标案例的信息： 1234https://promptperfect.jina.ai/PromptPerfect - 尖端提示词优化器PromptPerfect是什么PromptPerfect是一款AI提示生成器和优化器，专门设计用于提升像GPT-4、Claude和Midjourney这样的模型的性能。它提供AIGC 办公平台、AI提示词、AIGC、AI写作提示、Cha-GPT、Prompt、Prompt优化 选择 网址 ➡️ 所有网址，然后点击 添加网址 按钮： 标签要单独建立，这里就跳过了，填入三个主要信息： 然后选择刚刚新建的的目录，点击 发布 按钮： 回到首页，就能看到这个网址了： 2、开放网址详情页可能你这时候点击网址，并不会进入详情页，而是直接跳转到了目标网站。如果你想开放详情页的话，需要前往 主题设置 ➡️ 内容设置 ➡️ 网址设置 页面：像我这样开启详情页：之后，详情页的小图标就出现了：点击进入详情页： 结束。","link":"/2024/10/11/wordpress_onenav_add_link/"},{"title":"使用 ZeroSSL 申请免费的 IP SSL 证书","text":"前言国内服务器绑定域名需要备案，使用小厂的云还需要过白名单，实在麻烦。我只有使用 HTTPS 访问我的服务器这一个需求，使用免费的 IP SSL 证书就足够了。 申请步骤一、注册账号打开 ZeroSSL 官网，点击右上角的 Sign Up 注册账号。顺便看下各订阅的价格和功能：免费的套餐只能申请 3 个证书，有效期 90 天，不支持通配符域名。暂时够用了，需要更多的证书再升级吧。 二、申请证书登录账号后，点击 New Certificate 开始申请证书。在 Domain 输入框中填写你的 IP 地址，点击 Next：之后一路下一步即可。 三、认证 IP 所有权这里需要下载一个验证文件，然后将其放到你的服务器上。ZeroSSL 通过访问 http://xxx.xxx.xxx.xxx/.well-known/pki-validation/2CFXXXXXXXXXXXXXXXXXXXXX124C3680868.txt 来获取对应的文件以验证你的 IP 所有权。 我这里就图方便直接通过 Nginx 来实现了： 12apt-get updateapt-get install nginx 安装完成后启动 Nginx： 1systemctl start nginx Nginx 的默认网站目录是 /var/www/html，将验证文件放到这个目录下： 1234567# 创建验证文件目录mkdir -vp /var/www/html/.well-known/pki-validation# 将验证文件放到目录下，或是像我一样创建一个文件并将内容复制进去# 注意应该有三行内容echo &quot;2CFXXXXXXXXXXXXXXXXXXXXX124C3680868&quot; &gt; /var/www/html/.well-known/pki-validation/2CFXXXXXXXXXXXXXXXXXXXXX124C3680868.txtecho &quot;xxxxxx.com&quot; &gt;&gt; /var/www/html/.well-known/pki-validation/2CFXXXXXXXXXXXXXXXXXXXXX124C3680868.txtecho &quot;AAABBBCCCCC&quot; &gt;&gt; /var/www/html/.well-known/pki-validation/2CFXXXXXXXXXXXXXXXXXXXXX124C3680868.txt 之后访问下对应的 URL，看看是否能访问到验证文件。没问题的话点击 Verify Domain：通常认证需要数秒，等待一会儿即可。 四、下载证书选择你的 Web 服务器类型，下载证书：我这里选择了 Default Format，下载后解压得到三个文件： ca_bundle.crt：根证书 certificate.crt：证书 private.key：私钥 五、使用Stunnel按照 private.key、certificate.crt、ca_bundle.crt 的顺序合并成一个文件，注意顺序不能错！ 1cat private.key certificate.crt ca_bundle.crt &gt; /root/ssl/stunnel.pem 为 stunnel 配置文件添加证书路径： 12345client = no[squid]accept = 443connect = 127.0.0.1:8910cert = /root/ssl/stunnel.pem 结束。","link":"/2024/09/02/zerossl_ip_ssl_certificate/"},{"title":"WordPress 使用 Polylang 插件实现文章多语言支持（国际化）并分析表数据","text":"前言导航站的多语言支持是基础功能之一。由于 OneNav 基于 WordPress 的一个主题，所以通过 Polylang 这个 WordPress 插件来实现即可。需要注意：你的一篇内容要支持几种语言，就要创建几篇文章。 Polylang 是 WordPress 建站平台上的一款免费的建立多语言网站版本的插件，它允许您创建双语或多语言 WordPress 网站。您可以在正常编写帖子，页面并创建类别和帖子标签后，为它们再创建一份别国语言的内容。 方案概述 安装 Polylang 插件 设置站点默认语言 设置其他语言的 URL 形式 在页面上添加切换语言的按钮 为一篇内容写多篇不同语言文章 分析文章的表数据 操作步骤一、安装 Polylang 插件选择插件 -&gt; 安装新插件 -&gt; 搜索 Polylang -&gt; 安装并启用：之后选择启用，会进入设置界面： 二、设置站点默认语言在语言列表中，将哪个语言标 ⭐ 就是代表其为默认语言： 三、设置其他语言的 URL 形式选择： ✅ 根据固定链接中的目录名称设置语言 ✅ 为默认语言隐藏网址中的语言信息，比如默认为中文时，不要在网址中添加 /zh/ 部分 ✅ 移除固定链接中的 /language/ 部分 之后，各个语言的文章链接就会类似于： 中文：https://my.blog.com/2024/10/17/my_first_post/ 日文：https://my.blog.com/ja/2024/10/17/my_first_post/ 英文：https://my.blog.com/en/2024/10/17/my_first_post/ 这对于你的主要用户群体来说是非常友好的。 四、在页面上添加切换语言的按钮官方的 WordPress 主题中是没有 小工具 这一概念的，而 Polylang 的语言切换工具需要通过小工具来添加的。我这里省事，安装个带小工具的第三方主题：在自定义页面添加 语言切换器 小工具：点击完成，之后发布，再回到页面上就可以看到切换语言的按钮了：这里由于我目前只有一篇中文文章，所以只有中文按钮。 五、为一篇内容写多篇不同语言文章这里先创建一篇中文文章： 直接写文章的话，会自动保存为你的默认语言。我这里是中文。 然后点击英文下面的加号，创建一篇对应的英文文章：同样点击加号，再创建一篇日语文章： 之后回到页面上，就能通过切换语言看到对应的文章了： 六、分析文章的表数据 为了二开做准备，单纯使用插件的话可以不了解。 1、中文文章 wp_posts 表： ID post_author post_date post_date_gmt post_content post_title post_excerpt post_status comment_status ping_status post_password post_name to_ping pinged post_modified post_modified_gmt post_content_filtered post_parent guid menu_order post_type post_mime_type comment_count 31 1 2024-10-18 11:04:21 2024-10-18 03:04:21 中文文章的内容。 这是中文文章的标题 publish open closed %e8%bf%99%e6%98%af%e4%b8%ad%e6%96%87%e6%96%87%e7%ab%a0%e7%9a%84%e6%a0%87%e9%a2%98 2024-10-18 11:04:21 2024-10-18 03:04:21 0 https://test.steam.cash/?p=31 0 post 0 32 1 2024-10-18 11:04:21 2024-10-18 03:04:21 中文文章的内容。 这是中文文章的标题 inherit closed closed 31-revision-v1 2024-10-18 11:04:21 2024-10-18 03:04:21 31 https://test.steam.cash/?p=32 0 revision 0 wp_postmeta 表： post_id 为 32 的没有数据。 meta_id post_id meta_key meta_value 262 31 views 0 263 31 _down_count 0 264 31 _like_count 0 265 31 _star_count 0 266 31 _user_purview_level all 267 31 _edit_last 1 268 31 _edit_lock 1729220662:1 269 31 _seo_title 270 31 _seo_metakey 271 31 _seo_desc 272 31 sidebar_layout default 273 31 buy_option a:7:{s:8:””buy_type””;s:4:””view””;s:5:””limit””;s:3:””all””;s:8:””pay_type””;s:5:””money””;s:10:””price_type””;s:6:””single””;s:9:””pay_title””;s:0:””””;s:9:””pay_price””;s:1:””0””;s:5:””price””;s:1:””0””;} 这里在 wp_posts 建立了两张表，其中 post_id 为 32 的数据是子数据。而 post_id 等于 31 的则是父数据，且在 wp_postmeta 中拥有完整的元数据（特征信息）。 比较让我惊奇的是，居然没有在 wp_postmeta 表中建立一行来标记文章的语言属性。 2、英文文章 wp_posts 表： ID post_author post_date post_date_gmt post_content post_title post_excerpt post_status comment_status ping_status post_password post_name to_ping pinged post_modified post_modified_gmt post_content_filtered post_parent guid menu_order post_type post_mime_type comment_count 33 1 2024-10-18 11:19:57 2024-10-18 03:19:57 English content. English title publish open closed english-title 2024-10-18 11:19:57 2024-10-18 03:19:57 0 https://test.steam.cash/?p=33 0 post 0 34 1 2024-10-18 11:19:57 2024-10-18 03:19:57 English content. English title inherit closed closed 33-revision-v1 2024-10-18 11:19:57 2024-10-18 03:19:57 33 https://test.steam.cash/?p=34 0 revision 0 wp_postmeta 表： post_id 为 34 的没有数据。 meta_id post_id meta_key meta_value 274 33 views 0 275 33 _down_count 0 276 33 _like_count 0 277 33 _star_count 0 278 33 _user_purview_level all 279 33 sidebar_layout default 280 33 buy_option a:7:{s:8:””buy_type””;s:4:””view””;s:5:””limit””;s:3:””all””;s:8:””pay_type””;s:5:””money””;s:10:””price_type””;s:6:””single””;s:9:””pay_title””;s:0:””””;s:9:””pay_price””;s:1:””0””;s:5:””price””;s:1:””0””;} 281 33 _edit_last 1 282 33 _edit_lock 1729221598:1 283 33 _seo_title 284 33 _seo_metakey 285 33 _seo_desc 与中文文章的表数据看起来没什么差别。 3、日语文章 wp_posts 表： ID post_author post_date post_date_gmt post_content post_title post_excerpt post_status comment_status ping_status post_password post_name to_ping pinged post_modified post_modified_gmt post_content_filtered post_parent guid menu_order post_type post_mime_type comment_count 36 1 2024-10-18 11:34:08 2024-10-18 03:34:08 日本語内容。 日本語文章 publish open closed %e6%97%a5%e6%9c%ac%e8%aa%9e%e6%96%87%e7%ab%a0 2024-10-18 11:34:08 2024-10-18 03:34:08 0 https://test.steam.cash/?p=36 0 post 0 37 1 2024-10-18 11:34:08 2024-10-18 03:34:08 日本語内容。 日本語文章 inherit closed closed 36-revision-v1 2024-10-18 11:34:08 2024-10-18 03:34:08 36 https://test.steam.cash/?p=37 0 revision 0 wp_postmeta 表： post_id 为 37 的没有数据。 meta_id post_id meta_key meta_value 291 36 views 0 292 36 _down_count 0 293 36 _like_count 0 294 36 _star_count 0 295 36 _user_purview_level all 296 36 sidebar_layout default 297 36 buy_option a:7:{s:8:””buy_type””;s:4:””view””;s:5:””limit””;s:3:””all””;s:8:””pay_type””;s:5:””money””;s:10:””price_type””;s:6:””single””;s:9:””pay_title””;s:0:””””;s:9:””pay_price””;s:1:””0””;s:5:””price””;s:1:””0””;} 298 36 _edit_last 1 299 36 _edit_lock 1729222449:1 300 36 _seo_title 301 36 _seo_metakey 302 36 _seo_desc 与中文文章的表数据看起来依然没什么差别。 4、连接结构既然 wp_posts 表中不记录语言和其他文章的连接信息。那么问题就来了，下面这样将多个语言的文章连接的数据是记录在哪里的呢？ 翻了下目录和标签相关的 wp_terms 表，在 wp_term_taxonomy 表中找到了这么一条数据： term_taxonomy_id term_id taxonomy description parent count 22 22 post_translations a:3:{s:2:””en””;i:33;s:2:””zh””;i:31;s:2:””ja””;i:36;} 0 3 那么很显然，一篇内容的各语言版本文章是通过目录或标签的形式连接在一起的。再看下其他表的信息： wp_terms 表： term_id name slug term_group 22 pll_6711d3dd4efb0 pll_6711d3dd4efb0 0 wp_term_relationships 表： object_id term_taxonomy_id term_order 31 1 0 31 2 0 31 22 0 33 9 0 33 19 0 33 22 0 36 5 0 36 7 0 36 22 0 wp_terms 表中的 name 和 slug 字段应该是自动生成的，一般情况下用户也看不见就不用去管了。wp_term_relationships 表中的数据和 wp_posts 表中的文章 ID 可以匹配上： 中文文章 post_id：31 英文文章 post_id：33 日语文章 post_id：36 其中 1、2、9、19、5 和 7 的分类或标签，分别对应各语言和各语言的“未分类”组。 参考资料： WordPress多语言插件Polylang使用教程_外贸多语言建站","link":"/2024/10/17/wordpress_polylang_internationalization/"}],"tags":[{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"SSL","slug":"SSL","link":"/tags/SSL/"},{"name":"Cloudflare","slug":"Cloudflare","link":"/tags/Cloudflare/"},{"name":"博客","slug":"博客","link":"/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"AWS","slug":"AWS","link":"/tags/AWS/"},{"name":"AWS Lambda","slug":"AWS-Lambda","link":"/tags/AWS-Lambda/"},{"name":"Twikoo","slug":"Twikoo","link":"/tags/Twikoo/"},{"name":"Terraform","slug":"Terraform","link":"/tags/Terraform/"},{"name":"Apollo","slug":"Apollo","link":"/tags/Apollo/"},{"name":"配置中心","slug":"配置中心","link":"/tags/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/"},{"name":"归档文章","slug":"归档文章","link":"/tags/%E5%BD%92%E6%A1%A3%E6%96%87%E7%AB%A0/"},{"name":"長城を越える","slug":"長城を越える","link":"/tags/%E9%95%B7%E5%9F%8E%E3%82%92%E8%B6%8A%E3%81%88%E3%82%8B/"},{"name":"RabbitMQ","slug":"RabbitMQ","link":"/tags/RabbitMQ/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"Zabbix","slug":"Zabbix","link":"/tags/Zabbix/"},{"name":"GOST","slug":"GOST","link":"/tags/GOST/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Linux 基础","slug":"Linux-基础","link":"/tags/Linux-%E5%9F%BA%E7%A1%80/"},{"name":"Jupyter","slug":"Jupyter","link":"/tags/Jupyter/"},{"name":"Python3","slug":"Python3","link":"/tags/Python3/"},{"name":"Matplotlib","slug":"Matplotlib","link":"/tags/Matplotlib/"},{"name":"MinIO","slug":"MinIO","link":"/tags/MinIO/"},{"name":"对象存储","slug":"对象存储","link":"/tags/%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8/"},{"name":"服务器监控","slug":"服务器监控","link":"/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9B%91%E6%8E%A7/"},{"name":"Django","slug":"Django","link":"/tags/Django/"},{"name":"Nginx","slug":"Nginx","link":"/tags/Nginx/"},{"name":"OpenSSL","slug":"OpenSSL","link":"/tags/OpenSSL/"},{"name":"小猫咪","slug":"小猫咪","link":"/tags/%E5%B0%8F%E7%8C%AB%E5%92%AA/"},{"name":"全球主机","slug":"全球主机","link":"/tags/%E5%85%A8%E7%90%83%E4%B8%BB%E6%9C%BA/"},{"name":"DataX","slug":"DataX","link":"/tags/DataX/"},{"name":"PostgreSQL","slug":"PostgreSQL","link":"/tags/PostgreSQL/"},{"name":"MongoDB","slug":"MongoDB","link":"/tags/MongoDB/"},{"name":"图床","slug":"图床","link":"/tags/%E5%9B%BE%E5%BA%8A/"},{"name":"ETH","slug":"ETH","link":"/tags/ETH/"},{"name":"挖矿","slug":"挖矿","link":"/tags/%E6%8C%96%E7%9F%BF/"},{"name":"抓包","slug":"抓包","link":"/tags/%E6%8A%93%E5%8C%85/"},{"name":"Fiddler","slug":"Fiddler","link":"/tags/Fiddler/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"GitHub Action","slug":"GitHub-Action","link":"/tags/GitHub-Action/"},{"name":"Hugo","slug":"Hugo","link":"/tags/Hugo/"},{"name":"K3s","slug":"K3s","link":"/tags/K3s/"},{"name":"Rancher","slug":"Rancher","link":"/tags/Rancher/"},{"name":"服务器集群","slug":"服务器集群","link":"/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%9B%86%E7%BE%A4/"},{"name":"Proxmox VE","slug":"Proxmox-VE","link":"/tags/Proxmox-VE/"},{"name":"爱快","slug":"爱快","link":"/tags/%E7%88%B1%E5%BF%AB/"},{"name":"OpenWrt","slug":"OpenWrt","link":"/tags/OpenWrt/"},{"name":"LEDE","slug":"LEDE","link":"/tags/LEDE/"},{"name":"家庭网络","slug":"家庭网络","link":"/tags/%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C/"},{"name":"Nextcloud","slug":"Nextcloud","link":"/tags/Nextcloud/"},{"name":"Google Analytics","slug":"Google-Analytics","link":"/tags/Google-Analytics/"},{"name":"Let&#39;s Encrypt","slug":"Let-s-Encrypt","link":"/tags/Let-s-Encrypt/"},{"name":"Plesk","slug":"Plesk","link":"/tags/Plesk/"},{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Synology","slug":"Synology","link":"/tags/Synology/"},{"name":"爬虫","slug":"爬虫","link":"/tags/%E7%88%AC%E8%99%AB/"},{"name":"Steam","slug":"Steam","link":"/tags/Steam/"},{"name":"MetaMask","slug":"MetaMask","link":"/tags/MetaMask/"},{"name":"区块链","slug":"区块链","link":"/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Rust","slug":"Rust","link":"/tags/Rust/"},{"name":"游戏服务器","slug":"游戏服务器","link":"/tags/%E6%B8%B8%E6%88%8F%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"VS Code","slug":"VS-Code","link":"/tags/VS-Code/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"Windows","slug":"Windows","link":"/tags/Windows/"},{"name":"Android","slug":"Android","link":"/tags/Android/"},{"name":"效率","slug":"效率","link":"/tags/%E6%95%88%E7%8E%87/"},{"name":"CLF","slug":"CLF","link":"/tags/CLF/"},{"name":"云服务","slug":"云服务","link":"/tags/%E4%BA%91%E6%9C%8D%E5%8A%A1/"},{"name":"stunnel","slug":"stunnel","link":"/tags/stunnel/"},{"name":"Crawl4AI","slug":"Crawl4AI","link":"/tags/Crawl4AI/"},{"name":"Crawlab","slug":"Crawlab","link":"/tags/Crawlab/"},{"name":"Loki","slug":"Loki","link":"/tags/Loki/"},{"name":"Grafana","slug":"Grafana","link":"/tags/Grafana/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"WordPress","slug":"WordPress","link":"/tags/WordPress/"},{"name":"OneNav","slug":"OneNav","link":"/tags/OneNav/"},{"name":"steam.cash","slug":"steam-cash","link":"/tags/steam-cash/"},{"name":"Portainer","slug":"Portainer","link":"/tags/Portainer/"},{"name":"Seafile","slug":"Seafile","link":"/tags/Seafile/"},{"name":"日语","slug":"日语","link":"/tags/%E6%97%A5%E8%AF%AD/"},{"name":"半泽直树","slug":"半泽直树","link":"/tags/%E5%8D%8A%E6%B3%BD%E7%9B%B4%E6%A0%91/"},{"name":"重启人生","slug":"重启人生","link":"/tags/%E9%87%8D%E5%90%AF%E4%BA%BA%E7%94%9F/"},{"name":"Eclipse","slug":"Eclipse","link":"/tags/Eclipse/"},{"name":"Polylang","slug":"Polylang","link":"/tags/Polylang/"},{"name":"PHP","slug":"PHP","link":"/tags/PHP/"},{"name":"Mini PC","slug":"Mini-PC","link":"/tags/Mini-PC/"},{"name":"Plex","slug":"Plex","link":"/tags/Plex/"},{"name":"Transmission","slug":"Transmission","link":"/tags/Transmission/"},{"name":"BT&#x2F;PT","slug":"BT-PT","link":"/tags/BT-PT/"},{"name":"qBittorrent","slug":"qBittorrent","link":"/tags/qBittorrent/"},{"name":"SAA","slug":"SAA","link":"/tags/SAA/"},{"name":"SAP","slug":"SAP","link":"/tags/SAP/"},{"name":"cert-manager","slug":"cert-manager","link":"/tags/cert-manager/"},{"name":"読み方","slug":"読み方","link":"/tags/%E8%AA%AD%E3%81%BF%E6%96%B9/"},{"name":"Kubernetes","slug":"Kubernetes","link":"/tags/Kubernetes/"},{"name":"PMP","slug":"PMP","link":"/tags/PMP/"},{"name":"文法","slug":"文法","link":"/tags/%E6%96%87%E6%B3%95/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/tags/Machine-Learning/"},{"name":"AI","slug":"AI","link":"/tags/AI/"},{"name":"S3","slug":"S3","link":"/tags/S3/"},{"name":"Serverless","slug":"Serverless","link":"/tags/Serverless/"},{"name":"Lambda","slug":"Lambda","link":"/tags/Lambda/"},{"name":"VPC","slug":"VPC","link":"/tags/VPC/"},{"name":"WebDAV","slug":"WebDAV","link":"/tags/WebDAV/"},{"name":"S3fs","slug":"S3fs","link":"/tags/S3fs/"},{"name":"Markdown","slug":"Markdown","link":"/tags/Markdown/"},{"name":"n8n","slug":"n8n","link":"/tags/n8n/"},{"name":"工作流","slug":"工作流","link":"/tags/%E5%B7%A5%E4%BD%9C%E6%B5%81/"},{"name":"Caddy","slug":"Caddy","link":"/tags/Caddy/"},{"name":"项目管理","slug":"项目管理","link":"/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"},{"name":"每日练习","slug":"每日练习","link":"/tags/%E6%AF%8F%E6%97%A5%E7%BB%83%E4%B9%A0/"},{"name":"PO 文","slug":"PO-文","link":"/tags/PO-%E6%96%87/"},{"name":"レゾナンス","slug":"レゾナンス","link":"/tags/%E3%83%AC%E3%82%BE%E3%83%8A%E3%83%B3%E3%82%B9/"},{"name":"無限号列車","slug":"無限号列車","link":"/tags/%E7%84%A1%E9%99%90%E5%8F%B7%E5%88%97%E8%BB%8A/"},{"name":"Selenium","slug":"Selenium","link":"/tags/Selenium/"},{"name":"翻译","slug":"翻译","link":"/tags/%E7%BF%BB%E8%AF%91/"},{"name":"歌词","slug":"歌词","link":"/tags/%E6%AD%8C%E8%AF%8D/"},{"name":"macOS","slug":"macOS","link":"/tags/macOS/"},{"name":"前端","slug":"前端","link":"/tags/%E5%89%8D%E7%AB%AF/"},{"name":"Next.js","slug":"Next-js","link":"/tags/Next-js/"},{"name":"React","slug":"React","link":"/tags/React/"},{"name":"NextUI","slug":"NextUI","link":"/tags/NextUI/"},{"name":"IaC","slug":"IaC","link":"/tags/IaC/"},{"name":"商业文档","slug":"商业文档","link":"/tags/%E5%95%86%E4%B8%9A%E6%96%87%E6%A1%A3/"},{"name":"BLUE PROTOCOL","slug":"BLUE-PROTOCOL","link":"/tags/BLUE-PROTOCOL/"},{"name":"佐川急便","slug":"佐川急便","link":"/tags/%E4%BD%90%E5%B7%9D%E6%80%A5%E4%BE%BF/"},{"name":"N1 真题","slug":"N1-真题","link":"/tags/N1-%E7%9C%9F%E9%A2%98/"},{"name":"新闻","slug":"新闻","link":"/tags/%E6%96%B0%E9%97%BB/"},{"name":"公司简讯","slug":"公司简讯","link":"/tags/%E5%85%AC%E5%8F%B8%E7%AE%80%E8%AE%AF/"},{"name":"影评","slug":"影评","link":"/tags/%E5%BD%B1%E8%AF%84/"},{"name":"杂志文章","slug":"杂志文章","link":"/tags/%E6%9D%82%E5%BF%97%E6%96%87%E7%AB%A0/"},{"name":"Mailgun","slug":"Mailgun","link":"/tags/Mailgun/"}],"categories":[{"name":"运维笔记","slug":"运维笔记","link":"/categories/%E8%BF%90%E7%BB%B4%E7%AC%94%E8%AE%B0/"},{"name":"各种教程","slug":"各种教程","link":"/categories/%E5%90%84%E7%A7%8D%E6%95%99%E7%A8%8B/"},{"name":"基础操作","slug":"运维笔记/基础操作","link":"/categories/%E8%BF%90%E7%BB%B4%E7%AC%94%E8%AE%B0/%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"name":"服务部署","slug":"运维笔记/服务部署","link":"/categories/%E8%BF%90%E7%BB%B4%E7%AC%94%E8%AE%B0/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"},{"name":"缺陷修复","slug":"运维笔记/缺陷修复","link":"/categories/%E8%BF%90%E7%BB%B4%E7%AC%94%E8%AE%B0/%E7%BC%BA%E9%99%B7%E4%BF%AE%E5%A4%8D/"},{"name":"开发笔记","slug":"开发笔记","link":"/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"},{"name":"虚拟资产","slug":"虚拟资产","link":"/categories/%E8%99%9A%E6%8B%9F%E8%B5%84%E4%BA%A7/"},{"name":"数据库","slug":"开发笔记/数据库","link":"/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"CI&#x2F;CD","slug":"运维笔记/CI-CD","link":"/categories/%E8%BF%90%E7%BB%B4%E7%AC%94%E8%AE%B0/CI-CD/"},{"name":"问题解决","slug":"开发笔记/问题解决","link":"/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"},{"name":"备考","slug":"运维笔记/备考","link":"/categories/%E8%BF%90%E7%BB%B4%E7%AC%94%E8%AE%B0/%E5%A4%87%E8%80%83/"},{"name":"AI","slug":"AI","link":"/categories/AI/"},{"name":"Crawl4AI","slug":"AI/Crawl4AI","link":"/categories/AI/Crawl4AI/"},{"name":"日语学习","slug":"日语学习","link":"/categories/%E6%97%A5%E8%AF%AD%E5%AD%A6%E4%B9%A0/"},{"name":"影视笔记","slug":"日语学习/影视笔记","link":"/categories/%E6%97%A5%E8%AF%AD%E5%AD%A6%E4%B9%A0/%E5%BD%B1%E8%A7%86%E7%AC%94%E8%AE%B0/"},{"name":"前端","slug":"开发笔记/前端","link":"/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E5%89%8D%E7%AB%AF/"},{"name":"实操","slug":"运维笔记/实操","link":"/categories/%E8%BF%90%E7%BB%B4%E7%AC%94%E8%AE%B0/%E5%AE%9E%E6%93%8D/"},{"name":"知识点","slug":"日语学习/知识点","link":"/categories/%E6%97%A5%E8%AF%AD%E5%AD%A6%E4%B9%A0/%E7%9F%A5%E8%AF%86%E7%82%B9/"},{"name":"知识点","slug":"运维笔记/知识点","link":"/categories/%E8%BF%90%E7%BB%B4%E7%AC%94%E8%AE%B0/%E7%9F%A5%E8%AF%86%E7%82%B9/"},{"name":"项目管理","slug":"项目管理","link":"/categories/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"},{"name":"知识点","slug":"项目管理/知识点","link":"/categories/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/%E7%9F%A5%E8%AF%86%E7%82%B9/"},{"name":"n8n","slug":"AI/n8n","link":"/categories/AI/n8n/"},{"name":"后端","slug":"开发笔记/后端","link":"/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/%E5%90%8E%E7%AB%AF/"},{"name":"备考","slug":"项目管理/备考","link":"/categories/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/%E5%A4%87%E8%80%83/"},{"name":"翻译练习","slug":"日语学习/翻译练习","link":"/categories/%E6%97%A5%E8%AF%AD%E5%AD%A6%E4%B9%A0/%E7%BF%BB%E8%AF%91%E7%BB%83%E4%B9%A0/"},{"name":"DevOps","slug":"运维笔记/DevOps","link":"/categories/%E8%BF%90%E7%BB%B4%E7%AC%94%E8%AE%B0/DevOps/"}],"pages":[{"title":"","text":"404 Not Found 对不起，您所访问的页面不存在或者已删除。 Sorry, the page you are looking for doesn't exist or has been moved. ➡️ 为什么会发生这样的事情？ 该博客于 2023/01/26 和 2024/01/10 重构过 2 次，过程中将原本博文链接中 /yyyy/MM 形式的日期路径修改为了 /yyyy/MM/dd 形式，这导致了大部分外链失效。 老旧、错误和验证在最新情况下已经不起作用的博文被移除了。 2024/01/10 的归档操作修改了部分博文路径中的博文 ID。 🔧 我希望看到博文，我该怎么做？ 您可以使用右上角的 🔍 搜索 功能，输入关键词来检索相应的文章，它不会遗漏。 如果无法检索到对应信息，那么很抱歉文章就已经不存在了。 我保留着备份，如果您实在需要可以使用左侧的联系方式找到我，我会尽力帮您。","link":"/404.html"},{"title":"","text":"🧑‍💻 这里是兔子，本科软件工程。​🌟 拥有 2 年项目管理、5 年开发和 6 年运维经验，目前从事对日外包的项目管理工作。​📧 整理项目中，邮件和 Issue 积压太多也在努力处理…… 空闲之余我会进行 Steam 和第三方市场相关应用的开发，当然仅限空闲时间，因此你也会看到非常多的烂尾作品 🤦不过我会尽量留足文档，来记录我的思考和尝试，希望能帮到你。BTW 可以在这里找到我：🎮 Steam💬 Telegram🐱 GitHub 🌟 技术栈如下： Java, Spring, Spring Boot Python3, FastAPI, Django Vue2, React, TypeScript PostgreSQL, Oracle MongoDB, InfluxDB 🌟 最近的活跃状态： 🌟 证书：","link":"/about/index.html"}]}